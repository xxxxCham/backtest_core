#!/usr/bin/env python3
"""
Test CPU + GPU parall√®le
V√©rifie que BacktestEngine utilise le GPU et ProcessPoolExecutor utilise tous les CPU cores
"""

import sys
import time
from concurrent.futures import ProcessPoolExecutor

import numpy as np
import pandas as pd

from backtest.engine import BacktestEngine


def test_gpu_backend():
    """Test 1: V√©rifier que BacktestEngine utilise le GPU"""
    print("=" * 60)
    print("TEST 1: GPU Backend dans BacktestEngine")
    print("=" * 60)

    # Donn√©es de test
    dates = pd.date_range("2024-01-01", periods=1000, freq="1H")
    df = pd.DataFrame({
        "open": np.random.randn(1000).cumsum() + 100,
        "high": np.random.randn(1000).cumsum() + 102,
        "low": np.random.randn(1000).cumsum() + 98,
        "close": np.random.randn(1000).cumsum() + 100,
        "volume": np.random.randint(1000, 10000, 1000),
    }, index=dates)

    # Engine standard (use_gpu obsol√®te, supprim√© de l'API)
    print("\n1Ô∏è‚É£ BacktestEngine (GPU auto-d√©tect√©):")
    engine = BacktestEngine(initial_capital=10000)
    print(f"   Engine initialis√©: capital={engine.initial_capital}")

    # V√©rifier si CuPy est disponible pour GPU
    try:
        import cupy as cp
        gpu_available = True
        print(f"   CuPy disponible: {cp.__version__}")
        print(f"   GPUs d√©tect√©s: {cp.cuda.runtime.getDeviceCount()}")
    except ImportError:
        gpu_available = False
        print("   CuPy non install√© (mode CPU)")

    # Backtest rapide
    print("\n2Ô∏è‚É£ Backtest rapide (EMA cross):")
    start = time.time()
    result = engine.run(df, "ema_cross", {"fast_period": 10, "slow_period": 21})
    duration = time.time() - start

    print(f"   Dur√©e: {duration:.3f}s")
    print(f"   Trades: {result.metrics.get('total_trades', 0)}")
    print(f"   Sharpe: {result.metrics.get('sharpe_ratio', 0):.2f}")

    return gpu_available


def worker_backtest(params):
    """Worker function pour ProcessPoolExecutor"""
    fast, slow = params

    # Chaque processus initialise son propre backend
    dates = pd.date_range("2024-01-01", periods=500, freq="h")  # 'h' au lieu de '1H' (FutureWarning)
    df = pd.DataFrame({
        "open": np.random.randn(500).cumsum() + 100,
        "high": np.random.randn(500).cumsum() + 102,
        "low": np.random.randn(500).cumsum() + 98,
        "close": np.random.randn(500).cumsum() + 100,
        "volume": np.random.randint(1000, 10000, 500).astype(float),
    }, index=dates)

    engine = BacktestEngine(initial_capital=10000)  # use_gpu supprim√©
    result = engine.run(df, "ema_cross", {"fast_period": fast, "slow_period": slow})

    return {
        "params": f"fast={fast}, slow={slow}",
        "sharpe": result.metrics.get("sharpe_ratio", 0),
        "trades": len(result.trades),
        "device": "auto",  # backend.device_type supprim√©
    }


def test_multiprocessing():
    """Test 2: V√©rifier ProcessPoolExecutor multi-CPU"""
    print("\n" + "=" * 60)
    print("TEST 2: ProcessPoolExecutor multi-CPU")
    print("=" * 60)

    # Grille de param√®tres
    param_grid = [(fast, slow) for fast in range(5, 15, 2) for slow in range(20, 40, 5)]
    print(f"\nüìä Grille: {len(param_grid)} combinaisons")

    # Ex√©cution parall√®le
    print("\n1Ô∏è‚É£ Lancement ProcessPoolExecutor (8 workers):")
    start = time.time()

    with ProcessPoolExecutor(max_workers=8) as executor:
        results = list(executor.map(worker_backtest, param_grid))

    duration = time.time() - start

    print("\n2Ô∏è‚É£ R√©sultats:")
    print(f"   Dur√©e totale: {duration:.2f}s")
    print(f"   Dur√©e par run: {duration/len(param_grid):.3f}s")
    print(f"   Speedup th√©orique: ~{len(param_grid)/duration:.1f}x")

    # Afficher quelques r√©sultats
    print("\n3Ô∏è‚É£ Top 3 Sharpe:")
    sorted_results = sorted(results, key=lambda x: x["sharpe"], reverse=True)[:3]
    for i, res in enumerate(sorted_results, 1):
        print(f"   {i}. {res['params']}: Sharpe={res['sharpe']:.2f}, Trades={res['trades']}, Device={res['device']}")

    return duration


def main():
    """Ex√©cuter tous les tests"""
    print("üöÄ TEST CPU + GPU PARALL√àLE")
    print()

    try:
        # Test 1: GPU backend
        gpu_ok = test_gpu_backend()

        # Test 2: Multi-CPU
        duration = test_multiprocessing()

        # R√©sum√©
        print("\n" + "=" * 60)
        print("üìã R√âSUM√â")
        print("=" * 60)

        if gpu_ok:
            print("‚úÖ GPU backend activ√© et fonctionnel")
        else:
            print("‚ö†Ô∏è GPU backend non disponible (CPU fallback)")

        print("‚úÖ ProcessPoolExecutor multi-CPU fonctionnel")
        print(f"‚úÖ Performance: {duration:.2f}s pour 20 runs")

        print("\nüí° Architecture:")
        print("   - Chaque processus ‚Üí 1 CPU core")
        print("   - Chaque processus ‚Üí Acc√®s GPU (via CuPy)")
        print("   - Parall√©lisme r√©el: CPU + GPU simultan√©s")

        return True

    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
