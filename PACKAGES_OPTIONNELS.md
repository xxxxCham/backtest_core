# üîç Packages Optionnels et Optimisations

Guide des packages manquants qui pourraient am√©liorer les performances et r√©soudre certains probl√®mes.

---

## ‚ö†Ô∏è Packages Manquants D√©tect√©s

### üöÄ **Performance Critiques** (Recommand√©s)

#### 1. **Bottleneck** - Acc√©l√©ration Pandas

**Probl√®me r√©solu**: Ralentissements sur rolling/groupby avec gros datasets

```bash
pip install bottleneck
```

**Impact**:
- ‚úÖ Acc√©l√®re `rolling()`, `rank()`, `median()` de 5-20x
- ‚úÖ Utilis√© automatiquement par Pandas si pr√©sent
- ‚úÖ Particuli√®rement utile pour calculs Bollinger/EMA/ATR

**Utilisation**: Automatique une fois install√©

---

#### 2. **Numexpr** - √âvaluation Rapide d'Expressions

**Probl√®me r√©solu**: Calculs NumPy lents sur grandes matrices

```bash
pip install numexpr
```

**Impact**:
- ‚úÖ Acc√©l√®re expressions complexes de 2-10x
- ‚úÖ Utilise multi-threading automatique
- ‚úÖ R√©duit usage m√©moire sur gros arrays

**Exemple**:
```python
# Avant (NumPy standard): 100ms
result = (df['close'] - df['low']) / (df['high'] - df['low'])

# Apr√®s (avec numexpr): 15ms
# Pandas utilise automatiquement numexpr si install√©
```

---

### üìä **Analyse Statistique Avanc√©e** (Optionnel)

#### 3. **Statsmodels** - Mod√®les Statistiques

**Probl√®me r√©solu**: Calculs statistiques avanc√©s (autocorr√©lation, r√©gression)

```bash
pip install statsmodels
```

**Cas d'usage**:
- Analyse autocorr√©lation des r√©sidus de strat√©gie
- Tests de stationnarit√© (ADF test)
- R√©gression pour analyse factorielle
- ARIMA/GARCH pour pr√©dictions

**Utilisation**:
```python
from statsmodels.tsa.stattools import adfuller

# Test si une s√©rie est stationnaire
result = adfuller(equity_curve)
print(f"P-value: {result[1]}")  # < 0.05 = stationnaire
```

---

#### 4. **Scikit-learn** - Machine Learning

**Probl√®me r√©solu**: Validation crois√©e avanc√©e, clustering de strat√©gies

```bash
pip install scikit-learn
```

**Cas d'usage**:
- Walk-forward validation robuste
- Clustering de patterns de march√©
- Feature engineering pour strat√©gies ML
- Cross-validation time-series

**Utilisation**:
```python
from sklearn.model_selection import TimeSeriesSplit

# Walk-forward validation propre
tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(data):
    train, test = data.iloc[train_idx], data.iloc[test_idx]
    # Backtest sur train, valider sur test
```

---

### ‚ö° **Compilation & Performance Extr√™me** (Expert)

#### 5. **Cython** - Compilation C

**Probl√®me r√©solu**: Boucles Python tr√®s lentes

```bash
pip install cython
```

**Impact**:
- ‚úÖ Compile Python en C pour vitesse native
- ‚úÖ Utile pour indicateurs custom complexes
- ‚úÖ Peut donner 10-100x speedup sur boucles

**Quand l'utiliser**:
- Indicateurs custom avec boucles imbriqu√©es
- Calculs de g√©om√©trie de march√© complexes
- Simulations Monte Carlo intensives

---

## üîß Probl√®mes Connus et Solutions

### ‚ùå **Probl√®me 1: Calculs Incorrects sur Petits Datasets**

**Sympt√¥me**: Sharpe Ratio NaN ou infini sur < 30 trades

**Cause**: Division par z√©ro ou variance nulle

**Solution**:
```python
# Dans metrics_tier_s.py, ajouter validation
if len(returns) < 30:
    logger.warning("Moins de 30 trades, Sharpe Ratio peut √™tre impr√©cis")
    return 0.0

std = returns.std()
if std < 1e-10:  # Variance quasi-nulle
    return 0.0
```

---

### ‚ùå **Probl√®me 2: Overflow/Underflow dans Calculs**

**Sympt√¥me**: `RuntimeWarning: overflow encountered in multiply`

**Cause**: Valeurs trop grandes (leverage √©lev√©, prix crypto)

**Solution**:
```python
# Activer gestion des erreurs NumPy
import numpy as np
np.seterr(all='warn')  # Afficher warnings
np.seterr(over='raise')  # Lever exception sur overflow

# Ou utiliser float64 explicitement
df['close'] = df['close'].astype(np.float64)
```

---

### ‚ùå **Probl√®me 3: Ralentissements sur Grid Search**

**Sympt√¥me**: Grid search > 1h pour 10k combinaisons

**Solutions prioritaires**:

1. **Installer bottleneck + numexpr** (gain imm√©diat)
   ```bash
   pip install bottleneck numexpr
   ```

2. **Utiliser Numba sur calculs critiques**
   ```python
   from numba import jit

   @jit(nopython=True, cache=True)
   def calculate_signals_fast(close, upper, lower):
       # Code vectoris√© pur NumPy
       return signals
   ```

3. **Activer cache Numba**
   ```bash
   # Windows
   set NUMBA_CACHE_DIR=d:\backtest_core\.numba_cache

   # Linux/macOS
   export NUMBA_CACHE_DIR=/path/to/backtest_core/.numba_cache
   ```

---

### ‚ùå **Probl√®me 4: Pr√©cision D√©cimale sur Prix Crypto**

**Sympt√¥me**: Erreurs d'arrondi sur tokens √† faible prix (0.0001 USDT)

**Solution**:
```python
from decimal import Decimal, getcontext

# Pr√©cision 28 d√©cimales
getcontext().prec = 28

# Utiliser Decimal pour calculs critiques
entry_price = Decimal(str(price))
quantity = capital / entry_price
```

---

### ‚ùå **Probl√®me 5: M√©moire Satur√©e sur Gros Datasets**

**Sympt√¥me**: `MemoryError` sur datasets > 1M lignes

**Solutions**:

1. **Utiliser Pandas chunking**
   ```python
   chunk_size = 100000
   for chunk in pd.read_csv('huge_data.csv', chunksize=chunk_size):
       result = backtest(chunk)
   ```

2. **Downcast dtypes**
   ```python
   df['close'] = df['close'].astype(np.float32)  # 32-bit au lieu de 64
   df['volume'] = pd.to_numeric(df['volume'], downcast='unsigned')
   ```

3. **Utiliser Parquet au lieu de CSV**
   ```python
   # Parquet = 5-10x moins d'espace + plus rapide
   df.to_parquet('data.parquet', compression='snappy')
   df = pd.read_parquet('data.parquet')
   ```

---

## üì¶ Installation Compl√®te Recommand√©e

### Pour Usage Standard

```bash
pip install bottleneck numexpr
```

### Pour Analyse Avanc√©e

```bash
pip install bottleneck numexpr statsmodels scikit-learn
```

### Pour Performance Extr√™me

```bash
pip install bottleneck numexpr statsmodels scikit-learn cython
```

---

## ‚úÖ Script de V√©rification Complet

Cr√©ez `check_performance.py`:

```python
#!/usr/bin/env python3
"""V√©rifie packages de performance install√©s."""

packages_performance = {
    'bottleneck': 'Acc√©l√©ration Pandas rolling/groupby',
    'numexpr': '√âvaluation rapide expressions NumPy',
    'statsmodels': 'Mod√®les statistiques avanc√©s',
    'sklearn': 'Machine learning / validation crois√©e',
    'cython': 'Compilation C pour boucles critiques',
}

print("=" * 60)
print("PACKAGES DE PERFORMANCE")
print("=" * 60)

missing = []
for pkg, desc in packages_performance.items():
    try:
        __import__(pkg)
        print(f"‚úÖ {pkg:15s} - {desc}")
    except ImportError:
        print(f"‚ùå {pkg:15s} - {desc}")
        missing.append(pkg)

if missing:
    print(f"\n‚ö†Ô∏è  {len(missing)} package(s) manquant(s)")
    print(f"Installation: pip install {' '.join(missing)}")
else:
    print("\n‚úÖ Tous les packages de performance install√©s!")
```

---

## üéØ Recommandations par Priorit√©

### üî¥ **PRIORIT√â 1 - √Ä Installer MAINTENANT**
- ‚úÖ `bottleneck` - Gain imm√©diat 5-20x sur rolling
- ‚úÖ `numexpr` - Gain 2-10x sur calculs complexes

**Installation**:
```bash
pip install bottleneck numexpr
```

### üü° **PRIORIT√â 2 - Si Probl√®mes d'Analyse**
- `statsmodels` - Tests statistiques robustes
- `scikit-learn` - Walk-forward validation propre

### üü¢ **PRIORIT√â 3 - Optimisation Avanc√©e**
- `cython` - Compilation custom code
- `cupy` - GPU acceleration (si NVIDIA GPU)

---

## üîç Diagnostic Rapide

```bash
# Test si packages critiques manquent
python -c "import bottleneck; print('‚úÖ Bottleneck OK')" 2>&1 || echo "‚ùå Installer: pip install bottleneck"
python -c "import numexpr; print('‚úÖ Numexpr OK')" 2>&1 || echo "‚ùå Installer: pip install numexpr"
```

---

**Derni√®re mise √† jour**: 2025-01-XX
