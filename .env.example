# Backtest Core - Configuration Environnement
# =============================================
# Copiez ce fichier en .env et ajustez les valeurs selon vos besoins

# === OPTIMISATION GPU DU LLM ===
# Décharge automatiquement le LLM du GPU pendant les calculs de backtest
# pour libérer la VRAM et améliorer les performances des calculs NumPy/CuPy.
#
# Valeurs acceptées: True, False, 1, 0, yes, no (case insensitive)
# Défaut: False (compatibilité CPU-only)
#
# Recommandé: True si vous utilisez un GPU et CuPy pour les indicateurs
UNLOAD_LLM_DURING_BACKTEST=False

# === CONFIGURATION OLLAMA (optionnel) ===
# URL du serveur Ollama si différent du défaut
# OLLAMA_HOST=http://localhost:11434

# === CONFIGURATION OPENAI (optionnel) ===
# Clé API OpenAI pour utiliser GPT-4o-mini ou autres modèles
# OPENAI_API_KEY=sk-...

# === LOGS ET OBSERVABILITÉ ===
# Niveau de logging (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO

# Activer les logs détaillés pour le débogage
# DEBUG=False
