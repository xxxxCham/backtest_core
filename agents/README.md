# Agents Module - Intelligence LLM

> **SystÃ¨me d'optimisation autonome par agents LLM**  
> Version : 1.8.1 | Phase 3 | Date : 13/12/2025

---

## ðŸ¤– Vue d'Ensemble

Le module `agents/` implÃ©mente un systÃ¨me d'optimisation autonome basÃ© sur des agents LLM (Large Language Models). Il permet d'optimiser automatiquement les paramÃ¨tres de stratÃ©gies de trading en utilisant l'intelligence artificielle.

**Deux modes de fonctionnement :**
1. **Mode Autonome (RECOMMANDE)** : L'agent lance des backtests et itere
2. **Mode Orchestre** : Orchestrator multi-agents; backtests uniquement si un callback `on_backtest_needed` est fourni

---

## ðŸ“ Structure

```
agents/
â”œâ”€â”€ base_agent.py              â†’ Classe abstraite pour tous les agents
â”œâ”€â”€ analyst.py                 â†’ Agent Analyst (analyse quantitative)
â”œâ”€â”€ strategist.py              â†’ Agent Strategist (propositions crÃ©atives)
â”œâ”€â”€ critic.py                  â†’ Agent Critic (dÃ©tection overfitting)
â”œâ”€â”€ validator.py               â†’ Agent Validator (dÃ©cision finale)
â”œâ”€â”€ orchestrator.py            â†’ Orchestrateur workflow multi-agents
â”œâ”€â”€ orchestration_logger.py    â†’ Logging structure (JSONL) pour l'orchestration
â”œâ”€â”€ autonomous_strategist.py   â†’ Agent autonome avec backtests rÃ©els
â”œâ”€â”€ backtest_executor.py       â†’ Interface d'exÃ©cution backtests
â”œâ”€â”€ integration.py             â†’ Pont vers BacktestEngine
â”œâ”€â”€ state_machine.py           â†’ Machine Ã  Ã©tats du workflow
â”œâ”€â”€ llm_client.py              â†’ Client LLM unifiÃ© (Ollama/OpenAI)
â”œâ”€â”€ model_config.py            â†’ Configuration multi-modÃ¨les par rÃ´le
â”œâ”€â”€ ollama_manager.py          â†’ Gestion GPU/VRAM pour LLM
â””â”€â”€ __init__.py                â†’ Exports publics
```

---

## ðŸŽ¯ Architecture - Mode Autonome

### Workflow ItÃ©ratif

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BASELINE  â”‚ â† Backtest initial avec paramÃ¨tres par dÃ©faut
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ANALYZE   â”‚ â† Analyst : Analyse quantitative des rÃ©sultats
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PROPOSE   â”‚ â† Strategist : Propose nouveaux paramÃ¨tres
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKTEST   â”‚ â† ExÃ©cution backtest avec nouveaux params
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EVALUATE   â”‚ â† Critic : Ã‰value overfitting et risques
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ACCEPT ?   â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”œâ”€â”€â”€ OUI â†’ STOP (meilleurs params trouvÃ©s)
         â””â”€â”€â”€ NON â†’ Retour Ã  ANALYZE (itÃ©ration suivante)
```

### Composants ClÃ©s

1. **AutonomousStrategist** : Agent principal
   - Lance des backtests rÃ©els via `BacktestExecutor`
   - Boucle d'itÃ©ration jusqu'Ã  convergence
   - Tracking de l'historique des expÃ©riences

2. **BacktestExecutor** : Interface d'exÃ©cution
   - Abstraction pour lancer des backtests
   - Support walk-forward validation
   - Gestion des erreurs et timeout

3. **Integration Layer** : Pont vers BacktestEngine
   - `run_backtest_for_agent()` : Lance un backtest
   - `create_optimizer_from_engine()` : CrÃ©e optimiseur complet
   - `quick_optimize()` : Raccourci rapide

---

## ðŸš€ Guide d'Utilisation

### 1. Mode Autonome (RecommandÃ©)

**Exemple complet avec intÃ©gration BacktestEngine :**

```python
from agents import create_optimizer_from_engine, quick_optimize
from agents.llm_client import LLMConfig, LLMProvider

# MÃ©thode 1: ContrÃ´le complet
config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
strategist, executor = create_optimizer_from_engine(
    llm_config=config,
    strategy_name="ema_cross",  # StratÃ©gie du registre
    data=ohlcv_df,              # DataFrame OHLCV
    use_walk_forward=True,      # Activer validation anti-overfitting
)

session = strategist.optimize(
    executor=executor,
    initial_params={"fast_period": 10, "slow_period": 21},
    param_bounds={"fast_period": (5, 20), "slow_period": (15, 50)},
    max_iterations=10,
)

# RÃ©sultats
print(f"Meilleur Sharpe: {session.best_result.sharpe_ratio:.2f}")
print(f"Params: {session.best_result.request.parameters}")
print(f"Final status: {session.final_status} after {session.current_iteration} iterations")

# MÃ©thode 2: Raccourci rapide
session = quick_optimize(
    config=config,
    strategy_name="ema_cross",
    data=df,
    max_iterations=10,
)
```

**ParamÃ¨tres ClÃ©s :**
- `initial_params` : Point de dÃ©part (dÃ©faut: stratÃ©gie par dÃ©faut)
- `param_bounds` : Bornes d'exploration (ex: `{"fast": (5, 50)}`)
- `max_iterations` : Limite itÃ©rations (dÃ©faut: 10)
- `target_metric` : MÃ©trique Ã  maximiser (dÃ©faut: `sharpe_ratio`)
- `use_walk_forward` : Validation robuste (dÃ©faut: `True`)

---

### 2. Mode Orchestre (Analyse Multi-Agents)

**Analyse multi-agents (backtests si callback fourni) :**

```python
from agents import create_orchestrator_with_backtest
from agents.llm_client import LLMConfig, LLMProvider

config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
orchestrator = create_orchestrator_with_backtest(
    strategy_name="ema_cross",
    data=ohlcv_df,
    initial_params={"fast_period": 12, "slow_period": 26},
    llm_config=config,
)

result = orchestrator.run()

# Resultat
print(result.decision)      # APPROVE / REJECT / ABORT
print(result.final_params)  # meilleurs parametres retenus
print(result.final_report)  # rapport complet
```

---

### 3. Configuration LLM

**Variables d'environnement :**

```bash
# Ollama (local, gratuit)
export BACKTEST_LLM_PROVIDER=ollama
export BACKTEST_LLM_MODEL=llama3.2
export OLLAMA_HOST=http://localhost:11434

# OpenAI (cloud, payant)
export BACKTEST_LLM_PROVIDER=openai
export BACKTEST_LLM_MODEL=gpt-4
export OPENAI_API_KEY=sk-...
```

**Configuration Python :**

```python
from agents.llm_client import LLMConfig, LLMProvider

# Ollama
config_ollama = LLMConfig(
    provider=LLMProvider.OLLAMA,
    model="deepseek-r1:8b",
    host="http://localhost:11434",
    temperature=0.7,
)

# OpenAI
config_openai = LLMConfig(
    provider=LLMProvider.OPENAI,
    model="gpt-4",
    api_key="sk-...",
    temperature=0.5,
)
```

---

### 4. Configuration Multi-ModÃ¨les par RÃ´le

**Attribuer des modÃ¨les diffÃ©rents par agent :**

```python
from agents.model_config import RoleModelConfig, ModelCategory, set_global_model_config

# Configuration personnalisÃ©e
config = RoleModelConfig(
    analyst="deepseek-r1:32b",      # ModÃ¨le fort pour analyse
    strategist="llama3.2",          # ModÃ¨le crÃ©atif
    critic="mistral",               # ModÃ¨le sceptique
    validator="qwen2.5:32b",        # ModÃ¨le dÃ©cisionnel
)

set_global_model_config(config)

# Note: si plusieurs modeles sont listes pour un role, la selection est aleatoire par defaut.
```

**ModÃ¨les connus et catÃ©gories :**

| ModÃ¨le | CatÃ©gorie | Taille | Recommandation |
|--------|-----------|--------|----------------|
| `deepseek-r1:32b` | Premier | 32B | **Analyse**, Validation |
| `qwen2.5:32b` | Premier | 32B | Validation, Critique |
| `llama3.2` | Standard | 8B | Strategist, usage gÃ©nÃ©ral |
| `mistral` | Standard | 7B | Critic, analyse risques |
| `phi3` | Rapide | 3B | Tests, prototypage |

---

### 5. Gestion GPU/VRAM

**DÃ©charger le LLM pendant les backtests (libÃ©rer VRAM) :**

```python
from agents import create_autonomous_optimizer, gpu_compute_context

# MÃ©thode 1: Variable d'env (global)
# export UNLOAD_LLM_DURING_BACKTEST=True

# MÃ©thode 2: ParamÃ¨tre Python
strategist = AutonomousStrategist(
    llm_client=client,
    unload_llm_during_backtest=True,  # DÃ©charge LLM avant backtest
)

# MÃ©thode 3: Context manager pour calculs manuels
with gpu_compute_context("deepseek-r1:32b"):
    # GPU libre pour calculs NumPy/CuPy
    result = heavy_gpu_computation()
# LLM rechargÃ© automatiquement
```

**Impact :**

| Mode | VRAM LLM | VRAM Backtest | Latence |
|------|----------|---------------|---------|
| `unload=False` | PartagÃ© | PartagÃ© | 0s |
| `unload=True` | 0 GB | 100% libre | +2-5s |

---

## ðŸ§  Les 4 Agents SpÃ©cialisÃ©s

### 1. Analyst Agent ðŸ“Š

**RÃ´le :** Analyse quantitative des performances

**Analyse :**
- MÃ©triques Tier S (Sharpe, Sortino, Calmar)
- Drawdown et volatilitÃ©
- Distribution des trades
- CorrÃ©lations temporelles

**Output :**
```json
{
  "summary": "Performance correcte mais volatilitÃ© Ã©levÃ©e...",
  "strengths": ["Sharpe > 1.5", "Win rate 58%"],
  "weaknesses": ["Max drawdown 12%", "Peu de trades"],
  "key_observations": ["SensibilitÃ© Ã  fast_period..."]
}
```

---

### 2. Strategist Agent ðŸŽ¯

**RÃ´le :** Propositions crÃ©atives d'optimisation

**Propose :**
- Ajustements de paramÃ¨tres ciblÃ©s
- Justifications quantitatives
- Risques anticipÃ©s

**Output :**
```json
{
  "proposals": [
    {
      "name": "RÃ©duire fast_period",
      "params": {"fast_period": 8, "slow_period": 21},
      "rationale": "Augmente rÃ©activitÃ© aux retournements",
      "expected_impact": "Sharpe +0.2, trades +15%"
    }
  ]
}
```

---

### 3. Critic Agent ðŸ›¡ï¸

**RÃ´le :** DÃ©tection overfitting et risques

**Ã‰value :**
- Ratio train/test
- StabilitÃ© paramÃ¨tres
- Sur-optimisation
- Robustesse

**Output :**
```json
{
  "concerns": [
    {
      "type": "overfitting",
      "severity": "medium",
      "evidence": "Train Sharpe 2.1 vs Test Sharpe 0.9"
    }
  ],
  "evaluations": [
    {
      "proposal": "RÃ©duire fast_period",
      "overfitting_score": 25,  # 0-100 (plus bas = mieux)
      "robustness_score": 85
    }
  ]
}
```

---

### 4. Validator Agent âœ…

**RÃ´le :** DÃ©cision finale APPROVE/REJECT/ITERATE

**CritÃ¨res :**
- âœ… Sharpe > objectif
- âœ… Drawdown < limite
- âœ… Pas d'overfitting sÃ©vÃ¨re
- âœ… AmÃ©lioration vs baseline

**Output :**
```json
{
  "decision": "APPROVE",
  "recommendation": "Adopter Proposal 2",
  "rationale": "Sharpe 1.8, drawdown 5%, robuste sur walk-forward"
}
```

---

## ðŸ“Š Suivi de Session

### OptimizationSession

Objet retournÃ© contenant :

```python
session = strategist.optimize(...)

# RÃ©sultats finaux
session.best_result           # BacktestResult (mÃ©triques, trades)
session.all_results           # Liste des BacktestResult (baseline incluse)
session.decisions             # Liste des IterationDecision du LLM

# Historique
session.current_iteration     # Iteration actuelle
session.start_time            # Date de debut de session

# Statut final
session.final_status          # "success" | "max_iterations" | "timeout" | "no_improvement"
session.final_reasoning       # Raison finale

# MÃ©triques
session.best_result.sharpe_ratio
session.best_result.max_drawdown
session.best_result.total_trades
```

---

## ðŸŽ“ Cas d'Usage AvancÃ©s

### Cas 1 : Optimisation Multi-StratÃ©gie

```python
strategies = ["ema_cross", "bollinger_atr", "macd_cross"]

for strategy_name in strategies:
    session = quick_optimize(config, strategy_name, df)
    print(f"{strategy_name}: Sharpe {session.best_result.sharpe_ratio:.2f}")
```

---

### Cas 2 : Walk-Forward avec Validation Stricte

```python
strategist, executor = create_optimizer_from_engine(
    llm_config=config,
    strategy_name="ema_cross",
    data=df,
    use_walk_forward=True,      # Active WF (n_windows=6, train_ratio=0.75)
)

session = strategist.optimize(executor, max_iterations=15)
```

---

### Cas 3 : Analyse de SensibilitÃ©

```python
history = executor.history

# Sensibilite d'un parametre
sensitivity = history.analyze_parameter_sensitivity()
fast_stats = sensitivity.get("fast_period")
if fast_stats:
    print(f"fast_period corr: {fast_stats['correlation']:.2f}")

# Meilleurs runs
top_5 = sorted(
    [exp for exp in history.experiments if exp.success],
    key=lambda exp: exp.sharpe_ratio,
    reverse=True,
)[:5]
for exp in top_5:
    print(f"Sharpe {exp.sharpe_ratio:.2f} | Params: {exp.request.parameters}")
```

---

## ðŸ”§ Configuration AvancÃ©e

### ParamÃ¨tres AutonomousStrategist

```python
strategist = AutonomousStrategist(
    llm_client=client,
    unload_llm_during_backtest=True,  # DÃ©charger LLM
    verbose=True,                     # Logs dÃ©taillÃ©s
    on_progress=lambda i, p: print(f"Iteration {i}: {p}"),
)
```

### ParamÃ¨tres BacktestExecutor

```python
executor = BacktestExecutor(
    backtest_fn=my_backtest_function,
    strategy_name="ema_cross",
    data=df,
    validation_fn=my_walk_forward_fn,  # optionnel: doit retourner train_sharpe/test_sharpe/overfitting_ratio
)
```

---

## ðŸ› Troubleshooting

### Erreur : "Ollama not available"
```bash
# VÃ©rifier Ollama
curl http://localhost:11434/api/version

# DÃ©marrer Ollama
ollama serve
```

### Erreur : "GPU Out of Memory"
```python
# Activer dÃ©chargement LLM
export UNLOAD_LLM_DURING_BACKTEST=True
```

### Convergence lente
```python
# RÃ©duire complexitÃ©
session = strategist.optimize(
    executor,
    max_iterations=5,              # Moins d'itÃ©rations
    param_bounds={"fast": (8, 12)},  # Espace restreint
)
```

### LLM rÃ©pond mal
```python
# Changer tempÃ©rature
config = LLMConfig(
    provider=LLMProvider.OLLAMA,
    model="llama3.2",
    temperature=0.3,  # Plus dÃ©terministe (dÃ©faut: 0.7)
)
```

---

## ðŸ“š RÃ©fÃ©rences

- [Phase 3 LLM Integration](../.github/ROADMAP.md#phase-3---intelligence-llm)
- [Ollama Documentation](https://ollama.ai/docs)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [GPU Memory Management](../docs/UNLOAD_LLM_FEATURE.md)

---

*DerniÃ¨re mise Ã  jour : 13/12/2025 | Version : 1.8.1 | Phase 3*
