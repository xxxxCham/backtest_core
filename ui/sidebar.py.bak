"""
Module-ID: ui.sidebar

Purpose: G√®re la configuration et les contr√¥les de la sidebar pour la s√©lection de strat√©gies et param√®tres.

Role in pipeline: configuration / inputs

Key components: render_sidebar, gestion des param√®tres

Inputs: Donn√©es disponibles, strat√©gies

Outputs: SidebarState configur√©

Dependencies: ui.context, ui.constants

Conventions: Param√®tres valid√©s selon contraintes

Read-if: Configuration de l'interface utilisateur

Skip-if: Logique backend pure
"""

from __future__ import annotations

import json
import os
import re
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

from ui.constants import (
    MODE_BUTTON_CSS,
    MODE_OPTIONS,
    PARAM_CONSTRAINTS,
    build_strategy_options,
    get_strategy_description,
    get_strategy_ui_indicators,
)
from ui.context import (
    KNOWN_MODELS,
    LLM_AVAILABLE,
    LLM_IMPORT_ERROR,
    RECOMMENDED_FOR_STRATEGY,
    LLMConfig,
    LLMProvider,
    ModelCategory,
    compute_search_space_stats,
    discover_available_data,
    ensure_ollama_running,
    get_available_models_for_ui,
    get_data_date_range,
    get_global_model_config,
    get_model_info,
    get_storage,
    get_strategy,
    get_strategy_info,
    is_ollama_available,
    list_available_models,
    list_strategies,
    list_strategy_versions,
    load_strategy_version,
    resolve_latest_version,
    set_global_model_config,
)
from ui.helpers import (
    _data_cache_key,
    _find_saved_run_meta,
    _parse_run_timestamp,
    apply_versioned_preset,
    create_param_range_selector,
    load_selected_data,
    render_saved_runs_panel,
    validate_param,
)
from ui.state import SidebarState
from utils.observability import is_debug_enabled, set_log_level


def _is_valid_timeframe_format(tf: str) -> bool:
    """Valide qu'un timeframe est dans un format correct."""
    if not tf or len(tf) < 2:
        return False
    unit = tf[-1]
    if unit not in ('m', 'h', 'd', 'w', 'M'):
        return False
    try:
        amount = int(tf[:-1])
        return amount > 0
    except ValueError:
        return False


def _normalize_signature_value(value: Any) -> Any:
    if isinstance(value, dict):
        return {str(k): _normalize_signature_value(v) for k, v in value.items()}
    if isinstance(value, (list, tuple)):
        return [_normalize_signature_value(v) for v in value]
    if isinstance(value, (set, frozenset)):
        return sorted(_normalize_signature_value(v) for v in value)
    if hasattr(value, "tolist"):
        try:
            return value.tolist()
        except Exception:
            pass
    if hasattr(value, "item"):
        try:
            return value.item()
        except Exception:
            pass
    if isinstance(value, (str, int, float, bool)) or value is None:
        return value
    return str(value)


def _get_padded_date_range(
    start_ts: Optional[pd.Timestamp],
    end_ts: Optional[pd.Timestamp],
    pad_days: int = 1,
) -> Tuple[Optional[object], Optional[object]]:
    if start_ts is None or end_ts is None:
        return None, None
    start_date = start_ts.date()
    end_date = end_ts.date()
    if pad_days <= 0:
        return start_date, end_date
    padded_start = (start_ts + pd.Timedelta(days=pad_days)).date()
    padded_end = (end_ts - pd.Timedelta(days=pad_days)).date()
    if padded_start < padded_end:
        return padded_start, padded_end
    return start_date, end_date


def _extract_llm_signature(llm_config: Optional[LLMConfig]) -> Optional[Dict[str, Any]]:
    if llm_config is None:
        return None
    provider = getattr(llm_config.provider, "value", str(llm_config.provider))
    return {
        "provider": provider,
        "model": getattr(llm_config, "model", None),
        "ollama_host": getattr(llm_config, "ollama_host", None),
        "openai_base_url": getattr(llm_config, "openai_base_url", None),
        "openai_key_set": bool(getattr(llm_config, "openai_api_key", None)),
        "temperature": getattr(llm_config, "temperature", None),
        "max_tokens": getattr(llm_config, "max_tokens", None),
        "top_p": getattr(llm_config, "top_p", None),
        "timeout_seconds": getattr(llm_config, "timeout_seconds", None),
        "max_retries": getattr(llm_config, "max_retries", None),
        "retry_delay_seconds": getattr(llm_config, "retry_delay_seconds", None),
    }


def _extract_role_model_signature(role_model_config: Any) -> Optional[Dict[str, Any]]:
    if role_model_config is None:
        return None

    def _role_payload(role: Any) -> Dict[str, Any]:
        return {
            "models": list(getattr(role, "models", []) or []),
            "allow_heavy_after_iteration": getattr(role, "allow_heavy_after_iteration", None),
        }

    return {
        "analyst": _role_payload(getattr(role_model_config, "analyst", None)),
        "strategist": _role_payload(getattr(role_model_config, "strategist", None)),
        "critic": _role_payload(getattr(role_model_config, "critic", None)),
        "validator": _role_payload(getattr(role_model_config, "validator", None)),
    }


def _build_config_signature(state: SidebarState) -> str:
    """Construit une signature stable de la configuration appliqu√©e."""
    payload = {
        "debug_enabled": state.debug_enabled,
        "symbol": state.symbol,
        "timeframe": state.timeframe,
        "use_date_filter": state.use_date_filter,
        "start_date": state.start_date,
        "end_date": state.end_date,
        "symbols": sorted(state.symbols or []),
        "timeframes": sorted(state.timeframes or []),
        "strategy_key": state.strategy_key,
        "strategy_keys": sorted(state.strategy_keys or []),
        "params": state.params,
        "param_ranges": state.param_ranges,
        "all_params": state.all_params,
        "all_param_ranges": state.all_param_ranges,
        "active_indicators": sorted(state.active_indicators or []),
        "optimization_mode": state.optimization_mode,
        "max_combos": state.max_combos,
        "n_workers": state.n_workers,
        "use_optuna": state.use_optuna,
        "optuna_n_trials": state.optuna_n_trials,
        "optuna_sampler": state.optuna_sampler,
        "optuna_pruning": state.optuna_pruning,
        "optuna_metric": state.optuna_metric,
        "optuna_early_stop": state.optuna_early_stop,
        "llm": _extract_llm_signature(state.llm_config),
        "llm_model": state.llm_model,
        "llm_use_multi_agent": state.llm_use_multi_agent,
        "role_model_config": _extract_role_model_signature(state.role_model_config),
        "llm_max_iterations": state.llm_max_iterations,
        "llm_use_walk_forward": state.llm_use_walk_forward,
        "llm_unload_during_backtest": state.llm_unload_during_backtest,
        "llm_compare_enabled": state.llm_compare_enabled,
        "llm_compare_auto_run": state.llm_compare_auto_run,
        "llm_compare_strategies": sorted(state.llm_compare_strategies or []),
        "llm_compare_tokens": sorted(state.llm_compare_tokens or []),
        "llm_compare_timeframes": sorted(state.llm_compare_timeframes or []),
        "llm_compare_metric": state.llm_compare_metric,
        "llm_compare_aggregate": state.llm_compare_aggregate,
        "llm_compare_max_runs": state.llm_compare_max_runs,
        "llm_compare_use_preset": state.llm_compare_use_preset,
        "llm_compare_generate_report": state.llm_compare_generate_report,
        "initial_capital": state.initial_capital,
        "leverage": state.leverage,
        "leverage_enabled": state.leverage_enabled,
        "disabled_params": sorted(state.disabled_params or []),
    }

    normalized = _normalize_signature_value(payload)
    return json.dumps(normalized, sort_keys=True, default=str)


def _env_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except (TypeError, ValueError):
        return default


def _env_bool(key: str, default: bool) -> bool:
    value = os.getenv(key)
    if value is None:
        return default
    return value.strip().lower() in ("1", "true", "yes", "y", "on")


def _apply_config_guard(draft_state: SidebarState) -> SidebarState:
    draft_signature = _build_config_signature(draft_state)
    applied_signature = st.session_state.get("applied_config_signature")
    applied_state = st.session_state.get("applied_sidebar_state")

    if applied_signature is None or applied_state is None:
        st.session_state["applied_config_signature"] = draft_signature
        st.session_state["applied_sidebar_state"] = draft_state
        applied_state = draft_state
        pending = False
    else:
        pending = draft_signature != applied_signature

    st.session_state["config_pending_changes"] = pending
    st.session_state["draft_config_signature"] = draft_signature

    return applied_state


def render_sidebar() -> SidebarState:
    st.sidebar.header("‚öôÔ∏è Configuration")

    with st.sidebar.expander("üîß Debug", expanded=False):
        debug_enabled = st.checkbox(
            "Mode DEBUG",
            value=is_debug_enabled(),
            key="debug_toggle",
        )
        if debug_enabled:
            set_log_level("DEBUG")
            st.caption("üü¢ Logs d√©taill√©s activ√©s")
        else:
            set_log_level("INFO")

    st.sidebar.subheader("üìä Donn√©es")

    data_status = st.sidebar.empty()
    try:
        available_tokens, available_timeframes = discover_available_data()
        if not available_tokens:
            available_tokens = ["BTCUSDC", "ETHUSDC"]
            data_status.warning("Aucune donn√©e trouv√©e, utilisation des d√©fauts")
        else:
            data_status.success(f"‚úÖ {len(available_tokens)} symboles disponibles")

        if not available_timeframes:
            available_timeframes = ["1h", "4h", "1d"]

        # Nettoyer les valeurs de session invalides (bug fix 23/01/2026)
        if "symbol_select" in st.session_state:
            if st.session_state["symbol_select"] not in available_tokens:
                del st.session_state["symbol_select"]

        if "timeframe_select" in st.session_state:
            if not _is_valid_timeframe_format(st.session_state["timeframe_select"]) or \
               st.session_state["timeframe_select"] not in available_timeframes:
                del st.session_state["timeframe_select"]

    except Exception as exc:
        available_tokens = ["BTCUSDC", "ETHUSDC"]
        available_timeframes = ["1h", "4h", "1d"]
        data_status.error(f"Erreur scan: {exc}")

    pending_meta = None
    pending_run_id = st.session_state.get("pending_run_load_id")
    if pending_run_id:
        try:
            storage = get_storage()
            pending_meta = _find_saved_run_meta(storage, pending_run_id)
        except Exception as exc:
            st.session_state["saved_runs_status"] = f"Pending load failed: {exc}"
            pending_meta = None

    if pending_meta is not None:
        # Valider que symbol et timeframe sont valides avant de les ajouter
        if pending_meta.symbol and pending_meta.symbol not in available_tokens:
            # V√©rifier que le symbol est valide (lettres et chiffres seulement)
            if pending_meta.symbol.replace("_", "").replace("-", "").isalnum():
                available_tokens = [pending_meta.symbol] + available_tokens

        if pending_meta.timeframe and pending_meta.timeframe not in available_timeframes:
            # Valider format timeframe (ex: 1m, 5m, 1h, 4h, 1d)
            if _is_valid_timeframe_format(pending_meta.timeframe):
                available_timeframes = [pending_meta.timeframe] + available_timeframes

        if pending_meta.symbol:
            st.session_state["symbol_select"] = pending_meta.symbol
        if pending_meta.timeframe:
            st.session_state["timeframe_select"] = pending_meta.timeframe
        # Activer le filtre de dates seulement si des dates sp√©cifiques sont d√©finies
        start_ts = _parse_run_timestamp(pending_meta.period_start)
        end_ts = _parse_run_timestamp(pending_meta.period_end)
        if start_ts is not None and end_ts is not None:
            st.session_state["use_date_filter"] = True
            # Initialiser seulement si pas d√©j√† d√©fini (√©vite conflit avec widget)
            if "start_date" not in st.session_state:
                st.session_state["start_date"] = start_ts.date()
            if "end_date" not in st.session_state:
                st.session_state["end_date"] = end_ts.date()

    # === NETTOYAGE SESSION STATE ===
    # Nettoyer les cl√©s de session obsol√®tes ou invalides
    session_keys_to_clean = [
        "symbols_select", "timeframes_select", "symbol_select", "timeframe_select"
    ]
    for key in session_keys_to_clean:
        if key in st.session_state:
            if "symbol" in key:
                if isinstance(st.session_state[key], list):
                    # Multi-select : filtrer valeurs invalides
                    valid_symbols = [s for s in st.session_state[key] if s in available_tokens]
                    if not valid_symbols or len(valid_symbols) != len(st.session_state[key]):
                        st.session_state[key] = valid_symbols if valid_symbols else available_tokens[:1]
                elif st.session_state[key] not in available_tokens:
                    del st.session_state[key]
            elif "timeframe" in key:
                if isinstance(st.session_state[key], list):
                    # Multi-select : filtrer valeurs invalides
                    valid_timeframes = [tf for tf in st.session_state[key] if tf in available_timeframes]
                    if not valid_timeframes or len(valid_timeframes) != len(st.session_state[key]):
                        st.session_state[key] = valid_timeframes if valid_timeframes else available_timeframes[:1]
                elif st.session_state[key] not in available_timeframes:
                    del st.session_state[key]

    # === MULTI-S√âLECTION TOKENS (multiselect) ===
    # Tokens √† potentiel (base de comparaison m√©ticuleuse)
    POTENTIAL_TOKENS = [
        "BTCUSDC",    # Bitcoin - R√©f√©rence march√©
        "ETHUSDC",    # Ethereum - Leader DeFi
        "BNBUSDC",    # Binance Coin - Plateforme CEX
        "SOLUSDC",    # Solana - Haute vitesse
        "AVAXUSDC",   # Avalanche - DeFi concurrente
        "LINKUSDC",   # Chainlink - Oracle leader
        "ADAUSDC",    # Cardano - Approche acad√©mique
        "DOTUSDC",    # Polkadot - Interop√©rabilit√©
        "ATOMUSDC",   # Cosmos - Hub inter-cha√Ænes
    ]

    default_symbols = ["BTCUSDC"] if "BTCUSDC" in available_tokens else available_tokens[:1]

    # Appliquer la s√©lection des tokens potentiels avant la cr√©ation du widget
    if st.session_state.get("_apply_potential_tokens", False):
        valid_potential = [t for t in POTENTIAL_TOKENS if t in available_tokens]
        current_symbols = st.session_state.get("symbols_select", default_symbols)
        merged_symbols = list(current_symbols)
        for token in valid_potential:
            if token not in merged_symbols:
                merged_symbols.append(token)
        st.session_state["symbols_select"] = merged_symbols or default_symbols
        del st.session_state["_apply_potential_tokens"]

    # Layout: multiselect + bouton c√¥te √† c√¥te
    col1, col2 = st.sidebar.columns([3, 1])
    with col1:
        multiselect_kwargs = {
            "label": "Symbole(s)",
            "options": available_tokens,
            "key": "symbols_select",
            "help": "S√©lectionnez un ou plusieurs tokens √† analyser",
        }
        if "symbols_select" not in st.session_state:
            multiselect_kwargs["default"] = default_symbols
        symbols = st.multiselect(**multiselect_kwargs)
    with col2:
        st.write("")  # Espacement pour aligner avec le multiselect
        if st.button("üéØ", key="select_potential_tokens", help="S√©lectionner tokens √† potentiel"):
            st.session_state["_apply_potential_tokens"] = True
            st.rerun()

    # Fallback si aucune s√©lection
    if not symbols:
        symbols = default_symbols
        st.sidebar.warning("‚ö†Ô∏è Au moins un symbole requis. BTCUSDC s√©lectionn√© par d√©faut.")
    symbol = symbols[0]  # Compatibilit√© r√©tro

    # === MULTI-S√âLECTION TIMEFRAMES (multiselect) ===
    default_timeframes = ["30m"] if "30m" in available_timeframes else available_timeframes[:1]
    timeframes = st.sidebar.multiselect(
        "Timeframe(s)",
        available_timeframes,
        default=default_timeframes,
        key="timeframes_select",
        help="S√©lectionnez un ou plusieurs timeframes",
    )
    # Fallback si aucune s√©lection
    if not timeframes:
        timeframes = default_timeframes
        st.sidebar.warning("‚ö†Ô∏è Au moins un timeframe requis. 30m s√©lectionn√© par d√©faut.")
    timeframe = timeframes[0]  # Compatibilit√© r√©tro

    # Info multi-sweep si plusieurs s√©lections
    if len(symbols) > 1 or len(timeframes) > 1:
        total_combos = len(symbols) * len(timeframes)
        st.sidebar.info(f"üîÑ Mode multi-sweep: {len(symbols)} token(s) √ó {len(timeframes)} TF(s) = {total_combos} combinaison(s)")

    # Analyse des donn√©es disponibles pour validation (toujours n√©cessaire)
    from data.config import scan_data_availability
    availability_result = scan_data_availability(symbols, timeframes)

    use_date_filter = st.sidebar.checkbox(
        "Filtrer par dates",
        value=False,
        help="D√©sactiv√© = utilise toutes les donn√©es disponibles (recommand√©)",
        key="use_date_filter",
    )
    if use_date_filter:
        # === ANALYSE PAR CAT√âGORIE DE TIMEFRAME ===
        from data.config import (
            analyze_by_timeframe,
            find_optimal_periods,
            get_min_period_days_for_timeframes,
        )

        # Analyse par timeframe (plage commune par TF)
        timeframe_analysis = analyze_by_timeframe(symbols, timeframes)

        # Interface de s√©lection par timeframe
        with st.sidebar.expander("üéØ **Analyse par Timeframe**", expanded=True):
            if len(timeframes) > 1:
                analysis_mode = st.radio(
                    "Mode d'analyse",
                    ["P√©riode harmonis√©e", "P√©riodes ind√©pendantes par timeframe"],
                    help="Harmonis√©e = m√™me p√©riode pour tous. Ind√©pendantes = p√©riode optimale par timeframe",
                )
            else:
                analysis_mode = "P√©riode harmonis√©e"  # Auto si un seul timeframe

            st.caption(
                "Harmonis√©e = une seule p√©riode commune (comparaisons strictes). "
                "Ind√©pendantes = meilleure p√©riode par TF (comparaisons plus souples)."
            )

            available_start = None
            available_end = None
            default_start = None
            default_end = None

            if analysis_mode == "P√©riode harmonis√©e":
                if availability_result.has_common_range:
                    common_start = availability_result.common_start
                    common_end = availability_result.common_end
                    duration = (common_end - common_start).days

                    st.success(f"‚úÖ **P√©riode harmonis√©e**: {common_start.strftime('%d/%m/%Y')} ‚Üí {common_end.strftime('%d/%m/%Y')} ({duration}j)")
                    st.caption(
                        f"üí° Plage commune stricte (max d√©but, min fin) sur "
                        f"{len(symbols)} token(s) √ó {len(timeframes)} TF(s)"
                    )

                    available_start = common_start.date()
                    available_end = common_end.date()
                    default_start, default_end = _get_padded_date_range(common_start, common_end)
                else:
                    st.warning("‚ö†Ô∏è Impossible de trouver une p√©riode commune (intersection vide)")
                    default_start = pd.Timestamp("2023-01-01").date()
                    default_end = pd.Timestamp.now().date()
                    available_start = default_start
                    available_end = default_end

            else:
                st.info("üìä **P√©riodes optimales par timeframe**:")

                best_timeframe = None
                best_score = 0.0
                best_period_ref = None

                for tf, data in timeframe_analysis.items():
                    st.write(f"**{tf}**")

                    if data['optimal_periods']:
                        best_period = data['optimal_periods'][0]
                        start_fr = best_period.start_date.strftime("%d/%m/%Y")
                        end_fr = best_period.end_date.strftime("%d/%m/%Y")
                        duration = (best_period.end_date - best_period.start_date).days

                        st.write(f"- üéØ {start_fr} ‚Üí {end_fr} ({duration}j)")
                        st.caption(
                            f"  Score: {best_period.completeness_score:.0f}%, "
                            f"Gap tol√©r√©: {data['gap_tolerance']:.0f}%"
                        )

                        for recommendation in data['recommendations']:
                            st.caption(f"  {recommendation}")

                        combined_score = best_period.completeness_score * best_period.avg_data_density
                        if combined_score > best_score:
                            best_score = combined_score
                            best_timeframe = tf
                            best_period_ref = best_period
                    else:
                        st.write("- ‚ùå Aucune p√©riode optimale trouv√©e")

                if best_timeframe and best_period_ref:
                    available_start = best_period_ref.start_date.date()
                    available_end = best_period_ref.end_date.date()
                    default_start, default_end = _get_padded_date_range(
                        best_period_ref.start_date,
                        best_period_ref.end_date,
                    )
                    st.success(f"üèÜ **D√©faut bas√© sur {best_timeframe}** (meilleur score: {best_score:.1f})")
                else:
                    st.warning("‚ö†Ô∏è Aucune p√©riode optimale trouv√©e pour les timeframes s√©lectionn√©s")
                    default_start = pd.Timestamp("2023-01-01").date()
                    default_end = pd.Timestamp.now().date()
                    available_start = default_start
                    available_end = default_end

            st.markdown("---")
            st.caption("üìÖ **P√©riode d'analyse** (format: DD/MM/YYYY)")

            # Auto-aligner les dates sur la plage commune si hors limites.
            if default_start and default_end and available_start and available_end:
                selection_key = (
                    tuple(sorted(symbols)),
                    tuple(sorted(timeframes)),
                    analysis_mode,
                )
                if st.session_state.get("_date_range_selection_key") != selection_key:
                    st.session_state["start_date"] = default_start
                    st.session_state["end_date"] = default_end
                    st.session_state["_date_range_selection_key"] = selection_key

                start_state = st.session_state.get("start_date")
                end_state = st.session_state.get("end_date")
                if start_state and (start_state < available_start or start_state > available_end):
                    st.session_state["start_date"] = default_start
                if end_state and (end_state < available_start or end_state > available_end):
                    st.session_state["end_date"] = default_end

                if st.session_state.get("start_date") and st.session_state.get("end_date"):
                    if st.session_state["start_date"] >= st.session_state["end_date"]:
                        st.session_state["start_date"] = default_start
                        st.session_state["end_date"] = default_end

            col1, col2 = st.sidebar.columns(2)
            with col1:
                start_date = st.date_input(
                    "Date d√©but üìÖ",
                    key="start_date",
                    format="DD/MM/YYYY",
                    help="Date de d√©but de la p√©riode d'analyse"
                )
            with col2:
                end_date = st.date_input(
                    "Date fin üìÖ",
                    key="end_date",
                    format="DD/MM/YYYY",
                    help="Date de fin de la p√©riode d'analyse"
                )

            # Validation que start_date < end_date
            if start_date and end_date and start_date >= end_date:
                st.sidebar.error("‚ö†Ô∏è La date de d√©but doit √™tre ant√©rieure √† la date de fin")

            # Affichage de la dur√©e s√©lectionn√©e
            if start_date and end_date and start_date < end_date:
                selected_days = (end_date - start_date).days
                st.sidebar.caption(f"üìä Dur√©e s√©lectionn√©e: **{selected_days} jours**")

            # Validation de la p√©riode par rapport √† la plage commune
            if availability_result.has_common_range and start_date and end_date:
                common_start = availability_result.common_start
                common_end = availability_result.common_end
                common_start_date = common_start.date()
                common_end_date = common_end.date()

                if analysis_mode == "P√©riode harmonis√©e":
                    if end_date < common_start_date:
                        st.sidebar.error(
                            f"‚ö†Ô∏è P√©riode demand√©e ({start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}) est AVANT "
                            f"la plage commune ({common_start_date.strftime('%d/%m/%Y')})"
                        )
                    elif start_date > common_end_date:
                        st.sidebar.error(
                            f"‚ö†Ô∏è P√©riode demand√©e ({start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}) est APR√àS "
                            f"la plage commune ({common_end_date.strftime('%d/%m/%Y')})"
                        )
                    elif start_date < common_start_date:
                        st.sidebar.warning(
                            f"‚ö†Ô∏è D√©but demand√© ({start_date.strftime('%d/%m/%Y')}) est AVANT la plage commune. "
                            f"Donn√©es r√©elles √† partir de **{common_start_date.strftime('%d/%m/%Y')}**"
                        )
                    elif end_date > common_end_date:
                        st.sidebar.warning(
                            f"‚ö†Ô∏è Fin demand√©e ({end_date.strftime('%d/%m/%Y')}) est APR√àS la plage commune. "
                            f"Donn√©es r√©elles jusqu'√† **{common_end_date.strftime('%d/%m/%Y')}**"
                        )
                else:
                    if start_date < common_start_date or end_date > common_end_date:
                        st.sidebar.info(
                            f"‚ÑπÔ∏è Plage commune globale: {common_start_date.strftime('%d/%m/%Y')} ‚Üí {common_end_date.strftime('%d/%m/%Y')}. "
                            "En mode ind√©pendant, certaines combinaisons peuvent √™tre tronqu√©es."
                        )

            st.markdown("---")
            with st.sidebar.expander("üîç Analyse d√©taill√©e des donn√©es", expanded=False):
                if availability_result.rows:
                    df_analysis = pd.DataFrame(availability_result.rows)
                    st.dataframe(
                        df_analysis,
                        width="stretch",
                        column_config={
                            "Token": st.column_config.TextColumn("Token", width="small"),
                            "TF": st.column_config.TextColumn("TF", width="small"),
                            "D√©but": st.column_config.TextColumn("D√©but", width="medium"),
                            "Fin": st.column_config.TextColumn("Fin", width="medium"),
                            "Jours": st.column_config.NumberColumn("Jours", width="small"),
                            "Plage commune %": st.column_config.NumberColumn("Plage commune %", format="%.1f%%", width="small"),
                            "Couverture %": st.column_config.NumberColumn("Couverture %", format="%.1f%%", width="small"),
                            "Manquant %": st.column_config.NumberColumn("Manquant %", format="%.1f%%", width="small"),
                            "Jours manquants": st.column_config.NumberColumn("Jours manquants", format="%.1f", width="small"),
                            "Status": st.column_config.TextColumn("Status", width="small"),
                            "D√©tails": st.column_config.TextColumn("D√©tails", width="large")
                        }
                    )

                    total_combos = len(df_analysis)
                    complete_combos = len(df_analysis[df_analysis["Status"] == "‚úÖ"])
                    incomplete_combos = len(df_analysis[df_analysis["Status"] == "‚ö†Ô∏è"])
                    missing_combos = len(df_analysis[df_analysis["Status"] == "‚ùå"])

                    st.markdown("**R√©sum√© qualit√© des donn√©es (gaps)**")
                    st.caption(
                        "‚úÖ = couverture correcte (<10% de gaps) ‚Ä¢ ‚ö†Ô∏è = gaps significatifs ‚Ä¢ ‚ùå = fichier manquant."
                    )
                    st.markdown(
                        f"- ‚úÖ Compl√®tes : {complete_combos}/{total_combos}\n"
                        f"- ‚ö†Ô∏è Incompl√®tes : {incomplete_combos}/{total_combos}\n"
                        f"- ‚ùå Manquantes : {missing_combos}/{total_combos}"
                    )

                    if hasattr(availability_result, 'optimal_periods') and availability_result.optimal_periods:
                        st.markdown(
                            "üí° **Conseil :** Les p√©riodes optimales ci-dessus √©vitent automatiquement les zones avec trop de donn√©es manquantes."
                        )
    else:
        start_date = None
        end_date = None

    current_data_key = _data_cache_key(symbol, timeframe, start_date, end_date)
    if st.session_state.get("ohlcv_cache_key") != current_data_key:
        st.session_state["ohlcv_cache_key"] = current_data_key
        st.session_state["ohlcv_df"] = None
        # FIX 04/01/2026: NE PAS effacer les r√©sultats quand les donn√©es changent
        # Les r√©sultats d'un backtest/grid peuvent √™tre visualis√©s ind√©pendamment
        # des donn√©es OHLCV actuellement charg√©es. Effacer les r√©sultats causait
        # la perte de tous les r√©sultats apr√®s un grid search lors du prochain rerun.
        # st.session_state["last_run_result"] = None
        # st.session_state["last_winner_params"] = None
        # st.session_state["last_winner_metrics"] = None
        # st.session_state["last_winner_origin"] = None
        # st.session_state["last_winner_meta"] = None

    pending_run_id = st.session_state.get("pending_run_load_id")
    if pending_run_id:
        try:
            storage = get_storage()
            result = storage.load_result(pending_run_id)
            st.session_state["last_run_result"] = result
            st.session_state["last_winner_params"] = result.meta.get("params", {})
            st.session_state["last_winner_metrics"] = result.metrics
            st.session_state["last_winner_origin"] = "storage"
            st.session_state["last_winner_meta"] = result.meta
            if st.session_state.get("pending_run_load_data", True):
                df_loaded, msg = load_selected_data(
                    symbol,
                    timeframe,
                    start_date,
                    end_date,
                )
                if df_loaded is None:
                    st.session_state["saved_runs_status"] = f"Data load failed: {msg}"
                else:
                    st.session_state["saved_runs_status"] = f"Run loaded with data: {msg}"
            else:
                st.session_state["saved_runs_status"] = f"Run loaded: {pending_run_id}"
        except Exception as exc:
            st.session_state["saved_runs_status"] = f"Load failed: {exc}"
        st.session_state.pop("pending_run_load_id", None)
        st.session_state.pop("pending_run_load_data", None)

    if st.session_state.get("ohlcv_df") is None:
        st.sidebar.info("Donnees non chargees.")
    else:
        cached_msg = st.session_state.get("ohlcv_status_msg", "")
        if cached_msg:
            st.sidebar.caption(f"Cache: {cached_msg}")

    st.sidebar.subheader("üéØ Strat√©gie")

    available_strategies = list_strategies()
    strategy_options = build_strategy_options(available_strategies)
    strategy_name = st.sidebar.selectbox(
        "Strat√©gie",
        list(strategy_options.keys()),
    )
    strategy_key = strategy_options[strategy_name]

    st.sidebar.caption(get_strategy_description(strategy_key))

    strategy_info = None
    try:
        strategy_info = get_strategy_info(strategy_key)

        if strategy_info.required_indicators:
            indicators_list = ", ".join(
                [f"**{ind.upper()}**" for ind in strategy_info.required_indicators]
            )
            st.sidebar.info(f"üìä Indicateurs requis: {indicators_list}")
        else:
            st.sidebar.info("üìä Indicateurs: Calcul√©s internement")

        if strategy_info.internal_indicators:
            internal_list = ", ".join(
                [f"{ind.upper()}" for ind in strategy_info.internal_indicators]
            )
            st.sidebar.caption(f"_Calcul√©s: {internal_list}_")

    except KeyError:
        st.sidebar.warning(f"‚ö†Ô∏è Indicateurs non d√©finis pour '{strategy_key}'")

    st.sidebar.subheader("Indicateurs")
    available_indicators = get_strategy_ui_indicators(strategy_key)
    # Tous les indicateurs sont toujours affich√©s
    active_indicators: List[str] = available_indicators if available_indicators else []

    if available_indicators:
        st.sidebar.caption(f"üìä {len(available_indicators)} indicateur(s) : {', '.join(available_indicators)}")
    else:
        st.sidebar.caption("Aucun indicateur disponible.")

    # (Versioned Presets moved to bottom)

    st.sidebar.subheader("üîÑ Mode d'ex√©cution")

    if "optimization_mode" not in st.session_state:
        st.session_state.optimization_mode = "Grille de Param√®tres"
    if "run_backtest_requested" not in st.session_state:
        st.session_state.run_backtest_requested = False
    if "is_running" not in st.session_state:
        st.session_state.is_running = False

    if "default_preset_applied" not in st.session_state:
        cpu_count = os.cpu_count() or 1
        optimal_workers = min(cpu_count, 32)
        st.session_state["grid_n_workers"] = optimal_workers
        st.session_state["grid_worker_threads"] = 1
        st.session_state["gpu_n_workers"] = 1
        st.session_state["gpu_worker_threads"] = 1
        os.environ["BACKTEST_WORKER_THREADS"] = "1"
        st.session_state["default_preset_applied"] = True

    st.sidebar.markdown(MODE_BUTTON_CSS, unsafe_allow_html=True)

    for mode_name, icon, description in MODE_OPTIONS:
        button_key = f"mode_btn_{mode_name}"
        is_active = st.session_state.optimization_mode == mode_name

        col1, col2 = st.sidebar.columns([1, 10])
        with col1:
            st.write(icon)
        with col2:
            if st.button(
                mode_name,
                key=button_key,
                help=description,
                width="stretch",
                type="primary" if is_active else "secondary",
                disabled=st.session_state.is_running,
            ):
                st.session_state.optimization_mode = mode_name
                st.rerun()

    optimization_mode = st.session_state.optimization_mode

    st.sidebar.caption(f"‚ÑπÔ∏è Mode actif: **{optimization_mode}**")

    action_slot = st.sidebar.container()

    default_max_combos = _env_int("BACKTEST_SWEEP_MAX_COMBOS", 30_000_000)
    unlimited_max_combos = 1_000_000_000_000
    default_workers_gpu = _env_int("BACKTEST_WORKERS_GPU_OPTIMIZED", 40)
    default_llm_unload = _env_bool("UNLOAD_LLM_DURING_BACKTEST", True)
    default_worker_threads = _env_int("BACKTEST_WORKER_THREADS", 1)

    max_combos = unlimited_max_combos
    n_workers = default_workers_gpu

    # Configuration Optuna (int√©gr√©e dans Grille de Param√®tres)
    use_optuna = False
    optuna_n_trials = 100
    optuna_sampler = "tpe"
    optuna_pruning = True
    optuna_metric = "sharpe_ratio"
    optuna_early_stop = 0  # 0 = d√©sactiv√© par d√©faut

    if optimization_mode == "Grille de Param√®tres":
        st.sidebar.markdown("---")
        st.sidebar.subheader("‚öôÔ∏è M√©thode d'exploration")

        use_optuna = st.sidebar.checkbox(
            "Utiliser Optuna (Bay√©sien) ‚ö°",
            value=False,
            help="Optuna explore intelligemment l'espace des param√®tres (10-100x plus rapide que la grille exhaustive)",
        )

        if use_optuna:
            st.sidebar.caption("üéØ **Mode Bay√©sien** - Exploration intelligente")

            optuna_n_trials = st.sidebar.number_input(
                "Nombre de trials",
                min_value=10,
                max_value=10000,
                value=200,
                step=10,
                help="Nombre d'essais bay√©siens (100-500 recommand√©)",
            )

            optuna_sampler = st.sidebar.selectbox(
                "Algorithme",
                ["tpe", "cmaes", "random"],
                index=0,
                help="TPE: Rapide et efficace | CMA-ES: Pour espaces continus | Random: Baseline",
            )

            optuna_metric = st.sidebar.selectbox(
                "M√©trique √† optimiser",
                ["sharpe_ratio", "sortino_ratio", "total_return_pct", "profit_factor", "calmar_ratio"],
                index=0,
                help="M√©trique principale pour l'optimisation",
            )

            optuna_pruning = st.sidebar.checkbox(
                "Pruning (arr√™t pr√©coce) ‚úÇÔ∏è",
                value=True,
                help="Abandonne les trials peu prometteurs pour acc√©l√©rer",
            )

            # Early stop: 0 = d√©sactiv√©, sinon patience en nombre de trials
            optuna_early_stop = st.sidebar.slider(
                "Early stop patience (0=d√©sactiv√©)",
                min_value=0,
                max_value=max(200, optuna_n_trials),
                value=0,  # D√©sactiv√© par d√©faut pour ne pas interrompre pr√©matur√©ment
                help="Arr√™t apr√®s N trials sans am√©lioration. 0 = d√©sactiv√© (recommand√© pour explorer compl√®tement)",
            )

            n_workers = st.sidebar.slider(
                "Workers parall√®les (CPU)",
                min_value=1,
                max_value=32,
                value=8,
                help="Nombre de trials √©valu√©s en parall√®le",
            )

            st.sidebar.caption(f"‚ö° {optuna_n_trials} trials √ó {n_workers} workers")
        else:
            st.sidebar.caption("üî¢ **Mode Grille** - Exploration exhaustive")

            max_combos = unlimited_max_combos
            st.sidebar.caption("Limite de combinaisons: illimit√©e")

            grid_workers_default = max(1, min(default_workers_gpu, 32))  # ‚úÖ min=1
            if "grid_n_workers" not in st.session_state:
                st.session_state["grid_n_workers"] = grid_workers_default
            else:
                try:
                    st.session_state["grid_n_workers"] = max(
                        1,  # ‚úÖ min=1
                        min(int(st.session_state["grid_n_workers"]), 32),
                    )
                except (TypeError, ValueError):
                    st.session_state["grid_n_workers"] = grid_workers_default

            grid_threads_default = max(1, min(default_worker_threads, 32))  # ‚úÖ min=1
            if "grid_worker_threads" not in st.session_state:
                st.session_state["grid_worker_threads"] = grid_threads_default
            else:
                try:
                    st.session_state["grid_worker_threads"] = max(
                        1,  # ‚úÖ min=1
                        min(int(st.session_state["grid_worker_threads"]), 32),
                    )
                except (TypeError, ValueError):
                    st.session_state["grid_worker_threads"] = grid_threads_default

            col_preset_1, col_preset_2 = st.sidebar.columns(2)
            with col_preset_1:
                if st.button("Preset 32 c≈ìurs", key="preset_32_cores"):
                    st.session_state["grid_n_workers"] = 32
                    st.session_state["grid_worker_threads"] = 1
                    st.sidebar.success("Preset 32 c≈ìurs appliqu√©")
                    st.rerun()
            with col_preset_2:
                if st.button("Preset 24 c≈ìurs", key="preset_24_cores"):
                    st.session_state["grid_n_workers"] = 24
                    st.session_state["grid_worker_threads"] = 1
                    st.sidebar.success("Preset 24 c≈ìurs appliqu√©")
                    st.rerun()

            n_workers = st.sidebar.slider(
                "Workers parall√®les (CPU)",
                min_value=1,  # ‚úÖ Corrig√©: minimum 1 worker requis
                max_value=32,
                help="24-32 recommand√© pour 9950X. Donn√©es pr√©-charg√©es = initialisation rapide",
                key="grid_n_workers",
            )

            worker_threads = st.sidebar.slider(
                "Threads par worker (CPU/BLAS)",
                min_value=1,  # ‚úÖ Corrig√©: minimum 1 thread requis
                max_value=32,
                step=1,
                key="grid_worker_threads",
                help=(
                    "Nombre de threads CPU par process. "
                    "Total ‚âà workers √ó threads. "
                    "Recommand√©: 1 si beaucoup de workers."
                ),
            )

            st.sidebar.caption(
                f"Total th√©orique: ~{n_workers * worker_threads} threads (workers √ó threads)"
            )
    llm_config = None
    llm_max_iterations = 10
    llm_use_walk_forward = True
    role_model_config = None
    llm_compare_enabled = False
    llm_compare_auto_run = True
    llm_compare_strategies: List[str] = []
    llm_compare_tokens: List[str] = []
    llm_compare_timeframes: List[str] = []
    llm_compare_metric = "sharpe_ratio"
    llm_compare_aggregate = "median"
    llm_compare_max_runs = 25
    llm_compare_use_preset = True
    llm_compare_generate_report = True
    llm_use_multi_agent = False
    llm_use_multi_model = False
    llm_limit_small_models = False
    llm_unload_during_backtest = default_llm_unload
    llm_model = None

    if optimization_mode == "ü§ñ Optimisation LLM":
        st.sidebar.markdown("---")
        st.sidebar.subheader("üß† Configuration LLM")

        st.sidebar.markdown("---")
        st.sidebar.caption("**‚öôÔ∏è Param√®tres d'ex√©cution**")

        max_combos = unlimited_max_combos
        st.sidebar.caption("Limite de combinaisons LLM: illimit√©e")

        llm_workers_default = max(1, min(default_workers_gpu, 61))
        n_workers = st.sidebar.slider(
            "Workers parall√®les (CPU)",
            min_value=1,
            max_value=61,
            value=llm_workers_default,
            help="Nombre de backtests ex√©cut√©s en parall√®le (40 recommand√©)",
            key="llm_n_workers",
        )

        st.sidebar.caption(
            f"üîß Parall√©lisation: jusqu'√† {n_workers} backtests simultan√©s"
        )
        st.sidebar.markdown("---")

        if not LLM_AVAILABLE:
            st.sidebar.error("‚ùå Module LLM non disponible")
            st.sidebar.caption(f"Erreur: {LLM_IMPORT_ERROR}")
        else:
            llm_provider = st.sidebar.selectbox(
                "Provider LLM",
                ["Ollama (Local)", "OpenAI"],
                help="Ollama = gratuit et local | OpenAI = API payante",
            )

            llm_use_multi_agent = st.sidebar.checkbox(
                "Mode multi-agents üë•",
                value=False,
                key="llm_use_multi_agent",
                help="Utiliser Analyst/Strategist/Critic/Validator",
            )

            def _extract_model_params_b(model_name: str) -> Optional[float]:
                match = re.search(r"(\d+(?:\.\d+)?)b", model_name.lower())
                if match:
                    return float(match.group(1))
                return None

            def _is_model_under_limit(model_name: str, limit: float) -> bool:
                size = _extract_model_params_b(model_name)
                if size is None:
                    return False
                return size < limit

            def _is_model_over_limit(model_name: str, limit: float) -> bool:
                size = _extract_model_params_b(model_name)
                if size is None:
                    return False
                return size >= limit

            if "Ollama" in llm_provider:
                if is_ollama_available():
                    st.sidebar.success("‚úÖ Ollama connect√©")
                else:
                    st.sidebar.warning("‚ö†Ô∏è Ollama non d√©tect√©")
                    if st.sidebar.button("üöÄ D√©marrer Ollama"):
                        with st.spinner("D√©marrage d'Ollama..."):
                            success, msg = ensure_ollama_running()
                            if success:
                                st.sidebar.success(msg)
                                st.rerun()
                            else:
                                st.sidebar.error(msg)

                llm_use_multi_model = False
                if llm_use_multi_agent:
                    llm_use_multi_model = st.sidebar.checkbox(
                        "Multi-modeles par role",
                        value=False,
                        key="llm_use_multi_model",
                        help="Assigner differents modeles a chaque role d'agent",
                    )

                if llm_use_multi_model:
                    available_models_list = list_available_models()
                    available_model_names = [m.name for m in available_models_list]

                    llm_limit_small_models = st.sidebar.checkbox(
                        "Limiter selection aleatoire a <20B",
                        value=True,
                        key="llm_limit_small_models",
                        help="Filtre la liste par taille et exclut deepseek-r1:70b",
                    )
                    llm_limit_large_models = st.sidebar.checkbox(
                        "Limiter selection aleatoire a >=20B",
                        value=False,
                        key="llm_limit_large_models",
                        help="Filtre la liste par taille (>=20B uniquement)",
                    )

                    effective_small_filter = llm_limit_small_models
                    effective_large_filter = llm_limit_large_models
                    if effective_small_filter and effective_large_filter:
                        st.sidebar.warning(
                            "Filtres <20B et >=20B actifs: >=20B prioritaire."
                        )
                        effective_small_filter = False

                    excluded_models = set()
                    if not effective_large_filter:
                        excluded_models = {"deepseek-r1:70b"}
                    if excluded_models:
                        available_model_names = [
                            m for m in available_model_names if m not in excluded_models
                        ]

                    if effective_small_filter:
                        filtered = [
                            m for m in available_model_names if _is_model_under_limit(m, 20)
                        ]
                        if filtered:
                            available_model_names = filtered
                        else:
                            st.sidebar.warning(
                                "Aucun modele <20B detecte, filtre desactive."
                            )

                    if effective_large_filter:
                        filtered = [
                            m for m in available_model_names if _is_model_over_limit(m, 20)
                        ]
                        if filtered:
                            available_model_names = filtered
                        else:
                            available_model_names = []
                            st.sidebar.warning("Aucun modele >=20B detecte.")
                    if effective_large_filter and not available_model_names:
                        st.sidebar.error(
                            "Selection >=20B activee mais aucun modele compatible."
                        )

                    st.sidebar.markdown("---")
                    st.sidebar.caption("**Configuration des mod√®les**")

                    # ===== GESTION DES PRESETS =====
                    from ui.model_presets import (
                        apply_preset_to_config,
                        delete_model_preset,
                        get_current_config_as_dict,
                        list_model_presets,
                        load_model_preset,
                        save_model_preset,
                    )

                    # Lister tous les presets
                    all_presets = list_model_presets()
                    preset_names = [p["name"] for p in all_presets]

                    # Selectbox pour choisir un preset
                    col1, col2 = st.sidebar.columns([3, 1])
                    with col1:
                        selected_preset = st.selectbox(
                            "Charger un preset",
                            options=["Aucun (manuel)"] + preset_names,
                            key="selected_model_preset",
                            help="Charge une configuration pr√©d√©finie de mod√®les LLM"
                        )

                    with col2:
                        # Bouton pour appliquer le preset
                        if selected_preset != "Aucun (manuel)":
                            if st.button("‚ö°", key="apply_preset", help="Appliquer ce preset"):
                                preset = load_model_preset(selected_preset)
                                apply_preset_to_config(preset, get_global_model_config())
                                st.rerun()

                    # Expander pour sauvegarder/g√©rer les presets
                    with st.sidebar.expander("üíæ G√©rer les presets"):
                        user_presets = [p for p in all_presets if not p.get("builtin", False)]

                        # Tab pour organiser les actions
                        action_choice = st.radio(
                            "Action",
                            ["‚ûï Cr√©er nouveau", "‚úèÔ∏è Modifier existant", "üóëÔ∏è Supprimer"],
                            key="preset_action",
                            horizontal=True
                        )

                        if action_choice == "‚ûï Cr√©er nouveau":
                            st.markdown("**Cr√©er un nouveau preset**")
                            new_preset_name = st.text_input(
                                "Nom du preset",
                                key="new_preset_name",
                                placeholder="Ex: Pr√©cis, Rapide, Test..."
                            )
                            st.caption("üí° Ajustez les mod√®les ci-dessous avant de sauvegarder")

                            if st.button("üíæ Cr√©er", key="create_preset"):
                                if new_preset_name.strip():
                                    try:
                                        current_config = get_current_config_as_dict(get_global_model_config())
                                        save_model_preset(new_preset_name.strip(), current_config["models"])
                                        st.success(f"‚úÖ Preset '{new_preset_name}' cr√©√©")
                                        st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                                else:
                                    st.error("Nom de preset requis")

                        elif action_choice == "‚úèÔ∏è Modifier existant":
                            st.markdown("**Modifier un preset existant**")
                            if user_presets:
                                preset_to_modify = st.selectbox(
                                    "Preset √† modifier",
                                    options=[p["name"] for p in user_presets],
                                    key="preset_to_modify"
                                )
                                st.caption("üí° Chargez le preset ci-dessus, ajustez les mod√®les, puis sauvegardez")

                                if st.button("üíæ Sauvegarder modifications", key="update_preset"):
                                    try:
                                        current_config = get_current_config_as_dict(get_global_model_config())
                                        save_model_preset(preset_to_modify, current_config["models"])
                                        st.success(f"‚úÖ Preset '{preset_to_modify}' mis √† jour")
                                        st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                            else:
                                st.info("Aucun preset utilisateur √† modifier")

                        elif action_choice == "üóëÔ∏è Supprimer":
                            st.markdown("**Supprimer un preset**")
                            if user_presets:
                                preset_to_delete = st.selectbox(
                                    "Preset √† supprimer",
                                    options=[p["name"] for p in user_presets],
                                    key="preset_to_delete"
                                )
                                st.warning(f"‚ö†Ô∏è Supprimer '{preset_to_delete}' d√©finitivement ?")

                                if st.button("üóëÔ∏è Confirmer suppression", key="delete_preset"):
                                    try:
                                        if delete_model_preset(preset_to_delete):
                                            st.success(f"‚úÖ Preset '{preset_to_delete}' supprim√©")
                                            st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                            else:
                                st.info("Aucun preset utilisateur √† supprimer")

                    st.sidebar.markdown("---")
                    st.sidebar.caption("**Modeles par role d'agent**")
                    st.sidebar.caption("Rapide | Moyen | Lent")

                    # Checkbox pour pr√©-configuration optimale
                    use_optimal_config = st.sidebar.checkbox(
                        "Pr√©-config optimale",
                        value=False,
                        key="use_optimal_model_config",
                        help=(
                            "Active la configuration recommand√©e bas√©e sur les benchmarks:\n"
                            "‚Ä¢ Analyst ‚Üí qwen2.5:14b (rapide)\n"
                            "‚Ä¢ Strategist ‚Üí gemma3:27b (√©quilibr√©)\n"
                            "‚Ä¢ Critic ‚Üí llama3.3-70b-optimized (puissant)\n"
                            "‚Ä¢ Validator ‚Üí llama3.3-70b-optimized (critique)"
                        ),
                    )

                    if use_optimal_config:
                        st.sidebar.info(
                            "üí° Configuration optimale activ√©e. "
                            "Vous pouvez ajuster manuellement les s√©lections ci-dessous."
                        )

                    role_model_config = get_global_model_config()

                    def model_with_badge(name: str) -> str:
                        info = KNOWN_MODELS.get(name)
                        if info:
                            if info.category == ModelCategory.LIGHT:
                                return f"[L] {name}"
                            if info.category == ModelCategory.MEDIUM:
                                return f"[M] {name}"
                            return f"[H] {name}"
                        return name

                    model_options_display = [
                        model_with_badge(m) for m in available_model_names
                    ]
                    name_to_display = {
                        n: model_with_badge(n) for n in available_model_names
                    }
                    display_to_name = {v: k for k, v in name_to_display.items()}

                    use_single_model_for_roles = st.sidebar.checkbox(
                        "M√™me mod√®le pour tous les r√¥les",
                        value=False,
                        key="llm_single_model_for_roles",
                        help="Applique un seul mod√®le √† Analyst/Strategist/Critic/Validator.",
                    )

                    single_model_selection = None
                    if use_single_model_for_roles:
                        if model_options_display:
                            default_model = (
                                role_model_config.analyst.models[0]
                                if role_model_config.analyst.models
                                else (available_model_names[0] if available_model_names else None)
                            )
                            default_display = name_to_display.get(
                                default_model, model_options_display[0]
                            )
                            default_index = (
                                model_options_display.index(default_display)
                                if default_display in model_options_display
                                else 0
                            )
                            single_model_selection = st.sidebar.selectbox(
                                "Mod√®le unique (tous r√¥les)",
                                model_options_display,
                                index=default_index,
                                key="llm_single_model_for_roles_name",
                                help="Ce mod√®le sera utilis√© pour tous les r√¥les.",
                            )
                        else:
                            st.sidebar.warning(
                                "Aucun mod√®le disponible pour unifier les r√¥les."
                            )

                    st.sidebar.markdown("**Analyst** (analyse rapide)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("analyst", [])
                        analyst_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        from ui.components.model_selector import get_optimal_config_for_role
                        optimal_analyst = get_optimal_config_for_role("analyst", available_model_names)
                        analyst_default_options = [
                            name_to_display.get(m, m) for m in optimal_analyst
                        ]
                    else:
                        # Comportement existant
                        analyst_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.analyst.models
                            if m in available_model_names
                        ]
                        analyst_default_options = (
                            analyst_defaults[:3] if analyst_defaults else model_options_display[:2]
                        )

                    if not model_options_display:
                        analyst_default_options = []

                    analyst_selection = st.sidebar.multiselect(
                        "Modeles Analyst",
                        model_options_display,
                        default=analyst_default_options,
                        key="analyst_models",
                        help="Modeles rapides recommandes pour l'analyse",
                    )

                    st.sidebar.markdown("**Strategist** (propositions)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("strategist", [])
                        strategist_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_strategist = get_optimal_config_for_role("strategist", available_model_names)
                        strategist_default_options = [
                            name_to_display.get(m, m) for m in optimal_strategist
                        ]
                    else:
                        # Comportement existant
                        strategist_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.strategist.models
                            if m in available_model_names
                        ]
                        strategist_default_options = (
                            strategist_defaults[:3]
                            if strategist_defaults
                            else model_options_display[:2]
                        )

                    if not model_options_display:
                        strategist_default_options = []

                    strategist_selection = st.sidebar.multiselect(
                        "Modeles Strategist",
                        model_options_display,
                        default=strategist_default_options,
                        key="strategist_models",
                        help="Modeles moyens pour la creativite",
                    )

                    st.sidebar.markdown("**Critic** (evaluation critique)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("critic", [])
                        critic_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_critic = get_optimal_config_for_role("critic", available_model_names)
                        critic_default_options = [
                            name_to_display.get(m, m) for m in optimal_critic
                        ]
                    else:
                        # Comportement existant
                        critic_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.critic.models
                            if m in available_model_names
                        ]
                        critic_default_options = (
                            critic_defaults[:3] if critic_defaults else model_options_display[:2]
                        )

                    if not model_options_display:
                        critic_default_options = []

                    critic_selection = st.sidebar.multiselect(
                        "Modeles Critic",
                        model_options_display,
                        default=critic_default_options,
                        key="critic_models",
                        help="Modeles puissants pour la reflexion",
                    )

                    st.sidebar.markdown("**Validator** (d√©cision finale)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("validator", [])
                        validator_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_validator = get_optimal_config_for_role("validator", available_model_names)
                        validator_default_options = [
                            name_to_display.get(m, m) for m in optimal_validator
                        ]
                    else:
                        # Comportement existant
                        validator_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.validator.models
                            if m in available_model_names
                        ]
                        validator_default_options = (
                            validator_defaults[:3]
                            if validator_defaults
                            else model_options_display[:2]
                        )

                    if not model_options_display:
                        validator_default_options = []

                    validator_selection = st.sidebar.multiselect(
                        "Modeles Validator",
                        model_options_display,
                        default=validator_default_options,
                        key="validator_models",
                        help="Modeles puissants pour decisions finales",
                    )

                    if use_single_model_for_roles and single_model_selection:
                        analyst_selection = [single_model_selection]
                        strategist_selection = [single_model_selection]
                        critic_selection = [single_model_selection]
                        validator_selection = [single_model_selection]

                    st.sidebar.markdown("---")
                    st.sidebar.caption("Modeles lourds")
                    heavy_after_iter = st.sidebar.number_input(
                        "Autoriser apres iteration N",
                        min_value=1,
                        max_value=20,
                        value=3,
                        help="Les modeles lourds ne seront utilises qu'apres cette iteration",
                    )

                    def _normalize_selection(selection: List[str]) -> List[str]:
                        names = [display_to_name.get(m, m) for m in selection]
                        return [n for n in names if n in available_model_names]

                    role_model_config.analyst.models = _normalize_selection(analyst_selection)
                    role_model_config.strategist.models = _normalize_selection(strategist_selection)
                    role_model_config.critic.models = _normalize_selection(critic_selection)
                    role_model_config.validator.models = _normalize_selection(validator_selection)

                    for assignment in [
                        role_model_config.analyst,
                        role_model_config.strategist,
                        role_model_config.critic,
                        role_model_config.validator,
                    ]:
                        assignment.allow_heavy_after_iteration = heavy_after_iter

                    set_global_model_config(role_model_config)

                    st.sidebar.info(
                        "Si plusieurs modeles sont selectionnes, "
                        "un sera choisi aleatoirement a chaque appel."
                    )

                    if role_model_config.analyst.models:
                        llm_model = role_model_config.analyst.models[0]
                    elif available_model_names:
                        llm_model = available_model_names[0]
                    elif effective_large_filter:
                        llm_model = None
                    else:
                        llm_model = "deepseek-r1:8b"

                else:
                    available_models = get_available_models_for_ui(
                        preferred_order=RECOMMENDED_FOR_STRATEGY
                    )

                    llm_model = st.sidebar.selectbox(
                        "Mod√®le Ollama",
                        available_models,
                        help="Mod√®les install√©s localement via Ollama",
                    )

                    if llm_model:
                        model_info = get_model_info(llm_model)
                        size = model_info["size_gb"]
                        desc = model_info["description"]
                        st.sidebar.caption(f"üì¶ ~{size} GB | {desc}")

                ollama_host = st.sidebar.text_input(
                    "URL Ollama",
                    value="http://localhost:11434",
                    help="Adresse du serveur Ollama",
                )
                if llm_model:
                    llm_config = LLMConfig(
                        provider=LLMProvider.OLLAMA,
                        model=llm_model,
                        ollama_host=ollama_host,
                    )
                else:
                    llm_config = None
            else:
                openai_key = st.sidebar.text_input(
                    "Cl√© API OpenAI",
                    type="password",
                    help="Votre cl√© API OpenAI",
                )
                llm_model = st.sidebar.selectbox(
                    "Mod√®le OpenAI",
                    ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
                    help="gpt-4o-mini recommand√© pour co√ªt/performance",
                )
                if openai_key:
                    llm_config = LLMConfig(
                        provider=LLMProvider.OPENAI,
                        model=llm_model,
                        api_key=openai_key,
                    )
                else:
                    st.sidebar.warning("‚ö†Ô∏è Cl√© API requise")

            st.sidebar.markdown("---")
            st.sidebar.caption("**Options d'optimisation**")

            llm_unlimited_iterations = st.sidebar.checkbox(
                "It√©rations illimit√©es",
                value=True,
                key="llm_unlimited_iterations",
                help="Lance l'optimisation sans limite d'it√©rations (arr√™t manuel requis)",
            )

            if llm_unlimited_iterations:
                llm_max_iterations = 0
                st.sidebar.caption("‚àû it√©rations (arr√™t manuel)")
            else:
                llm_max_iterations = st.sidebar.slider(
                    "Max it√©rations",
                    min_value=3,
                    max_value=50,
                    value=10,
                    help="Nombre max de cycles d'am√©lioration",
                )

            walk_forward_enabled = True
            walk_forward_reason = ""

            df_cached = st.session_state.get("ohlcv_df")
            if df_cached is not None and not df_cached.empty:
                data_duration_days = (df_cached.index[-1] - df_cached.index[0]).days
                data_duration_months = data_duration_days / 30.44

                if data_duration_months < 6:
                    walk_forward_enabled = False
                    walk_forward_reason = (
                        "‚ö†Ô∏è Walk-Forward d√©sactiv√© "
                        f"(dur√©e: {data_duration_months:.1f} mois < 6 mois requis)"
                    )
                else:
                    walk_forward_reason = (
                        f"‚úÖ Walk-Forward disponible (dur√©e: {data_duration_months:.1f} mois)"
                    )

            if walk_forward_reason:
                if walk_forward_enabled:
                    st.sidebar.caption(walk_forward_reason)
                else:
                    st.sidebar.warning(walk_forward_reason)

            llm_use_walk_forward = st.sidebar.checkbox(
                "Walk-Forward Validation",
                value=walk_forward_enabled,
                disabled=not walk_forward_enabled,
                help=(
                    "Anti-overfitting: valide sur donn√©es hors-√©chantillon "
                    "(n√©cessite >6 mois de donn√©es)"
                ),
            )

            llm_unload_during_backtest = st.sidebar.checkbox(
                "D√©charger LLM du GPU",
                value=default_llm_unload,
                help=(
                    "Lib√®re la VRAM GPU pendant les backtests pour am√©liorer les performances. "
                    "Recommand√© si vous utilisez CuPy/GPU pour les indicateurs. "
                    "Peut √™tre d√©sactiv√© pour compatibilit√© CPU-only."
                ),
            )

            st.sidebar.markdown("---")
            with st.sidebar.expander("Comparaison multi-strategies", expanded=False):
                llm_compare_enabled = st.checkbox(
                    "Comparer strategies (multi-tokens/timeframes)",
                    value=False,
                    key="llm_compare_enabled",
                )
                if llm_compare_enabled:
                    llm_compare_auto_run = st.checkbox(
                        "Execution automatique",
                        value=True,
                        key="llm_compare_auto_run",
                        help="Lance la comparaison avant l'optimisation LLM",
                    )
                    compare_strategy_labels = st.multiselect(
                        "Strategies a comparer",
                        list(strategy_options.keys()),
                        default=[strategy_name],
                        key="llm_compare_strategy_labels",
                    )
                    llm_compare_strategies = [
                        strategy_options[label]
                        for label in compare_strategy_labels
                        if label in strategy_options
                    ]

                    llm_compare_tokens = st.multiselect(
                        "Tokens",
                        available_tokens,
                        default=[symbol],
                        key="llm_compare_tokens",
                    )
                    llm_compare_timeframes = st.multiselect(
                        "Timeframes",
                        available_timeframes,
                        default=[timeframe],
                        key="llm_compare_timeframes",
                    )

                    llm_compare_metric = st.selectbox(
                        "Metrica principale",
                        [
                            "sharpe_ratio",
                            "total_return_pct",
                            "max_drawdown",
                            "win_rate",
                        ],
                        index=0,
                        key="llm_compare_metric",
                    )
                    llm_compare_aggregate = st.selectbox(
                        "Agregation",
                        ["median", "mean", "worst"],
                        index=0,
                        key="llm_compare_aggregate",
                    )
                    llm_compare_max_runs = st.number_input(
                        "Max runs comparaison",
                        min_value=1,
                        max_value=500,
                        value=25,
                        step=1,
                        key="llm_compare_max_runs",
                    )
                    llm_compare_use_preset = st.checkbox(
                        "Utiliser presets si disponibles",
                        value=True,
                        key="llm_compare_use_preset",
                    )
                    llm_compare_generate_report = st.checkbox(
                        "Generer justification LLM",
                        value=True,
                        key="llm_compare_generate_report",
                    )

                    if (
                        llm_compare_strategies
                        and llm_compare_tokens
                        and llm_compare_timeframes
                    ):
                        total_runs = (
                            len(llm_compare_strategies)
                            * len(llm_compare_tokens)
                            * len(llm_compare_timeframes)
                        )
                        st.caption(
                            f"Estime: {total_runs} runs (cap {llm_compare_max_runs})."
                        )

                    if not llm_compare_auto_run:
                        if "llm_compare_run_now" not in st.session_state:
                            st.session_state["llm_compare_run_now"] = False
                        if st.button("Lancer comparaison", key="llm_compare_run_button"):
                            st.session_state["llm_compare_run_now"] = True
                else:
                    if "llm_compare_run_now" in st.session_state:
                        st.session_state["llm_compare_run_now"] = False

            if llm_use_multi_agent:
                max_iter_label = "‚àû" if llm_max_iterations <= 0 else str(llm_max_iterations)
                st.sidebar.caption(
                    "Agents: Analyst/Strategist/Critic/Validator | "
                    f"Max iterations: {max_iter_label}"
                )
            else:
                max_iter_label = "‚àû" if llm_max_iterations <= 0 else str(llm_max_iterations)
                st.sidebar.caption(
                    f"Agent autonome | Max iterations: {max_iter_label}"
                )

    # ======================== GPU ACCELERATION ========================
    st.sidebar.markdown("---")
    st.sidebar.subheader("‚ö° Acc√©l√©ration GPU")

    # GPU d√©sactiv√© pour sweeps (CPU + cache RAM plus efficace en multiprocess)
    # VRAM lib√©r√©e pour LLM agents (Ollama, etc.)
    st.sidebar.info(
        "üîµ **GPU d√©sactiv√© pour sweeps**\n\n"
        "‚Ä¢ CPU + Cache RAM = optimal (350-450 runs/sec)\n"
        "‚Ä¢ GPU queue incompatible multiprocess\n"
        "‚Ä¢ VRAM libre pour LLM agents ü§ñ"
    )

    # Forcer d√©sactivation GPU pour √©viter chargement VRAM inutile
    os.environ["BACKTEST_USE_GPU"] = "0"
    os.environ["BACKTEST_GPU_QUEUE_ENABLED"] = "0"
    use_gpu = False

    # ===== SECTION GPU MASQU√âE (inutile pour sweeps) =====
    # gpu_enabled_default = _env_bool("BACKTEST_USE_GPU", False)
    # use_gpu = st.sidebar.checkbox(
    #     "Utiliser GPU pour les indicateurs (CuPy)",
    #     value=gpu_enabled_default,
    #     key="use_gpu_indicators",
    #     help=(
    #         "Active les indicateurs GPU (SMA/EMA/RSI/Bollinger/ATR/MACD). "
    #         "N√©cessite CuPy + CUDA."
    #     ),
    # )
    # os.environ["BACKTEST_USE_GPU"] = "1" if use_gpu else "0"

    if use_gpu:
        try:
            default_min_samples = _env_int("BACKTEST_GPU_MIN_SAMPLES", 5000)
        except Exception:
            default_min_samples = 5000

        min_samples = st.sidebar.number_input(
            "Seuil min barres (GPU)",
            min_value=1000,
            max_value=2000000,
            value=default_min_samples,
            step=1000,
            key="gpu_min_samples",
            help="En-dessous de ce seuil, le calcul reste sur CPU (√©vite overhead GPU).",
        )
        os.environ["BACKTEST_GPU_MIN_SAMPLES"] = str(int(min_samples))

        st.sidebar.markdown("---")
        st.sidebar.caption("‚öôÔ∏è R√©glages GPU (workers/threads)")

        gpu_override_default = _env_bool("BACKTEST_GPU_WORKERS_OVERRIDE", False)
        gpu_workers_override = st.sidebar.checkbox(
            "Utiliser r√©glages GPU pour workers/threads",
            value=gpu_override_default,
            key="gpu_workers_override",
            help=(
                "Applique ces r√©glages quand le GPU est actif. "
                "Recommand√©: 1-2 workers pour √©viter la contention GPU."
            ),
        )
        os.environ["BACKTEST_GPU_WORKERS_OVERRIDE"] = "1" if gpu_workers_override else "0"

        if gpu_workers_override:
            gpu_workers_default = max(1, min(_env_int("BACKTEST_GPU_N_WORKERS", 1), 32))  # ‚úÖ min=1
            gpu_threads_default = max(
                1,  # ‚úÖ min=1
                min(_env_int("BACKTEST_GPU_WORKER_THREADS", default_worker_threads), 32),
            )
            # ‚úÖ Initialiser session_state AVANT le widget (pattern correct)
            if "gpu_n_workers" not in st.session_state:
                st.session_state["gpu_n_workers"] = gpu_workers_default
            else:
                try:
                    st.session_state["gpu_n_workers"] = max(
                        1,  # ‚úÖ min=1
                        min(int(st.session_state["gpu_n_workers"]), 32),
                    )
                except (TypeError, ValueError):
                    st.session_state["gpu_n_workers"] = gpu_workers_default

            if "gpu_worker_threads" not in st.session_state:
                st.session_state["gpu_worker_threads"] = gpu_threads_default
            else:
                try:
                    st.session_state["gpu_worker_threads"] = max(
                        1,  # ‚úÖ min=1
                        min(int(st.session_state["gpu_worker_threads"]), 32),
                    )
                except (TypeError, ValueError):
                    st.session_state["gpu_worker_threads"] = gpu_threads_default

            # ‚úÖ Pas de param√®tre 'value' - laisse Streamlit utiliser session_state
            gpu_n_workers = st.sidebar.slider(
                "Workers parall√®les (GPU)",
                min_value=1,  # ‚úÖ Corrig√©: 0 invalide, minimum 1 worker requis
                max_value=32,
                help="Nombre de process CPU quand GPU actif (1-2 recommand√©).",
                key="gpu_n_workers",
            )
            gpu_worker_threads = st.sidebar.slider(
                "Threads par worker (GPU)",
                min_value=1,  # ‚úÖ Corrig√©: 0 invalide, minimum 1 thread requis
                max_value=32,
                step=1,
                key="gpu_worker_threads",
                help="Limite threads CPU par worker en mode GPU.",
            )
            os.environ["BACKTEST_GPU_N_WORKERS"] = str(int(gpu_n_workers))
            os.environ["BACKTEST_GPU_WORKER_THREADS"] = str(int(gpu_worker_threads))

            st.sidebar.caption(
                f"GPU: {gpu_n_workers} workers √ó {gpu_worker_threads} threads"
            )

        try:
            from performance.gpu import get_gpu_info, get_gpu_manager
            info = get_gpu_info()
            if info.get("gpu_available"):
                mgr = get_gpu_manager()
                devices = mgr.available_devices
                if devices:
                    options = {}
                    for dev in devices:
                        label = f"GPU {dev['id']} - {dev['name']} ({dev['total_memory_gb']:.1f} GB)"
                        options[label] = dev["id"]
                    labels = list(options.keys())
                    selected_label = st.sidebar.selectbox(
                        "GPU actif",
                        labels,
                        index=0,
                        key="gpu_device_select",
                    )
                    os.environ["BACKTEST_GPU_ID"] = str(options[selected_label])

                st.sidebar.caption(
                    f"GPU: {info.get('cupy_device_name', 'n/a')} "
                    f"| VRAM libre: {info.get('cupy_memory_free_gb', 0):.1f} GB"
                )
            else:
                st.sidebar.warning("GPU non d√©tect√© (CuPy/CUDA manquant ?)")
        except Exception as exc:
            st.sidebar.warning(f"GPU non disponible: {exc}")

        st.sidebar.markdown("---")
        st.sidebar.caption("üß™ Benchmark GPU/CPU (indicateurs)")

        bench_size = st.sidebar.selectbox(
            "Taille benchmark (barres)",
            [5000, 20000, 50000, 100000, 200000],
            index=2,
            key="gpu_bench_size",
        )

        if st.sidebar.button("Lancer benchmark GPU/CPU", key="gpu_bench_run"):
            with st.spinner("Benchmark GPU/CPU en cours..."):
                try:
                    from performance.gpu import benchmark_gpu_cpu
                    bench = benchmark_gpu_cpu(n_samples=int(bench_size), n_runs=3)
                    st.sidebar.success(
                        f"CPU {bench.get('cpu_avg_time', 0):.3f}s | "
                        f"GPU {bench.get('gpu_avg_time', 0):.3f}s | "
                        f"Speedup √ó{bench.get('speedup', 0):.2f}"
                    )
                    st.sidebar.json(bench)
                except Exception as exc:
                    st.sidebar.error(f"Benchmark √©chou√©: {exc}")

        if st.sidebar.button("Benchmark sur donn√©es charg√©es", key="gpu_bench_loaded"):
            df_loaded = st.session_state.get("ohlcv_df")
            if df_loaded is None or df_loaded.empty:
                st.sidebar.warning("Charge d'abord des donn√©es OHLCV.")
            else:
                max_rows = min(len(df_loaded), 100000)
                df_bench = df_loaded.tail(max_rows)
                try:
                    from performance.gpu import GPUIndicatorCalculator, gpu_available
                    import time as _time
                    calc_cpu = GPUIndicatorCalculator(use_gpu=False)
                    calc_gpu = GPUIndicatorCalculator(use_gpu=True, min_samples=0) if gpu_available() else None

                    # CPU
                    t0 = _time.time()
                    calc_cpu.sma(df_bench["close"], 20)
                    calc_cpu.ema(df_bench["close"], 12)
                    calc_cpu.rsi(df_bench["close"], 14)
                    calc_cpu.bollinger_bands(df_bench["close"], 20, 2.0)
                    calc_cpu.atr(df_bench["high"], df_bench["low"], df_bench["close"], 14)
                    cpu_time = _time.time() - t0

                    if calc_gpu is None:
                        st.sidebar.warning("GPU indisponible pour benchmark.")
                    else:
                        t1 = _time.time()
                        calc_gpu.sma(df_bench["close"], 20)
                        calc_gpu.ema(df_bench["close"], 12)
                        calc_gpu.rsi(df_bench["close"], 14)
                        calc_gpu.bollinger_bands(df_bench["close"], 20, 2.0)
                        calc_gpu.atr(df_bench["high"], df_bench["low"], df_bench["close"], 14)
                        gpu_time = _time.time() - t1
                        speedup = cpu_time / gpu_time if gpu_time > 0 else 0.0
                        st.sidebar.success(
                            f"Donn√©es charg√©es: CPU {cpu_time:.3f}s | "
                            f"GPU {gpu_time:.3f}s | Speedup √ó{speedup:.2f}"
                        )
                except Exception as exc:
                    st.sidebar.error(f"Benchmark charg√© √©chou√©: {exc}")

    st.sidebar.subheader("üîß Param√®tres")

    param_mode = "range" if optimization_mode == "Grille de Param√®tres" else "single"

    params: Dict[str, Any] = {}
    param_ranges: Dict[str, Any] = {}
    param_specs: Dict[str, Any] = {}
    strategy_class = get_strategy(strategy_key)
    strategy_instance = None

    if strategy_class:
        temp_strategy = strategy_class()
        strategy_instance = temp_strategy
        param_specs = temp_strategy.parameter_specs or {}
        label_overrides: Dict[str, str] = {}

        if strategy_key == "bollinger_best_longe_3i":
            label_overrides = {
                "entry_level": "Entr√©e",
                "tp_level": "Sortie_gagnante",
                "sl_level": "Stop-loss",
                "bb_std": "Bollinger_amplitude",
                "bb_period": "Bollinger_signal",
            }

        if param_specs:
            validation_errors = []

            for param_name, spec in param_specs.items():
                if not getattr(spec, "optimize", True):
                    continue

                if param_mode == "single":
                    value = create_param_range_selector(
                        param_name,
                        strategy_key,
                        mode="single",
                        spec=spec,
                        label=label_overrides.get(param_name),
                    )
                    if value is not None:
                        params[param_name] = value

                        is_valid, error = validate_param(param_name, value)
                        if not is_valid:
                            validation_errors.append(error)
                else:
                    range_data = create_param_range_selector(
                        param_name,
                        strategy_key,
                        mode="range",
                        spec=spec,
                        label=label_overrides.get(param_name),
                    )
                    if range_data is not None:
                        param_ranges[param_name] = range_data
                        if spec is not None:
                            params[param_name] = spec.default
                        else:
                            params[param_name] = PARAM_CONSTRAINTS[param_name]["default"]
                        # DEBUG: Afficher les ranges g√©n√©r√©s
                        print(f"[DEBUG] param_ranges[{param_name}] = {range_data}")

            if validation_errors:
                for err in validation_errors:
                    st.sidebar.error(err)

            # DEBUG: Afficher le r√©sum√© des param_ranges
            print(f"[DEBUG] param_ranges final = {list(param_ranges.keys())}")
            print(f"[DEBUG] Total param√®tres optimisables: {sum(1 for s in param_specs.values() if getattr(s, 'optimize', True))}")

            if param_mode == "range" and param_ranges:
                st.sidebar.markdown("---")
                stats = compute_search_space_stats(
                    param_ranges,
                    max_combinations=max_combos,
                )

                if stats.is_continuous:
                    st.sidebar.info("‚ÑπÔ∏è Espace continu d√©tect√©")
                elif stats.has_overflow:
                    st.sidebar.warning(
                        f"‚ö†Ô∏è {stats.total_combinations:,} combinaisons (limite: {max_combos:,})"
                    )
                    st.sidebar.caption("R√©duisez les plages ou augmentez le step")
                else:
                    st.sidebar.success(
                        f"‚úÖ {stats.total_combinations:,} combinaisons √† tester"
                    )

                with st.sidebar.expander("üìä D√©tail par param√®tre"):
                    for pname, pcount in stats.per_param_counts.items():
                        st.caption(f"‚Ä¢ {pname}: {pcount} valeurs")
            else:
                st.sidebar.caption("üìä Mode simple: 1 combinaison")
    else:
        st.sidebar.error(f"Strat√©gie '{strategy_key}' non trouv√©e")

    st.sidebar.subheader("üí∞ Trading")

    # Checkbox pour activer/d√©sactiver le leverage
    leverage_enabled = st.sidebar.checkbox(
        "ÔøΩ Activer le leverage",
        value=False,  # D√©sactiv√© par d√©faut = leverage forc√© √† 1
        key="leverage_enabled",
        help="Si d√©coch√©, leverage=1 (sans effet de levier). Recommand√© pour tests s√ªrs.",
    )

    if leverage_enabled:
        leverage = create_param_range_selector("leverage", "trading", mode="single")
        params["leverage"] = leverage
    else:
        leverage = 1.0
        params["leverage"] = 1.0
        st.sidebar.caption("_Leverage d√©sactiv√© ‚Üí forc√© √† 1√ó_")

    initial_capital = st.sidebar.number_input(
        "Capital Initial ($)",
        min_value=1000,
        max_value=1000000,
        value=10000,
        step=1000,
        help="Capital de d√©part (1,000 - 1,000,000)",
    )

    # Liste des param√®tres d√©sactiv√©s (pour transmission au backtest)
    disabled_params: List[str] = []
    if not leverage_enabled:
        disabled_params.append("leverage")

    # Ajouter les indicateurs non coch√©s √† disabled_params (info seulement)
    if available_indicators:
        unchecked_indicators = [ind for ind in available_indicators if ind not in active_indicators]
        if unchecked_indicators:
            st.sidebar.caption(f"_Indicateurs masqu√©s: {', '.join(unchecked_indicators)}_")

    st.sidebar.subheader("üíæ Versioned Presets")

    versioned_presets = list_strategy_versions(strategy_key)

    if "_sync_preset_version" in st.session_state:
        st.session_state["versioned_preset_version"] = st.session_state.pop(
            "_sync_preset_version"
        )
    if "_sync_preset_name" in st.session_state:
        st.session_state["versioned_preset_name"] = st.session_state.pop(
            "_sync_preset_name"
        )

    last_saved = st.session_state.pop("versioned_preset_last_saved", None)
    if last_saved:
        st.sidebar.success(f"Preset saved: {last_saved}")

    if versioned_presets:
        versions = []
        for preset in versioned_presets:
            meta = preset.metadata or {}
            version = meta.get("version")
            if version and version not in versions:
                versions.append(version)

        default_version = resolve_latest_version(strategy_key)
        if default_version in versions:
            default_index = versions.index(default_version)
        else:
            default_index = 0

        if (
            "versioned_preset_version" in st.session_state
            and st.session_state["versioned_preset_version"] not in versions
        ):
            del st.session_state["versioned_preset_version"]

        selected_version = st.sidebar.selectbox(
            "Preset version",
            versions,
            index=default_index,
            key="versioned_preset_version",
        )

        presets_for_version = [
            p for p in versioned_presets if (p.metadata or {}).get("version") == selected_version
        ]
        preset_names = [p.name for p in presets_for_version]

        if (
            "versioned_preset_name" in st.session_state
            and st.session_state["versioned_preset_name"] not in preset_names
        ):
            del st.session_state["versioned_preset_name"]

        selected_preset_name = st.sidebar.selectbox(
            "Preset",
            preset_names,
            key="versioned_preset_name",
        )

        selected_preset = next(
            (p for p in presets_for_version if p.name == selected_preset_name),
            None,
        )

        if selected_preset is not None:
            meta = selected_preset.metadata or {}
            created_at = meta.get("created_at", "")
            if created_at:
                st.sidebar.caption(f"Created: {created_at}")

            indicators = selected_preset.indicators or []
            if indicators:
                st.sidebar.caption(f"Indicators: {', '.join(indicators)}")

            params_values = selected_preset.get_default_values()
            if params_values:
                st.sidebar.json(params_values)

            metrics = meta.get("metrics") or {}
            summary_keys = [
                "sharpe_ratio",
                "total_return_pct",
                "max_drawdown",
                "win_rate",
            ]
            summary = {k: metrics.get(k) for k in summary_keys if k in metrics}
            if summary:
                st.sidebar.json(summary)

        if st.sidebar.button("‚¨áÔ∏è Charger versioned preset", key="load_versioned_preset"):
            try:
                loaded_preset = load_strategy_version(
                    strategy_name=strategy_key,
                    version=selected_version,
                    preset_name=selected_preset_name,
                )
                apply_versioned_preset(loaded_preset, strategy_key)
                st.session_state["loaded_versioned_preset"] = loaded_preset.to_dict()
                st.sidebar.success("Versioned preset loaded")
                st.rerun()
            except Exception as exc:
                st.sidebar.error(f"Failed to load preset: {exc}")
    else:
        st.sidebar.caption("No versioned presets found.")

    render_saved_runs_panel(
        st.session_state.get("last_run_result"),
        strategy_key,
        symbol,
        timeframe,
    )

    # Multi-sweep lists (symbols et timeframes d√©j√† d√©finis par multiselect)
    # strategy_keys et all_params/ranges/specs bas√©s sur s√©lection simple de strat√©gie
    strategy_keys = [strategy_key]
    all_params = {strategy_key: params}
    all_param_ranges = {strategy_key: param_ranges}
    all_param_specs = {strategy_key: param_specs}

    draft_state = SidebarState(
        debug_enabled=debug_enabled,
        symbol=symbol,
        timeframe=timeframe,
        use_date_filter=use_date_filter,
        start_date=start_date,
        end_date=end_date,
        available_tokens=available_tokens,
        available_timeframes=available_timeframes,
        strategy_key=strategy_key,
        strategy_name=strategy_name,
        strategy_info=strategy_info,
        strategy_instance=strategy_instance,
        params=params,
        param_ranges=param_ranges,
        param_specs=param_specs,
        active_indicators=active_indicators,
        optimization_mode=optimization_mode,
        max_combos=max_combos,
        n_workers=n_workers,
        # Multi-sweep lists
        symbols=symbols,
        timeframes=timeframes,
        strategy_keys=strategy_keys,
        all_params=all_params,
        all_param_ranges=all_param_ranges,
        all_param_specs=all_param_specs,
        # Optuna
        use_optuna=use_optuna,
        optuna_n_trials=optuna_n_trials,
        optuna_sampler=optuna_sampler,
        optuna_pruning=optuna_pruning,
        optuna_metric=optuna_metric,
        optuna_early_stop=optuna_early_stop,
        llm_config=llm_config,
        llm_model=llm_model,
        llm_use_multi_agent=llm_use_multi_agent,
        role_model_config=role_model_config,
        llm_max_iterations=llm_max_iterations,
        llm_use_walk_forward=llm_use_walk_forward,
        llm_unload_during_backtest=llm_unload_during_backtest,
        llm_compare_enabled=llm_compare_enabled,
        llm_compare_auto_run=llm_compare_auto_run,
        llm_compare_strategies=llm_compare_strategies,
        llm_compare_tokens=llm_compare_tokens,
        llm_compare_timeframes=llm_compare_timeframes,
        llm_compare_metric=llm_compare_metric,
        llm_compare_aggregate=llm_compare_aggregate,
        llm_compare_max_runs=llm_compare_max_runs,
        llm_compare_use_preset=llm_compare_use_preset,
        llm_compare_generate_report=llm_compare_generate_report,
        initial_capital=initial_capital,
        leverage=leverage,
        leverage_enabled=leverage_enabled,
        disabled_params=disabled_params,
    )

    applied_state = _apply_config_guard(draft_state)
    pending = st.session_state.get("config_pending_changes", False)

    run_label_map = {
        "Backtest Simple": "üöÄ Lancer le Backtest",
        "Grille de Param√®tres": "üß™ Lancer le Sweep",
        "ü§ñ Optimisation LLM": "üß† Lancer l'it√©ration LLM",
    }
    run_label = run_label_map.get(
        st.session_state.optimization_mode,
        "üöÄ Lancer le Backtest",
    )

    def _apply_pending_config() -> None:
        st.session_state["applied_config_signature"] = st.session_state.get(
            "draft_config_signature"
        )
        st.session_state["applied_sidebar_state"] = draft_state
        st.session_state["config_pending_changes"] = False

    with action_slot:
        st.markdown("---")
        st.caption("Actions")

        col_load, col_run = st.columns(2)
        with col_load:
            if st.button(
                "‚¨áÔ∏è Charger donn√©es",
                key="load_ohlcv_action",
                disabled=st.session_state.is_running,
                use_container_width=True,
            ):
                if pending:
                    _apply_pending_config()
                df_loaded, msg = load_selected_data(
                    symbol, timeframe, start_date, end_date
                )
                if df_loaded is None:
                    st.error(f"Erreur chargement: {msg}")
                else:
                    st.success(f"Donn√©es charg√©es: {msg}")

        with col_run:
            if st.button(
                run_label,
                key="run_sidebar_action",
                type="primary",
                disabled=st.session_state.is_running,
                use_container_width=True,
            ):
                if pending:
                    _apply_pending_config()
                st.session_state.run_backtest_requested = True
                st.rerun()

        if pending:
            st.warning(
                "‚ö†Ô∏è Modifications non appliqu√©es (seront appliqu√©es au lancement/chargement)"
            )
        else:
            st.caption("‚úÖ Configuration pr√™te.")

    return applied_state