# Diagnostic CPU-Only Mode - Rapport de Cartographie

**Date**: 6 f√©vrier 2026
**Objectif**: Rendre le mode CPU-only 100% propre (z√©ro init CUDA / z√©ro VRAM touch√©e)

## üìä Cartographie des Touchpoints GPU/CUDA

### R√©sum√© Ex√©cutif

| Cat√©gorie | Fichiers | Statut | Priorit√© |
|-----------|----------|--------|----------|
| **Imports conditionnels CuPy** | 26 fichiers | ‚ö†Ô∏è √Ä prot√©ger | HAUTE |
| **D√©tection GPU automatique** | 4 modules | ‚ö†Ô∏è √Ä d√©sactiver | HAUTE |
| **Imports implicites dans __init__** | 2 fichiers | ‚ùå CRITIQUE | CRITIQUE |
| **Cache Numba versionn√©** | `.numba_cache/` | ‚ùå √Ä nettoyer | MOYENNE |
| **Scripts tools GPU** | 0 trouv√©s | ‚úÖ OK | BASSE |

---

## üîç Analyse D√©taill√©e

### 1. Configuration Actuelle

**Performance/gpu.py** (ligne 33-36):
```python
# D√©sactivation forc√©e du GPU : op√©ration CPU-only (RAM)
GPU_DISABLED = True
HAS_CUPY = False
cp = None
```

‚úÖ **Bon point**: Variable `GPU_DISABLED` d√©j√† pr√©sente
‚ùå **Probl√®me**: Pas respect√©e ailleurs dans le code

### 2. Imports CuPy (26 fichiers d√©tect√©s)

#### CRITIQUE - Imports implicites dans __init__.py

**performance/__init__.py** (ligne 22):
```python
from performance.gpu import (
    GPUIndicatorCalculator,
    benchmark_gpu_cpu,
    get_gpu_info,
    gpu_available,
    to_cpu,
    to_gpu,
)
```

**Impact**: Importer `performance` d√©clenche automatiquement le chargement de `gpu.py`
**Solution**: Lazy import ou suppression de l'import automatique

#### Imports conditionnels (24 autres fichiers)

| Module | Type Import | Dangerosit√© | Note |
|--------|-------------|-------------|------|
| `performance/device_backend.py` | Lazy (L99, L182, L383, L391, L400, L421) | ‚úÖ OK | Imports dans fonctions |
| `performance/benchmark.py` | Lazy (L358) | ‚úÖ OK | Fonction isol√©e |
| `performance/hybrid_compute.py` | Lazy (L252, L353) | ‚úÖ OK | Contexte isol√© |
| `utils/gpu_utils.py` | Top-level (L28) | ‚ö†Ô∏è MOYEN | Mais avec `HAS_CUPY` guard |
| `utils/gpu_oom.py` | Dans docstrings (L83, L116, L133...) | ‚úÖ OK | Exemples seulement |
| `utils/error_recovery.py` | Lazy (L328, L434) | ‚úÖ OK | Fonction de fallback |
| `cli/commands.py` | Lazy (L1633) | ‚úÖ OK | Commande check-gpu uniquement |
| `ui/helpers.py`, `ui/helpers_backup.py` | Lazy (L1131, L1141) | ‚úÖ OK | Diagnostic UI |
| `ui/emergency_stop.py` | Lazy (L235) | ‚úÖ OK | Cleanup emergency |

**Conclusion**: La plupart des imports sont **lazy** (dans fonctions), ce qui est bien. Le probl√®me majeur est `performance/__init__.py`.

### 3. D√©tection GPU Automatique

#### device_backend.py (ligne 93-130)

```python
def _try_init_gpu(self) -> bool:
    """Tente d'initialiser le support GPU."""
    # V√©rifier si d√©sactiv√© par env var
    if os.environ.get("BACKTEST_DISABLE_GPU", "").lower() in ("1", "true", "yes"):
        logger.info("GPU d√©sactiv√© par BACKTEST_DISABLE_GPU")
        self._setup_cpu()
        return False

    try:
        import cupy as cp
        # ...
```

‚úÖ **Bon point**: Variable d'environnement `BACKTEST_DISABLE_GPU` d√©j√† pr√©sente
‚ùå **Probl√®me**: Appel de `_try_init_gpu()` dans `__init__()` m√™me en mode CPU-only

#### GPUDeviceManager (performance/gpu.py, ligne 47-90)

```python
def __init__(self):
    if GPUDeviceManager._initialized:
        return

    # ...
    if HAS_CUPY:
        self._detect_devices()
        self._select_best_device()
```

‚úÖ **Bon point**: Guard `if HAS_CUPY` pr√©sent
‚ùå **Probl√®me**: `GPUDeviceManager` instanci√© m√™me si GPU_DISABLED

### 4. Chemins "Fast" (Numba CPU, pas GPU)

**backtest/execution_fast.py** et **backtest/simulator_fast.py**:

‚úÖ **EXCELLENT**: Ces fichiers utilisent **Numba CPU uniquement** (`@njit`, pas de CUDA)
‚úÖ **Pas de probl√®me**: `HAS_NUMBA` d√©tecte l'installation, mais reste CPU-only

```python
try:
    from numba import njit
    HAS_NUMBA = True
except ImportError:
    HAS_NUMBA = False
```

### 5. Cache Numba

```bash
Test-Path .numba_cache
# Output: True
```

‚ùå **Probl√®me**: Cache Numba versionn√© dans le repo
**Impact**: Pollution du repo, cache peut contenir des artefacts GPU
**Solution**: Ajouter √† `.gitignore` et supprimer du suivi

### 6. Scripts Tools GPU

**Fichiers mentionn√©s dans la demande**: NON TROUV√âS
- `check_gpu.py`: ‚ùå N'existe pas
- `test_cpu_gpu_parallel.py`: ‚ùå N'existe pas
- `configure_ollama_multigpu.py`: ‚ùå N'existe pas

**Fichiers existants**:
- `tools/benchmark_system.py`: ‚úÖ Pr√©sent, aucun import GPU direct

**Conclusion**: Scripts GPU tools mentionn√©s n'existent pas dans le repo actuel.

### 7. Variables d'Environnement Existantes

Aucun fichier `.env` trouv√©, mais variables utilis√©es dans le code:

| Variable | Usage | Fichier |
|----------|-------|---------|
| `BACKTEST_DISABLE_GPU` | D√©sactive GPU | `device_backend.py` L95 |
| `BACKTEST_GPU_ID` | Force GPU sp√©cifique | `gpu.py` L135 |
| `CUDA_VISIBLE_DEVICES` | Limite GPUs visibles | Commentaire `gpu.py` L57 |

---

## üéØ Probl√®mes Identifi√©s (par priorit√©)

### CRITIQUE ‚ùå

1. **Import implicite dans performance/__init__.py**
   - Fichier: `performance/__init__.py` ligne 22
   - Probl√®me: `from performance.gpu import ...` ex√©cut√© √† l'import du package
   - Impact: Charger `performance` = tenter de d√©tecter GPU
   - Solution: Supprimer ou lazy import

### HAUTE ‚ö†Ô∏è

2. **device_backend.py initialise GPU dans __init__()**
   - Fichier: `performance/device_backend.py` ligne 86
   - Probl√®me: `_try_init_gpu()` appel√© syst√©matiquement
   - Impact: Tente import CuPy m√™me si mode CPU-only souhait√©
   - Solution: V√©rifier variable backend AVANT import

3. **Pas de m√©canisme BACKTEST_BACKEND centralis√©**
   - Probl√®me: Logique √©parpill√©e (`GPU_DISABLED`, `BACKTEST_DISABLE_GPU`)
   - Impact: Incoh√©rence, confusion, maintenance difficile
   - Solution: Variable unique `BACKTEST_BACKEND=cpu|gpu|auto`

4. **GPUDeviceManager instanci√© sans raison**
   - Fichier: `performance/gpu.py` ligne 74
   - Probl√®me: Singleton cr√©√© m√™me si `GPU_DISABLED=True`
   - Impact: Code mort, overhead minimal mais confus
   - Solution: Lazy singleton uniquement si backend=gpu

### MOYENNE üü°

5. **Cache Numba versionn√©**
   - Fichier: `.numba_cache/`
   - Probl√®me: Dossier dans le repo (test via `Test-Path`)
   - Impact: Pollution, cache peut contenir code GPU
   - Solution: `.gitignore` + `git rm --cached`

6. **Numba parallel=True sans contr√¥le workers**
   - Fichier: `backtest/sweep_numba.py` (mentionn√© dans AGENTS.md)
   - Probl√®me: Threads Numba * workers ProcessPool = oversubscription
   - Impact: Saturation CPU, performances d√©grad√©es
   - Solution: `NUMBA_NUM_THREADS=1` dans workers, ou d√©sactiver parallel

---

## üöÄ Solutions Propos√©es

### √âtape B - Backend Selection (Patch minimal)

**1. Cr√©er utils/backend_config.py** (nouveau fichier)

```python
"""Configuration centralis√©e du backend de calcul."""
import os
from enum import Enum

class BackendType(Enum):
    CPU = "cpu"
    GPU = "gpu"
    AUTO = "auto"

_BACKEND = None

def get_backend() -> BackendType:
    """Retourne le backend configur√©."""
    global _BACKEND
    if _BACKEND is None:
        env = os.environ.get("BACKTEST_BACKEND", "cpu").lower()
        if env == "gpu":
            _BACKEND = BackendType.GPU
        elif env == "auto":
            _BACKEND = BackendType.AUTO
        else:
            _BACKEND = BackendType.CPU
    return _BACKEND

def is_gpu_enabled() -> bool:
    """True si GPU peut √™tre utilis√©."""
    backend = get_backend()
    if backend == BackendType.CPU:
        return False
    return True  # AUTO ou GPU
```

**2. Modifier performance/__init__.py** (suppression imports GPU)

```python
# AVANT (ligne 22-29):
from performance.gpu import (
    GPUIndicatorCalculator,
    benchmark_gpu_cpu,
    get_gpu_info,
    gpu_available,
    to_cpu,
    to_gpu,
)

# APR√àS:
# Imports GPU supprim√©s (lazy import uniquement)
# Utiliser: from performance.gpu import gpu_available
```

**3. Modifier performance/device_backend.py** (lazy GPU)

```python
# AVANT (ligne 86):
def __init__(self):
    if self._initialized:
        return
    # ...
    self._try_init_gpu()
    self._initialized = True

# APR√àS:
def __init__(self):
    if self._initialized:
        return
    # ...
    from utils.backend_config import is_gpu_enabled
    if is_gpu_enabled():
        self._try_init_gpu()
    else:
        self._setup_cpu()
    self._initialized = True
```

**4. Modifier performance/gpu.py** (lazy singleton)

```python
# AVANT (ligne 250):
_gpu_manager: Optional[GPUDeviceManager] = None

# APR√àS:
_gpu_manager: Optional[GPUDeviceManager] = None

def get_gpu_manager() -> Optional[GPUDeviceManager]:
    """Lazy singleton GPU manager."""
    global _gpu_manager
    if _gpu_manager is None and HAS_CUPY:
        from utils.backend_config import is_gpu_enabled
        if is_gpu_enabled():
            _gpu_manager = GPUDeviceManager()
    return _gpu_manager
```

**5. Ajouter √† .gitignore**

```
# Numba cache
.numba_cache/
__pycache__/
*.pyc

# Old venvs
.venv_old/
```

**6. Nettoyer cache Numba**

```powershell
git rm -r --cached .numba_cache/
```

**7. Contr√¥ler Numba dans workers**

Dans `backtest/worker.py` (ou fichier d'init workers):

```python
def init_worker_with_dataframe(...):
    # Limiter Numba √† 1 thread dans workers
    os.environ["NUMBA_NUM_THREADS"] = "1"
    os.environ["OMP_NUM_THREADS"] = "1"
    # ...
```

---

## ‚úÖ Tests de Non-R√©gression Propos√©s

### Test 1: Mode CPU strict

```python
# tests/test_backend_cpu_only.py
import os
import sys
import pytest

def test_cpu_only_does_not_import_torch_cuda():
    """V√©rifie que mode CPU-only ne touche pas torch/cuda."""
    os.environ["BACKTEST_BACKEND"] = "cpu"

    # Import principal
    import performance

    # V√©rifications
    assert "torch" not in sys.modules
    assert "cupy" not in sys.modules
    assert "numba.cuda" not in sys.modules

def test_cpu_only_backend_selection():
    """V√©rifie s√©lection backend CPU."""
    os.environ["BACKTEST_BACKEND"] = "cpu"

    from utils.backend_config import get_backend, BackendType
    assert get_backend() == BackendType.CPU

def test_device_backend_respects_cpu_mode():
    """V√©rifie device_backend reste CPU."""
    os.environ["BACKTEST_BACKEND"] = "cpu"

    from performance.device_backend import ArrayBackend
    backend = ArrayBackend()

    assert backend.device_type.value == "cpu"
    assert not backend.gpu_available
```

### Test 2: Mode GPU optionnel

```python
def test_gpu_mode_requires_explicit_flag():
    """GPU activ√© uniquement si BACKTEST_BACKEND=gpu."""
    os.environ["BACKTEST_BACKEND"] = "gpu"

    from utils.backend_config import is_gpu_enabled
    assert is_gpu_enabled()

@pytest.mark.skipif(not HAS_CUPY, reason="CuPy non install√©")
def test_gpu_mode_validates_cuda():
    """Mode GPU doit valider CUDA disponible."""
    os.environ["BACKTEST_BACKEND"] = "gpu"

    from performance.device_backend import ArrayBackend
    backend = ArrayBackend()

    # Si CUDA absent, doit fallback CPU ou raise
    assert backend.device_type.value in ("cpu", "gpu")
```

---

## üìà Impact Performance Estim√©

| Modification | Overhead CPU-only | Gain |
|--------------|-------------------|------|
| Supprimer import GPU dans __init__ | **0ms** | ‚úÖ Pas d'init CuPy |
| Backend config (1 read env var) | **<0.1ms** | ‚úÖ N√©gligeable |
| Lazy GPU manager | **0ms** | ‚úÖ Pas d'instanciation |
| Numba 1 thread dans workers | **0ms** | ‚úÖ √âvite oversubscription |

**Conclusion**: **Z√âRO overhead** dans le chemin CPU-only.

---

## üéØ Checklist d'Acceptation

- [ ] `BACKTEST_BACKEND=cpu` ne charge jamais CuPy
- [ ] `sys.modules` ne contient ni `torch` ni `cupy` apr√®s import
- [ ] Tests unitaires passent (nouveaux tests ajout√©s)
- [ ] `.numba_cache/` retir√© du suivi git
- [ ] Documentation backend selection ajout√©e
- [ ] Performance CPU-only inchang√©e (benchmark avant/apr√®s)
- [ ] Mode GPU reste fonctionnel (BACKTEST_BACKEND=gpu|auto)

---

## üìù Documentation Utilisateur

**Nouveau fichier**: `docs/BACKEND_SELECTION.md`

```markdown
# Backend Selection: CPU / GPU / Auto

## Configuration

Variable d'environnement: `BACKTEST_BACKEND`

| Valeur | Comportement |
|--------|--------------|
| `cpu` | **CPU-only strict** (d√©faut) - Aucun GPU utilis√© |
| `gpu` | **GPU requis** - Erreur si CUDA absent |
| `auto` | **D√©tection auto** - GPU si disponible, sinon CPU |

## Exemples

### Mode CPU-only (recommand√©)
```powershell
$env:BACKTEST_BACKEND = "cpu"
python run_backtest.py
```

### Mode GPU
```powershell
$env:BACKTEST_BACKEND = "gpu"
python run_backtest.py
```

### Mode Auto (legacy)
```powershell
$env:BACKTEST_BACKEND = "auto"
python run_backtest.py
```

## Diagnostic

```powershell
# V√©rifier backend actif
python -c "from utils.backend_config import get_backend; print(get_backend())"
```
```

---

## üî¨ Validation Finale

**Commandes de test**:

```powershell
# 1. Mode CPU strict
$env:BACKTEST_BACKEND = "cpu"
python -c "import performance; import sys; assert 'cupy' not in sys.modules"

# 2. Lancer tests
pytest tests/test_backend_cpu_only.py -v

# 3. Benchmark avant/apr√®s
python tools/benchmark_system.py

# 4. V√©rifier .gitignore
git status .numba_cache/  # Doit √™tre ignor√©
```

---

## üìä M√©triques de Succ√®s

| Crit√®re | Objectif | Validation |
|---------|----------|------------|
| Init CUDA en mode CPU | **0 appels** | `assert 'cupy' not in sys.modules` |
| VRAM touch√©e | **0 bytes** | nvidia-smi avant/apr√®s |
| Overhead CPU-only | **<1ms** | Benchmark diff |
| Tests passent | **100%** | pytest --tb=short |
| Code modifi√© | **<200 lignes** | git diff --stat |

---

**Signature**: Claude (GitHub Copilot)
**Date**: 6 f√©vrier 2026
