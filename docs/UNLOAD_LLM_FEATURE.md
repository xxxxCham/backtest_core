# Variable d'Environnement UNLOAD_LLM_DURING_BACKTEST

## Vue d'Ensemble

La variable d'environnement `UNLOAD_LLM_DURING_BACKTEST` permet de contr√¥ler le d√©chargement du mod√®le LLM de la m√©moire GPU pendant les backtests autonomes.

**Valeur par d√©faut** : `False` (compatible CPU-only)

---

## üéØ Objectif

### Probl√®me Initial
Lors des backtests autonomes avec agents LLM, le mod√®le LLM reste en VRAM GPU, limitant l'espace disponible pour les calculs NumPy/CuPy intensifs.

### Solution
D√©charger temporairement le LLM du GPU pendant les calculs de backtest :
1. **D√©charge** : LLM quitt√© du GPU ‚Üí VRAM libre
2. **Calculs** : Backtest avec 100% VRAM disponible
3. **Recharge** : LLM ramen√© en GPU pour prochaine it√©ration

---

## üìä Impact Performance

### Avec UNLOAD_LLM=True (GPU Optimization)
- ‚úÖ **VRAM libre** : 100% disponible pour calculs
- ‚úÖ **Pas d'OOM** : √âvite les erreurs Out-of-Memory
- ‚ö†Ô∏è **Latence** : +2-5s par it√©ration (rechargement mod√®le)

**Recommand√© pour** :
- GPU avec VRAM limit√©e (< 12 GB)
- Mod√®les LLM volumineux (> 4 GB)
- Backtests sur grandes s√©ries (> 100k bars)

### Avec UNLOAD_LLM=False (Default)
- ‚úÖ **Pas de latence** : LLM reste en m√©moire
- ‚úÖ **It√©rations rapides** : 0s overhead
- ‚ö†Ô∏è **VRAM partag√©e** : Risque d'OOM sur petites GPU

**Recommand√© pour** :
- Syst√®mes CPU-only (majorit√© des utilisateurs)
- GPU avec VRAM abondante (> 16 GB)
- Mod√®les LLM petits (< 2 GB)
- Backtests sur petites s√©ries (< 50k bars)

---

## üîß Configuration

### M√©thode 1 : Fichier .env

```bash
# .env
UNLOAD_LLM_DURING_BACKTEST=False  # Default, CPU-compatible
```

ou

```bash
# .env
UNLOAD_LLM_DURING_BACKTEST=True   # GPU optimization
```

### M√©thode 2 : Variable d'Environnement

**PowerShell** :
```powershell
$env:UNLOAD_LLM_DURING_BACKTEST = "True"
```

**Linux/Mac** :
```bash
export UNLOAD_LLM_DURING_BACKTEST=True
```

### M√©thode 3 : Param√®tre Python

```python
from agents import create_optimizer_from_engine
from agents.llm_client import LLMConfig, LLMProvider

config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
strategist, executor = create_optimizer_from_engine(
    llm_config=config,
    strategy_name="ema_cross",
    data=df,
    unload_llm_during_backtest=True,  # Override env var
)
```

---

## üí° Valeurs Accept√©es

### True (D√©chargement activ√©)
- `True` (case-insensitive)
- `1`
- `yes` (case-insensitive)

### False (D√©chargement d√©sactiv√©)
- `False` (case-insensitive)
- `0`
- `no` (case-insensitive)
- *(non d√©finie)* ‚Üí Default = False

---

## üß™ Tests

10 tests unitaires valident le comportement :

```bash
python -m pytest tests/test_unload_llm_env.py -v
```

**Tests couverts** :
1. ‚úÖ Valeur par d√©faut `False` si variable non d√©finie
2. ‚úÖ Parsing `True`, `1`, `yes` ‚Üí True
3. ‚úÖ Parsing `False`, `0`, `no` ‚Üí False
4. ‚úÖ Case-insensitivity (`TRUE`, `true`, `True`)
5. ‚úÖ Override par param√®tre explicite
6. ‚úÖ Appel `GPUMemoryManager` si True
7. ‚úÖ Pas d'appel `GPUMemoryManager` si False

**R√©sultat** :
```
10 passed in 2.84s ‚úÖ
```

---

## üìö Impl√©mentation

### Fichiers Modifi√©s

1. **`agents/autonomous_strategist.py`**
   - Lecture de `UNLOAD_LLM_DURING_BACKTEST`
   - Logique conditionnelle dans `_run_backtest_with_gpu_optimization()`
   - Correction bug : `self.llm_client` ‚Üí `self.llm`

2. **`.env.example`**
   - Documentation de la variable
   - Valeur par d√©faut : `False`

3. **`ENVIRONMENT.md`**
   - Section compl√®te sur GPU Memory Management
   - Exemples CPU-only vs GPU systems
   - Troubleshooting OOM

### Fichiers Cr√©√©s

1. **`tests/test_unload_llm_env.py`** (250 lignes)
   - 10 tests unitaires
   - Validation comportement complet

---

## üêõ Troubleshooting

### Probl√®me : Latence importante entre it√©rations

**Cause** : `UNLOAD_LLM_DURING_BACKTEST=True` sur syst√®me CPU-only  
**Solution** : `UNLOAD_LLM_DURING_BACKTEST=False`

**V√©rification** :
```python
import os
print(os.getenv('UNLOAD_LLM_DURING_BACKTEST', 'NOT_SET'))
```

### Probl√®me : OOM (Out of Memory) GPU

**Cause** : `UNLOAD_LLM_DURING_BACKTEST=False` avec GPU trop petite  
**Solution** : `UNLOAD_LLM_DURING_BACKTEST=True`

**V√©rification VRAM** :
```bash
nvidia-smi
```

### Probl√®me : Variable ignor√©e

**Cause** : Param√®tre explicite override la variable d'env  
**Solution** : Passer `unload_llm_during_backtest=None` pour auto-d√©tection

---

## üìñ Documentation Compl√®te

| Fichier | Description |
|---------|-------------|
| [ENVIRONMENT.md](ENVIRONMENT.md) | Documentation toutes variables d'env |
| [.env.example](.env.example) | Template configuration |
| [LLM_INTEGRATION_README.md](LLM_INTEGRATION_README.md) | Guide complet agents LLM |

---

## üîÑ Workflow Typique

### Sc√©nario 1 : D√©veloppement Local (CPU-only)

```bash
# .env
UNLOAD_LLM_DURING_BACKTEST=False  # Pas de latence
```

**R√©sultat** :
- It√©rations rapides
- Pas d'overhead
- Compatible tous syst√®mes

### Sc√©nario 2 : Production GPU (VRAM limit√©e)

```bash
# .env
UNLOAD_LLM_DURING_BACKTEST=True   # Lib√®re VRAM
```

**R√©sultat** :
- 100% VRAM pour backtests
- Pas d'OOM
- +2-5s par it√©ration acceptable

### Sc√©nario 3 : Benchmarking

```bash
# Tester les deux modes
UNLOAD_LLM_DURING_BACKTEST=False python benchmark.py
UNLOAD_LLM_DURING_BACKTEST=True python benchmark.py

# Comparer temps total et pics m√©moire
```

---

## üéì R√©f√©rences

### Code Source
- `agents/autonomous_strategist.py` lignes 180-250
- `agents/ollama_manager.py` (GPUMemoryManager)

### Tests
- `tests/test_unload_llm_env.py`

### Documentation
- [ENVIRONMENT.md](ENVIRONMENT.md) section "GPU Memory Management"
- [README.md](README.md) section "Configuration Critique"

---

*Feature impl√©ment√©e : 13/12/2025*  
*Tests : 10/10 passants ‚úÖ*
