# Correction Configuration GPU - RÃ©sumÃ©

**Date**: 2026-01-06
**Objectif**: Corriger la rÃ©partition GPU pour prioriser RTX 5080 (GPU 0) sur RTX 2060 (GPU 1)

---

## ğŸ” ProblÃ¨me DÃ©tectÃ©

### Configuration GPU RÃ©elle (nvidia-smi)
```
GPU 0 = RTX 5080 (16 GB VRAM)          â† GPU PRIORITAIRE
GPU 1 = RTX 2060 SUPER (8 GB VRAM)     â† GPU SECONDAIRE
GPU 2 = AMD iGPU (NON VISIBLE)         â† Pas CUDA, ignorÃ©e automatiquement
```

### Erreurs IdentifiÃ©es

1. **Indices GPU inversÃ©s** dans les commentaires des scripts
   - âŒ Commentaires disaient "GPU 1 = RTX 5080" (FAUX)
   - âœ… RÃ©alitÃ©: GPU 0 = RTX 5080

2. **Ordre de prioritÃ© inversÃ©**
   - âŒ `CUDA_VISIBLE_DEVICES="1,0"` â†’ RTX 2060 en premier
   - âœ… Devrait Ãªtre `"0,1"` â†’ RTX 5080 en premier

3. **DÃ©tection incorrecte du nombre de GPUs**
   - Risque de dÃ©tecter 3 GPUs au lieu de 2 (si iGPU visible)

---

## âœ… Corrections AppliquÃ©es

### 1. **tests/Start-OllamaMultiGPU.ps1**
```diff
- # GPU 1 (RTX 5080) = Primaire
- # GPU 0 (RTX 2060 SUPER) = Secondaire
- $env:CUDA_VISIBLE_DEVICES = "1,0"
+ # GPU 0 (RTX 5080) = Primaire
+ # GPU 1 (RTX 2060 SUPER) = Secondaire
+ $env:CUDA_VISIBLE_DEVICES = "0,1"  # RTX 5080 en premier âœ…
```

### 2. **run_streamlit_multigpu.bat**
```diff
- set CUDA_VISIBLE_DEVICES=1,0
+ set CUDA_VISIBLE_DEVICES=0,1
```

### 3. **.vscode/launch.json**
```diff
- "CUDA_VISIBLE_DEVICES": "1,0"
+ "CUDA_VISIBLE_DEVICES": "0,1"
```

### 4. **tests/configure_ollama_multigpu.py**

**a) Fonction `get_gpu_count()` - Filtrage iGPU**
```diff
def get_gpu_count():
-   """Retourne le nombre de GPUs disponibles."""
+   """Retourne le nombre de GPUs CUDA disponibles (ignore iGPU)."""
    try:
        result = subprocess.run(
-           ["nvidia-smi", "--list-gpus"],
+           ["nvidia-smi", "--query-gpu=index,name", "--format=csv,noheader"],
            ...
        )
+       # Filtrer uniquement les GPUs NVIDIA (ignore AMD iGPU)
+       lines = result.stdout.strip().split('\n')
+       cuda_gpus = [line for line in lines if line and 'NVIDIA' in line]
+       return len(cuda_gpus)
```

**b) Fonction `set_environment_variables()` - Documentation**
```diff
+ # CUDA_VISIBLE_DEVICES : tous les GPUs CUDA (0 = RTX 5080, 1 = RTX 2060)
+ # PrioritÃ© : GPU 0 (plus puissante) en premier
  gpu_ids = ",".join(str(i) for i in range(num_gpu))
```

### 5. **restart_ollama_multigpu.bat** âœ…
- DÃ©jÃ  correct (`CUDA_VISIBLE_DEVICES=0,1`)
- Aucune modification nÃ©cessaire

---

## ğŸ¯ RÃ©sultat Final

### Configuration GPU Correcte
```bash
CUDA_VISIBLE_DEVICES=0,1
```

**Ordre d'utilisation par Ollama** :
1. **GPU 0 (RTX 5080)** - 16 GB VRAM - Charge principale
2. **GPU 1 (RTX 2060)** - 8 GB VRAM - Charge secondaire
3. **iGPU AMD** - IgnorÃ©e (pas CUDA)

### Variables d'Environnement Multi-GPU
```bash
CUDA_VISIBLE_DEVICES=0,1      # RTX 5080 + RTX 2060
OLLAMA_NUM_GPU=2              # 2 GPUs actifs
OLLAMA_GPU_OVERHEAD=0         # Pas d'overhead
OLLAMA_MAX_LOADED_MODELS=1    # 1 modÃ¨le Ã  la fois
OLLAMA_FLASH_ATTENTION=1      # Flash Attention activÃ©
```

---

## ğŸ§ª Tests RecommandÃ©s

### 1. VÃ©rifier la configuration GPU
```bash
nvidia-smi --query-gpu=index,name,memory.total --format=csv
```

**Sortie attendue** :
```
index, name, memory.total [MiB]
0, NVIDIA GeForce RTX 5080, 16303 MiB
1, NVIDIA GeForce RTX 2060 SUPER, 8192 MiB
```

### 2. Tester Ollama Multi-GPU
```powershell
# DÃ©marrer Ollama avec configuration corrigÃ©e
.\tests\Start-OllamaMultiGPU.ps1

# Dans un autre terminal
nvidia-smi -l 1

# Lancer un modÃ¨le 70B
ollama run llama3.3-70b-2gpu "Analyse le marchÃ© Bitcoin"
```

**VÃ©rifier** :
- GPU 0 et GPU 1 montrent activitÃ© dans nvidia-smi
- VRAM utilisÃ©e sur les 2 GPUs
- GPU 0 a plus de charge que GPU 1 (car prioritaire)

### 3. Tester Streamlit
```batch
run_streamlit_multigpu.bat
```

VÃ©rifier dans l'UI :
- ModÃ¨les chargÃ©s correctement
- Backtests utilisent GPU 0 en prioritÃ©
- Multi-GPU fonctionne pour gros modÃ¨les

---

## ğŸ“Š Impact Attendu

### Performances
- âœ… **GPU 0 (RTX 5080)** utilisÃ©e en prioritÃ© (16 GB > 8 GB)
- âœ… Meilleure rÃ©partition charge pour modÃ¨les 70B
- âœ… Backtests plus rapides (GPU la plus puissante en premier)

### StabilitÃ©
- âœ… Plus de confusion sur indices GPU
- âœ… iGPU correctement ignorÃ©e
- âœ… Configuration cohÃ©rente dans tous les scripts

---

## ğŸ”— Fichiers ModifiÃ©s

| Fichier | Modification | Statut |
|---------|--------------|--------|
| `tests/Start-OllamaMultiGPU.ps1` | CUDA_VISIBLE_DEVICES + commentaires | âœ… CorrigÃ© |
| `run_streamlit_multigpu.bat` | CUDA_VISIBLE_DEVICES | âœ… CorrigÃ© |
| `.vscode/launch.json` | CUDA_VISIBLE_DEVICES | âœ… CorrigÃ© |
| `tests/configure_ollama_multigpu.py` | Filtrage iGPU + docs | âœ… CorrigÃ© |
| `restart_ollama_multigpu.bat` | Aucune | âœ… DÃ©jÃ  correct |

---

## ğŸ’¡ Notes Importantes

1. **iGPU AMD** : Non visible par nvidia-smi, donc jamais utilisÃ©e par CUDA/Ollama
2. **Ordre GPU** : GPU 0 est **toujours** prioritaire dans `CUDA_VISIBLE_DEVICES`
3. **RedÃ©marrage** : Ollama doit Ãªtre redÃ©marrÃ© pour appliquer les changements
4. **VÃ©rification** : Utiliser `nvidia-smi` pendant infÃ©rence pour confirmer

---

**Corrections appliquÃ©es le** : 2026-01-06
**ValidÃ© par** : Claude Sonnet 4.5
