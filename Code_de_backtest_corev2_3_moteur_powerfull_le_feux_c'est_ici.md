## Sommaire

1. `analyze_bollinger_params.py`
2. `metrics_types.py`
3. `profile_sweep.py`
4. `agents\analyst.py`
5. `agents\autonomous_strategist.py`
6. `agents\backtest_executor.py`
7. `agents\base_agent.py`
8. `agents\critic.py`
9. `agents\indicator_context.py`
10. `agents\integration.py`
11. `agents\llm_client.py`
12. `agents\llm_config.py`
13. `agents\model_config.py`
14. `agents\ollama_manager.py`
15. `agents\orchestration_logger.py`
16. `agents\orchestrator.py`
17. `agents\state_machine.py`
18. `agents\strategist.py`
19. `agents\validator.py`
20. `agents\__init__.py`
21. `backtest\engine.py`
22. `backtest\errors.py`
23. `backtest\execution.py`
24. `backtest\execution_fast.py`
25. `backtest\facade.py`
26. `backtest\metrics_tier_s.py`
27. `backtest\monte_carlo.py`
28. `backtest\optuna_optimizer.py`
29. `backtest\pareto.py`
30. `backtest\performance.py`
31. `backtest\performance_numba.py`
32. `backtest\report_generator.py`
33. `backtest\results_organizer.py`
34. `backtest\simulator.py`
35. `backtest\simulator_fast.py`
36. `backtest\storage.py`
37. `backtest\sweep.py`
38. `backtest\validation.py`
39. `backtest\warmup.py`
40. `backtest\worker.py`
41. `backtest\__init__.py`
42. `cli\commands.py`
43. `cli\formatters.py`
44. `cli\report_generator.py`
45. `cli\sweep_executor.py`
46. `cli\validators.py`
47. `cli\__init__.py`
48. `cli\__main__.py`
49. `data\config.py`
50. `data\indicator_bank.py`
51. `data\loader.py`
52. `data\__init__.py`
53. `data\sample_data\generate_sample.py`
54. `indicators\adx.py`
55. `indicators\amplitude_hunter.py`
56. `indicators\aroon.py`
57. `indicators\atr.py`
58. `indicators\bollinger.py`
59. `indicators\cci.py`
60. `indicators\donchian.py`
61. `indicators\ema.py`
62. `indicators\fear_greed.py`
63. `indicators\fibonacci.py`
64. `indicators\filters.py`
65. `indicators\fva.py`
66. `indicators\fvg.py`
67. `indicators\ichimoku.py`
68. `indicators\keltner.py`
69. `indicators\macd.py`
70. `indicators\markov_switching.py`
71. `indicators\mfi.py`
72. `indicators\momentum.py`
73. `indicators\obv.py`
74. `indicators\onchain_smoothing.py`
75. `indicators\pivot_points.py`
76. `indicators\pi_cycle.py`
77. `indicators\psar.py`
78. `indicators\registry.py`
79. `indicators\roc.py`
80. `indicators\rsi.py`
81. `indicators\scoring.py`
82. `indicators\smart_legs.py`
83. `indicators\standard_deviation.py`
84. `indicators\stochastic.py`
85. `indicators\stoch_rsi.py`
86. `indicators\supertrend.py`
87. `indicators\swing.py`
88. `indicators\volume_oscillator.py`
89. `indicators\vortex.py`
90. `indicators\vwap.py`
91. `indicators\williams_r.py`
92. `indicators\__init__.py`
93. `labs\lab_launcher.py`
94. `labs\analysis\analyze_bollinger_atr_results.py`
95. `labs\analysis\analyze_code_health.py`
96. `labs\analysis\analyze_trade6.py`
97. `labs\analysis\detailed_bollinger_analysis.py`
98. `labs\debug\debug_full_simulator.py`
99. `labs\debug\debug_multi_sweep.py`
100. `labs\debug\debug_optimal_periods.py`
101. `labs\debug\debug_simulator_trace.py`
102. `labs\debug\debug_tp_bug.py`
103. `labs\debug\diagnose_gpu.py`
104. `labs\debug\diagnose_startup.py`
105. `labs\debug\diagnostic_sweep_blocked.py`
106. `labs\debug\fix_streamlit_config.py`
107. `labs\debug\reproduce_macd_inf.py`
108. `labs\optimization\bollinger_atr_optimized_ranges.py`
109. `labs\optimization\bollinger_atr_theory_ranges.py`
110. `labs\optimization\profile_backtest.py`
111. `labs\optimization\quick_ranges_test.py`
112. `labs\optimization\validate_rsi_reversal.py`
113. `performance\benchmark.py`
114. `performance\device_backend.py`
115. `performance\gpu.py`
116. `performance\memory.py`
117. `performance\monitor.py`
118. `performance\parallel.py`
119. `performance\profiler.py`
120. `performance\__init__.py`
121. `strategies\base.py`
122. `strategies\bollinger_atr.py`
123. `strategies\bollinger_atr_v2.py`
124. `strategies\bollinger_atr_v3.py`
125. `strategies\bollinger_best_longe_3i.py`
126. `strategies\bollinger_best_short_3i.py`
127. `strategies\ema_cross.py`
128. `strategies\fvg_strategy.py`
129. `strategies\indicators_mapping.py`
130. `strategies\macd_cross.py`
131. `strategies\rsi_reversal.py`
132. `strategies\__init__.py`
133. `ui\app.py`
134. `ui\cache_integration.py`
135. `ui\cache_manager.py`
136. `ui\constants.py`
137. `ui\context.py`
138. `ui\deep_trace_viewer.py`
139. `ui\emergency_stop.py`
140. `ui\helpers.py`
141. `ui\indicators_panel.py`
142. `ui\llm_handlers.py`
143. `ui\log_taps.py`
144. `ui\main.py`
145. `ui\model_presets.py`
146. `ui\orchestration_viewer.py`
147. `ui\results.py`
148. `ui\results_hub.py`
149. `ui\sidebar.py`
150. `ui\state.py`
151. `ui\validation_integration.py`
152. `ui\worker_utils.py`
153. `ui\__init__.py`
154. `ui\components\agent_timeline.py`
155. `ui\components\charts.py`
156. `ui\components\diagram_factory.py`
157. `ui\components\model_selector.py`
158. `ui\components\monitor.py`
159. `ui\components\sweep_monitor.py`
160. `ui\components\validation_viewer.py`
161. `ui\components\__init__.py`
162. `ui\components\archive\indicator_explorer.py`
163. `ui\components\archive\sweep_monitor.py`
164. `ui\components\archive\themes.py`
165. `ui\components\archive\thinking_viewer.py`
166. `ui\components\archive\validation_viewer.py`
167. `ui\theme\colors.py`
168. `ui\theme\plotly_config.py`
169. `ui\theme\__init__.py`
170. `utils\checkpoint.py`
171. `utils\circuit_breaker.py`
172. `utils\config.py`
173. `utils\config_validator.py`
174. `utils\data.py`
175. `utils\diagnose_sweep_activity.py`
176. `utils\error_recovery.py`
177. `utils\gpu_monitor.py`
178. `utils\gpu_oom.py`
179. `utils\gpu_utils.py`
180. `utils\health.py`
181. `utils\indicator_ranges.py`
182. `utils\llm_memory.py`
183. `utils\log.py`
184. `utils\memory.py`
185. `utils\model_loader.py`
186. `utils\observability.py`
187. `utils\parameters.py`
188. `utils\preset_validation.py`
189. `utils\run_tracker.py`
190. `utils\session_param_tracker.py`
191. `utils\session_ranges_tracker.py`
192. `utils\sweep_diagnostics.py`
193. `utils\template.py`
194. `utils\validate_presets.py`
195. `utils\version.py`
196. `utils\visualization.py`
197. `utils\__init__.py`


<!-- MODULE-START: analyze_bollinger_params.py -->
```json
{
  "name": "analyze_bollinger_params.py",
  "path": "analyze_bollinger_params.py",
  "ext": ".py",
  "anchor": "analyze_bollinger_params_py"
}
```
## analyze_bollinger_params_py
*Chemin* : `analyze_bollinger_params.py`  
*Type* : `.py`  

```python
"""Script d'analyse des meilleurs param√®tres bb_period et bb_std."""

import json
import os
from pathlib import Path
import pandas as pd

# R√©pertoire des r√©sultats
results_dir = Path("backtest_results")

# Collecter les donn√©es
data = []

for result_folder in results_dir.glob("bollinger_atr_*"):
    metadata_file = result_folder / "metadata.json"

    if not metadata_file.exists():
        continue

    try:
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        # Extraire les param√®tres et m√©triques
        params = metadata.get("params", {})
        metrics = metadata.get("metrics", {})

        # Extraire les infos importantes
        entry = {
            "folder": result_folder.name,
            "strategy": metadata.get("strategy", ""),
            "symbol": metadata.get("symbol", ""),
            "timeframe": metadata.get("timeframe", ""),

            # Param√®tres Bollinger
            "bb_period": params.get("bb_period"),
            "bb_std": params.get("bb_std"),

            # Param√®tres ATR (pour r√©f√©rence)
            "atr_period": params.get("atr_period"),
            "atr_percentile": params.get("atr_percentile"),

            # M√©triques de performance
            "total_return": metrics.get("total_return"),
            "sharpe_ratio": metrics.get("sharpe_ratio"),
            "sortino_ratio": metrics.get("sortino_ratio"),
            "max_drawdown": metrics.get("max_drawdown"),
            "win_rate": metrics.get("win_rate"),
            "total_trades": metrics.get("total_trades"),
            "profit_factor": metrics.get("profit_factor"),
            "calmar_ratio": metrics.get("calmar_ratio"),
        }

        data.append(entry)

    except Exception as e:
        print(f"Erreur lors de la lecture de {metadata_file}: {e}")
        continue

# Cr√©er DataFrame
df = pd.DataFrame(data)

if len(df) == 0:
    print("Aucune donn√©e trouv√©e.")
    exit(0)

# Trier par Sharpe ratio (m√©trique principale)
df_sorted = df.sort_values("sharpe_ratio", ascending=False)

print("="*100)
print("ANALYSE DES PARAM√àTRES BOLLINGER (bb_period et bb_std)")
print("="*100)
print(f"\nNombre total de backtests analys√©s: {len(df)}\n")

# Top 10 configurations
print("\n" + "="*100)
print("TOP 10 CONFIGURATIONS (par Sharpe Ratio)")
print("="*100)
top10 = df_sorted.head(10)[["symbol", "timeframe", "bb_period", "bb_std",
                              "sharpe_ratio", "total_return", "max_drawdown",
                              "win_rate", "total_trades"]]
print(top10.to_string(index=False))

# Statistiques par bb_period
print("\n" + "="*100)
print("STATISTIQUES PAR bb_period")
print("="*100)
period_stats = df.groupby("bb_period").agg({
    "sharpe_ratio": ["mean", "median", "std", "count"],
    "total_return": "mean",
    "max_drawdown": "mean",
    "win_rate": "mean"
}).round(3)
print(period_stats.to_string())

# Statistiques par bb_std
print("\n" + "="*100)
print("STATISTIQUES PAR bb_std")
print("="*100)
std_stats = df.groupby("bb_std").agg({
    "sharpe_ratio": ["mean", "median", "std", "count"],
    "total_return": "mean",
    "max_drawdown": "mean",
    "win_rate": "mean"
}).round(3)
print(std_stats.to_string())

# Statistiques par combinaison bb_period + bb_std
print("\n" + "="*100)
print("STATISTIQUES PAR COMBINAISON (bb_period, bb_std)")
print("="*100)
combo_stats = df.groupby(["bb_period", "bb_std"]).agg({
    "sharpe_ratio": ["mean", "count"],
    "total_return": "mean",
    "max_drawdown": "mean"
}).round(3)
combo_stats_sorted = combo_stats.sort_values(("sharpe_ratio", "mean"), ascending=False)
print(combo_stats_sorted.head(15).to_string())

# Sauvegarder dans CSV
output_file = "backtest_results/bollinger_params_analysis.csv"
df_sorted.to_csv(output_file, index=False)
print(f"\n\nR√©sultats complets sauvegard√©s dans: {output_file}")
```
<!-- MODULE-END: analyze_bollinger_params.py -->

<!-- MODULE-START: metrics_types.py -->
```json
{
  "name": "metrics_types.py",
  "path": "metrics_types.py",
  "ext": ".py",
  "anchor": "metrics_types_py"
}
```
## metrics_types_py
*Chemin* : `metrics_types.py`  
*Type* : `.py`  

```python
from __future__ import annotations

from typing import Any, Dict, Literal, Mapping, TypedDict, Union, cast, overload

Unit = Literal["pct", "frac"]
MetricValue = Union[int, float]

# TypedDict keeps payloads dict-like for boundary transport.


class PerformanceMetricsPct(TypedDict, total=False):
    total_pnl: float
    total_return_pct: float
    annualized_return: float
    cagr: float
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float
    max_drawdown_pct: float
    volatility_annual: float
    total_trades: int
    win_rate_pct: float
    profit_factor: float
    expectancy: float


class AgentBacktestMetricsFrac(TypedDict, total=False):
    sharpe_ratio: float
    sortino_ratio: float
    total_return: float
    max_drawdown: float
    win_rate: float
    profit_factor: float
    total_trades: int
    calmar_ratio: float
    sqn: float
    recovery_factor: float


class UIMetricsPct(PerformanceMetricsPct, total=False):
    sqn: float
    recovery_factor: float


_ALIAS_TO_PCT = {
    "total_return": "total_return_pct",
    "max_drawdown": "max_drawdown_pct",
    "win_rate": "win_rate_pct",
}
_ALIAS_TO_FRAC = {
    "total_return_pct": "total_return",
    "max_drawdown_pct": "max_drawdown",
    "win_rate_pct": "win_rate",
}


def _coerce_numeric(value: Any, key: str) -> float:
    if isinstance(value, bool) or not isinstance(value, (int, float)):
        raise TypeError(f"{key} must be a number, got {type(value).__name__}")
    return float(value)


def _validate_range(payload: Mapping[str, Any], key: str, lo: float, hi: float) -> None:
    if key not in payload:
        return
    value = _coerce_numeric(payload[key], key)
    if value < lo or value > hi:
        raise ValueError(f"{key} out of range [{lo}, {hi}]: {value}")


def _validate_invariants(payload: Mapping[str, Any], unit: Unit) -> None:
    if unit == "pct":
        _validate_range(payload, "win_rate_pct", 0.0, 100.0)
        _validate_range(payload, "max_drawdown_pct", -100.0, 0.0)
    else:
        _validate_range(payload, "win_rate", 0.0, 1.0)
        _validate_range(payload, "max_drawdown", -1.0, 0.0)


def _apply_aliases(payload: Mapping[str, Any], unit: Unit) -> Dict[str, Any]:
    normalized: Dict[str, Any] = dict(payload)
    mapping = _ALIAS_TO_PCT if unit == "pct" else _ALIAS_TO_FRAC
    for alias, canonical in mapping.items():
        if alias not in normalized:
            continue
        if canonical in normalized and normalized[canonical] != normalized[alias]:
            raise ValueError(f"Conflicting values for {canonical} and {alias}")
        if canonical not in normalized:
            normalized[canonical] = normalized[alias]
        if alias != canonical:
            normalized.pop(alias, None)
    return normalized


@overload
def normalize_metrics(
    payload: Mapping[str, Any], unit: Literal["pct"]
) -> PerformanceMetricsPct:
    ...


@overload
def normalize_metrics(
    payload: Mapping[str, Any], unit: Literal["frac"]
) -> AgentBacktestMetricsFrac:
    ...


def normalize_metrics(payload: Mapping[str, Any], unit: Unit) -> Dict[str, Any]:
    normalized = _apply_aliases(payload, unit)
    _validate_invariants(normalized, unit)
    return normalized


def pct_to_frac(pct_payload: Mapping[str, Any]) -> AgentBacktestMetricsFrac:
    normalized = normalize_metrics(pct_payload, "pct")
    converted: Dict[str, Any] = dict(normalized)
    if "total_return_pct" in normalized:
        converted["total_return"] = normalized["total_return_pct"] / 100.0
        converted.pop("total_return_pct", None)
    if "max_drawdown_pct" in normalized:
        converted["max_drawdown"] = normalized["max_drawdown_pct"] / 100.0
        converted.pop("max_drawdown_pct", None)
    if "win_rate_pct" in normalized:
        converted["win_rate"] = normalized["win_rate_pct"] / 100.0
        converted.pop("win_rate_pct", None)
    _validate_invariants(converted, "frac")
    return cast(AgentBacktestMetricsFrac, converted)


def frac_to_pct(frac_payload: Mapping[str, Any]) -> PerformanceMetricsPct:
    normalized = normalize_metrics(frac_payload, "frac")
    converted: Dict[str, Any] = dict(normalized)
    if "total_return" in normalized:
        converted["total_return_pct"] = normalized["total_return"] * 100.0
        converted.pop("total_return", None)
    if "max_drawdown" in normalized:
        converted["max_drawdown_pct"] = normalized["max_drawdown"] * 100.0
        converted.pop("max_drawdown", None)
    if "win_rate" in normalized:
        converted["win_rate_pct"] = normalized["win_rate"] * 100.0
        converted.pop("win_rate", None)
    _validate_invariants(converted, "pct")
    return cast(PerformanceMetricsPct, converted)


__all__ = [
    "AgentBacktestMetricsFrac",
    "PerformanceMetricsPct",
    "UIMetricsPct",
    "frac_to_pct",
    "normalize_metrics",
    "pct_to_frac",
]
```
<!-- MODULE-END: metrics_types.py -->

<!-- MODULE-START: profile_sweep.py -->
```json
{
  "name": "profile_sweep.py",
  "path": "profile_sweep.py",
  "ext": ".py",
  "anchor": "profile_sweep_py"
}
```
## profile_sweep_py
*Chemin* : `profile_sweep.py`  
*Type* : `.py`  

```python
"""
Script de profiling pour identifier les goulots d'√©tranglement dans les sweeps.
"""
import cProfile
import pstats
import io
from pstats import SortKey

from data.loader import load_ohlcv
from backtest.engine import BacktestEngine
from strategies import get_strategy


def profile_sweep():
    """Profile un petit sweep de 20 backtests."""
    print("=" * 80)
    print("PROFILING SWEEP - Identification des goulots d'√©tranglement")
    print("=" * 80)

    # Charger donn√©es
    print("\n[1/3] Chargement donn√©es BTCUSDC/30m...")
    df = load_ohlcv("BTCUSDC", "30m")
    print(f"‚úì {len(df):,} barres charg√©es")

    # Pr√©parer strat√©gie
    strategy_key = "bollinger_atr"
    strategy_class = get_strategy(strategy_key)

    # G√©n√©rer 20 combinaisons de param√®tres
    print(f"\n[2/3] Pr√©paration sweep {strategy_key}...")
    param_combos = []
    for entry_z in [1.5, 2.0, 2.5]:
        for k_sl in [1.0, 1.5, 2.0]:
            for leverage in [1, 3]:
                param_combos.append({
                    "entry_z": entry_z,
                    "k_sl": k_sl,
                    "leverage": leverage,
                    "bb_period": 20,
                    "bb_std_dev": 2.0,
                    "atr_period": 14,
                })

    print(f"‚úì {len(param_combos)} combinaisons g√©n√©r√©es")

    # Profiler l'ex√©cution
    print(f"\n[3/3] Profiling {len(param_combos)} backtests...")

    profiler = cProfile.Profile()
    profiler.enable()

    # Ex√©cuter le sweep
    engine = BacktestEngine(initial_capital=10000)
    results = []

    for i, params in enumerate(param_combos, 1):
        try:
            result = engine.run(
                df=df,
                strategy=strategy_key,
                params=params,
                symbol="BTCUSDC",
                timeframe="30m",
                silent_mode=True,
                fast_metrics=True
            )
            results.append(result)

            if i % 5 == 0:
                print(f"  {i}/{len(param_combos)} backtests termin√©s...")
        except Exception as e:
            print(f"  ‚ùå Backtest {i} √©chou√©: {e}")

    profiler.disable()

    # Analyser les r√©sultats
    print("\n" + "=" * 80)
    print("R√âSULTATS DU PROFILING")
    print("=" * 80)

    # Statistiques de base
    s = io.StringIO()
    ps = pstats.Stats(profiler, stream=s)
    ps.strip_dirs()

    # Top 30 fonctions par temps cumul√©
    print("\nüìä TOP 30 FONCTIONS PAR TEMPS CUMUL√â:")
    print("-" * 80)
    ps.sort_stats(SortKey.CUMULATIVE)
    ps.print_stats(30)
    print(s.getvalue())

    # Rechercher sp√©cifiquement les fonctions critiques
    s = io.StringIO()
    ps = pstats.Stats(profiler, stream=s)
    ps.strip_dirs()

    print("\n" + "=" * 80)
    print("üîç ANALYSE D√âTAILL√âE DES INDICATEURS")
    print("=" * 80)

    # Filtrer les fonctions d'indicateurs
    ps.sort_stats(SortKey.CUMULATIVE)
    ps.print_stats('bollinger|atr|rsi|ema|calculate_indicator')
    print(s.getvalue())

    # V√©rifier si le cache est utilis√©
    s = io.StringIO()
    ps = pstats.Stats(profiler, stream=s)
    ps.strip_dirs()

    print("\n" + "=" * 80)
    print("üíæ ANALYSE DU CACHE")
    print("=" * 80)

    ps.sort_stats(SortKey.CUMULATIVE)
    ps.print_stats('cache|get_indicator|put')
    cache_output = s.getvalue()
    print(cache_output)

    if 'get_indicator_bank' in cache_output or '_worker_indicator_cache' in cache_output:
        print("‚úì Cache d√©tect√© dans le profiling")
    else:
        print("‚ùå PROBL√àME: Aucune fonction de cache d√©tect√©e!")
        print("   ‚Üí Les indicateurs sont recalcul√©s √† chaque fois")

    # R√©sum√©
    print("\n" + "=" * 80)
    print("üìà R√âSUM√â")
    print("=" * 80)
    print(f"Backtests r√©ussis: {len(results)}/{len(param_combos)}")

    # Calculer le temps total
    total_time = sum(stat[3] for stat in ps.stats.values())
    avg_time_per_bt = total_time / len(param_combos) if param_combos else 0

    print(f"Temps total: {total_time:.2f}s")
    print(f"Temps moyen/backtest: {avg_time_per_bt:.3f}s")
    print(f"D√©bit: {len(param_combos)/total_time:.1f} backtests/sec")

    # Sauvegarder le profiling complet
    profiler.dump_stats("profiling_results/sweep_profile.prof")
    print("\n‚úì Profiling complet sauvegard√©: profiling_results/sweep_profile.prof")
    print("  Analysez avec: python -m pstats profiling_results/sweep_profile.prof")


if __name__ == "__main__":
    profile_sweep()
```
<!-- MODULE-END: profile_sweep.py -->

<!-- MODULE-START: analyst.py -->
```json
{
  "name": "analyst.py",
  "path": "agents\\analyst.py",
  "ext": ".py",
  "anchor": "analyst_py"
}
```
## analyst_py
*Chemin* : `agents\analyst.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.analyst

Purpose: Analyser quantitativement les r√©sultats de backtest et diagnostiquer les forces/faiblesses.

Role in pipeline: orchestration

Key components: AnalystAgent, AnalysisResponse, KeyMetricsAssessment

Inputs: AgentContext (m√©triques, configuration, walk-forward metrics optionnels)

Outputs: AnalysisResponse (JSON Pydantic valid√©) avec √©valuations et ratings

Dependencies: agents.base_agent, utils.template, pydantic, utils.log

Conventions: Ratings en patterns stricts (EXCELLENT/GOOD/FAIR/POOR/CRITICAL); fields non-null; template Jinja2 + parse_json

Read-if: Modification analyse diagnostic, formules de notation, ou structure r√©ponse.

Skip-if: Vous ne changez que propose/critique/validate.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import json
import logging
import time
from typing import Any, Dict, List

from pydantic import BaseModel, Field, ValidationError, field_validator

from utils.template import render_prompt

from .base_agent import (
    AgentContext,
    AgentResult,
    AgentRole,
    BaseAgent,
)

logger = logging.getLogger(__name__)


# === Mod√®les Pydantic pour validation ===

class MetricAssessment(BaseModel):
    """√âvaluation d'une m√©trique individuelle."""
    value: float
    assessment: str = Field(..., min_length=1)


class KeyMetricsAssessment(BaseModel):
    """√âvaluation des m√©triques cl√©s."""
    sharpe_ratio: MetricAssessment
    max_drawdown: MetricAssessment
    win_rate: MetricAssessment
    profit_factor: MetricAssessment


class AnalysisResponse(BaseModel):
    """Structure de la r√©ponse d'analyse du LLM.

    Utilise Pydantic pour validation robuste et typ√©e.
    """
    summary: str = Field(..., min_length=10)
    performance_rating: str = Field(..., pattern="^(EXCELLENT|GOOD|FAIR|POOR|CRITICAL)$")
    risk_rating: str = Field(..., pattern="^(LOW|MODERATE|HIGH|EXTREME)$")
    overfitting_risk: str = Field(..., pattern="^(LOW|MODERATE|HIGH|CRITICAL)$")
    strengths: List[str] = Field(default_factory=list)
    weaknesses: List[str] = Field(default_factory=list)
    concerns: List[str] = Field(default_factory=list)
    key_metrics_assessment: KeyMetricsAssessment
    recommendations: List[str] = Field(default_factory=list)
    proceed_to_optimization: bool
    reasoning: str = Field(..., min_length=10)

    @field_validator('strengths', 'weaknesses', 'concerns', 'recommendations', mode='after')
    @classmethod
    def validate_non_empty_strings(cls, v):
        """Valide que les items de liste ne sont pas vides."""
        if isinstance(v, list):
            for item in v:
                if isinstance(item, str) and not item.strip():
                    raise ValueError("Les items de liste ne doivent pas √™tre vides")
            return [item.strip() if isinstance(item, str) else item for item in v]
        return v


class AnalystAgent(BaseAgent):
    """
    Agent Analyst - Expert en analyse quantitative.

    Analyse:
    - Performance absolue (rendement, sharpe, etc.)
    - Risque (drawdown, volatilit√©, etc.)
    - Qualit√© des trades (win rate, profit factor)
    - Overfitting (train vs test)
    - Tendances historiques (si plusieurs it√©rations)
    """

    @property
    def role(self) -> AgentRole:
        return AgentRole.ANALYST

    @property
    def system_prompt(self) -> str:
        return """You are a senior quantitative analyst specializing in algorithmic trading strategy evaluation.

Your expertise includes:
- Statistical analysis of trading performance metrics
- Risk assessment and drawdown analysis
- Detection of overfitting and curve-fitting issues
- Identification of market regime dependencies
- Recognition of strategy strengths and weaknesses

Your analysis must be:
- Data-driven and objective
- Structured and clear
- Actionable with specific recommendations
- Honest about limitations and risks

When analyzing, always consider:
1. Is the sample size (number of trades) sufficient for statistical significance?
2. Are the results consistent across train/test splits (walk-forward)?
3. Is the strategy robust or likely overfit to historical data?
4. What are the main risk factors?

Respond ONLY in valid JSON format with this exact structure:
{
    "summary": "Brief one-paragraph analysis summary",
    "performance_rating": "EXCELLENT|GOOD|FAIR|POOR|CRITICAL",
    "risk_rating": "LOW|MODERATE|HIGH|EXTREME",
    "overfitting_risk": "LOW|MODERATE|HIGH|CRITICAL",
    "strengths": ["strength1", "strength2", ...],
    "weaknesses": ["weakness1", "weakness2", ...],
    "concerns": ["concern1", "concern2", ...],
    "key_metrics_assessment": {
        "sharpe_ratio": {"value": X, "assessment": "..."},
        "max_drawdown": {"value": X, "assessment": "..."},
        "win_rate": {"value": X, "assessment": "..."},
        "profit_factor": {"value": X, "assessment": "..."}
    },
    "recommendations": ["recommendation1", "recommendation2", ...],
    "proceed_to_optimization": true/false,
    "reasoning": "Why proceed or not proceed"
}"""

    def execute(self, context: AgentContext) -> AgentResult:
        """
        Ex√©cute l'analyse quantitative.

        Args:
            context: Contexte avec m√©triques

        Returns:
            Rapport d'analyse
        """
        start_time = time.time()

        # Construire le prompt utilisateur
        user_prompt = self._build_analysis_prompt(context)

        # Appeler le LLM
        response = self._call_llm(user_prompt, json_mode=True, temperature=0.3)

        execution_time = (time.time() - start_time) * 1000

        # V√©rifier la r√©ponse
        if not response.content:
            return AgentResult.failure_result(
                self.role,
                "LLM n'a pas retourn√© de r√©ponse",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Parser la r√©ponse LLM avec try/except robuste
        try:
            analysis = response.parse_json()
            if analysis is None:
                return AgentResult.failure_result(
                    self.role,
                    f"√âchec parse JSON: {response.parse_error or 'Unknown'}",
                    execution_time_ms=execution_time,
                    raw_llm_response=response,
                )
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            logger.error(f"Parse JSON crash: {e}")
            return AgentResult.failure_result(
                self.role,
                f"Exception parse JSON: {type(e).__name__} - {str(e)}",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Valider la structure
        try:
            validation_errors = self._validate_analysis(analysis)
            if validation_errors:
                return AgentResult.failure_result(
                    self.role,
                    f"Structure d'analyse invalide: {validation_errors[0]}",
                    execution_time_ms=execution_time,
                    raw_llm_response=response,
                )
        except Exception as e:
            logger.error(f"Validation analysis crash: {e}")
            return AgentResult.failure_result(
                self.role,
                f"Exception validation: {type(e).__name__}",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Cr√©er le r√©sultat
        return AgentResult.success_result(
            self.role,
            content=analysis.get("summary", ""),
            data={
                "analysis": analysis,
                "performance_rating": analysis.get("performance_rating"),
                "risk_rating": analysis.get("risk_rating"),
                "overfitting_risk": analysis.get("overfitting_risk"),
                "proceed_to_optimization": analysis.get("proceed_to_optimization", False),
                "strengths": analysis.get("strengths", []),
                "weaknesses": analysis.get("weaknesses", []),
                "concerns": analysis.get("concerns", []),
                "recommendations": analysis.get("recommendations", []),
            },
            execution_time_ms=execution_time,
            tokens_used=response.total_tokens,
            llm_calls=1,
            raw_llm_response=response,
        )

    def _build_analysis_prompt(self, context: AgentContext) -> str:
        """Construit le prompt d'analyse via template Jinja2."""

        # Convertir MetricsSnapshot en dict pour le template
        current_metrics_dict = None
        if context.current_metrics:
            current_metrics_dict = context.current_metrics.to_dict()

        train_metrics_dict = None
        if context.train_metrics:
            train_metrics_dict = context.train_metrics.to_dict()

        test_metrics_dict = None
        if context.test_metrics:
            test_metrics_dict = context.test_metrics.to_dict()

        # Pr√©parer le dictionnaire de contexte pour le template
        template_context = {
            "strategy_name": context.strategy_name,
            "strategy_description": context.strategy_description,
            "data_symbol": context.data_symbol,
            "data_timeframe": context.data_timeframe,
            "data_date_range": context.data_date_range,
            "data_rows": context.data_rows,
            "iteration": context.iteration,
            "comparison_context": context.comparison_context,
            "current_params": context.current_params,
            "param_specs": context.param_specs,
            "current_metrics": current_metrics_dict,
            "train_metrics": train_metrics_dict,
            "test_metrics": test_metrics_dict,
            "overfitting_ratio": context.overfitting_ratio,
            "max_overfitting_ratio": context.max_overfitting_ratio,
            "iteration_history": context.iteration_history,
            "optimization_target": context.optimization_target,
            "min_sharpe": context.min_sharpe,
            "max_drawdown_limit": context.max_drawdown_limit,
            "min_trades": context.min_trades,
            "memory_summary": context.memory_summary,
            "strategy_indicators_context": context.strategy_indicators_context,
            "readonly_indicators_context": context.readonly_indicators_context,
            "indicator_context_warnings": context.indicator_context_warnings,
        }

        # Rendre le template
        return render_prompt("analyst.jinja2", template_context)

    def _validate_analysis(self, analysis: Dict[str, Any]) -> List[str]:
        """Valide la structure de l'analyse avec Pydantic.

        Args:
            analysis: Dictionnaire JSON √† valider

        Returns:
            Liste d'erreurs (vide si validation r√©ussie)
        """
        try:
            # Validation Pydantic - l√®ve ValidationError si invalide
            validated = AnalysisResponse.model_validate(analysis)

            # Validation r√©ussie
            logger.debug(
                f"Analyse valid√©e avec succ√®s: {validated.performance_rating} "
                f"performance, {validated.risk_rating} risk"
            )
            return []  # Aucune erreur

        except ValidationError as e:
            # Extraire les messages d'erreur Pydantic
            errors = []
            for error in e.errors():
                field_path = " -> ".join(str(loc) for loc in error["loc"])
                error_msg = error["msg"]
                error_type = error["type"]

                errors.append(
                    f"Champ '{field_path}': {error_msg} (type: {error_type})"
                )

            logger.warning(f"Validation Pydantic √©chou√©e: {len(errors)} erreur(s)")
            return errors

        except Exception as e:
            # Erreur inattendue
            logger.error(f"Erreur inattendue lors validation Pydantic: {e}")
            return [f"Erreur validation: {type(e).__name__} - {str(e)}"]
```
<!-- MODULE-END: analyst.py -->

<!-- MODULE-START: autonomous_strategist.py -->
```json
{
  "name": "autonomous_strategist.py",
  "path": "agents\\autonomous_strategist.py",
  "ext": ".py",
  "anchor": "autonomous_strategist_py"
}
```
## autonomous_strategist_py
*Chemin* : `agents\autonomous_strategist.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.autonomous_strategist

Purpose: Optimiseur autonome pilot√© par LLM qui it√®re propose ‚Üí backtest ‚Üí analyse ‚Üí d√©cide.

Role in pipeline: orchestration

Key components: AutonomousStrategist, OptimizationSession, IterationDecision, create_autonomous_optimizer

Inputs: LLMClient/LLMConfig, BacktestExecutor/backtest_fn, DataFrame OHLCV, initial_params/param_bounds

Outputs: OptimizationSession (best_result/all_results/decisions), historique de BacktestResult

Dependencies: agents.backtest_executor, agents.base_agent, agents.llm_client, agents.ollama_manager, utils.parameters

Conventions: target_metric="sharpe_ratio"; max_time_seconds en secondes; stop si next_parameters vide; LLM d√©charg√© GPU durant backtests.

Read-if: Vous modifiez/debuggez la boucle d'optimisation autonome ou son int√©gration d'ex√©cution.

Skip-if: Vous utilisez uniquement le mode orchestr√© sans ex√©cution de backtests.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import itertools
import logging

# Import search space statistics
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional

import pandas as pd

from strategies.base import get_strategy_overview
from utils.parameters import ParameterSpec, RangeProposal, compute_search_space_stats

from .backtest_executor import (
    BacktestExecutor,
    BacktestRequest,
    BacktestResult,
)
from .base_agent import AgentContext, AgentResult, AgentRole, BaseAgent
from .indicator_context import build_indicator_context
from .llm_client import LLMClient, LLMConfig
from .ollama_manager import GPUMemoryManager

logger = logging.getLogger(__name__)
# Force WARNING level pour ce module pour voir les d√©cisions critiques
logger.setLevel(logging.WARNING)


@dataclass
class IterationDecision:
    """D√©cision du LLM apr√®s analyse d'un r√©sultat."""

    action: str  # "continue", "accept", "stop", "change_direction", "sweep"
    confidence: float  # 0-1

    # Prochaine action si "continue"
    next_hypothesis: str = ""
    next_parameters: Dict[str, Any] = field(default_factory=dict)

    # Raison
    reasoning: str = ""

    # Insights accumul√©s
    insights: List[str] = field(default_factory=list)

    # Champs sp√©cifiques au sweep
    ranges: Optional[Dict[str, Dict[str, float]]] = None
    rationale: str = ""  # Explication du sweep (diff√©rent de reasoning)
    optimize_for: str = "sharpe_ratio"
    max_combinations: int = 100


@dataclass
class OptimizationSession:
    """Session d'optimisation compl√®te."""

    # Configuration
    strategy_name: str
    initial_params: Dict[str, Any]
    target_metric: str = "sharpe_ratio"

    # Contraintes
    max_iterations: int = 20
    min_improvement_threshold: float = 0.01
    max_time_seconds: float = 3600.0  # 1 heure max

    # √âtat
    current_iteration: int = 0
    start_time: datetime = field(default_factory=datetime.now)

    # R√©sultats
    best_result: Optional[BacktestResult] = None
    all_results: List[BacktestResult] = field(default_factory=list)
    decisions: List[IterationDecision] = field(default_factory=list)

    # Status final
    final_status: str = ""  # "success", "max_iterations", "timeout", "no_improvement"
    final_reasoning: str = ""

    # Contexte indicateurs (calcul√© une fois par run)
    strategy_indicators_context: str = ""
    readonly_indicators_context: str = ""
    indicator_context_warnings: List[str] = field(default_factory=list)
    indicator_context_cached: bool = False
    comparison_context: Optional[Dict[str, Any]] = None


def _param_bounds_to_specs(
    param_bounds: Dict[str, tuple],
    defaults: Dict[str, Any]
) -> List[ParameterSpec]:
    """
    Convertit param_bounds en List[ParameterSpec] pour run_llm_sweep().

    Args:
        param_bounds: {param: (min, max) ou (min, max, step)}
        defaults: {param: default_value}

    Returns:
        List de ParameterSpec
    """
    specs = []
    for param_name, bound_spec in param_bounds.items():
        if isinstance(bound_spec, (tuple, list)) and len(bound_spec) >= 2:
            min_val = float(bound_spec[0])
            max_val = float(bound_spec[1])
            step = float(bound_spec[2]) if len(bound_spec) >= 3 else 1.0
        else:
            min_val = max_val = float(bound_spec)
            step = 1.0

        # Default: moyenne ou depuis defaults dict
        default = defaults.get(param_name, (min_val + max_val) / 2)

        # D√©tecter type: int si tous les bounds sont int
        is_int = all(isinstance(bound_spec[i], int) for i in range(min(2, len(bound_spec))))
        param_type = "int" if is_int else "float"

        specs.append(ParameterSpec(
            name=param_name,
            min_val=min_val,
            max_val=max_val,
            default=default,
            step=step,
            param_type=param_type
        ))

    return specs


class AutonomousStrategist(BaseAgent):
    """
    Agent Strategist Autonome capable de lancer des backtests.

    Workflow:
    1. Analyser la configuration initiale
    2. Formuler une hypoth√®se d'am√©lioration
    3. Lancer un backtest
    4. Analyser les r√©sultats
    5. D√©cider: continuer, accepter, ou changer de direction
    6. R√©p√©ter jusqu'√† convergence ou limite

    GPU Memory Optimization:
    - Le LLM est d√©charg√© du GPU avant chaque backtest
    - La VRAM est ainsi disponible pour les calculs NumPy/CuPy
    - Le LLM est recharg√© apr√®s le backtest pour l'analyse

    Example:
        >>> strategist = AutonomousStrategist(llm_client)
        >>> session = strategist.optimize(
        ...     executor=executor,
        ...     initial_params={"fast": 10, "slow": 21},
        ...     param_bounds={"fast": (5, 20), "slow": (15, 50)},
        ...     max_iterations=10
        ... )
        >>> print(f"Best Sharpe: {session.best_result.sharpe_ratio}")
    """

    @property
    def role(self) -> AgentRole:
        return AgentRole.STRATEGIST

    @property
    def system_prompt(self) -> str:
        return """You are an autonomous trading strategy optimizer with the ability to run backtests.

Your process:
1. ANALYZE current results and history
2. FORMULATE a hypothesis about what might improve performance
3. PROPOSE specific parameters to test OR request a grid search over ranges
4. After seeing results, DECIDE whether to continue, accept, or change direction

Key principles:
- Each experiment should test ONE clear hypothesis
- Learn from failures - don't repeat similar mistakes
- Balance exploration (trying new things) vs exploitation (refining what works)
- Watch for overfitting - prefer robust solutions over peak performance
- Consider parameter interactions (e.g., fast/slow periods should maintain ratio)
- Use grid search ("sweep") when you need to explore parameter correlations systematically
- Use "Strategy Indicators (modifiable)" for parameter changes; "Context Indicators (read-only)" are informational only

You will receive experiment history and must respond with a decision.

Response format (JSON):
{
    "action": "continue|accept|stop|change_direction|sweep",
    "confidence": 0.0 to 1.0,
    "reasoning": "Why this decision",
    "next_hypothesis": "What you want to test next (if continuing)",
    "next_parameters": {"param": value},
    "insights": ["insight1", "insight2"]
}

üö® CRITICAL REQUIREMENT FOR "continue" / "change_direction":
- You MUST provide ALL parameters in "next_parameters" field
- DO NOT return empty {} or null for "next_parameters"
- Each parameter must have a concrete numeric value
- If you cannot decide on parameters, use action="stop" instead

‚úÖ VALID EXAMPLE (continue with all parameters):
{
    "action": "continue",
    "confidence": 0.75,
    "next_hypothesis": "Testing slow=25 to capture longer trends",
    "next_parameters": {
        "fast": 10,
        "slow": 25,
        "k_sl": 1.5,
        "k_tp": 3.0
    },
    "reasoning": "Slow period correlates with Sharpe improvement in range 20-25",
    "insights": ["Higher slow periods reduce false signals", "Maintain fast/slow ratio ~1:2.5"]
}

‚ùå INVALID (will cause fallback to defaults):
{
    "action": "continue",
    "next_parameters": {}  # ‚Üê EMPTY, DO NOT DO THIS
}

‚ùå INVALID (missing parameters):
{
    "action": "continue",
    "next_parameters": {"fast": 10}  # ‚Üê INCOMPLETE, must include ALL params
}

üîç GRID SEARCH ("sweep") - Use when exploring parameter interactions:

‚úÖ VALID EXAMPLE (sweep):
{
    "action": "sweep",
    "confidence": 0.85,
    "ranges": {
        "bb_period": {"min": 20, "max": 25, "step": 1},
        "bb_std": {"min": 2.0, "max": 2.5, "step": 0.1}
    },
    "rationale": "Explore bb_period/bb_std correlation systematically",
    "optimize_for": "sharpe_ratio",
    "max_combinations": 50,
    "reasoning": "Grid search more efficient than sequential testing for parameter interactions",
    "insights": ["bb_period and bb_std appear correlated", "Need exhaustive search in narrow range"]
}

üö® CRITICAL REQUIREMENTS FOR "sweep":
- You MUST provide "ranges" dict with format: {"param": {"min": x, "max": y, "step": z}}
- Each range must have min, max, and step
- "rationale" field is REQUIRED (explains why grid search is needed)
- "optimize_for" is optional (default: "sharpe_ratio")
- "max_combinations" is optional (default: 100, max: 200)
- Ranges will be clamped to parameter bounds automatically
- Grid search runs in parallel and returns top 10 configs + summary
- Use sweep when testing 2-3 parameter interactions, not for single params

When to use "sweep":
- Testing parameter correlations (e.g., fast/slow ratio, bb_period/bb_std)
- Exploring narrow ranges exhaustively after finding promising region
- When sequential testing is too slow for parameter interactions
- NOT for initial exploration - use "continue" first to narrow down ranges

Actions:
- "continue": Run another backtest with next_parameters (MUST provide all params)
- "accept": Accept current best as final solution
- "stop": Stop due to diminishing returns or constraints
- "change_direction": Abandon current approach, try something different (MUST provide all params)
- "sweep": Request grid search over parameter ranges (MUST provide ranges dict with min/max/step)"""

    def __init__(
        self,
        llm_client: LLMClient,
        verbose: bool = False,
        on_progress: Optional[Callable[[int, BacktestResult], None]] = None,
        unload_llm_during_backtest: Optional[bool] = None,
        comparison_context: Optional[Dict[str, Any]] = None,
        orchestration_logger: Optional[Any] = None,
    ):
        """
        Initialise le strategist autonome.

        Args:
            llm_client: Client LLM
            verbose: Afficher les logs d√©taill√©s
            on_progress: Callback appel√© apr√®s chaque it√©ration
            unload_llm_during_backtest: Si True, d√©charge le LLM du GPU pendant
                les calculs de backtest. Si None, utilise UNLOAD_LLM_DURING_BACKTEST
                env var (default: False pour CPU-only compatibility)
            comparison_context: Contexte multi-sweep pour enrichir les d√©cisions LLM
            orchestration_logger: Logger pour enregistrer les actions d'orchestration
        """
        import os
        super().__init__(llm_client)
        self.verbose = verbose
        self.on_progress = on_progress
        self.orchestration_logger = orchestration_logger
        self.comparison_context = comparison_context

        # Lire depuis env var si non sp√©cifi√© (default False pour CPU-only)
        if unload_llm_during_backtest is None:
            env_val = os.getenv('UNLOAD_LLM_DURING_BACKTEST', 'False')
            self.unload_llm_during_backtest = env_val.lower() in ('true', '1', 'yes')
        else:
            self.unload_llm_during_backtest = unload_llm_during_backtest

        # GPU Memory Manager - initialis√© avec le mod√®le du client
        self._gpu_manager: Optional[GPUMemoryManager] = None
        self._conversation_context: List[dict] = []

    def _get_model_name(self) -> str:
        """R√©cup√®re le nom du mod√®le depuis le client LLM."""
        if hasattr(self.llm, 'config'):
            return self.llm.config.model
        return "unknown"

    def _ensure_gpu_manager(self) -> GPUMemoryManager:
        """Cr√©e ou retourne le GPU manager."""
        if self._gpu_manager is None:
            self._gpu_manager = GPUMemoryManager(
                model_name=self._get_model_name(),
                verbose=self.verbose,
            )
        return self._gpu_manager

    def _run_backtest_with_gpu_optimization(
        self,
        executor: BacktestExecutor,
        request: BacktestRequest,
    ) -> BacktestResult:
        """
        Ex√©cute un backtest avec optimisation m√©moire GPU.

        1. D√©charge le LLM du GPU
        2. Ex√©cute le backtest (GPU libre)
        3. Recharge le LLM

        Args:
            executor: BacktestExecutor
            request: Requ√™te de backtest

        Returns:
            R√©sultat du backtest
        """
        if not self.unload_llm_during_backtest:
            # Mode sans optimisation GPU
            return executor.run(request)

        manager = self._ensure_gpu_manager()

        # D√©charger le LLM ‚Üí GPU libre pour calculs
        state = manager.unload(self._conversation_context)

        try:
            # Calculs GPU intensifs (NumPy/CuPy)
            result = executor.run(request)
        finally:
            # Recharger le LLM (toujours, m√™me en cas d'erreur)
            manager.reload(state)

        # Stats pour debug
        if self.verbose:
            stats = manager.get_stats()
            if stats.get("was_loaded"):
                logger.debug(
                    f"‚è±Ô∏è GPU swap: unload={stats['unload_time_ms']:.0f}ms, "
                    f"reload={stats['reload_time_ms']:.0f}ms"
                )

        return result

    def optimize(
        self,
        executor: BacktestExecutor,
        initial_params: Dict[str, Any],
        param_bounds: Dict[str, tuple],
        max_iterations: int = 20,
        target_metric: str = "sharpe_ratio",
        min_sharpe: float = 0.5,
        max_drawdown: float = 0.30,
        check_pause_callback: Optional[callable] = None,
    ) -> OptimizationSession:
        """
        Lance une session d'optimisation autonome.

        Args:
            executor: BacktestExecutor configur√©
            initial_params: Param√®tres de d√©part
            param_bounds: {param_name: (min, max)} pour chaque param√®tre
            max_iterations: Maximum d'it√©rations
            target_metric: M√©trique √† optimiser
            min_sharpe: Sharpe minimum acceptable
            max_drawdown: Drawdown maximum acceptable
            check_pause_callback: Callback appel√© √† chaque it√©ration qui retourne (is_paused, should_stop)

        Returns:
            OptimizationSession avec tous les r√©sultats
        """
        session = OptimizationSession(
            strategy_name=executor.strategy_name,
            initial_params=initial_params,
            target_metric=target_metric,
            max_iterations=max_iterations,
            comparison_context=self.comparison_context,
        )

        # Tracker de ranges pour √©viter boucles infinies
        from utils.session_ranges_tracker import SessionRangesTracker
        ranges_tracker = SessionRangesTracker(
            session_id=f"{session.strategy_name}_{session.start_time.strftime('%Y%m%d_%H%M%S')}"
        )

        max_iter_label = "‚àû" if max_iterations <= 0 else str(max_iterations)
        logger.info(
            f"D√©marrage optimisation: {session.strategy_name} | "
            f"max_iter={max_iter_label}"
        )

        # Logger d'orchestration: d√©but de l'optimisation
        if self.orchestration_logger:
            self.orchestration_logger.log_analysis_start(
                agent="AutonomousStrategist",
                details={
                    "strategy": session.strategy_name,
                    "initial_params": initial_params,
                }
            )

        # 1. Backtest initial
        initial_request = BacktestRequest(
            requested_by=self.role.value,
            hypothesis="Baseline: testing initial configuration",
            parameters=initial_params,
        )

        # Logger: lancement du backtest baseline
        if self.orchestration_logger:
            self.orchestration_logger.log_backtest_launch(
                agent="AutonomousStrategist",
                params=initial_params,
                combination_id=0,
                total_combinations=max_iterations,
            )

        baseline_result = self._run_backtest_with_gpu_optimization(executor, initial_request)
        session.all_results.append(baseline_result)
        session.best_result = baseline_result

        # Logger: r√©sultat du backtest baseline
        if self.orchestration_logger:
            self.orchestration_logger.log_backtest_complete(
                agent="AutonomousStrategist",
                params=initial_params,
                results={
                    "pnl": baseline_result.total_return,
                    "sharpe": baseline_result.sharpe_ratio,
                    "return": baseline_result.total_return,
                },
                combination_id=0,
            )

        if self.on_progress:
            self.on_progress(0, baseline_result)

        logger.info(
            f"Baseline: Sharpe={baseline_result.sharpe_ratio:.3f}, "
            f"Return={baseline_result.total_return:.2%}"
        )

        # Contexte indicateurs (une seule fois par run)
        try:
            indicator_ctx = build_indicator_context(
                df=executor.data,
                strategy_name=session.strategy_name,
                params=initial_params,
            )
            session.strategy_indicators_context = indicator_ctx.get("strategy", "")
            session.readonly_indicators_context = indicator_ctx.get("read_only", "")
            session.indicator_context_warnings = indicator_ctx.get("warnings", [])
            session.indicator_context_cached = True
        except Exception as exc:
            logger.warning(f"Contexte indicateurs indisponible: {exc}")
            session.strategy_indicators_context = ""
            session.readonly_indicators_context = ""
            session.indicator_context_warnings = []
            session.indicator_context_cached = True

        if self.orchestration_logger and (
            session.strategy_indicators_context
            or session.readonly_indicators_context
            or session.indicator_context_warnings
        ):
            payload = {
                "event_type": "indicator_context",
                "timestamp": datetime.now().isoformat(),
                "agent": "AutonomousStrategist",
                "session_id": f"{session.strategy_name}_{session.start_time.strftime('%Y%m%d_%H%M%S')}",
                "iteration": session.current_iteration,
                "strategy_indicators_context": session.strategy_indicators_context,
                "readonly_indicators_context": session.readonly_indicators_context,
                "warnings": session.indicator_context_warnings,
            }
            try:
                if hasattr(self.orchestration_logger, "log"):
                    self.orchestration_logger.log("indicator_context", payload)
                elif hasattr(self.orchestration_logger, "add_event"):
                    self.orchestration_logger.add_event("indicator_context", payload)
                elif hasattr(self.orchestration_logger, "append"):
                    self.orchestration_logger.append(payload)
            except Exception:
                pass

        # 2. Boucle d'it√©ration avec budget de combinaisons
        total_combinations_tested = 1  # Baseline = 1 combo
        sweeps_performed = 0
        max_sweeps_per_session = 3  # Limite de sweeps pour √©viter l'abus

        if max_iterations <= 0:
            iteration_iter = itertools.count(1)
        else:
            iteration_iter = range(1, max_iterations + 1)

        for iteration in iteration_iter:
            session.current_iteration = iteration

            # V√©rifier le budget de combinaisons test√©es
            if max_iterations > 0 and total_combinations_tested >= max_iterations:
                session.final_status = "max_iterations"
                session.final_reasoning = (
                    f"Budget √©puis√©: {total_combinations_tested} combinaisons test√©es "
                    f"(limite: {max_iterations})"
                )
                logger.warning(
                    f"‚ö†Ô∏è Budget √©puis√©: {total_combinations_tested} combos test√©es "
                    f"dont {sweeps_performed} sweeps"
                )
                break

            # V√©rifier pause/stop si callback fourni
            if check_pause_callback:
                import time
                is_paused, should_stop = check_pause_callback()

                # Si stop demand√©, sortir imm√©diatement
                if should_stop:
                    session.final_reasoning = "Arr√™t demand√© par l'utilisateur"
                    logger.info("Arr√™t demand√© - Fin de l'optimisation")
                    break

                # Si pause demand√©e, attendre
                while is_paused:
                    time.sleep(0.5)
                    is_paused, should_stop = check_pause_callback()
                    if should_stop:
                        session.final_reasoning = "Arr√™t demand√© par l'utilisateur"
                        logger.info("Arr√™t demand√© pendant la pause - Fin de l'optimisation")
                        break

                # Sortir de la boucle externe si stop pendant pause
                if should_stop:
                    break

            # Logger: nouvelle it√©ration
            if self.orchestration_logger:
                self.orchestration_logger.next_iteration()

            # G√©n√©rer le contexte pour le LLM
            context = self._build_iteration_context(
                executor, session, param_bounds, min_sharpe, max_drawdown
            )

            # Demander une d√©cision au LLM
            decision = self._get_llm_decision(context, session)

            # VALIDATION STRICTE : Forcer STOP si next_parameters vide pour continue/change_direction
            if decision.action in ("continue", "change_direction"):
                if not decision.next_parameters or len(decision.next_parameters) == 0:
                    optim_id = f"{session.strategy_name}_{session.start_time.strftime('%Y%m%d_%H%M%S')}"
                    logger.error(
                        f"LLM_INVALID_DECISION optim_id={optim_id} iteration={session.current_iteration} "
                        f"action_original={decision.action} action_forced=stop "
                        f"reason=next_parameters_empty_or_missing"
                    )
                    # Forcer STOP au lieu d'utiliser defaults silencieusement
                    original_action = decision.action
                    decision.action = "stop"
                    decision.reasoning = (
                        f"LLM chose '{original_action}' but provided no parameters. "
                        f"Stopping to avoid using defaults silently. "
                        f"Original reasoning: {decision.reasoning}"
                    )

            session.decisions.append(decision)

            # Logger: d√©cision prise
            if self.orchestration_logger:
                action_type = decision.action if decision.action in ("continue", "stop", "change_approach") else "continue"
                self.orchestration_logger.log_decision(
                    agent="AutonomousStrategist",
                    decision_type=action_type,
                    reason=decision.reasoning,
                    details={"next_params": decision.next_parameters, "confidence": decision.confidence},
                )

            # Logging d√©taill√© de la d√©cision (toujours actif pour actions critiques)
            if decision.action in ("stop", "accept"):
                logger.warning(
                    f"ü§ñ Iteration {iteration}/{max_iter_label}: ACTION CRITIQUE = '{decision.action.upper()}' | "
                    f"Confidence={decision.confidence:.2f} | Reasoning: {decision.reasoning}"
                )
            elif self.verbose:
                logger.info(
                    f"ü§ñ Iteration {iteration}/{max_iter_label}: action='{decision.action}' | "
                    f"confidence={decision.confidence:.2f} | reasoning={decision.reasoning[:80]}..."
                )
            else:
                # Log minimaliste pour continue/change_direction
                logger.info(f"Iteration {iteration}: {decision.action}")

            # Traiter la d√©cision
            if decision.action == "accept":
                session.final_status = "success"
                session.final_reasoning = decision.reasoning
                logger.info(f"Optimisation accept√©e: {decision.reasoning}")
                break

            elif decision.action == "stop":
                session.final_status = "no_improvement"
                session.final_reasoning = decision.reasoning
                logger.info(f"Arr√™t: {decision.reasoning}")
                break

            elif decision.action == "sweep":
                # V√©rifier la limite de sweeps
                if sweeps_performed >= max_sweeps_per_session:
                    logger.warning(
                        f"‚ö†Ô∏è Limite de sweeps atteinte ({max_sweeps_per_session}). "
                        f"Sweep request ignor√©, continue avec proposals normales."
                    )
                    # Forcer l'action √† "stop" pour √©viter boucle infinie
                    decision.action = "stop"
                    decision.reasoning = (
                        f"Sweep limit reached ({sweeps_performed}/{max_sweeps_per_session}). "
                        f"Original rationale: {decision.rationale}"
                    )
                    session.final_status = "sweep_limit_reached"
                    session.final_reasoning = decision.reasoning
                    break

                # Grid search demand√© par le LLM
                logger.warning(
                    f"üîç Iteration {iteration}/{max_iter_label}: SWEEP REQUEST #{sweeps_performed + 1} | "
                    f"Ranges={list(decision.ranges.keys()) if decision.ranges else []} | "
                    f"Rationale: {decision.rationale[:80]}"
                )

                # Logger: lancement du sweep
                if self.orchestration_logger:
                    self.orchestration_logger.log_decision(
                        agent="AutonomousStrategist",
                        decision_type="sweep",
                        reason=decision.rationale,
                        details={
                            "ranges": decision.ranges,
                            "optimize_for": decision.optimize_for,
                            "max_combinations": decision.max_combinations,
                        },
                    )

                # V√©rifier si ces ranges ont d√©j√† √©t√© test√©es
                if ranges_tracker.was_tested(decision.ranges):
                    logger.warning(
                        f"‚ö†Ô∏è Ranges d√©j√† test√©es dans cette session! | "
                        f"Params={list(decision.ranges.keys())} | "
                        f"Forcing diversification..."
                    )
                    # Forcer √† stop pour √©viter boucle infinie
                    decision.action = "stop"
                    decision.reasoning = (
                        f"Ranges already tested. Need different ranges. "
                        f"Original rationale: {decision.rationale}"
                    )
                    session.final_status = "ranges_already_tested"
                    session.final_reasoning = decision.reasoning
                    break

                try:
                    # Cr√©er RangeProposal
                    range_proposal = RangeProposal(
                        ranges=decision.ranges,
                        rationale=decision.rationale,
                        optimize_for=decision.optimize_for,
                        max_combinations=decision.max_combinations,
                    )

                    # Convertir param_bounds en param_specs
                    param_specs = _param_bounds_to_specs(param_bounds, initial_params)

                    # Ex√©cuter le sweep via run_llm_sweep()
                    from agents.integration import run_llm_sweep

                    sweep_results = run_llm_sweep(
                        range_proposal=range_proposal,
                        param_specs=param_specs,
                        data=executor.data,
                        strategy_name=executor.strategy_name,
                        initial_capital=10000.0,  # Default
                        n_workers=None,  # Auto-detect
                    )

                    # Incr√©menter les compteurs de budget
                    n_combinations = sweep_results['n_combinations']
                    sweeps_performed += 1
                    total_combinations_tested += n_combinations

                    # Enregistrer les ranges test√©es dans le tracker
                    best_sharpe = sweep_results['best_metrics'].get('sharpe_ratio', 0)
                    ranges_tracker.register(
                        ranges=decision.ranges,
                        n_combinations=n_combinations,
                        best_sharpe=best_sharpe,
                        rationale=decision.rationale
                    )

                    logger.info(
                        f"‚úÖ Sweep #{sweeps_performed} termin√©: {n_combinations} combinaisons test√©es | "
                        f"Best {decision.optimize_for}={sweep_results['best_metrics'].get(decision.optimize_for, 0):.3f} | "
                        f"Budget: {total_combinations_tested}/{max_iter_label} combos"
                    )

                    # Logger: r√©sultat du sweep
                    if self.orchestration_logger:
                        self.orchestration_logger.log_backtest_complete(
                            agent="AutonomousStrategist",
                            params=sweep_results['best_params'],
                            results={
                                "pnl": sweep_results['best_metrics'].get('total_return', 0),
                                "sharpe": sweep_results['best_metrics'].get('sharpe_ratio', 0),
                                "return": sweep_results['best_metrics'].get('total_return', 0),
                                "n_combinations": sweep_results['n_combinations'],
                            },
                            combination_id=iteration,
                        )

                    # Valider le meilleur config avec un backtest complet (d√©j√† fait par sweep)
                    # On cr√©e un BacktestResult artificiel depuis les m√©triques
                    best_params = sweep_results['best_params']
                    best_metrics = sweep_results['best_metrics']

                    # Cr√©er BacktestRequest pour tra√ßabilit√©
                    request = BacktestRequest(
                        requested_by=self.role.value,
                        hypothesis=f"Sweep best config: {decision.rationale}",
                        parameters=best_params,
                    )

                    # Cr√©er BacktestResult artificiel (sweep a d√©j√† ex√©cut√© le backtest)
                    result = BacktestResult(
                        request=request,
                        success=True,
                        sharpe_ratio=best_metrics.get('sharpe_ratio', 0),
                        total_return=best_metrics.get('total_return', 0),
                        max_drawdown=best_metrics.get('max_drawdown', 1),
                        win_rate=best_metrics.get('win_rate', 0),
                        total_trades=best_metrics.get('total_trades', 0),
                        overfitting_ratio=best_metrics.get('overfitting_ratio', 1.0),
                        execution_time_ms=0,
                    )

                    session.all_results.append(result)

                    # Mettre √† jour le meilleur si applicable
                    if self._is_better(result, session.best_result, target_metric):
                        session.best_result = result
                        logger.info(
                            f"Nouveau meilleur trouv√© par sweep! Sharpe={result.sharpe_ratio:.3f}"
                        )

                    if self.on_progress:
                        self.on_progress(iteration, result)

                except Exception as e:
                    logger.error(f"Erreur durant le sweep: {e}")
                    # Continuer l'optimisation malgr√© l'erreur
                    if self.orchestration_logger:
                        self.orchestration_logger.log_decision(
                            agent="AutonomousStrategist",
                            decision_type="sweep_failed",
                            reason=f"Sweep failed: {str(e)}",
                            details={},
                        )

            elif decision.action in ("continue", "change_direction"):
                # Valider et corriger les param√®tres
                next_params = self._validate_parameters(
                    decision.next_parameters, param_bounds, initial_params, session
                )

                # Logger: changement de param√®tres
                if self.orchestration_logger and next_params != session.best_result.request.parameters:
                    for param, new_value in next_params.items():
                        old_value = session.best_result.request.parameters.get(param)
                        if old_value != new_value:
                            self.orchestration_logger.log_indicator_values_change(
                                agent="AutonomousStrategist",
                                indicator=param,
                                old_values={"value": old_value},
                                new_values={"value": new_value},
                                reason=decision.next_hypothesis,
                            )

                # Cr√©er la requ√™te
                request = BacktestRequest(
                    requested_by=self.role.value,
                    hypothesis=decision.next_hypothesis,
                    parameters=next_params,
                )

                # Logger: lancement du backtest
                if self.orchestration_logger:
                    self.orchestration_logger.log_backtest_launch(
                        agent="AutonomousStrategist",
                        params=next_params,
                        combination_id=iteration,
                        total_combinations=max_iterations,
                    )

                # Ex√©cuter le backtest (avec d√©chargement LLM si activ√©)
                result = self._run_backtest_with_gpu_optimization(executor, request)
                session.all_results.append(result)

                # Logger: r√©sultat du backtest
                if self.orchestration_logger:
                    self.orchestration_logger.log_backtest_complete(
                        agent="AutonomousStrategist",
                        params=next_params,
                        results={
                            "pnl": result.total_return,
                            "sharpe": result.sharpe_ratio,
                            "return": result.total_return,
                        },
                        combination_id=iteration,
                    )

                # Mettre √† jour le meilleur si applicable
                if self._is_better(result, session.best_result, target_metric):
                    session.best_result = result
                    logger.info(
                        f"Nouveau meilleur! Sharpe={result.sharpe_ratio:.3f}"
                    )

                # Incr√©menter le compteur de budget (1 combo test√©e)
                total_combinations_tested += 1

                if self.on_progress:
                    self.on_progress(iteration, result)

        else:
            session.final_status = "max_iterations"
            session.final_reasoning = f"Reached {max_iterations} iterations"

        # Logger: fin de l'optimisation
        if self.orchestration_logger:
            self.orchestration_logger.log_analysis_complete(
                agent="AutonomousStrategist",
                results={
                    "status": session.final_status,
                    "reasoning": session.final_reasoning,
                    "best_sharpe": session.best_result.sharpe_ratio,
                    "iterations": session.current_iteration,
                },
            )

            # Forcer la sauvegarde finale des logs
            try:
                self.orchestration_logger.save_to_jsonl()
            except Exception as e:
                logger.warning(f"√âchec de la sauvegarde finale des logs: {e}")

        logger.info(
            f"Optimisation termin√©e: {session.final_status} | "
            f"Meilleur Sharpe: {session.best_result.sharpe_ratio:.3f}"
        )

        return session

    def _build_iteration_context(
        self,
        executor: BacktestExecutor,
        session: OptimizationSession,
        param_bounds: Dict[str, tuple],
        min_sharpe: float,
        max_drawdown: float,
    ) -> str:
        """Construit le contexte pour le LLM."""
        def _format_items(items: Any) -> str:
            if isinstance(items, (list, tuple)):
                return ", ".join(str(item) for item in items) if items else "N/A"
            return str(items) if items else "N/A"

        def _format_float(value: Any, precision: int = 2) -> str:
            try:
                return f"{float(value):.{precision}f}"
            except Exception:
                return "N/A"

        max_iter_label = "‚àû" if session.max_iterations <= 0 else str(session.max_iterations)

        lines = [
            f"=== Optimization Session: {session.strategy_name} ===",
            f"Iteration: {session.current_iteration}/{max_iter_label}",
            f"Target: {session.target_metric}",
            "",
        ]

        context_block = executor.get_context_for_agent()
        if context_block:
            lines.extend([context_block, ""])

        if session.comparison_context:
            context_data = session.comparison_context
            lines.extend([
                "Multi-Sweep Context:",
                f"  Mode: {context_data.get('mode', 'N/A')}",
                f"  Strategies: {_format_items(context_data.get('strategies'))}",
                f"  Symbols: {_format_items(context_data.get('symbols'))}",
                f"  Timeframes: {_format_items(context_data.get('timeframes'))}",
                f"  Total combinations: {context_data.get('total_combinations', 0)}",
            ])

            if context_data.get("has_results"):
                lines.extend([
                    f"  Sweeps: {context_data.get('total_sweeps', 0)}",
                    f"  Profitable: {context_data.get('profitable_count', 0)}",
                    f"  Avg PnL: {_format_float(context_data.get('avg_pnl'), 2)}",
                    f"  Median PnL: {_format_float(context_data.get('median_pnl'), 2)}",
                    f"  Best Sharpe: {_format_float(context_data.get('best_sharpe'), 3)}",
                    f"  Avg Sharpe: {_format_float(context_data.get('avg_sharpe'), 3)}",
                ])

                best_overall = context_data.get("best_overall")
                if isinstance(best_overall, dict) and best_overall:
                    best_strategy = best_overall.get("strategy", "")
                    best_symbol = best_overall.get("symbol", "")
                    best_timeframe = best_overall.get("timeframe", "")
                    best_pnl = _format_float(best_overall.get("total_pnl", best_overall.get("pnl", 0)), 2)
                    best_sharpe = _format_float(best_overall.get("sharpe_ratio", best_overall.get("sharpe", 0)), 3)
                    label = "  Best Overall:"
                    if best_strategy or best_symbol or best_timeframe:
                        lines.append(
                            f"{label} {best_strategy} {best_symbol} {best_timeframe} | "
                            f"PnL={best_pnl} Sharpe={best_sharpe}"
                        )
                    else:
                        lines.append(f"{label} PnL={best_pnl} Sharpe={best_sharpe}")

            lines.append("")

        if not session.indicator_context_cached:
            try:
                indicator_ctx = build_indicator_context(
                    df=executor.data,
                    strategy_name=session.strategy_name,
                    params=session.best_result.request.parameters,
                )
                session.strategy_indicators_context = indicator_ctx.get("strategy", "")
                session.readonly_indicators_context = indicator_ctx.get("read_only", "")
                session.indicator_context_warnings = indicator_ctx.get("warnings", [])
            except Exception:
                session.strategy_indicators_context = ""
                session.readonly_indicators_context = ""
                session.indicator_context_warnings = []
            session.indicator_context_cached = True

        if session.strategy_indicators_context:
            lines.extend([
                "Strategy Indicators (modifiable):",
                session.strategy_indicators_context,
                "",
            ])
        if session.readonly_indicators_context:
            lines.extend([
                "Context Indicators (read-only):",
                session.readonly_indicators_context,
                "",
            ])
        if session.indicator_context_warnings:
            lines.append("Indicator Context Warnings:")
            for w in session.indicator_context_warnings:
                lines.append(f"  - {w}")
            lines.append("")

        lines.extend([
            "Indicator Usage Notes:",
            "  - Strategy indicators are tied to tunable parameters.",
            "  - Context indicators are read-only and for regime interpretation only.",
            "  - Indicator values are computed once per run (baseline snapshot).",
            "",
        ])

        lines.append("Parameter Bounds:")

        # Calculer les statistiques d'espace de recherche
        try:
            stats = compute_search_space_stats(param_bounds, max_combinations=100000)

            for param, (min_val, max_val) in param_bounds.items():
                current = session.best_result.request.parameters.get(param, "?")
                param_count = stats.per_param_counts.get(param, "?")
                lines.append(
                    f"  {param}: [{min_val}, {max_val}] "
                    f"(current: {current}, values: {param_count})"
                )

            # Ajouter le r√©sum√© de l'espace de recherche
            lines.extend([
                "",
                "Search Space:",
                f"  {stats.summary()}",
            ])

            if stats.warnings:
                lines.append(f"  Warnings: {', '.join(stats.warnings)}")

        except Exception as e:
            # Fallback si le calcul des stats √©choue
            logger.warning(f"Failed to compute search space stats: {e}")
            for param, (min_val, max_val) in param_bounds.items():
                current = session.best_result.request.parameters.get(param, "?")
                lines.append(f"  {param}: [{min_val}, {max_val}] (current: {current})")

        lines.extend([
            "",
            "Constraints:",
            f"  Min Sharpe: {min_sharpe}",
            f"  Max Drawdown: {max_drawdown:.0%}",
        ])

        # Derni√®res d√©cisions
        if session.decisions:
            lines.extend(["", "Recent Decisions:"])
            for i, dec in enumerate(session.decisions[-5:], 1):
                lines.append(f"  {i}. {dec.action}: {dec.reasoning[:60]}...")

        lines.extend([
            "",
            "What is your next action?",
            "Remember: respond in JSON format with action, reasoning, next_hypothesis, next_parameters.",
        ])

        return "\n".join(lines)

    def _get_llm_decision(self, context: str, session: OptimizationSession) -> IterationDecision:
        """Obtient une d√©cision du LLM."""

        # Identifiant pour corr√©lation logs (optim_id = strategy + timestamp)
        import hashlib
        import time
        optim_id = f"{session.strategy_name}_{session.start_time.strftime('%Y%m%d_%H%M%S')}"

        # LLM_CALL_START
        # R√©cup√©rer config depuis le client LLM
        model_name = self.llm.config.model if hasattr(self.llm, 'config') else 'unknown'
        max_tokens = self.llm.config.max_tokens if hasattr(self.llm, 'config') else 0
        timeout = (
            getattr(self.llm.config, "timeout_seconds", 0)
            if hasattr(self.llm, "config")
            else 0
        )

        logger.info(
            f"LLM_CALL_START optim_id={optim_id} iteration={session.current_iteration} "
            f"model={model_name} temperature=0.5 "
            f"tokens_max={max_tokens} "
            f"timeout={timeout}"
        )

        # LLM_PROMPT_META
        context_hash = hashlib.sha256(context.encode()).hexdigest()[:8]
        logger.debug(
            f"LLM_PROMPT_META optim_id={optim_id} iteration={session.current_iteration} "
            f"prompt_hash={context_hash} prompt_chars={len(context)} "
            f"prompt_tokens={len(context.split())} template_version=v1.0"
        )

        # Appel LLM avec mesure latence
        start_time = time.time()
        response = self._call_llm(context, json_mode=True, temperature=0.5)
        latency = time.time() - start_time

        # LLM_RESPONSE_META
        tokens_out = len(response.content.split()) if response.content else 0
        logger.info(
            f"LLM_RESPONSE_META optim_id={optim_id} iteration={session.current_iteration} "
            f"latency_sec={latency:.2f} tokens_out={tokens_out} "
            f"finish_reason=complete"
        )

        if not response.content:
            logger.error("‚ùå LLM n'a pas r√©pondu (response.content vide)")
            return IterationDecision(
                action="stop",
                confidence=0.0,
                reasoning="LLM did not respond",
            )

        data = response.parse_json()
        if data is None:
            logger.error(
                f"‚ùå √âchec parsing JSON de la r√©ponse LLM. "
                f"R√©ponse brute (100 premiers chars): {response.content[:100]}"
            )
            return IterationDecision(
                action="stop",
                confidence=0.0,
                reasoning=f"Failed to parse LLM response: {response.content[:100]}",
            )

        # Log succ√®s du parsing
        action = data.get("action", "stop")
        logger.debug(f"‚úÖ D√©cision LLM pars√©e avec succ√®s: action='{action}'")

        # Protection contre les valeurs None du LLM
        next_params = data.get("next_parameters", {})
        if next_params is None:
            next_params = {}

        insights = data.get("insights", [])
        if insights is None:
            insights = []

        # Extraction champs sp√©cifiques au sweep
        ranges = data.get("ranges", None)
        rationale = data.get("rationale", "") or ""
        optimize_for = data.get("optimize_for", "sharpe_ratio")
        max_combinations = data.get("max_combinations", 100)

        # LLM_DECISION_PARSED
        reasoning_hash = hashlib.sha256(str(data.get("reasoning", "")).encode()).hexdigest()[:8]
        if action == "sweep":
            ranges_count = len(ranges) if ranges else 0
            logger.info(
                f"LLM_DECISION_PARSED optim_id={optim_id} iteration={session.current_iteration} "
                f"action={action} confidence={data.get('confidence', 0.5):.2f} "
                f"ranges_count={ranges_count} optimize_for={optimize_for} "
                f"max_combinations={max_combinations} reasoning_hash={reasoning_hash}"
            )
        else:
            logger.info(
                f"LLM_DECISION_PARSED optim_id={optim_id} iteration={session.current_iteration} "
                f"action={action} confidence={data.get('confidence', 0.5):.2f} "
                f"next_params_count={len(next_params) if next_params else 0} "
                f"next_params_keys={list(next_params.keys()) if next_params else []} "
                f"reasoning_hash={reasoning_hash}"
            )

        # LLM_FALLBACK_USED - Warning si next_parameters vide pour continue/change_direction
        if action in ("continue", "change_direction") and not next_params:
            logger.warning(
                f"LLM_FALLBACK_USED optim_id={optim_id} iteration={session.current_iteration} "
                f"action={action} fallback=will_use_defaults cause=next_params_empty"
            )

        # Validation sweep: ranges obligatoire si action == "sweep"
        if action == "sweep" and not ranges:
            logger.warning(
                f"LLM_INVALID_DECISION optim_id={optim_id} iteration={session.current_iteration} "
                f"action_original=sweep action_forced=stop reason=ranges_empty_or_missing"
            )
            return IterationDecision(
                action="stop",
                confidence=0.0,
                reasoning="LLM chose 'sweep' but provided no ranges. Stopping.",
            )

        return IterationDecision(
            action=action,
            confidence=data.get("confidence", 0.5),
            reasoning=data.get("reasoning", "") or "",
            next_hypothesis=data.get("next_hypothesis", "") or "",
            next_parameters=next_params,
            insights=insights,
            ranges=ranges,
            rationale=rationale,
            optimize_for=optimize_for,
            max_combinations=max_combinations,
        )

    def _validate_parameters(
        self,
        params: Dict[str, Any],
        bounds: Dict[str, tuple],
        defaults: Dict[str, Any],
        session: OptimizationSession,
    ) -> Dict[str, Any]:
        """Valide et corrige les param√®tres avec checks robustes."""

        # Identifiant pour corr√©lation logs
        optim_id = f"{session.strategy_name}_{session.start_time.strftime('%Y%m%d_%H%M%S')}"

        # VALIDATION_START
        logger.info(
            f"VALIDATION_START optim_id={optim_id} iteration={session.current_iteration} "
            f"validating=parameters proposed={params} bounds_count={len(bounds)}"
        )

        validated = {}
        used_defaults = []  # Track params qui utilisent defaults

        for param, bound_spec in bounds.items():
            try:
                # Extraire min/max selon le format des bounds
                # Peut √™tre (min, max) ou (min, max, step) ou [min, max, ...]
                if isinstance(bound_spec, (tuple, list)) and len(bound_spec) >= 2:
                    min_val = float(bound_spec[0])
                    max_val = float(bound_spec[1])

                    # Validation: min < max
                    if min_val >= max_val:
                        logger.warning(f"Param {param}: min >= max ({min_val} >= {max_val}), swap")
                        min_val, max_val = max_val, min_val
                else:
                    # Valeur scalaire (cas edge)
                    min_val = max_val = float(bound_spec) if not isinstance(bound_spec, (tuple, list)) else float(bound_spec[0])

                value_proposed = params.get(param)
                value_default = defaults.get(param)
                value = value_proposed if value_proposed is not None else value_default

                if value is None:
                    value = (min_val + max_val) / 2
                    used_defaults.append(param)
                else:
                    value = float(value)

                value_before_clamp = value

                # Clamp dans les bornes
                value = max(min_val, min(max_val, value))

                # Arrondir si n√©cessaire (detect int bounds)
                if all(isinstance(bound_spec[i], int) for i in range(2) if i < len(bound_spec)):
                    value = int(round(value))

                validated[param] = value

                # VALIDATION_RULE_RESULT - Log d√©tail validation
                status = "pass" if value_proposed is not None else "used_default"
                action = "clamped" if abs(value - value_before_clamp) > 1e-9 else "accepted"

                logger.debug(
                    f"VALIDATION_RULE_RESULT optim_id={optim_id} iteration={session.current_iteration} "
                    f"param={param} rule=bounds_check proposed={value_proposed} "
                    f"default={value_default} bounds=({min_val},{max_val}) "
                    f"final={value} status={status} action={action}"
                )

            except (ValueError, TypeError, IndexError) as e:
                logger.error(f"Param {param} validation failed: {e}, use default")
                validated[param] = defaults.get(param, 0)
                used_defaults.append(param)

        # VALIDATION_END
        logger.info(
            f"VALIDATION_END optim_id={optim_id} iteration={session.current_iteration} "
            f"validated={validated} used_defaults={used_defaults} verdict=accepted"
        )

        return validated

    def _is_better(
        self,
        new: BacktestResult,
        current: BacktestResult,
        metric: str,
    ) -> bool:
        """D√©termine si un r√©sultat est meilleur."""

        if not new.success:
            return False

        # V√©rifier overfitting
        if new.overfitting_ratio > 1.5:
            return False

        # Comparer la m√©trique
        new_value = getattr(new, metric, 0)
        current_value = getattr(current, metric, 0)

        if metric in ("max_drawdown",):  # M√©triques √† minimiser
            return new_value < current_value
        else:  # M√©triques √† maximiser
            return new_value > current_value

    def execute(self, context: AgentContext) -> AgentResult:
        """
        Ex√©cute une it√©ration (pour compatibilit√© avec BaseAgent).

        Pour une optimisation compl√®te, utilisez optimize() directement.
        """
        return AgentResult(
            success=True,
            agent_role=self.role,
            content="Use optimize() method for autonomous optimization",
            data={},
            execution_time_ms=0,
            tokens_used=0,
            llm_calls=0,
        )


def create_autonomous_optimizer(
    llm_config: LLMConfig,
    backtest_fn: Callable,
    strategy_name: str,
    data: pd.DataFrame,
    validation_fn: Optional[Callable] = None,
) -> tuple[AutonomousStrategist, BacktestExecutor]:
    """
    Factory pour cr√©er un optimiseur autonome complet.

    Args:
        llm_config: Configuration LLM
        backtest_fn: Fonction de backtest (strategy, params, data) -> metrics
        strategy_name: Nom de la strat√©gie
        data: DataFrame OHLCV
        validation_fn: Fonction walk-forward optionnelle

    Returns:
        (AutonomousStrategist, BacktestExecutor) pr√™ts √† l'emploi

    Example:
        >>> from agents.llm_client import LLMConfig, LLMProvider
        >>>
        >>> config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
        >>> strategist, executor = create_autonomous_optimizer(
        ...     llm_config=config,
        ...     backtest_fn=run_backtest,
        ...     strategy_name="ema_cross",
        ...     data=ohlcv_df,
        ... )
        >>>
        >>> session = strategist.optimize(
        ...     executor=executor,
        ...     initial_params={"fast": 10, "slow": 21},
        ...     param_bounds={"fast": (5, 20), "slow": (15, 50)},
        ... )
    """
    from .llm_client import create_llm_client

    llm_client = create_llm_client(llm_config)

    strategy_overview = get_strategy_overview(strategy_name)
    executor = BacktestExecutor(
        backtest_fn=backtest_fn,
        strategy_name=strategy_name,
        data=data,
        validation_fn=validation_fn,
        strategy_description=strategy_overview,
    )

    strategist = AutonomousStrategist(llm_client, verbose=True)

    return strategist, executor


# Docstring update summary
# - Docstring de module structur√©e et scannable (LLM-friendly)
# - Conventions explicit√©es (m√©trique, unit√©s, crit√®res d'arr√™t, GPU unload)
# - Read-if/Skip-if ajout√©s pour tri rapide
```
<!-- MODULE-END: autonomous_strategist.py -->

<!-- MODULE-START: backtest_executor.py -->
```json
{
  "name": "backtest_executor.py",
  "path": "agents\\backtest_executor.py",
  "ext": ".py",
  "anchor": "backtest_executor_py"
}
```
## backtest_executor_py
*Chemin* : `agents\backtest_executor.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.backtest_executor

Purpose: Fournir une interface stable pour ex√©cuter des backtests depuis les agents (batch, historique, contexte).

Role in pipeline: execution

Key components: BacktestExecutor, BacktestRequest, BacktestResult, ExperimentHistory, suggest_next_experiments

Inputs: backtest_fn callable, DataFrame OHLCV, strategy_name, parameters, options walk-forward (validation_fn)

Outputs: BacktestResult(s), agr√©gats/historique d‚Äôexp√©riences, contexte r√©sumable pour LLM

Dependencies: numpy, pandas, agents (dataclasses), validation_fn (walk-forward) si fourni

Conventions: *_pct keys are in percent (0-100); keys without suffix are fractions (0-1); execution_time_ms in milliseconds; request_id derived from params.

Read-if: Vous modifiez l‚Äôex√©cution des backtests c√¥t√© agents ou le format des r√©sultats expos√©s.

Skip-if: Vous ne touchez qu‚Äôau moteur backtest/ (engine/simulator/performance).
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import hashlib
import json
import logging
import time
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from metrics_types import normalize_metrics, pct_to_frac

logger = logging.getLogger(__name__)

if TYPE_CHECKING:  # pragma: no cover
    from agents.integration import AgentBacktestMetrics, WalkForwardMetrics

BacktestFn = Callable[[str, Dict[str, Any], pd.DataFrame], "AgentBacktestMetrics"]
ValidationFn = Callable[[str, Dict[str, Any], pd.DataFrame, int, float], "WalkForwardMetrics"]


@dataclass
class BacktestRequest:
    """Requ√™te de backtest formul√©e par un agent."""

    # Identification
    request_id: str = ""
    requested_by: str = ""  # Nom de l'agent
    hypothesis: str = ""     # Pourquoi ce test ? (valeur LLM)

    # Configuration
    strategy_name: str = ""
    parameters: Dict[str, Any] = field(default_factory=dict)

    # Options
    use_walk_forward: bool = True
    walk_forward_windows: int = 5
    train_ratio: float = 0.7

    # Timestamp
    created_at: datetime = field(default_factory=datetime.now)

    def __post_init__(self):
        if not self.request_id:
            # G√©n√©rer un ID bas√© sur les param√®tres
            param_str = json.dumps(self.parameters, sort_keys=True)
            self.request_id = hashlib.md5(
                f"{self.strategy_name}:{param_str}".encode()
            ).hexdigest()[:8]


@dataclass
class BacktestResult:
    """R√©sultat d'un backtest ex√©cut√©."""

    request: BacktestRequest
    success: bool

    # M√©triques principales
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    total_return: float = 0.0
    max_drawdown: float = 0.0
    win_rate: float = 0.0
    profit_factor: float = 0.0
    total_trades: int = 0

    # M√©triques Tier S
    sqn: float = 0.0
    calmar_ratio: float = 0.0
    recovery_factor: float = 0.0

    # Walk-Forward (si activ√©)
    train_sharpe: float = 0.0
    test_sharpe: float = 0.0
    overfitting_ratio: float = 0.0

    # M√©tadonn√©es
    execution_time_ms: float = 0.0
    error_message: str = ""

    # Donn√©es brutes (pour analyse d√©taill√©e)
    equity_curve: Optional[List[float]] = None
    trades: Optional[List[Dict]] = None

    def to_summary_dict(self) -> Dict[str, Any]:
        """R√©sum√© pour le LLM."""
        return {
            "request_id": self.request.request_id,
            "hypothesis": self.request.hypothesis,
            "parameters": self.request.parameters,
            "success": self.success,
            "sharpe_ratio": round(self.sharpe_ratio, 3),
            "sortino_ratio": round(self.sortino_ratio, 3),
            "total_return": f"{self.total_return:.2%}",
            "max_drawdown": f"{self.max_drawdown:.2%}",
            "win_rate": f"{self.win_rate:.2%}",
            "total_trades": self.total_trades,
            "overfitting_ratio": round(self.overfitting_ratio, 2) if self.overfitting_ratio else None,
            "execution_time_ms": round(self.execution_time_ms, 1),
        }

    def to_analysis_prompt(self) -> str:
        """Format pour analyse LLM."""
        lines = [
            f"=== Backtest Result: {self.request.request_id} ===",
            f"Hypothesis: {self.request.hypothesis}",
            f"Parameters: {json.dumps(self.request.parameters)}",
            "",
            "Metrics:",
            f"  Sharpe Ratio: {self.sharpe_ratio:.3f}",
            f"  Sortino Ratio: {self.sortino_ratio:.3f}",
            f"  Total Return: {self.total_return:.2%}",
            f"  Max Drawdown: {self.max_drawdown:.2%}",
            f"  Win Rate: {self.win_rate:.2%}",
            f"  Profit Factor: {self.profit_factor:.2f}",
            f"  Total Trades: {self.total_trades}",
        ]

        if self.overfitting_ratio > 0:
            lines.extend([
                "",
                "Walk-Forward Analysis:",
                f"  Train Sharpe: {self.train_sharpe:.3f}",
                f"  Test Sharpe: {self.test_sharpe:.3f}",
                f"  Overfitting Ratio: {self.overfitting_ratio:.2f}",
                f"  {'‚ö†Ô∏è OVERFITTING DETECTED' if self.overfitting_ratio > 1.5 else '‚úì Ratio acceptable'}",
            ])

        return "\n".join(lines)


@dataclass
class ExperimentHistory:
    """
    Historique complet des exp√©riences (backtests).

    Permet au LLM de voir tous les tests pr√©c√©dents,
    comprendre ce qui a √©t√© essay√©, et proposer de nouvelles directions.
    """

    experiments: List[BacktestResult] = field(default_factory=list)

    # Meilleure configuration trouv√©e
    best_result: Optional[BacktestResult] = None
    best_sharpe: float = float("-inf")

    # Statistiques
    total_experiments: int = 0
    total_time_ms: float = 0.0

    def add_result(self, result: BacktestResult) -> None:
        """Ajoute un r√©sultat et met √† jour les stats."""
        self.experiments.append(result)
        self.total_experiments += 1
        self.total_time_ms += result.execution_time_ms

        # Mettre √† jour le meilleur si applicable
        if result.success and result.sharpe_ratio > self.best_sharpe:
            # V√©rifier overfitting
            if result.overfitting_ratio == 0 or result.overfitting_ratio < 1.5:
                self.best_result = result
                self.best_sharpe = result.sharpe_ratio
                logger.info(
                    f"Nouveau meilleur r√©sultat: Sharpe={result.sharpe_ratio:.3f} "
                    f"avec params={result.request.parameters}"
                )

    def get_tried_parameters(self) -> List[Dict[str, Any]]:
        """Retourne tous les param√®tres d√©j√† test√©s."""
        return [exp.request.parameters for exp in self.experiments]

    def get_summary_for_llm(self, last_n: int = 10) -> str:
        """G√©n√®re un r√©sum√© pour le LLM."""
        lines = [
            f"=== Experiment History ({self.total_experiments} total) ===",
            "",
        ]

        if self.best_result:
            lines.extend([
                "Best Configuration Found:",
                f"  Parameters: {json.dumps(self.best_result.request.parameters)}",
                f"  Sharpe: {self.best_sharpe:.3f}",
                f"  Return: {self.best_result.total_return:.2%}",
                f"  Drawdown: {self.best_result.max_drawdown:.2%}",
                "",
            ])

        # Derni√®res exp√©riences
        recent = self.experiments[-last_n:] if len(self.experiments) > last_n else self.experiments

        lines.append(f"Last {len(recent)} Experiments:")
        for i, exp in enumerate(recent, 1):
            status = "‚úì" if exp.success else "‚úó"
            sharpe = f"{exp.sharpe_ratio:.2f}" if exp.success else "N/A"
            lines.append(
                f"  {i}. [{status}] {exp.request.hypothesis[:50]}... "
                f"Sharpe={sharpe}"
            )

        # Insights
        if len(self.experiments) >= 3:
            sharpes = [e.sharpe_ratio for e in self.experiments if e.success]
            if sharpes:
                lines.extend([
                    "",
                    "Insights:",
                    f"  Average Sharpe: {np.mean(sharpes):.3f}",
                    f"  Sharpe Range: [{min(sharpes):.3f}, {max(sharpes):.3f}]",
                    f"  Improvement: {'+' if len(sharpes) > 1 and sharpes[-1] > sharpes[0] else ''}"
                    f"{((sharpes[-1] - sharpes[0]) / abs(sharpes[0]) * 100):.1f}% from first to last"
                    if len(sharpes) > 1 and sharpes[0] != 0 else "",
                ])

        return "\n".join(lines)

    def analyze_parameter_sensitivity(self) -> Dict[str, Dict[str, float]]:
        """
        Analyse la sensibilit√© des param√®tres.

        Utile pour le LLM : savoir quels param√®tres ont le plus d'impact.
        """
        if len(self.experiments) < 3:
            return {}

        # Collecter les donn√©es
        param_values: Dict[str, List[Tuple[Any, float]]] = {}

        for exp in self.experiments:
            if not exp.success:
                continue
            for param, value in exp.request.parameters.items():
                if param not in param_values:
                    param_values[param] = []
                param_values[param].append((value, exp.sharpe_ratio))

        # Calculer la corr√©lation pour chaque param√®tre
        sensitivity = {}
        for param, values in param_values.items():
            if len(values) < 3:
                continue

            # Convertir en arrays
            try:
                x = np.array([float(v[0]) for v in values])
                y = np.array([v[1] for v in values])

                # Corr√©lation
                if np.std(x) > 0 and np.std(y) > 0:
                    corr = np.corrcoef(x, y)[0, 1]
                    sensitivity[param] = {
                        "correlation": float(corr),
                        "impact": abs(float(corr)),
                        "direction": "positive" if corr > 0 else "negative",
                        "range_tested": [float(min(x)), float(max(x))],
                    }
            except (ValueError, TypeError):
                continue

        return sensitivity


class BacktestExecutor:
    """
    Ex√©cuteur de backtests pour les agents LLM.

    L'agent peut :
    1. Demander un backtest avec une hypoth√®se
    2. Recevoir les r√©sultats
    3. Analyser et formuler une nouvelle hypoth√®se
    4. It√©rer

    Example:
        >>> executor = BacktestExecutor(engine, strategy, data)
        >>>
        >>> # L'agent formule une hypoth√®se
        >>> request = BacktestRequest(
        ...     hypothesis="Reducing fast_period should capture more signals",
        ...     parameters={"fast_period": 8, "slow_period": 21}
        ... )
        >>>
        >>> # Ex√©cution
        >>> result = executor.run(request)
        >>>
        >>> # L'agent analyse
        >>> print(result.to_analysis_prompt())
    """

    def __init__(
        self,
        backtest_fn: BacktestFn,
        strategy_name: str,
        data: pd.DataFrame,
        validation_fn: Optional[ValidationFn] = None,
        strategy_description: str = "",
    ) -> None:
        """
        Initialise l'ex√©cuteur.

        Args:
            backtest_fn: Fonction de backtest (strategy_name, params, data) -> metrics
            strategy_name: Nom de la strat√©gie
            data: DataFrame OHLCV
            validation_fn: Fonction de validation walk-forward optionnelle
        """
        self.backtest_fn = backtest_fn
        self.strategy_name = strategy_name
        self.data = data
        self.validation_fn = validation_fn
        self.strategy_description = strategy_description

        self.history = ExperimentHistory()

        logger.info(f"BacktestExecutor initialis√©: strategy={strategy_name}, rows={len(data)}")

    def run(self, request: BacktestRequest) -> BacktestResult:
        """
        Ex√©cute un backtest pour une requ√™te d'agent.

        Returns:
            BacktestResult avec toutes les m√©triques
        """
        request.strategy_name = self.strategy_name

        hypothesis_preview = (
            request.hypothesis[:50] + "..." if request.hypothesis else "N/A"
        )
        logger.info(
            f"Ex√©cution backtest: {request.request_id} | "
            f"Hypoth√®se: {hypothesis_preview}"
        )

        start_time = time.time()

        try:
            # Ex√©cuter le backtest principal
            metrics_raw: AgentBacktestMetrics = self.backtest_fn(
                self.strategy_name,
                request.parameters,
                self.data
            )

            if any(
                key in metrics_raw
                for key in ("total_return_pct", "max_drawdown_pct", "win_rate_pct")
            ):
                metrics_frac = pct_to_frac(metrics_raw)
            else:
                metrics_frac = normalize_metrics(metrics_raw, "frac")

            result = BacktestResult(
                request=request,
                success=True,
                sharpe_ratio=metrics_frac.get("sharpe_ratio", 0),
                sortino_ratio=metrics_frac.get("sortino_ratio", 0),
                total_return=metrics_frac.get("total_return", 0),
                max_drawdown=metrics_frac.get("max_drawdown", 0),
                win_rate=metrics_frac.get("win_rate", 0),
                profit_factor=metrics_frac.get("profit_factor", 0),
                total_trades=metrics_frac.get("total_trades", 0),
                sqn=metrics_frac.get("sqn", 0),
                calmar_ratio=metrics_frac.get("calmar_ratio", 0),
                recovery_factor=metrics_frac.get("recovery_factor", 0),
                equity_curve=metrics_frac.get("equity_curve"),
                trades=metrics_frac.get("trades"),
            )

            # Walk-forward si demand√© et disponible
            if request.use_walk_forward and self.validation_fn:
                try:
                    wf_result = self.validation_fn(
                        self.strategy_name,
                        request.parameters,
                        self.data,
                        n_windows=request.walk_forward_windows,
                        train_ratio=request.train_ratio,
                    )
                    result.train_sharpe = wf_result.get("train_sharpe", 0)
                    result.test_sharpe = wf_result.get("test_sharpe", 0)
                    result.overfitting_ratio = wf_result.get("overfitting_ratio", 0)
                except Exception as e:
                    logger.warning(f"Walk-forward √©chou√©: {e}")

            result.execution_time_ms = (time.time() - start_time) * 1000

        except Exception as e:
            logger.error(f"Backtest √©chou√©: {e}")
            result = BacktestResult(
                request=request,
                success=False,
                error_message=str(e),
                execution_time_ms=(time.time() - start_time) * 1000,
            )

        # Enregistrer dans l'historique
        self.history.add_result(result)

        return result

    def run_batch(self, requests: List[BacktestRequest]) -> List[BacktestResult]:
        """Ex√©cute plusieurs backtests en s√©quence."""
        return [self.run(req) for req in requests]

    def get_context_for_agent(self) -> str:
        """
        G√©n√®re le contexte complet pour un agent LLM.

        Inclut :
        - Historique des exp√©riences
        - Meilleure configuration
        - Analyse de sensibilit√©
        - Suggestions bas√©es sur les patterns
        """
        lines: List[str] = []

        if self.strategy_description:
            lines.extend([
                "=== Strategy Overview ===",
                self.strategy_description.strip(),
                "",
            ])

        lines.extend([
            self.history.get_summary_for_llm(),
            "",
        ])

        # Analyse de sensibilit√©
        sensitivity = self.history.analyze_parameter_sensitivity()
        if sensitivity:
            lines.extend([
                "Parameter Sensitivity Analysis:",
            ])
            for param, stats in sorted(
                sensitivity.items(),
                key=lambda x: x[1]["impact"],
                reverse=True
            ):
                direction = "‚Üë" if stats["direction"] == "positive" else "‚Üì"
                lines.append(
                    f"  {param}: impact={stats['impact']:.2f} {direction} "
                    f"(range: {stats['range_tested']})"
                )
            lines.append("")

        # Param√®tres non encore test√©s dans certaines plages
        if self.history.total_experiments > 0:
            lines.extend([
                "Observations:",
                f"  - {self.history.total_experiments} experiments completed",
                f"  - Total compute time: {self.history.total_time_ms/1000:.1f}s",
            ])

            if self.history.best_result:
                if self.history.best_result.overfitting_ratio > 1.3:
                    lines.append("  - ‚ö†Ô∏è Best config shows some overfitting tendency")
                if self.history.best_result.total_trades < 50:
                    lines.append("  - ‚ö†Ô∏è Low trade count - consider wider parameters")

        return "\n".join(lines)

    def suggest_next_experiments(self, n: int = 3) -> List[Dict[str, Any]]:
        """
        Sugg√®re les prochaines exp√©riences bas√©es sur l'historique.

        Ce n'est PAS de l'intelligence LLM - c'est de l'exploration
        algorithmique pour guider le LLM.
        """
        suggestions = []

        if not self.history.best_result:
            return suggestions

        best_params = self.history.best_result.request.parameters
        sensitivity = self.history.analyze_parameter_sensitivity()

        # 1. Varier le param√®tre le plus impactant
        if sensitivity:
            most_impactful = max(sensitivity.items(), key=lambda x: x[1]["impact"])
            param_name = most_impactful[0]
            if param_name in best_params:
                current = best_params[param_name]
                # Explorer dans la direction favorable
                if most_impactful[1]["direction"] == "positive":
                    new_value = current * 1.2
                else:
                    new_value = current * 0.8

                suggestions.append({
                    "type": "sensitivity_exploration",
                    "rationale": f"Explore {param_name} in favorable direction",
                    "parameters": {**best_params, param_name: int(new_value)},
                })

        # 2. Perturbation al√©atoire autour du meilleur
        perturbed = {}
        for k, v in best_params.items():
            if isinstance(v, (int, float)):
                # ¬±10% perturbation
                perturbed[k] = int(v * (1 + np.random.uniform(-0.1, 0.1)))

        if perturbed:
            suggestions.append({
                "type": "local_search",
                "rationale": "Small perturbation around best config",
                "parameters": perturbed,
            })

        return suggestions[:n]
```
<!-- MODULE-END: backtest_executor.py -->

<!-- MODULE-START: base_agent.py -->
```json
{
  "name": "base_agent.py",
  "path": "agents\\base_agent.py",
  "ext": ".py",
  "anchor": "base_agent_py"
}
```
## base_agent_py
*Chemin* : `agents\base_agent.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.base_agent

Purpose: Classe abstraite et structures communes pour tous les agents LLM (Analyst/Strategist/Critic/Validator).

Role in pipeline: orchestration

Key components: BaseAgent (abstract), AgentRole, MetricsSnapshot, ParameterConfig, AgentContext, AgentResult

Inputs: AgentContext (√©tat partag√© entre agents)

Outputs: AgentResult (succ√®s/erreur + r√©sultat typ√©)

Dependencies: agents.llm_client, agents.state_machine, utils.log

Conventions: Chaque agent impl√©mente execute() et role property; _call_llm() helper pour requ√™tes LLM; AgentContext immuable entre appels.

Read-if: Modification contrat agent, ajout de nouvelles structures, ou int√©gration LLM.

Skip-if: Vous ne changez qu'un agent sp√©cifique.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Mapping, Optional

from .llm_client import LLMClient, LLMMessage, LLMResponse
from .state_machine import ValidationResult

logger = logging.getLogger(__name__)


class AgentRole(Enum):
    """R√¥les des agents."""
    ANALYST = "analyst"
    STRATEGIST = "strategist"
    CRITIC = "critic"
    VALIDATOR = "validator"


@dataclass
class MetricsSnapshot:
    """Snapshot des m√©triques de performance."""

    # M√©triques de base
    total_return: float = 0.0
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    max_drawdown: float = 0.0
    win_rate: float = 0.0
    profit_factor: float = 0.0

    # M√©triques Tier S
    sqn: float = 0.0
    calmar_ratio: float = 0.0
    recovery_factor: float = 0.0
    ulcer_index: float = 0.0

    # Stats trades
    total_trades: int = 0
    avg_trade_duration: float = 0.0

    @classmethod
    def from_dict(cls, data: Mapping[str, Any]) -> MetricsSnapshot:
        """Cr√©e depuis un dictionnaire."""
        total_return = data.get("total_return")
        if total_return is None:
            total_return_pct = data.get("total_return_pct", 0.0)
            total_return = total_return_pct / 100.0

        max_drawdown = data.get("max_drawdown", 0.0)
        if abs(max_drawdown) > 1.0:
            max_drawdown = max_drawdown / 100.0

        win_rate = data.get("win_rate", 0.0)
        if win_rate > 1.0:
            win_rate = win_rate / 100.0

        avg_trade_duration = data.get("avg_trade_duration")
        if avg_trade_duration is None:
            avg_trade_duration = data.get("avg_trade_duration_hours", 0.0)

        return cls(
            total_return=total_return,
            sharpe_ratio=data.get("sharpe_ratio", 0.0),
            sortino_ratio=data.get("sortino_ratio", 0.0),
            max_drawdown=max_drawdown,
            win_rate=win_rate,
            profit_factor=data.get("profit_factor", 0.0),
            sqn=data.get("sqn", 0.0),
            calmar_ratio=data.get("calmar_ratio", 0.0),
            recovery_factor=data.get("recovery_factor", 0.0),
            ulcer_index=data.get("ulcer_index", 0.0),
            total_trades=data.get("total_trades", 0),
            avg_trade_duration=avg_trade_duration,
        )

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "total_return": self.total_return,
            "sharpe_ratio": self.sharpe_ratio,
            "sortino_ratio": self.sortino_ratio,
            "max_drawdown": self.max_drawdown,
            "win_rate": self.win_rate,
            "profit_factor": self.profit_factor,
            "sqn": self.sqn,
            "calmar_ratio": self.calmar_ratio,
            "recovery_factor": self.recovery_factor,
            "ulcer_index": self.ulcer_index,
            "total_trades": self.total_trades,
            "avg_trade_duration": self.avg_trade_duration,
        }

    def to_summary_str(self) -> str:
        """R√©sum√© textuel pour le LLM."""
        return f"""Performance Metrics:
- Total Return: {self.total_return:.2%}
- Sharpe Ratio: {self.sharpe_ratio:.2f}
- Sortino Ratio: {self.sortino_ratio:.2f}
- Max Drawdown: {self.max_drawdown:.2%}
- Win Rate: {self.win_rate:.2%}
- Profit Factor: {self.profit_factor:.2f}
- SQN: {self.sqn:.2f}
- Calmar Ratio: {self.calmar_ratio:.2f}
- Recovery Factor: {self.recovery_factor:.2f}
- Total Trades: {self.total_trades}"""


@dataclass
class ParameterConfig:
    """Configuration d'un param√®tre de strat√©gie."""

    name: str
    current_value: Any
    min_value: Any = None
    max_value: Any = None
    step: Any = None
    description: str = ""

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "current_value": self.current_value,
            "min_value": self.min_value,
            "max_value": self.max_value,
            "step": self.step,
            "description": self.description,
        }


@dataclass
class AgentContext:
    """
    Contexte partag√© entre les agents.

    Contient toutes les informations n√©cessaires pour
    l'analyse et la prise de d√©cision.
    """

    # Identification
    session_id: str = ""
    iteration: int = 0

    # Strat√©gie
    strategy_name: str = ""
    strategy_description: str = ""
    current_params: Dict[str, Any] = field(default_factory=dict)
    param_specs: List[ParameterConfig] = field(default_factory=list)

    # Donn√©es
    data_path: str = ""
    data_symbol: str = ""
    data_timeframe: str = ""
    data_rows: int = 0
    data_date_range: str = ""
    comparison_context: Optional[Dict[str, Any]] = None

    # R√©sultats actuels
    current_metrics: Optional[MetricsSnapshot] = None
    train_metrics: Optional[MetricsSnapshot] = None
    test_metrics: Optional[MetricsSnapshot] = None

    # Walk-forward results
    walk_forward_results: List[Dict[str, Any]] = field(default_factory=list)
    overfitting_ratio: float = 0.0
    classic_ratio: float = 0.0
    degradation_pct: float = 0.0
    test_stability_std: float = 0.0
    n_valid_folds: int = 0
    walk_forward_windows: int = 0

    # Historique des it√©rations
    iteration_history: List[Dict[str, Any]] = field(default_factory=list)
    best_metrics: Optional[MetricsSnapshot] = None
    best_params: Dict[str, Any] = field(default_factory=dict)

    # Objectifs
    optimization_target: str = "sharpe_ratio"
    min_sharpe: float = 1.0
    max_drawdown_limit: float = 0.20
    min_trades: int = 30
    max_overfitting_ratio: float = 1.5

    # Messages des agents pr√©c√©dents
    analyst_report: str = ""
    strategist_proposals: List[Dict[str, Any]] = field(default_factory=list)
    critic_assessment: str = ""
    critic_concerns: List[str] = field(default_factory=list)
    memory_summary: str = ""

    # Contexte indicateurs (strat√©gie vs lecture seule)
    strategy_indicators_context: str = ""
    readonly_indicators_context: str = ""
    indicator_context_warnings: List[str] = field(default_factory=list)

    # R√©sultats de sweep (LLM grid search)
    sweep_results: Optional[Dict[str, Any]] = None
    sweep_summary: str = ""

    def to_summary_str(self) -> str:
        """R√©sum√© textuel pour le LLM."""
        summary = f"""=== Optimization Context ===
Strategy: {self.strategy_name}
Data: {self.data_symbol} {self.data_timeframe} ({self.data_rows} rows)
Date Range: {self.data_date_range}
Iteration: {self.iteration}

Current Parameters:
{self._params_to_str()}

Optimization Objectives:
- Target: {self.optimization_target}
- Min Sharpe: {self.min_sharpe}
- Max Drawdown: {self.max_drawdown_limit:.0%}
- Min Trades: {self.min_trades}
- Max Overfitting Ratio: {self.max_overfitting_ratio}
"""

        if self.current_metrics:
            summary += f"\n{self.current_metrics.to_summary_str()}"

        if self.train_metrics and self.test_metrics:
            summary += f"""

Walk-Forward Analysis:
- Train Sharpe: {self.train_metrics.sharpe_ratio:.2f}
- Test Sharpe: {self.test_metrics.sharpe_ratio:.2f}
- Overfitting Ratio: {self.overfitting_ratio:.2f}
"""

        return summary

    def _params_to_str(self) -> str:
        """Formate les param√®tres en string."""
        lines = []
        for k, v in self.current_params.items():
            lines.append(f"  {k}: {v}")
        return "\n".join(lines) if lines else "  (none)"


@dataclass
class AgentResult:
    """
    R√©sultat d'ex√©cution d'un agent.

    Contient:
    - Le succ√®s/√©chec
    - Les donn√©es produites
    - Les erreurs √©ventuelles
    - Les m√©triques de performance
    """

    success: bool
    agent_role: AgentRole

    # Contenu principal
    content: str = ""
    data: Dict[str, Any] = field(default_factory=dict)

    # Erreurs et avertissements
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)

    # M√©triques d'ex√©cution
    execution_time_ms: float = 0.0
    tokens_used: int = 0
    llm_calls: int = 0

    # Timestamp
    timestamp: datetime = field(default_factory=datetime.now)

    # R√©ponse LLM brute (pour debug)
    raw_llm_response: Optional[LLMResponse] = None

    @classmethod
    def success_result(
        cls,
        role: AgentRole,
        content: str,
        data: Optional[Dict[str, Any]] = None,
        **kwargs,
    ) -> AgentResult:
        """Cr√©e un r√©sultat de succ√®s."""
        return cls(
            success=True,
            agent_role=role,
            content=content,
            data=data or {},
            **kwargs,
        )

    @classmethod
    def failure_result(
        cls,
        role: AgentRole,
        error: str,
        **kwargs,
    ) -> AgentResult:
        """Cr√©e un r√©sultat d'√©chec."""
        return cls(
            success=False,
            agent_role=role,
            errors=[error],
            **kwargs,
        )

    def to_validation_result(self) -> ValidationResult:
        """Convertit en ValidationResult pour la state machine."""
        if self.success:
            return ValidationResult.success(
                message=self.content[:100] if self.content else "OK",
                **self.data,
            )
        else:
            return ValidationResult.failure(
                message=self.errors[0] if self.errors else "Unknown error",
                errors=self.errors,
            )


class BaseAgent(ABC):
    """
    Classe de base pour tous les agents LLM.

    Chaque agent doit impl√©menter:
    - role: Son r√¥le dans le workflow
    - system_prompt: Le prompt syst√®me d√©finissant sa personnalit√©
    - execute(): La logique d'ex√©cution principale
    - validate_result(): Validation du r√©sultat produit
    """

    def __init__(self, llm_client: LLMClient) -> None:
        """
        Initialise l'agent.

        Args:
            llm_client: Client LLM √† utiliser
        """
        self.llm = llm_client
        self._execution_count = 0
        self._total_tokens = 0

    @property
    @abstractmethod
    def role(self) -> AgentRole:
        """R√¥le de l'agent."""
        pass

    @property
    @abstractmethod
    def system_prompt(self) -> str:
        """Prompt syst√®me d√©finissant la personnalit√© de l'agent."""
        pass

    @abstractmethod
    def execute(self, context: AgentContext) -> AgentResult:
        """
        Ex√©cute la t√¢che principale de l'agent.

        Args:
            context: Contexte d'ex√©cution

        Returns:
            R√©sultat de l'ex√©cution
        """
        pass

    def validate_result(self, result: AgentResult) -> ValidationResult:
        """
        Valide le r√©sultat produit par l'agent.

        Args:
            result: R√©sultat √† valider

        Returns:
            R√©sultat de validation
        """
        if not result.success:
            return ValidationResult.failure(
                f"Agent {self.role.value} a √©chou√©",
                errors=result.errors,
            )

        if not result.content and not result.data:
            return ValidationResult.failure(
                f"Agent {self.role.value} n'a produit aucun r√©sultat"
            )

        return ValidationResult.success()

    def _call_llm(
        self,
        user_message: str,
        json_mode: bool = False,
        temperature: Optional[float] = None,
    ) -> LLMResponse:
        """
        Appelle le LLM avec le prompt syst√®me de l'agent.

        Args:
            user_message: Message utilisateur
            json_mode: Forcer r√©ponse JSON
            temperature: Override temp√©rature

        Returns:
            R√©ponse LLM
        """
        messages = [
            LLMMessage(role="system", content=self.system_prompt),
            LLMMessage(role="user", content=user_message),
        ]

        response = self.llm.chat(
            messages,
            json_mode=json_mode,
            temperature=temperature,
        )

        self._execution_count += 1
        self._total_tokens += response.total_tokens

        return response

    @property
    def stats(self) -> Dict[str, Any]:
        """Statistiques de l'agent."""
        return {
            "role": self.role.value,
            "execution_count": self._execution_count,
            "total_tokens": self._total_tokens,
        }
```
<!-- MODULE-END: base_agent.py -->

<!-- MODULE-START: critic.py -->
```json
{
  "name": "critic.py",
  "path": "agents\\critic.py",
  "ext": ".py",
  "anchor": "critic_py"
}
```
## critic_py
*Chemin* : `agents\critic.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.critic

Purpose: √âvaluer critiquement les propositions pour d√©tecter overfitting et risques cach√©s.

Role in pipeline: orchestration

Key components: CriticAgent, CriticEvaluation, CriticResponse

Inputs: AgentContext (proposals du Strategist, walk-forward metrics si dispos)

Outputs: CriticResponse (√©vals par proposition, concerns consolid√©s, propositions approuv√©es)

Dependencies: agents.base_agent, utils.template, backtest.validation (walk-forward)

Conventions: Ratios overfitting calcul√©s √† partir de walk-forward si dispos; concern_severity (LOW/MEDIUM/HIGH/CRITICAL); template Jinja2.

Read-if: Modification logique critique, seuils overfitting, ou int√©gration walk-forward.

Skip-if: Vous ne modifiez que analyze/propose/validate.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
import time
from typing import Any, Dict, List

from utils.template import render_prompt

from .base_agent import (
    AgentContext,
    AgentResult,
    AgentRole,
    BaseAgent,
)

logger = logging.getLogger(__name__)


class CriticAgent(BaseAgent):
    """
    Agent Critic - Expert en d√©tection des risques.

    √âvalue:
    - Risque d'overfitting pour chaque proposition
    - Coh√©rence des changements propos√©s
    - Risques cach√©s ou non √©vidents
    - Faisabilit√© et robustesse
    """

    @property
    def role(self) -> AgentRole:
        return AgentRole.CRITIC

    @property
    def system_prompt(self) -> str:
        return """You are a senior risk analyst and trading strategy auditor with a skeptical mindset.
Your role is to critically evaluate optimization proposals and identify potential issues.

NEW WALK-FORWARD METRICS AVAILABLE:
- classic_ratio: average train Sharpe / average test Sharpe
- overfitting_ratio: classic_ratio + penalty for test instability (higher = worse)
- degradation_pct: % drop from train to test performance (0% = perfect forward)
- test_stability_std: standard deviation of test Sharpe across folds (lower = stable)
- n_valid_folds: number of successful out-of-sample tests

RED FLAGS (reject or flag heavily):
- overfitting_ratio > 1.8
- degradation_pct > 40%
- test_stability_std > 0.5
- n_valid_folds < 4

ADDITIONAL RED FLAGS:
- Very specific parameter values (e.g., 17.3 instead of 15 or 20)
- Large improvements with small changes
- Parameters at extreme bounds
- Inconsistent with analyst findings
- Overly complex parameter interactions

SCORING GUIDELINES:
- overfitting_score: 0-100 (0=no risk, 100=certain overfitting)
- robustness_score: 0-100 (0=fragile, 100=very robust)
- recommendation: APPROVE|MODIFY|REJECT

When evaluating proposals:
1. Prioritize walk-forward metrics - they are the strongest indicator of overfitting
2. Be skeptical but fair - look for real problems, not imaginary ones
3. Consider if changes could be data-mined coincidences
4. Check if the proposal addresses the real weakness or just symptoms
5. Evaluate if the expected improvement is realistic
6. Consider edge cases and regime changes

Respond ONLY in valid JSON format with this exact structure:
{
    "overall_assessment": "Brief critical summary",
    "walk_forward_summary": "Specific assessment of out-of-sample stability and degradation",
    "market_regime_concerns": ["concern1", "concern2"],
    "statistical_concerns": ["concern1", "concern2"],
    "proposal_evaluations": [
        {
            "proposal_id": 1,
            "overfitting_score": 0-100,
            "robustness_score": 0-100,
            "recommendation": "APPROVE|MODIFY|REJECT",
            "critical_issues": ["issue1", "issue2"],
            "warnings": ["warning1", "warning2"],
            "suggested_modifications": ["modification1"],
            "reasoning": "Detailed reasoning for the evaluation"
        }
    ],
    "approved_proposals": [1, 2],
    "rejected_proposals": [3],
    "best_proposal_id": 1,
    "proceed_with_testing": true/false,
    "final_concerns": ["Any remaining concerns to flag"]
}"""

    def execute(self, context: AgentContext) -> AgentResult:
        """
        √âvalue critiquement les propositions.

        Args:
            context: Contexte avec propositions du Strategist

        Returns:
            √âvaluation critique
        """
        start_time = time.time()

        # V√©rifier qu'il y a des propositions
        if not context.strategist_proposals:
            return AgentResult.failure_result(
                self.role,
                "Aucune proposition √† √©valuer",
                execution_time_ms=0,
            )

        # Construire le prompt
        user_prompt = self._build_critique_prompt(context)

        # Appeler le LLM
        response = self._call_llm(user_prompt, json_mode=True, temperature=0.3)

        execution_time = (time.time() - start_time) * 1000

        # V√©rifier la r√©ponse
        if not response.content:
            return AgentResult.failure_result(
                self.role,
                "LLM n'a pas retourn√© de r√©ponse",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Parser le JSON
        critique = response.parse_json()
        if critique is None:
            return AgentResult.failure_result(
                self.role,
                f"√âchec parsing JSON: {response.parse_error}",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Valider la structure
        validation_errors = self._validate_critique(critique)
        if validation_errors:
            logger.warning(f"Critique partiellement invalide: {validation_errors}")

        # Extraire les informations cl√©s
        approved = critique.get("approved_proposals", [])
        rejected = critique.get("rejected_proposals", [])
        best_id = critique.get("best_proposal_id")

        # Filtrer les propositions approuv√©es
        approved_proposals = []
        for prop in context.strategist_proposals:
            prop_id = prop.get("id")
            if prop_id in approved:
                # Trouver l'√©valuation correspondante
                eval_data = next(
                    (e for e in critique.get("proposal_evaluations", [])
                     if e.get("proposal_id") == prop_id),
                    {}
                )
                prop["critic_evaluation"] = eval_data
                prop["is_best"] = (prop_id == best_id)
                approved_proposals.append(prop)

        # Collecter les concerns
        concerns = (
            critique.get("market_regime_concerns", []) +
            critique.get("statistical_concerns", []) +
            critique.get("final_concerns", [])
        )

        return AgentResult.success_result(
            self.role,
            content=critique.get("overall_assessment", ""),
            data={
                "critique": critique,
                "approved_proposals": approved_proposals,
                "rejected_count": len(rejected),
                "best_proposal_id": best_id,
                "proceed_with_testing": critique.get("proceed_with_testing", False),
                "concerns": concerns,
                "proposal_evaluations": critique.get("proposal_evaluations", []),
            },
            execution_time_ms=execution_time,
            tokens_used=response.total_tokens,
            llm_calls=1,
            raw_llm_response=response,
        )

    def _build_critique_prompt(self, context: AgentContext) -> str:
        """Construit le prompt de critique via template Jinja2."""

        # Convertir MetricsSnapshot en dict pour le template
        current_metrics_dict = None
        if context.current_metrics:
            current_metrics_dict = context.current_metrics.to_dict()

        template_context = {
            "strategy_name": context.strategy_name,
            "strategy_description": context.strategy_description,
            "iteration": context.iteration,
            "comparison_context": context.comparison_context,
            "current_metrics": current_metrics_dict,
            "overfitting_ratio": context.overfitting_ratio,
            "classic_ratio": getattr(context, "classic_ratio", None),
            "degradation_pct": getattr(context, "degradation_pct", None),
            "test_stability_std": getattr(context, "test_stability_std", None),
            "n_valid_folds": getattr(context, "n_valid_folds", None),
            "walk_forward_windows": getattr(context, "walk_forward_windows", None),
            "data_rows": getattr(context, "data_rows", None),
            "data_date_range": getattr(context, "data_date_range", None),
            "analyst_report": context.analyst_report,
            "strategist_proposals": context.strategist_proposals,
            "current_params": context.current_params,
            "param_specs": context.param_specs,
            "min_sharpe": context.min_sharpe,
            "min_trades": context.min_trades,
            "max_drawdown_limit": context.max_drawdown_limit,
            "max_overfitting_ratio": context.max_overfitting_ratio,
            "iteration_history": context.iteration_history,
            "memory_summary": context.memory_summary,
            "strategy_indicators_context": context.strategy_indicators_context,
            "readonly_indicators_context": context.readonly_indicators_context,
            "indicator_context_warnings": context.indicator_context_warnings,
        }

        return render_prompt("critic.jinja2", template_context)

    def _validate_critique(self, critique: Dict[str, Any]) -> List[str]:
        """Valide la structure de la critique."""
        errors = []

        required_fields = [
            "overall_assessment",
            "proposal_evaluations",
            "proceed_with_testing",
        ]

        for field in required_fields:
            if field not in critique:
                errors.append(f"Champ manquant: {field}")

        # Valider les √©valuations
        evaluations = critique.get("proposal_evaluations", [])
        for eval_data in evaluations:
            if "proposal_id" not in eval_data:
                errors.append("proposal_id manquant dans √©valuation")
            if "recommendation" not in eval_data:
                errors.append("recommendation manquante dans √©valuation")
            elif eval_data["recommendation"] not in ["APPROVE", "MODIFY", "REJECT"]:
                errors.append(f"recommendation invalide: {eval_data['recommendation']}")

        return errors
```
<!-- MODULE-END: critic.py -->

<!-- MODULE-START: indicator_context.py -->
```json
{
  "name": "indicator_context.py",
  "path": "agents\\indicator_context.py",
  "ext": ".py",
  "anchor": "indicator_context_py"
}
```
## indicator_context_py
*Chemin* : `agents\indicator_context.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.indicator_context

Purpose: Construire un contexte indicateurs (strat√©gie vs lecture seule) pour LLM.

Role in pipeline: orchestration support

Key components: build_indicator_context, DEFAULT_READ_ONLY_INDICATORS

Inputs: DataFrame OHLCV, strat√©gie, param√®tres courants

Outputs: Dict avec sections texte + warnings

Dependencies: numpy, pandas, indicators.registry, strategies.*
"""

from __future__ import annotations

from typing import Any, Dict, Iterable, List, Optional, Tuple

import numpy as np
import pandas as pd

from indicators.registry import calculate_indicator
from strategies.base import get_strategy
from strategies.indicators_mapping import (
    get_internal_indicators,
    get_required_indicators,
)

# Indicateurs contextuels (lecture seule). Modifiable c√¥t√© code.
DEFAULT_READ_ONLY_INDICATORS: List[Tuple[str, Dict[str, Any]]] = [
    ("adx", {"period": 14}),
    ("atr", {"period": 14}),
    ("rsi", {"period": 14}),
    ("macd", {"fast_period": 12, "slow_period": 26, "signal_period": 9}),
    ("stochastic", {"k_period": 14, "d_period": 3, "smooth_k": 3}),
    ("stoch_rsi", {"rsi_period": 14, "stoch_period": 14, "k_smooth": 3, "d_smooth": 3, "oversold": 20, "overbought": 80}),
    ("cci", {"period": 20}),
    ("williams_r", {"period": 14}),
    ("momentum", {"period": 14}),
    ("roc", {"period": 12}),
    ("aroon", {"period": 14}),
    ("supertrend", {"atr_period": 10, "multiplier": 3.0}),
    ("vortex", {"period": 14, "threshold": 0.0}),
    ("psar", {"af_start": 0.02, "af_increment": 0.02, "af_max": 0.2}),
    ("ichimoku", {"tenkan_period": 9, "kijun_period": 26, "senkou_b_period": 52, "displacement": 26}),
    ("bollinger", {"period": 20, "std_dev": 2.0}),
    ("keltner", {"ema_period": 20, "atr_period": 10, "atr_multiplier": 2.0}),
    ("donchian", {"period": 20}),
    ("standard_deviation", {"period": 20}),
    ("vwap", {"period": 20}),
    ("obv", {}),
    ("mfi", {"period": 14}),
    ("volume_oscillator", {"short_period": 14, "long_period": 28, "method": "ema"}),
    ("amplitude_hunter", {"period": 20}),
    ("pivot_points", {"method": "classic"}),
    ("fibonacci_levels", {"period": 50}),
]

TUPLE_LABELS: Dict[str, Tuple[str, ...]] = {
    "bollinger": ("upper", "middle", "lower"),
    "stochastic": ("k", "d"),
}

DICT_KEY_ALIASES: Dict[str, str] = {
    "histogram": "hist",
}


def build_indicator_context(
    df: pd.DataFrame,
    strategy_name: str,
    params: Dict[str, Any],
    read_only_indicators: Optional[Iterable[Tuple[str, Dict[str, Any]]]] = None,
) -> Dict[str, Any]:
    """
    Construit un contexte indicateurs s√©par√© en:
    - strategy_indicators: indicateurs li√©s √† la strat√©gie (modifiables via params)
    - read_only_indicators: indicateurs contexte (lecture seule)
    """
    warnings: List[str] = []

    # Strategy indicators
    strategy_lines: List[str] = []
    try:
        strategy_cls = get_strategy(strategy_name)
        strategy = strategy_cls()
    except Exception as exc:
        return {
            "strategy": "",
            "read_only": "",
            "warnings": [f"Impossible de charger la strat√©gie '{strategy_name}': {exc}"],
        }

    try:
        required = get_required_indicators(strategy_name)
        internal = get_internal_indicators(strategy_name)
    except Exception:
        required = list(getattr(strategy, "required_indicators", []) or [])
        internal = []

    strategy_indicators = list(dict.fromkeys(required + internal))

    for indicator_name in strategy_indicators:
        strategy_lines.extend(
            _summarize_indicator(
                df=df,
                indicator_name=indicator_name,
                params=params,
                strategy=strategy,
                warnings=warnings,
                is_strategy=True,
            )
        )

    # Read-only indicators
    read_only_lines: List[str] = []
    ro_specs = list(read_only_indicators) if read_only_indicators else list(DEFAULT_READ_ONLY_INDICATORS)

    for indicator_name, indicator_params in ro_specs:
        # Eviter doublons si deja present en strategie
        if indicator_name in strategy_indicators:
            continue
        read_only_lines.extend(
            _summarize_indicator(
                df=df,
                indicator_name=indicator_name,
                params=indicator_params,
                strategy=None,
                warnings=warnings,
                is_strategy=False,
            )
        )

    return {
        "strategy": "\n".join(strategy_lines).strip(),
        "read_only": "\n".join(read_only_lines).strip(),
        "warnings": warnings,
    }


def _summarize_indicator(
    df: pd.DataFrame,
    indicator_name: str,
    params: Dict[str, Any],
    strategy: Any,
    warnings: List[str],
    is_strategy: bool,
) -> List[str]:
    lines: List[str] = []

    # Parametrage base
    indicator_params: Dict[str, Any] = {}
    if is_strategy and strategy is not None:
        try:
            indicator_params = strategy.get_indicator_params(indicator_name, params)
        except Exception:
            indicator_params = {}
    else:
        indicator_params = dict(params or {})

    # Heuristiques EMA/SMA internes (fast/slow)
    if indicator_name in ("ema", "sma") and not indicator_params:
        fast = _first_param(params, ["fast_period", "fast"])
        slow = _first_param(params, ["slow_period", "slow"])
        if fast is not None:
            lines.extend(
                _summarize_single_indicator(
                    df, indicator_name, {"period": int(fast)}, f"{indicator_name}_fast", warnings
                )
            )
        if slow is not None:
            lines.extend(
                _summarize_single_indicator(
                    df, indicator_name, {"period": int(slow)}, f"{indicator_name}_slow", warnings
                )
            )
        if lines:
            return lines

    return _summarize_single_indicator(
        df, indicator_name, indicator_params, indicator_name, warnings
    )


def _summarize_single_indicator(
    df: pd.DataFrame,
    indicator_name: str,
    params: Dict[str, Any],
    label_name: str,
    warnings: List[str],
) -> List[str]:
    try:
        result = calculate_indicator(indicator_name, df, params)
    except Exception as exc:
        warnings.append(f"{indicator_name}: {exc}")
        return []

    label = _format_indicator_label(label_name, params)

    if result is None:
        return [f"- {label}: N/A"]

    if isinstance(result, dict):
        parts = []
        for key, values in result.items():
            last = _last_valid_value(values)
            if last is not None:
                key_label = DICT_KEY_ALIASES.get(key, key)
                parts.append(f"{key_label}={_fmt(last)}")
        if parts:
            return [f"- {label}: " + ", ".join(parts)]
        return [f"- {label}: N/A"]

    if isinstance(result, tuple):
        parts = []
        key_labels = TUPLE_LABELS.get(indicator_name, tuple(f"v{i}" for i in range(len(result))))
        for key, values in zip(key_labels, result):
            last = _last_valid_value(values)
            if last is not None:
                parts.append(f"{key}={_fmt(last)}")
        if parts:
            return [f"- {label}: " + ", ".join(parts)]
        return [f"- {label}: N/A"]

    stats = _series_stats(result)
    if not stats:
        return [f"- {label}: N/A"]

    return [
        "- "
        + f"{label}: last={_fmt(stats['last'])}, "
        + f"mean={_fmt(stats['mean'])}, "
        + f"min={_fmt(stats['min'])}, "
        + f"max={_fmt(stats['max'])}"
    ]


def _series_stats(values: Any) -> Optional[Dict[str, float]]:
    arr = _to_array(values)
    if arr is None or arr.size == 0:
        return None

    mask = np.isfinite(arr)
    if not mask.any():
        return None

    arr_valid = arr[mask]
    last = arr_valid[-1]

    return {
        "last": float(last),
        "mean": float(np.mean(arr_valid)),
        "min": float(np.min(arr_valid)),
        "max": float(np.max(arr_valid)),
    }


def _last_valid_value(values: Any) -> Optional[float]:
    arr = _to_array(values)
    if arr is None or arr.size == 0:
        return None
    mask = np.isfinite(arr)
    if not mask.any():
        return None
    return float(arr[mask][-1])


def _to_array(values: Any) -> Optional[np.ndarray]:
    if values is None:
        return None
    if isinstance(values, pd.Series):
        arr = values.values
    else:
        arr = np.asarray(values)
    if arr.ndim != 1:
        arr = arr.reshape(-1)
    return arr.astype("float64", copy=False)


def _format_indicator_label(name: str, params: Dict[str, Any]) -> str:
    if not params:
        return name
    parts = []
    for key in sorted(params.keys()):
        val = params[key]
        parts.append(f"{key}={_fmt(val)}")
    return f"{name}(" + ", ".join(parts) + ")"


def _fmt(value: Any) -> str:
    if value is None:
        return "N/A"
    if isinstance(value, (int, np.integer)):
        return str(int(value))
    try:
        val = float(value)
    except Exception:
        return str(value)
    return f"{val:.4f}"


def _first_param(params: Dict[str, Any], keys: Iterable[str]) -> Optional[float]:
    for key in keys:
        if key in params:
            try:
                return float(params[key])
            except Exception:
                return None
    return None
```
<!-- MODULE-END: indicator_context.py -->

<!-- MODULE-START: integration.py -->
```json
{
  "name": "integration.py",
  "path": "agents\\integration.py",
  "ext": ".py",
  "anchor": "integration_py"
}
```
## integration_py
*Chemin* : `agents\integration.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.integration

Purpose: Relier les agents LLM (abstraits) au moteur de backtest concret (BacktestEngine + WalkForwardValidator).

Role in pipeline: orchestration

Key components: run_backtest_for_agent, run_walk_forward_for_agent, create_optimizer_from_engine, create_orchestrator_with_backtest, validate_walk_forward_period

Inputs: DataFrame OHLCV, Config, strat√©gie (key/name), LLMConfig/RoleModelConfig, param√®tres et options walk-forward

Outputs: R√©sultats de backtest/walk-forward adapt√©s aux agents, factories d‚Äôoptimiseurs/orchestrator pr√™ts √† l‚Äôemploi

Dependencies: backtest.engine, backtest.validation, strategies.base, utils.config, utils.observability, agents.backtest_executor

Conventions: MIN_DAYS_FOR_WALK_FORWARD=180; timestamps d√©tect√©s (index datetime ou colonne 'timestamp'); WF peut √™tre d√©sactiv√© si p√©riode insuffisante.

Read-if: Vous modifiez le wiring agents‚Üîengine (run_backtest, walk-forward, factories).

Skip-if: Vous ne changez que les strat√©gies/indicateurs ou la UI.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
from typing import TYPE_CHECKING, Any, Dict, List, Mapping, Optional, Tuple, TypedDict, Union

import numpy as np
import pandas as pd

from backtest.engine import BacktestEngine
from backtest.validation import ValidationFold, WalkForwardValidator
from metrics_types import normalize_metrics, pct_to_frac
from strategies.base import get_strategy, get_strategy_overview, list_strategies
from utils.config import Config
from utils.observability import (
    generate_run_id,
    get_obs_logger,
    trace_span,
)

from .autonomous_strategist import AutonomousStrategist, OptimizationSession
from .backtest_executor import BacktestExecutor
from .llm_client import LLMConfig, create_llm_client
from .model_config import RoleModelConfig

if TYPE_CHECKING:  # pragma: no cover
    from .orchestrator import Orchestrator

# Logger module-level (sans run_id sp√©cifique)
_logger = get_obs_logger(__name__)

# Constantes pour validation walk-forward
MIN_DAYS_FOR_WALK_FORWARD = 180  # 6 mois minimum


def _normalize_engine_metrics(metrics: Mapping[str, Any]) -> Dict[str, Any]:
    return normalize_metrics(metrics, "pct")


class AgentBacktestMetrics(TypedDict):
    sharpe_ratio: float
    sortino_ratio: float
    total_return: float
    max_drawdown: float
    win_rate: float
    profit_factor: float
    total_trades: int
    sqn: float
    calmar_ratio: float
    recovery_factor: float
    equity_curve: Optional[List[float]]
    trades: Optional[List[Dict[str, Any]]]
    run_id: str


class WalkForwardMetrics(TypedDict):
    train_sharpe: float
    test_sharpe: float
    overfitting_ratio: float
    classic_ratio: float
    degradation_pct: float
    test_stability_std: float
    n_valid_folds: int


def extract_dataframe_timestamps(
    data: pd.DataFrame
) -> Tuple[pd.Timestamp, pd.Timestamp]:
    """
    Extrait les timestamps de d√©but et fin d'un DataFrame OHLCV.

    G√®re automatiquement:
    - DatetimeIndex
    - Colonne 'timestamp' ou 'date' (datetime ou num√©rique ms/s)

    Args:
        data: DataFrame OHLCV

    Returns:
        Tuple (start_datetime, end_datetime)

    Raises:
        ValueError: Si aucun timestamp n'est trouv√© ou format invalide

    Example:
        >>> start, end = extract_dataframe_timestamps(df)
        >>> duration_days = (end - start).days
    """
    # Cas 1: DatetimeIndex
    if isinstance(data.index, pd.DatetimeIndex):
        return data.index[0], data.index[-1]

    # Cas 2: Colonne timestamp/date
    col = None
    if "timestamp" in data.columns:
        col = "timestamp"
    elif "date" in data.columns:
        col = "date"
    else:
        raise ValueError(
            "DataFrame must have DatetimeIndex or 'timestamp'/'date' column"
        )

    ts_col = data[col]

    # D√©j√† en datetime
    if pd.api.types.is_datetime64_any_dtype(ts_col):
        return ts_col.iloc[0], ts_col.iloc[-1]

    # Num√©rique: d√©tecter ms vs s
    if pd.api.types.is_numeric_dtype(ts_col):
        first_val = ts_col.iloc[0]
        # Heuristique: >1e12 = millisecondes, sinon secondes
        unit = "ms" if first_val > 1e12 else "s"
        return (
            pd.to_datetime(first_val, unit=unit),
            pd.to_datetime(ts_col.iloc[-1], unit=unit)
        )

    raise ValueError(
        f"Column '{col}' must be datetime or numeric, got {ts_col.dtype}"
    )


def validate_walk_forward_period(
    data: pd.DataFrame,
    min_days: int = MIN_DAYS_FOR_WALK_FORWARD,
) -> tuple[bool, int, str]:
    """
    Valide si la p√©riode de donn√©es est suffisante pour une walk-forward validation.

    La walk-forward n√©cessite une p√©riode minimale pour avoir une signification
    statistique. En dessous de 6 mois, les folds sont trop courts et les r√©sultats
    sont domin√©s par le bruit statistique.

    Args:
        data: DataFrame OHLCV avec index datetime ou colonne 'timestamp'
        min_days: Nombre de jours minimum requis (d√©faut: 180 = 6 mois)

    Returns:
        Tuple (is_valid, duration_days, message)
        - is_valid: True si p√©riode suffisante, False sinon
        - duration_days: Dur√©e en jours de la p√©riode
        - message: Message explicatif

    Exemples:
        >>> is_valid, days, msg = validate_walk_forward_period(df)
        >>> if not is_valid:
        ...     print(f"‚ö†Ô∏è {msg}")
        ...     # D√©sactiver walk-forward
    """
    # Extraire les timestamps (fonction helper centralis√©e)
    start_dt, end_dt = extract_dataframe_timestamps(data)

    # Calculer la dur√©e en jours
    duration = (end_dt - start_dt).days

    # Valider
    if duration < min_days:
        months = duration / 30.0
        min_months = min_days / 30.0
        message = (
            f"P√©riode insuffisante pour walk-forward validation: "
            f"{duration} jours ({months:.1f} mois) < {min_days} jours ({min_months:.0f} mois minimum). "
            f"Walk-forward D√âSACTIV√â automatiquement pour √©viter des r√©sultats non significatifs."
        )
        return False, duration, message

    months = duration / 30.0
    message = (
        f"P√©riode valid√©e pour walk-forward: "
        f"{duration} jours ({months:.1f} mois) ‚â• {min_days} jours. "
        f"Walk-forward validation activ√©e."
    )
    return True, duration, message


def run_backtest_for_agent(
    strategy_name: str,
    params: Dict[str, Any],
    data: pd.DataFrame,
    *,
    initial_capital: float = 10000.0,
    config: Optional[Config] = None,
    run_id: Optional[str] = None,
) -> AgentBacktestMetrics:
    """
    Ex√©cute un backtest et retourne les m√©triques pour un agent.

    C'est le pont entre BacktestExecutor et BacktestEngine.

    Args:
        strategy_name: Nom de la strat√©gie (ex: "ema_cross")
        params: Param√®tres de la strat√©gie
        data: DataFrame OHLCV
        initial_capital: Capital de d√©part
        config: Configuration optionnelle
        run_id: Identifiant de corr√©lation (g√©n√©r√© si None)

    Returns:
        Dict avec toutes les m√©triques n√©cessaires pour l'agent
    """
    # G√©n√©rer run_id si absent
    run_id = run_id or generate_run_id()
    logger = get_obs_logger(__name__, run_id=run_id, strategy=strategy_name)

    logger.info(
        "agent_backtest_start params=%s bars=%s", params, len(data)
    )

    # Cr√©er engine avec le m√™me run_id pour corr√©lation
    engine = BacktestEngine(
        initial_capital=initial_capital, config=config, run_id=run_id
    )

    try:
        with trace_span(logger, "agent_backtest", strategy=strategy_name):
            result = engine.run(
                df=data,
                strategy=strategy_name,
                params=params,
            )

        # Extraire les m√©triques pour l'agent
        metrics_pct = normalize_metrics(result.metrics, "pct")
        metrics_frac = pct_to_frac(metrics_pct)

        output: AgentBacktestMetrics = {
            "sharpe_ratio": metrics_frac.get("sharpe_ratio", 0),
            "sortino_ratio": metrics_frac.get("sortino_ratio", 0),
            "total_return": metrics_frac.get("total_return", 0),
            "max_drawdown": metrics_frac.get("max_drawdown", 0),
            "win_rate": metrics_frac.get("win_rate", 0),
            "profit_factor": metrics_frac.get("profit_factor", 0),
            "total_trades": metrics_frac.get("total_trades", 0),
            "sqn": metrics_frac.get("sqn", 0),
            "calmar_ratio": metrics_frac.get("calmar_ratio", 0),
            "recovery_factor": metrics_frac.get("recovery_factor", 0),
            # Donn√©es brutes pour analyse approfondie
            "equity_curve": (
                result.equity.tolist() if len(result.equity) < 10000 else None
            ),
            "trades": (
                result.trades.to_dict("records")
                if len(result.trades) < 1000 else None
            ),
            # M√©tadonn√©es de corr√©lation
            "run_id": run_id,
        }

        logger.info(
            "agent_backtest_end sharpe=%.2f trades=%s",
            output["sharpe_ratio"], output["total_trades"]
        )
        return output

    except Exception as e:
        logger.error("agent_backtest_error error=%s", str(e))
        raise


def run_walk_forward_for_agent(
    strategy_name: str,
    params: Dict[str, Any],
    data: pd.DataFrame,
    *,
    n_windows: int = 6,  # 6 fen√™tres pour ~4 mois/test sur 24 mois
    train_ratio: float = 0.75,  # 75% train, 25% test (18m/6m optimal)
    initial_capital: float = 10000.0,
    config: Optional[Config] = None,
    n_workers: int = 1,
) -> WalkForwardMetrics:
    """
    Ex√©cute une validation walk-forward et retourne les m√©triques.

    Configuration optimis√©e pour 2 ans de donn√©es :
    - 6 fen√™tres ‚Üí ~4 mois de test par fen√™tre
    - 75% train ‚Üí 18 mois d'entra√Ænement, 6 mois de test
    - 2% embargo ‚Üí √©vite le leakage entre train et test

    Args:
        strategy_name: Nom de la strat√©gie
        params: Param√®tres de la strat√©gie
        data: DataFrame OHLCV
        n_windows: Nombre de fen√™tres de validation
        train_ratio: Ratio train/total (1 - test_ratio)
        initial_capital: Capital de d√©part
        config: Configuration optionnelle
        n_workers: Nombre de workers pour parall√©lisation (1 = s√©quentiel)

    Returns:
        Dict avec train_sharpe, test_sharpe, overfitting_ratio, m√©triques robustes
    """
    test_pct = 1.0 - train_ratio

    validator = WalkForwardValidator(
        n_folds=n_windows,
        test_pct=test_pct,
        embargo_pct=0.02,  # 2% d'embargo pour √©viter le leakage
    )

    folds = validator.split(data)

    def _run_fold(fold: ValidationFold) -> tuple[ValidationFold, bool]:
        """Ex√©cute un fold complet (train + test) - thread-safe."""
        # Cr√©er une instance d'engine par thread pour √©viter les probl√®mes de concurrence
        engine = BacktestEngine(initial_capital=initial_capital, config=config)
        train_df, test_df = validator.get_data_splits(data, fold)

        try:
            # Backtest sur train
            train_result = engine.run(
                df=train_df,
                strategy=strategy_name,
                params=params,
            )

            # Backtest sur test
            test_result = engine.run(
                df=test_df,
                strategy=strategy_name,
                params=params,
            )

            # Stocker dans le fold
            fold.train_metrics = _normalize_engine_metrics(train_result.metrics)
            fold.test_metrics = _normalize_engine_metrics(test_result.metrics)

            return fold, True

        except Exception as e:
            _logger.warning("fold_%s_failed error=%s", fold.fold_id, str(e))
            return fold, False

    # Mode s√©quentiel (par d√©faut)
    if n_workers <= 1 or len(folds) <= 1:
        for fold in folds:
            _run_fold(fold)
    else:
        # Mode parall√®le - utiliser ThreadPoolExecutor pour parall√©liser les folds
        from concurrent.futures import ThreadPoolExecutor, as_completed

        _logger.info(f"Walk-forward parall√®le avec {n_workers} workers sur {len(folds)} folds")

        with ThreadPoolExecutor(max_workers=n_workers) as pool:
            futures = {pool.submit(_run_fold, fold): fold for fold in folds}

            for fut in as_completed(futures):
                original_fold = futures[fut]
                try:
                    updated_fold, success = fut.result()
                    if not success:
                        _logger.warning(f"Fold {original_fold.fold_id} a √©chou√©")
                except Exception as e:
                    _logger.warning(f"Erreur lors de l'ex√©cution du fold {original_fold.fold_id}: {e}")

    # Collecter les r√©sultats des folds valides
    train_sharpes = []
    test_sharpes = []
    for fold in folds:
        if fold.train_metrics and fold.test_metrics:
            train_sharpes.append(fold.train_metrics.get("sharpe_ratio", 0))
            test_sharpes.append(fold.test_metrics.get("sharpe_ratio", 0))

    n_folds = len(train_sharpes)

    if n_folds == 0:
        return {
            "train_sharpe": 0.0,
            "test_sharpe": 0.0,
            "overfitting_ratio": 999.0,
            "classic_ratio": 999.0,
            "degradation_pct": 100.0,
            "test_stability_std": 0.0,
            "n_valid_folds": 0,
        }

    # Moyennes avec numpy
    avg_train = np.mean(train_sharpes)
    avg_test = np.mean(test_sharpes)
    std_test = np.std(test_sharpes)

    # Ratio classique avec garde-fou
    classic_ratio = avg_train / avg_test if avg_test > 1e-6 else 999.0

    # D√©gradation % avec garde-fou
    degradation_pct = (avg_train - avg_test) / avg_train * 100 if avg_train > 1e-6 else 100.0
    degradation_pct = max(0.0, degradation_pct)

    # Ratio robuste = ratio classique + p√©nalit√© de stabilit√©
    stability_penalty = std_test * 2.0
    robust_ratio = classic_ratio + stability_penalty

    return {
        "train_sharpe": float(avg_train),
        "test_sharpe": float(avg_test),
        "overfitting_ratio": float(robust_ratio),
        "classic_ratio": float(classic_ratio),
        "degradation_pct": float(degradation_pct),
        "test_stability_std": float(std_test),
        "n_valid_folds": n_folds,
    }


def create_optimizer_from_engine(
    llm_config: LLMConfig,
    strategy_name: str,
    data: pd.DataFrame,
    *,
    initial_capital: float = 10000.0,
    config: Optional[Config] = None,
    use_walk_forward: bool = True,
    verbose: bool = True,
    unload_llm_during_backtest: Optional[bool] = None,
    comparison_context: Optional[Dict[str, Any]] = None,
    orchestration_logger: Optional[Any] = None,
) -> Tuple[AutonomousStrategist, BacktestExecutor]:
    """
    Factory compl√®te pour cr√©er un optimiseur autonome connect√© au vrai moteur.

    C'est LA fonction √† utiliser pour une optimisation autonome fonctionnelle.

    Args:
        llm_config: Configuration du LLM (Ollama ou OpenAI)
        strategy_name: Nom de la strat√©gie √† optimiser
        data: DataFrame OHLCV
        initial_capital: Capital de d√©part
        config: Configuration du backtest
        use_walk_forward: Activer validation walk-forward
        verbose: Logs d√©taill√©s
        unload_llm_during_backtest: Si True, d√©charge le LLM du GPU pendant les backtests
            pour lib√©rer la VRAM. Si None, utilise la variable d'environnement
            UNLOAD_LLM_DURING_BACKTEST (d√©faut: False pour compatibilit√© CPU-only)
        comparison_context: Contexte multi-sweep pour enrichir les d√©cisions LLM
        orchestration_logger: Logger pour enregistrer les actions d'orchestration

    Returns:
        (AutonomousStrategist, BacktestExecutor) pr√™ts √† l'emploi

    Example:
        >>> from agents.integration import create_optimizer_from_engine
        >>> from agents.llm_client import LLMConfig, LLMProvider
        >>>
        >>> config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
        >>>
        >>> strategist, executor = create_optimizer_from_engine(
        ...     llm_config=config,
        ...     strategy_name="ema_cross",
        ...     data=ohlcv_df,
        ... )
        >>>
        >>> session = strategist.optimize(
        ...     executor=executor,
        ...     initial_params={"fast_period": 10, "slow_period": 21},
        ...     param_bounds={"fast_period": (5, 20), "slow_period": (15, 50)},
        ...     max_iterations=10,
        ... )
        >>>
        >>> print(f"Best Sharpe: {session.best_result.sharpe_ratio}")
        >>> print(f"Best Params: {session.best_result.request.parameters}")
    """
    # V√©rifier que la strat√©gie existe
    if strategy_name not in list_strategies():
        available = ", ".join(list_strategies())
        raise ValueError(
            f"Strat√©gie '{strategy_name}' inconnue. Disponibles: {available}"
        )

    # Valider la p√©riode pour walk-forward (garde-fou)
    walk_forward_disabled_reason = None
    if use_walk_forward:
        is_valid, duration_days, message = validate_walk_forward_period(data)
        if not is_valid:
            _logger.warning(
                "walk_forward_auto_disabled duration_days=%s reason='period_too_short'",
                duration_days
            )
            _logger.warning(message)
            use_walk_forward = False  # Forcer d√©sactivation
            walk_forward_disabled_reason = message

    # Cr√©er le client LLM
    llm_client = create_llm_client(llm_config)

    # Cr√©er la fonction de backtest
    def backtest_fn(
        strategy: str, params: Dict[str, Any], df: pd.DataFrame
    ) -> AgentBacktestMetrics:
        return run_backtest_for_agent(
            strategy_name=strategy,
            params=params,
            data=df,
            initial_capital=initial_capital,
            config=config,
        )

    # Cr√©er la fonction de validation (optionnelle)
    def _validation_fn(
        strategy: str,
        params: Dict[str, Any],
        df: pd.DataFrame,
        n_windows: int = 6,  # Optimis√© pour 2 ans de donn√©es
        train_ratio: float = 0.75,  # 75/25 pour meilleur compromis
    ) -> WalkForwardMetrics:
        return run_walk_forward_for_agent(
            strategy_name=strategy,
            params=params,
            data=df,
            n_windows=n_windows,
            train_ratio=train_ratio,
            initial_capital=initial_capital,
            config=config,
        )

    validation_fn = _validation_fn if use_walk_forward else None

    # Pr√©parer un aper√ßu de strat√©gie pour le contexte LLM
    strategy_overview = get_strategy_overview(strategy_name)

    # Cr√©er l'ex√©cuteur
    executor = BacktestExecutor(
        backtest_fn=backtest_fn,
        strategy_name=strategy_name,
        data=data,
        validation_fn=validation_fn,
        strategy_description=strategy_overview,
    )

    # Cr√©er le strategist autonome
    strategist = AutonomousStrategist(
        llm_client,
        verbose=verbose,
        unload_llm_during_backtest=unload_llm_during_backtest,
        comparison_context=comparison_context,
        orchestration_logger=orchestration_logger,
    )

    _logger.info(
        "optimizer_created strategy=%s rows=%s walk_forward=%s",
        strategy_name, len(data), use_walk_forward
    )

    # Si walk-forward d√©sactiv√© automatiquement, logger pour rapport final
    if walk_forward_disabled_reason:
        _logger.info(
            "walk_forward_validation_status disabled_reason='%s'",
            walk_forward_disabled_reason
        )

    return strategist, executor


def get_strategy_param_bounds(
    strategy_name: str
) -> Dict[str, Tuple[float, float]]:
    """
    R√©cup√®re les bornes des param√®tres d'une strat√©gie.

    Utilise les parameter_specs de la strat√©gie si disponibles,
    sinon retourne des bornes par d√©faut.

    Note: Exclut les param√®tres avec optimize=False (ex: leverage).

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        Dict {param_name: (min, max)}
    """
    strategy_class = get_strategy(strategy_name)
    strategy = strategy_class()

    bounds = {}

    # Essayer d'utiliser parameter_specs si disponible
    if hasattr(strategy, 'parameter_specs'):
        specs = strategy.parameter_specs
        # parameter_specs est un dict {name: ParameterSpec}
        if isinstance(specs, dict):
            for name, spec in specs.items():
                # Exclure les param√®tres avec optimize=False
                if hasattr(spec, 'optimize') and spec.optimize is False:
                    continue
                # ParameterSpec utilise min_val et max_val
                if hasattr(spec, 'min_val') and hasattr(spec, 'max_val'):
                    bounds[name] = (spec.min_val, spec.max_val)

    # Fallback: utiliser default_params avec ¬±50%
    if not bounds and hasattr(strategy, 'default_params'):
        for name, value in strategy.default_params.items():
            if isinstance(value, (int, float)) and value > 0:
                # Exclure leverage du fallback aussi
                if name == 'leverage':
                    continue
                bounds[name] = (value * 0.5, value * 2.0)

    return bounds


def get_strategy_param_space(
    strategy_name: str,
    include_step: bool = True,
) -> Dict[str, Union[Tuple[float, float], Tuple[float, float, float]]]:
    """
    R√©cup√®re l'espace des param√®tres avec step si disponible.

    Extension de get_strategy_param_bounds() pour permettre:
    - Le calcul unifi√© des stats d'espace de recherche
    - L'affichage d'estimation dans le mode LLM

    Note: Exclut les param√®tres avec optimize=False (ex: leverage).

    Args:
        strategy_name: Nom de la strat√©gie
        include_step: Inclure le step si disponible

    Returns:
        Dict {param_name: (min, max)} ou {param_name: (min, max, step)}
    """
    strategy_class = get_strategy(strategy_name)
    strategy = strategy_class()

    space = {}

    # Utiliser parameter_specs si disponible
    if hasattr(strategy, 'parameter_specs'):
        specs = strategy.parameter_specs
        if isinstance(specs, dict):
            for name, spec in specs.items():
                # Exclure les param√®tres avec optimize=False
                if hasattr(spec, 'optimize') and spec.optimize is False:
                    continue
                if hasattr(spec, 'min_val') and hasattr(spec, 'max_val'):
                    min_v = spec.min_val
                    max_v = spec.max_val

                    if include_step and hasattr(spec, 'step') and spec.step:
                        space[name] = (min_v, max_v, spec.step)
                    else:
                        space[name] = (min_v, max_v)

    # Fallback: param_ranges (si pr√©sent dans la strat√©gie)
    if not space and hasattr(strategy, 'param_ranges'):
        for name, (min_v, max_v) in strategy.param_ranges.items():
            # param_ranges exclut d√©j√† leverage (via property)
            space[name] = (min_v, max_v)

    # Dernier fallback: default_params avec ¬±50%
    if not space and hasattr(strategy, 'default_params'):
        for name, value in strategy.default_params.items():
            if isinstance(value, (int, float)) and value > 0:
                # Exclure leverage du fallback
                if name == 'leverage':
                    continue
                space[name] = (value * 0.5, value * 2.0)

    return space


def quick_optimize(
    llm_config: LLMConfig,
    strategy_name: str,
    data: pd.DataFrame,
    max_iterations: int = 10,
    **kwargs
) -> OptimizationSession:
    """
    Raccourci pour lancer une optimisation rapidement.

    D√©tecte automatiquement les param√®tres initiaux et les bornes.

    Args:
        llm_config: Configuration LLM
        strategy_name: Nom de la strat√©gie
        data: DataFrame OHLCV
        max_iterations: Maximum d'it√©rations
        **kwargs: Arguments additionnels pour create_optimizer_from_engine

    Returns:
        OptimizationSession avec les r√©sultats

    Example:
        >>> session = quick_optimize(
        ...     llm_config=config,
        ...     strategy_name="ema_cross",
        ...     data=df,
        ...     max_iterations=15,
        ... )
        >>> print(session.best_result.sharpe_ratio)
    """
    # R√©cup√©rer la strat√©gie pour les params par d√©faut
    strategy_class = get_strategy(strategy_name)
    strategy = strategy_class()

    # Param√®tres initiaux
    initial_params = strategy.default_params.copy()

    # Bornes des param√®tres
    param_bounds = get_strategy_param_bounds(strategy_name)

    if not param_bounds:
        raise ValueError(
            f"Impossible de d√©terminer les bornes pour '{strategy_name}'. "
            "Utilisez create_optimizer_from_engine avec des bornes explicites."
        )

    # Cr√©er l'optimiseur
    strategist, executor = create_optimizer_from_engine(
        llm_config=llm_config,
        strategy_name=strategy_name,
        data=data,
        **kwargs
    )

    # Lancer l'optimisation
    session = strategist.optimize(
        executor=executor,
        initial_params=initial_params,
        param_bounds=param_bounds,
        max_iterations=max_iterations,
    )

    return session


def create_orchestrator_with_backtest(
    strategy_name: str,
    data: pd.DataFrame,
    initial_params: Dict[str, Any],
    data_symbol: str = "",
    data_timeframe: str = "",
    llm_config: Optional[LLMConfig] = None,
    role_model_config: Optional[RoleModelConfig] = None,
    use_walk_forward: bool = True,
    optimization_target: str = "sharpe_ratio",
    min_sharpe: float = 1.0,
    max_drawdown_limit: float = 0.20,
    min_trades: int = 30,
    max_overfitting_ratio: float = 1.5,
    max_proposals_per_iteration: int = 5,
    orchestration_logger: Optional[Any] = None,
    session_id: Optional[str] = None,
    n_workers: int = 1,
    max_iterations: int = 10,
    initial_capital: float = 10000.0,
    config: Optional[Config] = None,
    comparison_context: Optional[Dict[str, Any]] = None,
    unload_llm_during_backtest: Optional[bool] = None,
) -> "Orchestrator":
    """
    Cr√©e un Orchestrator multi-agents branch√© sur le vrai backtest.

    L'Orchestrator par d√©faut n√©cessite un callback `on_backtest_needed`.
    Cette fonction le configure automatiquement avec `run_backtest_for_agent()`.

    Args:
        strategy_name: Nom de la strat√©gie
        data: DataFrame OHLCV
        initial_params: Param√®tres initiaux
        data_symbol: Symbole (ex: "BTCUSDC")
        data_timeframe: Timeframe (ex: "1h")
        llm_config: Configuration LLM (optionnel, d√©faut depuis env)
        role_model_config: Configuration multi-modeles par role
        use_walk_forward: Activer la validation walk-forward (si possible)
        optimization_target: M√©trique cible d'optimisation
        min_sharpe: Sharpe minimum
        max_drawdown_limit: Drawdown maximum
        min_trades: Nombre minimum de trades
        max_overfitting_ratio: Ratio max train/test pour √©viter l'overfitting
        max_proposals_per_iteration: Nombre maximum de propositions par it√©ration
        orchestration_logger: Logger d'orchestration (UI live/persistance)
        session_id: Forcer l'ID de session (corr√©lation UI)
        n_workers: Nombre de workers pour parall√©liser les backtests de propositions
        max_iterations: Maximum d'it√©rations
        initial_capital: Capital de d√©part
        config: Configuration du backtest
        comparison_context: Contexte multi-sweep pour enrichir les agents LLM
        unload_llm_during_backtest: D√©charge LLM pendant backtests (r√©serv√© usage futur)

    Returns:
        Orchestrator configur√© et pr√™t √† ex√©cuter

    Example:
        >>> orchestrator = create_orchestrator_with_backtest(
        ...     strategy_name="ema_cross",
        ...     data=df,
        ...     initial_params={"fast_period": 12, "slow_period": 26},
        ... )
        >>> result = orchestrator.run()
        >>> if result.success:
        ...     print(f"Meilleurs params: {result.final_params}")
    """
    # Import ici pour √©viter les imports circulaires
    from .base_agent import ParameterConfig
    from .orchestrator import Orchestrator, OrchestratorConfig

    # Valider la p√©riode pour walk-forward (garde-fou)
    walk_forward_disabled_reason = None
    if use_walk_forward:
        is_valid, duration_days, message = validate_walk_forward_period(data)
        if not is_valid:
            _logger.warning(
                "walk_forward_auto_disabled duration_days=%s reason='period_too_short'",
                duration_days
            )
            _logger.warning(message)
            use_walk_forward = False  # Forcer d√©sactivation
            walk_forward_disabled_reason = message

    # R√©cup√©rer les specs des param√®tres
    param_space = get_strategy_param_space(strategy_name, include_step=True)
    param_specs = []
    for name, bounds in param_space.items():
        if len(bounds) == 3:
            min_v, max_v, step = bounds
        else:
            min_v, max_v = bounds
            step = None
        param_specs.append(ParameterConfig(
            name=name,
            min_value=min_v,
            max_value=max_v,
            step=step,
            current_value=initial_params.get(name, (min_v + max_v) / 2),
        ))

    # Cr√©er le callback de backtest
    def on_backtest_needed(params: Dict[str, Any]) -> AgentBacktestMetrics:
        return run_backtest_for_agent(
            strategy_name=strategy_name,
            params=params,
            data=data,
            initial_capital=initial_capital,
            config=config,
        )

    data_date_range = ""
    try:
        start_dt, end_dt = extract_dataframe_timestamps(data)
        data_date_range = f"{start_dt} -> {end_dt}"
    except (ValueError, Exception):
        data_date_range = ""

    # Pr√©parer un aper√ßu de strat√©gie pour le contexte LLM
    strategy_overview = get_strategy_overview(strategy_name)

    # Cr√©er la config
    orchestrator_config = OrchestratorConfig(
        strategy_name=strategy_name,
        strategy_description=strategy_overview,
        initial_params=initial_params,
        param_specs=param_specs,
        max_iterations=max_iterations,
        optimization_target=optimization_target,
        min_sharpe=min_sharpe,
        max_drawdown_limit=max_drawdown_limit,
        min_trades=min_trades,
        max_overfitting_ratio=max_overfitting_ratio,
        max_proposals_per_iteration=max_proposals_per_iteration,
        llm_config=llm_config,
        role_model_config=role_model_config,
        use_walk_forward=use_walk_forward,
        walk_forward_disabled_reason=walk_forward_disabled_reason,
        data=data,
        data_symbol=data_symbol,
        data_timeframe=data_timeframe,
        data_date_range=data_date_range,
        n_workers=n_workers,
        session_id=session_id,
        orchestration_logger=orchestration_logger,
        comparison_context=comparison_context,
        on_backtest_needed=on_backtest_needed,
    )

    _logger.info(
        "orchestrator_created strategy=%s rows=%s walk_forward=%s",
        strategy_name, len(data), use_walk_forward
    )

    # Si walk-forward d√©sactiv√© automatiquement, logger pour rapport final
    if walk_forward_disabled_reason:
        _logger.info(
            "walk_forward_validation_status disabled_reason='%s'",
            walk_forward_disabled_reason
        )

    return Orchestrator(orchestrator_config)


# =============================================================================
# LLM Grid Search Integration
# =============================================================================

def generate_sweep_summary(
    sweep_results: Any,  # SweepResults from backtest.sweep
    top_k: List[Dict[str, Any]],
    range_proposal: Any  # RangeProposal from utils.parameters
) -> str:
    """
    G√©n√®re un r√©sum√© textuel des r√©sultats de sweep pour feedback LLM.

    Args:
        sweep_results: R√©sultats complets du sweep (SweepResults)
        top_k: Top K configurations (list of dicts)
        range_proposal: Proposition de ranges initiale

    Returns:
        R√©sum√© format√© pour inclusion dans prompt LLM

    Example output:
        Grid Search Results (48 combinations tested):

        Top 10 Configurations:
        1. Sharpe=2.45, Return=8.3% | bb_period=23, bb_std=2.2
        2. Sharpe=2.12, Return=7.1% | bb_period=22, bb_std=2.3
        ...

        Key Patterns:
        - bb_period optimal range: 22-24
        - bb_std shows weak correlation with Sharpe
    """
    n_combos = sweep_results.n_completed

    summary = f"Grid Search Results ({n_combos} combinations tested):\n\n"
    summary += "Top 10 Configurations:\n"

    for i, config in enumerate(top_k[:10], 1):
        sharpe = config.get("sharpe_ratio", 0)
        ret = config.get("total_return_pct", 0)

        # Extraire params (ignorer success, error, etc.)
        param_keys = [
            k
            for k in config.keys()
            if k
            not in [
                "sharpe_ratio",
                "total_return_pct",
                "max_drawdown_pct",
                "total_trades",
                "success",
                "error",
                "win_rate_pct",
                "profit_factor",
                "sortino_ratio",
                "sqn",
                "calmar_ratio",
            ]
        ]
        params_str = ", ".join(f"{k}={config[k]}" for k in param_keys)

        summary += f"{i}. Sharpe={sharpe:.2f}, Return={ret:.1f}% | {params_str}\n"

    summary += "\nKey Patterns:\n"
    # TODO: Analyse automatique des corr√©lations (pour it√©ration future)
    # Pour l'instant, juste mentionner les ranges test√©es
    for param_name, range_def in range_proposal.ranges.items():
        summary += f"- {param_name}: tested range [{range_def['min']}, {range_def['max']}]\n"

    return summary


def run_llm_sweep(
    range_proposal: Any,  # RangeProposal from utils.parameters
    param_specs: List[Any],  # List[ParameterSpec]
    data: pd.DataFrame,
    strategy_name: str,
    initial_capital: float = 10000.0,
    n_workers: Optional[int] = None
) -> Dict[str, Any]:
    """
    Ex√©cute un sweep de ranges demand√© par le LLM.
    Fonction partag√©e entre mono-agent et multi-agents.

    Args:
        range_proposal: Proposition de ranges (RangeProposal)
        param_specs: Liste des sp√©cifications de param√®tres
        data: DataFrame OHLCV
        strategy_name: Nom de la strat√©gie
        initial_capital: Capital initial
        n_workers: Nombre de workers parall√®les (None = auto)

    Returns:
        Dict contenant:
            - best_params: Meilleurs param√®tres trouv√©s
            - best_metrics: M√©triques du meilleur r√©sultat
            - top_k: Top 10 configurations (list of dicts)
            - summary: R√©sum√© textuel pour LLM
            - n_combinations: Nombre de combinaisons test√©es

    Raises:
        ValueError: Si ranges invalides ou trop de combinaisons

    Example:
        >>> from utils.parameters import RangeProposal
        >>> proposal = RangeProposal(
        ...     ranges={"bb_period": {"min": 20, "max": 25, "step": 1}},
        ...     rationale="Test bb_period sensitivity",
        ...     max_combinations=50
        ... )
        >>> result = run_llm_sweep(proposal, param_specs, df, "bollinger_atr")
        >>> print(result["summary"])
    """
    from backtest.sweep import SweepEngine
    from utils.parameters import compute_search_space_stats, normalize_param_ranges

    _logger.info(
        f"llm_sweep_start strategy={strategy_name} "
        f"ranges={range_proposal.ranges} max_combos={range_proposal.max_combinations}"
    )

    # Normaliser ranges (clamp + validate)
    try:
        param_grid = normalize_param_ranges(param_specs, range_proposal.ranges)
    except ValueError as e:
        _logger.error(f"llm_sweep_validation_failed error='{e}'")
        raise

    # Log search space stats
    stats = compute_search_space_stats(param_grid)
    _logger.info(
        f"llm_sweep_space total_combos={stats.total_combinations} "
        f"estimated_memory_mb={getattr(stats, 'estimated_memory_mb', 'N/A')}"
    )

    if stats.warnings:
        for warning in stats.warnings:
            _logger.warning(f"llm_sweep_warning: {warning}")

    # V√©rifier limite
    if stats.total_combinations > range_proposal.max_combinations:
        raise ValueError(
            f"Trop de combinaisons ({stats.total_combinations} > "
            f"{range_proposal.max_combinations}). R√©duire les ranges ou augmenter max_combinations."
        )

    # Cr√©er SweepEngine
    engine = SweepEngine(
        max_workers=n_workers,
        initial_capital=initial_capital,
        auto_save=False  # On g√®re la sauvegarde nous-m√™mes
    )

    # Ex√©cuter sweep
    _logger.info(f"llm_sweep_executing n_combos={stats.total_combinations}")

    sweep_results = engine.run_sweep(
        df=data,
        strategy=strategy_name,
        param_grid=param_grid,
        optimize_for=range_proposal.optimize_for,
        show_progress=True,
        early_stop_threshold=range_proposal.early_stop_threshold
    )

    # Extraire top K
    df_results = sweep_results.to_dataframe()
    top_k = df_results.nlargest(10, range_proposal.optimize_for).to_dict('records')

    # G√©n√©rer summary pour LLM
    summary = generate_sweep_summary(sweep_results, top_k, range_proposal)

    _logger.info(
        f"llm_sweep_complete n_completed={sweep_results.n_completed} "
        f"best_{range_proposal.optimize_for}={sweep_results.best_metrics.get(range_proposal.optimize_for, 0):.3f}"
    )

    return {
        "best_params": sweep_results.best_params,
        "best_metrics": sweep_results.best_metrics,
        "top_k": top_k,
        "summary": summary,
        "n_combinations": sweep_results.n_completed
    }


# ===============================================================================
# COMPARISON CONTEXT FOR MULTI-SWEEP LLM
# ===============================================================================

def create_comparison_context(
    mode: str = "multi_sweep",
    strategies: Optional[List[str]] = None,
    symbols: Optional[List[str]] = None,
    timeframes: Optional[List[str]] = None,
    sweep_results: Optional[List[Dict[str, Any]]] = None,
    best_overall: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """
    Cr√©e un contexte de comparaison pour les agents LLM en mode multi-sweep.

    Ce contexte permet aux agents de voir:
    - Les strat√©gies/tokens/timeframes disponibles
    - Les r√©sultats de sweeps pr√©c√©dents
    - Les performances relatives
    - Les alternatives d'optimisation

    Args:
        mode: Mode de comparaison ("multi_sweep", "backtest_simple_comparison")
        strategies: Liste des strat√©gies disponibles
        symbols: Liste des tokens disponibles
        timeframes: Liste des timeframes disponibles
        sweep_results: R√©sultats de sweeps pr√©c√©dents (liste de dicts)
        best_overall: Meilleur r√©sultat global (dict)

    Returns:
        Dict contenant le contexte complet pour les templates LLM
    """
    context = {
        "mode": mode,
        "strategies": strategies or [],
        "symbols": symbols or [],
        "timeframes": timeframes or [],
        "total_combinations": len(strategies or []) * len(symbols or []) * len(timeframes or []),
        "sweep_results": sweep_results or [],
        "best_overall": best_overall or {},
        "has_results": bool(sweep_results),
    }

    # Calculer statistiques si r√©sultats disponibles
    if sweep_results:
        pnls = [r.get("total_pnl", 0) for r in sweep_results]
        sharpes = [r.get("sharpe_ratio", 0) for r in sweep_results]

        context.update({
            "total_sweeps": len(sweep_results),
            "profitable_count": sum(1 for p in pnls if p > 0),
            "avg_pnl": np.mean(pnls) if pnls else 0,
            "median_pnl": np.median(pnls) if pnls else 0,
            "best_sharpe": max(sharpes) if sharpes else 0,
            "avg_sharpe": np.mean(sharpes) if sharpes else 0,
        })

    _logger.debug(
        f"create_comparison_context mode={mode} strategies={len(strategies or [])} "
        f"symbols={len(symbols or [])} timeframes={len(timeframes or [])} "
        f"total_combinations={context['total_combinations']}"
    )

    return context
```
<!-- MODULE-END: integration.py -->

<!-- MODULE-START: llm_client.py -->
```json
{
  "name": "llm_client.py",
  "path": "agents\\llm_client.py",
  "ext": ".py",
  "anchor": "llm_client_py"
}
```
## llm_client_py
*Chemin* : `agents\llm_client.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.llm_client

Purpose: Client LLM unifi√© supportant Ollama (local) et OpenAI (cloud) avec abstraction commune.

Role in pipeline: orchestration

Key components: LLMClient (abstract), OllamaClient, OpenAIClient, LLMConfig, LLMMessage, LLMResponse

Inputs: LLMConfig (provider, model, params), messages, syst√®me prompt

Outputs: LLMResponse (texte/JSON, usage tokens, timing)

Dependencies: httpx, pydantic, utils.log

Conventions: json_mode force JSON strict; parse_json g√®re blocs ```json ``` et inline; timeout adaptatif pour reasoning models (deepseek-r1, o1); fallback parsing si JSON mode √©choue.

Read-if: Ajout providers, modification parsing, ou gestion erreurs LLM.

Skip-if: Vous appelez juste le client via create_llm_client().
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import json
import logging
import os
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional

import httpx

logger = logging.getLogger(__name__)


class LLMProvider(Enum):
    """Fournisseurs LLM support√©s."""
    OLLAMA = "ollama"
    OPENAI = "openai"


@dataclass
class LLMConfig:
    """Configuration du client LLM."""

    provider: LLMProvider = LLMProvider.OLLAMA
    model: str = "llama3.2"

    # Ollama
    ollama_host: str = "http://localhost:11434"

    # OpenAI
    openai_api_key: Optional[str] = None
    openai_base_url: str = "https://api.openai.com/v1"

    # Param√®tres de g√©n√©ration
    temperature: float = 0.7
    max_tokens: int = 2000
    top_p: float = 0.9

    # Retry/timeout
    # Note: 600s (10min) par d√©faut pour supporter les mod√®les de raisonnement
    # (deepseek-r1, qwq, etc.) qui peuvent prendre 5-10 minutes
    timeout_seconds: int = 600
    max_retries: int = 3
    retry_delay_seconds: float = 1.0

    @classmethod
    def from_env(cls) -> LLMConfig:
        """Cr√©e une configuration depuis les variables d'environnement."""
        provider_str = os.environ.get("BACKTEST_LLM_PROVIDER", "ollama").lower()
        provider = LLMProvider.OPENAI if provider_str == "openai" else LLMProvider.OLLAMA

        return cls(
            provider=provider,
            model=os.environ.get("BACKTEST_LLM_MODEL", "llama3.2"),
            ollama_host=os.environ.get("OLLAMA_HOST", "http://localhost:11434"),
            openai_api_key=os.environ.get("OPENAI_API_KEY"),
            openai_base_url=os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1"),
            temperature=float(os.environ.get("BACKTEST_LLM_TEMPERATURE", "0.7")),
            max_tokens=int(os.environ.get("BACKTEST_LLM_MAX_TOKENS", "2000")),
        )


@dataclass
class LLMMessage:
    """Message pour la conversation LLM."""

    role: str  # "system", "user", "assistant"
    content: str

    def to_dict(self) -> Dict[str, str]:
        return {"role": self.role, "content": self.content}


@dataclass
class LLMResponse:
    """R√©ponse du LLM."""

    content: str
    model: str
    provider: LLMProvider

    # M√©triques
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    latency_ms: float = 0.0

    # Parsing
    raw_response: Dict[str, Any] = field(default_factory=dict)
    parsed_json: Optional[Dict[str, Any]] = None
    parse_error: Optional[str] = None

    @property
    def is_valid(self) -> bool:
        """V√©rifie si la r√©ponse est valide."""
        return bool(self.content) and self.parse_error is None

    def parse_json(self) -> Optional[Dict[str, Any]]:
        """
        Tente de parser le contenu comme JSON.

        G√®re les cas o√π le JSON est dans un bloc markdown ```json ... ```
        """
        if self.parsed_json is not None:
            return self.parsed_json

        content = self.content.strip()

        # Essayer de parser directement
        try:
            self.parsed_json = json.loads(content)
            return self.parsed_json
        except json.JSONDecodeError:
            pass

        # Chercher un bloc JSON dans markdown
        import re
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
        if json_match:
            try:
                self.parsed_json = json.loads(json_match.group(1))
                return self.parsed_json
            except json.JSONDecodeError as e:
                self.parse_error = f"JSON invalide dans bloc markdown: {e}"

        # Chercher un objet JSON dans le texte
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                self.parsed_json = json.loads(json_match.group())
                return self.parsed_json
            except json.JSONDecodeError as e:
                self.parse_error = f"JSON invalide: {e}"

        self.parse_error = "Aucun JSON trouv√© dans la r√©ponse"
        return None


class LLMClient(ABC):
    """Interface abstraite pour les clients LLM."""

    def __init__(self, config: LLMConfig):
        self.config = config
        self._total_tokens = 0
        self._total_requests = 0

    @abstractmethod
    def chat(
        self,
        messages: List[LLMMessage],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        json_mode: bool = False,
    ) -> LLMResponse:
        """
        Envoie une conversation au LLM.

        Args:
            messages: Liste de messages
            temperature: Override temp√©rature
            max_tokens: Override max tokens
            json_mode: Forcer r√©ponse JSON (si support√©)

        Returns:
            R√©ponse du LLM
        """
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """V√©rifie si le LLM est disponible."""
        pass

    def simple_chat(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        **kwargs,
    ) -> LLMResponse:
        """
        Chat simplifi√© avec un seul message.

        Args:
            user_message: Message utilisateur
            system_prompt: Prompt syst√®me optionnel
            **kwargs: Arguments pass√©s √† chat()

        Returns:
            R√©ponse du LLM
        """
        messages = []
        if system_prompt:
            messages.append(LLMMessage(role="system", content=system_prompt))
        messages.append(LLMMessage(role="user", content=user_message))

        return self.chat(messages, **kwargs)

    @property
    def stats(self) -> Dict[str, Any]:
        """Statistiques d'utilisation."""
        return {
            "total_tokens": self._total_tokens,
            "total_requests": self._total_requests,
            "provider": self.config.provider.value,
            "model": self.config.model,
        }


def _is_reasoning_model(model_name: str) -> bool:
    """
    D√©tecte si un mod√®le est un mod√®le de raisonnement qui peut prendre plus de temps.

    Les mod√®les de raisonnement comme deepseek-r1, qwq, o1, etc. peuvent prendre
    5-15 minutes pour raisonner sur des t√¢ches complexes.
    """
    reasoning_patterns = [
        "deepseek-r1",
        "qwq",
        "o1",
        "o3",
        "r1",
        "reasoning",
    ]
    model_lower = model_name.lower()
    return any(pattern in model_lower for pattern in reasoning_patterns)


def _get_adaptive_timeout(config: LLMConfig) -> float:
    """
    Retourne un timeout adapt√© au type de mod√®le.

    - Mod√®les de raisonnement: 15 minutes (900s)
    - Mod√®les standards: timeout configur√©
    """
    if _is_reasoning_model(config.model):
        logger.info(f"üß† Mod√®le de raisonnement d√©tect√© ({config.model}): timeout √©tendu √† 15 min")
        return 900.0  # 15 minutes pour les mod√®les de raisonnement
    return float(config.timeout_seconds)


class OllamaClient(LLMClient):
    """Client pour Ollama (LLM local)."""

    def __init__(self, config: LLMConfig):
        super().__init__(config)
        # Timeout adaptatif selon le type de mod√®le
        adaptive_timeout = _get_adaptive_timeout(config)
        self._http_client = httpx.Client(timeout=adaptive_timeout)
        self._adaptive_timeout = adaptive_timeout

    def _messages_to_prompt(self, messages: List[LLMMessage], json_mode: bool) -> str:
        """Convertit une conversation en prompt simple pour /api/generate."""
        lines: List[str] = []
        for msg in messages:
            role = (msg.role or "user").strip().lower()
            if role == "system":
                label = "System"
            elif role == "assistant":
                label = "Assistant"
            else:
                label = "User"
            content = msg.content.strip()
            if content:
                lines.append(f"{label}: {content}")
        if json_mode:
            lines.append("System: Respond with valid JSON only.")
        lines.append("Assistant:")
        return "\n".join(lines).strip()

    def _chat_via_generate(
        self,
        messages: List[LLMMessage],
        temperature: Optional[float],
        max_tokens: Optional[int],
        json_mode: bool,
    ) -> LLMResponse:
        """Fallback Ollama via /api/generate quand /api/chat est indisponible."""
        url = f"{self.config.ollama_host}/api/generate"
        prompt = self._messages_to_prompt(messages, json_mode)

        payload = {
            "model": self.config.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temperature or self.config.temperature,
                "num_predict": max_tokens or self.config.max_tokens,
                "top_p": self.config.top_p,
            },
        }

        if json_mode:
            payload["format"] = "json"

        start_time = time.time()
        response = self._http_client.post(
            url,
            json=payload,
            timeout=self._adaptive_timeout,
        )
        response.raise_for_status()

        data = response.json()
        latency = (time.time() - start_time) * 1000

        prompt_tokens = data.get("prompt_eval_count", 0)
        completion_tokens = data.get("eval_count", 0)
        total_tokens = prompt_tokens + completion_tokens

        self._total_tokens += total_tokens
        self._total_requests += 1

        llm_response = LLMResponse(
            content=data.get("response", ""),
            model=self.config.model,
            provider=LLMProvider.OLLAMA,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens,
            latency_ms=latency,
            raw_response=data,
        )

        if json_mode:
            llm_response.parse_json()

        return llm_response

    def is_available(self) -> bool:
        """V√©rifie si Ollama est disponible."""
        try:
            response = self._http_client.get(
                f"{self.config.ollama_host}/api/tags",
                timeout=5.0,
            )
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"Ollama non disponible: {e}")
            return False

    def list_models(self) -> List[str]:
        """Liste les mod√®les disponibles dans Ollama."""
        try:
            response = self._http_client.get(f"{self.config.ollama_host}/api/tags")
            if response.status_code == 200:
                data = response.json()
                return [m["name"] for m in data.get("models", [])]
        except Exception as e:
            logger.error(f"Erreur liste mod√®les Ollama: {e}")
        return []

    def chat(
        self,
        messages: List[LLMMessage],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        json_mode: bool = False,
    ) -> LLMResponse:
        """Envoie une conversation √† Ollama."""

        url = f"{self.config.ollama_host}/api/chat"
        use_generate_fallback = False

        payload = {
            "model": self.config.model,
            "messages": [m.to_dict() for m in messages],
            "stream": False,
            "options": {
                "temperature": temperature or self.config.temperature,
                "num_predict": max_tokens or self.config.max_tokens,
                "top_p": self.config.top_p,
            },
        }

        if json_mode:
            payload["format"] = "json"

        start_time = time.time()

        for attempt in range(self.config.max_retries):
            try:
                # Log avec timeout adaptatif pour information
                if attempt == 0:
                    logger.info(
                        f"ü§ñ Interrogation {self.config.model} (timeout: {self._adaptive_timeout:.0f}s)..."
                    )

                if use_generate_fallback:
                    return self._chat_via_generate(messages, temperature, max_tokens, json_mode)

                response = self._http_client.post(
                    url,
                    json=payload,
                    timeout=self._adaptive_timeout,
                )
                if response.status_code == 404:
                    logger.warning(
                        "Ollama /api/chat introuvable (404). Fallback vers /api/generate."
                    )
                    use_generate_fallback = True
                    return self._chat_via_generate(messages, temperature, max_tokens, json_mode)

                response.raise_for_status()

                data = response.json()
                latency = (time.time() - start_time) * 1000

                # Extraire les tokens si disponibles
                prompt_tokens = data.get("prompt_eval_count", 0)
                completion_tokens = data.get("eval_count", 0)
                total_tokens = prompt_tokens + completion_tokens

                self._total_tokens += total_tokens
                self._total_requests += 1

                llm_response = LLMResponse(
                    content=data.get("message", {}).get("content", ""),
                    model=self.config.model,
                    provider=LLMProvider.OLLAMA,
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    total_tokens=total_tokens,
                    latency_ms=latency,
                    raw_response=data,
                )

                if json_mode:
                    llm_response.parse_json()

                return llm_response

            except httpx.TimeoutException:
                elapsed = time.time() - start_time
                logger.warning(
                    f"‚è±Ô∏è Timeout Ollama apr√®s {elapsed:.1f}s "
                    f"(tentative {attempt + 1}/{self.config.max_retries})"
                )
                logger.info(
                    f"üí° Le mod√®le {self.config.model} peut prendre du temps pour raisonner. "
                    f"Patience..."
                )
                if attempt < self.config.max_retries - 1:
                    time.sleep(self.config.retry_delay_seconds * (attempt + 1))
            except Exception as e:
                logger.error(f"Erreur Ollama: {e}")
                if attempt < self.config.max_retries - 1:
                    time.sleep(self.config.retry_delay_seconds)

        # √âchec apr√®s tous les retries
        return LLMResponse(
            content="",
            model=self.config.model,
            provider=LLMProvider.OLLAMA,
            parse_error="√âchec apr√®s plusieurs tentatives",
        )


class OpenAIClient(LLMClient):
    """Client pour OpenAI API (et compatibles)."""

    def __init__(self, config: LLMConfig):
        super().__init__(config)

        if not config.openai_api_key:
            raise ValueError("OpenAI API key requise (OPENAI_API_KEY)")

        # Timeout adaptatif selon le type de mod√®le
        adaptive_timeout = _get_adaptive_timeout(config)
        self._adaptive_timeout = adaptive_timeout

        self._http_client = httpx.Client(
            timeout=adaptive_timeout,
            headers={
                "Authorization": f"Bearer {config.openai_api_key}",
                "Content-Type": "application/json",
            },
        )

    def is_available(self) -> bool:
        """V√©rifie si l'API OpenAI est disponible."""
        try:
            response = self._http_client.get(
                f"{self.config.openai_base_url}/models",
                timeout=5.0,
            )
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"OpenAI non disponible: {e}")
            return False

    def chat(
        self,
        messages: List[LLMMessage],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        json_mode: bool = False,
    ) -> LLMResponse:
        """Envoie une conversation √† OpenAI."""

        url = f"{self.config.openai_base_url}/chat/completions"

        payload = {
            "model": self.config.model,
            "messages": [m.to_dict() for m in messages],
            "temperature": temperature or self.config.temperature,
            "max_tokens": max_tokens or self.config.max_tokens,
            "top_p": self.config.top_p,
        }

        if json_mode:
            payload["response_format"] = {"type": "json_object"}

        start_time = time.time()

        for attempt in range(self.config.max_retries):
            try:
                response = self._http_client.post(url, json=payload)
                response.raise_for_status()

                data = response.json()
                latency = (time.time() - start_time) * 1000

                usage = data.get("usage", {})
                prompt_tokens = usage.get("prompt_tokens", 0)
                completion_tokens = usage.get("completion_tokens", 0)
                total_tokens = usage.get("total_tokens", 0)

                self._total_tokens += total_tokens
                self._total_requests += 1

                content = ""
                if data.get("choices"):
                    content = data["choices"][0].get("message", {}).get("content", "")

                llm_response = LLMResponse(
                    content=content,
                    model=self.config.model,
                    provider=LLMProvider.OPENAI,
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    total_tokens=total_tokens,
                    latency_ms=latency,
                    raw_response=data,
                )

                if json_mode:
                    llm_response.parse_json()

                return llm_response

            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429:  # Rate limit
                    wait_time = self.config.retry_delay_seconds * (2 ** attempt)
                    logger.warning(f"Rate limit OpenAI, attente {wait_time}s")
                    time.sleep(wait_time)
                else:
                    logger.error(f"Erreur OpenAI HTTP: {e}")
                    break
            except Exception as e:
                logger.error(f"Erreur OpenAI: {e}")
                if attempt < self.config.max_retries - 1:
                    time.sleep(self.config.retry_delay_seconds)

        return LLMResponse(
            content="",
            model=self.config.model,
            provider=LLMProvider.OPENAI,
            parse_error="√âchec apr√®s plusieurs tentatives",
        )


def create_llm_client(config: Optional[LLMConfig] = None) -> LLMClient:
    """
    Factory pour cr√©er le bon client LLM.

    Args:
        config: Configuration (ou depuis env si None)

    Returns:
        Client LLM appropri√©
    """
    if config is None:
        config = LLMConfig.from_env()

    if config.provider == LLMProvider.OPENAI:
        return OpenAIClient(config)
    else:
        return OllamaClient(config)
```
<!-- MODULE-END: llm_client.py -->

<!-- MODULE-START: llm_config.py -->
```json
{
  "name": "llm_config.py",
  "path": "agents\\llm_config.py",
  "ext": ".py",
  "anchor": "llm_config_py"
}
```
## llm_config_py
*Chemin* : `agents\llm_config.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.llm_config

Purpose: Configuration et logique m√©tier pour les providers LLM.
         Extraction de la logique depuis ui/sidebar.py (DDD refactoring).

Role in pipeline: domain / configuration

Key components:
- LLMConfigOptions: Options disponibles pour la configuration LLM
- get_llm_options: R√©cup√®re les options de configuration
- validate_llm_config: Valide une configuration LLM
- extract_model_size: Parse la taille d'un mod√®le (ex: "14b" -> 14.0)
- filter_models_by_size: Filtre les mod√®les par taille

Dependencies: agents.llm_client, re

Conventions: Fonctions pures (pas de Streamlit), retournent des dicts/dataclasses

Read-if: Configuration LLM pour UI ou CLI
Skip-if: Logique de trading
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Set

# Import conditionnel des d√©pendances LLM
try:
    from agents.llm_client import LLMConfig, LLMProvider
    from agents.model_config import (
        KNOWN_MODELS,
        ModelCategory,
        RoleModelConfig,
        get_global_model_config,
        set_global_model_config,
    )
    LLM_AVAILABLE = True
    LLM_IMPORT_ERROR = None
except ImportError as e:
    LLM_AVAILABLE = False
    LLM_IMPORT_ERROR = str(e)
    LLMConfig = None
    LLMProvider = None
    KNOWN_MODELS = {}
    ModelCategory = None
    RoleModelConfig = None
    get_global_model_config = None
    set_global_model_config = None


# ============================================================================
# CONFIGURATION CONSTANTS
# ============================================================================

DEFAULT_OLLAMA_HOST = "http://localhost:11434"

RECOMMENDED_FOR_STRATEGY = [
    "deepseek-r1:8b",
    "qwen2.5:14b",
    "gemma3:27b",
    "llama3.3:70b",
]

OPENAI_MODELS = [
    "gpt-4o-mini",
    "gpt-4o",
    "gpt-4-turbo",
    "gpt-3.5-turbo",
]

# Mod√®les √† exclure par d√©faut des s√©lections al√©atoires
EXCLUDED_HEAVY_MODELS: Set[str] = {"deepseek-r1:70b"}


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class LLMConfigOptions:
    """Options disponibles pour la configuration LLM."""
    available: bool = False
    import_error: Optional[str] = None

    providers: List[str] = field(default_factory=lambda: ["Ollama (Local)", "OpenAI"])
    ollama_models: List[str] = field(default_factory=list)
    openai_models: List[str] = field(default_factory=lambda: OPENAI_MODELS.copy())

    ollama_connected: bool = False
    default_ollama_host: str = DEFAULT_OLLAMA_HOST


@dataclass
class ModelSizeFilter:
    """Configuration du filtrage par taille de mod√®le."""
    limit_small: bool = False  # < 20B
    limit_large: bool = False  # >= 20B
    excluded_models: Set[str] = field(default_factory=lambda: EXCLUDED_HEAVY_MODELS.copy())


# ============================================================================
# MODEL SIZE UTILITIES
# ============================================================================

def extract_model_size_b(model_name: str) -> Optional[float]:
    """
    Extrait la taille en milliards de param√®tres d'un nom de mod√®le.

    Args:
        model_name: Nom du mod√®le (ex: "llama3.3:70b", "qwen2.5:14b")

    Returns:
        Taille en milliards (ex: 70.0, 14.0) ou None si non trouv√©
    """
    match = re.search(r"(\d+(?:\.\d+)?)b", model_name.lower())
    if match:
        return float(match.group(1))
    return None


def is_model_under_limit(model_name: str, limit: float) -> bool:
    """
    V√©rifie si un mod√®le est sous une limite de taille.

    Args:
        model_name: Nom du mod√®le
        limit: Limite en milliards

    Returns:
        True si mod√®le < limite, False sinon
    """
    size = extract_model_size_b(model_name)
    if size is None:
        return False
    return size < limit


def is_model_over_limit(model_name: str, limit: float) -> bool:
    """
    V√©rifie si un mod√®le est au-dessus d'une limite de taille.

    Args:
        model_name: Nom du mod√®le
        limit: Limite en milliards

    Returns:
        True si mod√®le >= limite, False sinon
    """
    size = extract_model_size_b(model_name)
    if size is None:
        return False
    return size >= limit


def filter_models_by_size(
    models: List[str],
    size_filter: ModelSizeFilter
) -> List[str]:
    """
    Filtre une liste de mod√®les selon les crit√®res de taille.

    Args:
        models: Liste des noms de mod√®les
        size_filter: Configuration du filtrage

    Returns:
        Liste filtr√©e des mod√®les
    """
    # Exclure les mod√®les interdits
    filtered = [m for m in models if m not in size_filter.excluded_models]

    # Appliquer les filtres de taille (priorit√© aux >= 20B si les deux actifs)
    if size_filter.limit_small and size_filter.limit_large:
        # Priorit√© au filtre large
        result = [m for m in filtered if is_model_over_limit(m, 20)]
    elif size_filter.limit_large:
        result = [m for m in filtered if is_model_over_limit(m, 20)]
    elif size_filter.limit_small:
        result = [m for m in filtered if is_model_under_limit(m, 20)]
    else:
        result = filtered

    # Si le filtrage vide la liste, retourner la liste non filtr√©e par taille
    if not result and filtered:
        return filtered

    return result


# ============================================================================
# OLLAMA UTILITIES
# ============================================================================

def is_ollama_available() -> bool:
    """
    V√©rifie si Ollama est disponible et connect√©.

    Returns:
        True si Ollama r√©pond, False sinon
    """
    try:
        import httpx
        response = httpx.get(f"{DEFAULT_OLLAMA_HOST}/api/tags", timeout=2.0)
        return response.status_code == 200
    except Exception:
        return False


def list_available_ollama_models() -> List[str]:
    """
    Liste les mod√®les Ollama install√©s localement.

    Returns:
        Liste des noms de mod√®les disponibles
    """
    try:
        import httpx
        response = httpx.get(f"{DEFAULT_OLLAMA_HOST}/api/tags", timeout=5.0)
        if response.status_code == 200:
            data = response.json()
            models = data.get("models", [])
            return [m.get("name", "") for m in models if m.get("name")]
    except Exception:
        pass
    return []


def ensure_ollama_running() -> tuple[bool, str]:
    """
    Tente de d√©marrer Ollama s'il n'est pas en cours d'ex√©cution.

    Returns:
        Tuple (success, message)
    """
    if is_ollama_available():
        return True, "Ollama d√©j√† connect√©"

    try:
        import subprocess
        subprocess.Popen(
            ["ollama", "serve"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        # Attendre un peu et v√©rifier
        import time
        for _ in range(10):
            time.sleep(0.5)
            if is_ollama_available():
                return True, "Ollama d√©marr√© avec succ√®s"

        return False, "Ollama d√©marr√© mais ne r√©pond pas"
    except Exception as e:
        return False, f"Erreur d√©marrage Ollama: {e}"


# ============================================================================
# CONFIGURATION FUNCTIONS
# ============================================================================

def get_llm_options() -> LLMConfigOptions:
    """
    R√©cup√®re toutes les options disponibles pour la configuration LLM.

    Returns:
        LLMConfigOptions avec providers, mod√®les, et √©tat de connexion
    """
    options = LLMConfigOptions(
        available=LLM_AVAILABLE,
        import_error=LLM_IMPORT_ERROR,
    )

    if not LLM_AVAILABLE:
        return options

    # V√©rifier Ollama
    options.ollama_connected = is_ollama_available()
    if options.ollama_connected:
        options.ollama_models = list_available_ollama_models()

    return options


def get_model_display_name(model_name: str) -> str:
    """
    G√©n√®re un nom d'affichage avec badge de cat√©gorie.

    Args:
        model_name: Nom brut du mod√®le

    Returns:
        Nom avec badge (ex: "[L] qwen2.5:14b", "[H] llama3.3:70b")
    """
    if not LLM_AVAILABLE or KNOWN_MODELS is None:
        return model_name

    info = KNOWN_MODELS.get(model_name)
    if info:
        if info.category == ModelCategory.LIGHT:
            return f"[L] {model_name}"
        if info.category == ModelCategory.MEDIUM:
            return f"[M] {model_name}"
        return f"[H] {model_name}"
    return model_name


def create_display_mappings(model_names: List[str]) -> tuple[Dict[str, str], Dict[str, str]]:
    """
    Cr√©e les mappings nom ‚Üî affichage pour une liste de mod√®les.

    Args:
        model_names: Liste des noms de mod√®les

    Returns:
        Tuple (name_to_display, display_to_name)
    """
    name_to_display = {n: get_model_display_name(n) for n in model_names}
    display_to_name = {v: k for k, v in name_to_display.items()}
    return name_to_display, display_to_name


def validate_llm_config(config: Any) -> tuple[bool, Optional[str]]:
    """
    Valide une configuration LLM.

    Args:
        config: Configuration LLM √† valider

    Returns:
        Tuple (is_valid, error_message)
    """
    if config is None:
        return False, "Configuration LLM non d√©finie"

    if not LLM_AVAILABLE:
        return False, f"Module LLM non disponible: {LLM_IMPORT_ERROR}"

    if not hasattr(config, 'provider') or not hasattr(config, 'model'):
        return False, "Configuration LLM invalide (provider/model manquant)"

    if config.provider == LLMProvider.OLLAMA:
        if not is_ollama_available():
            return False, "Ollama non connect√©"

    if config.provider == LLMProvider.OPENAI:
        if not hasattr(config, 'api_key') or not config.api_key:
            return False, "Cl√© API OpenAI manquante"

    return True, None


def create_llm_config(
    provider: str,
    model: str,
    ollama_host: str = DEFAULT_OLLAMA_HOST,
    api_key: Optional[str] = None
) -> Optional[Any]:
    """
    Cr√©e une configuration LLM.

    Args:
        provider: "Ollama (Local)" ou "OpenAI"
        model: Nom du mod√®le
        ollama_host: URL du serveur Ollama
        api_key: Cl√© API OpenAI (si applicable)

    Returns:
        LLMConfig ou None si indisponible
    """
    if not LLM_AVAILABLE or LLMConfig is None:
        return None

    if "Ollama" in provider:
        return LLMConfig(
            provider=LLMProvider.OLLAMA,
            model=model,
            ollama_host=ollama_host,
        )
    else:
        if not api_key:
            return None
        return LLMConfig(
            provider=LLMProvider.OPENAI,
            model=model,
            api_key=api_key,
        )


# ============================================================================
# MULTI-MODEL ROLE CONFIGURATION
# ============================================================================

def get_optimal_models_for_role(
    role: str,
    available_models: List[str]
) -> List[str]:
    """
    Retourne les mod√®les optimaux pour un r√¥le d'agent.

    Args:
        role: "analyst", "strategist", "critic", ou "validator"
        available_models: Mod√®les disponibles

    Returns:
        Liste de mod√®les recommand√©s (max 3)
    """
    # Configuration optimale bas√©e sur benchmarks
    optimal_config = {
        "analyst": ["qwen2.5:14b", "gemma3:12b", "llama3.2:8b"],
        "strategist": ["gemma3:27b", "qwen2.5:14b", "mistral:7b"],
        "critic": ["llama3.3:70b", "deepseek-r1:32b", "gemma3:27b"],
        "validator": ["llama3.3:70b", "deepseek-r1:32b", "qwen2.5:32b"],
    }

    preferred = optimal_config.get(role, [])
    result = [m for m in preferred if m in available_models]

    # Fallback si aucun mod√®le optimal disponible
    if not result and available_models:
        result = available_models[:2]

    return result[:3]


def normalize_model_selection(
    selection: List[str],
    display_to_name: Dict[str, str],
    available_models: List[str]
) -> List[str]:
    """
    Normalise une s√©lection de mod√®les (display ‚Üí name, filtrage).

    Args:
        selection: Liste de noms d'affichage s√©lectionn√©s
        display_to_name: Mapping affichage ‚Üí nom
        available_models: Mod√®les disponibles

    Returns:
        Liste de noms de mod√®les normalis√©s et valid√©s
    """
    names = [display_to_name.get(m, m) for m in selection]
    return [n for n in names if n in available_models]
```
<!-- MODULE-END: llm_config.py -->

<!-- MODULE-START: model_config.py -->
```json
{
  "name": "model_config.py",
  "path": "agents\\model_config.py",
  "ext": ".py",
  "anchor": "model_config_py"
}
```
## model_config_py
*Chemin* : `agents\model_config.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.model_config

Purpose: Configuration multi-mod√®les par r√¥le d'agent avec s√©lection intelligente (rapide/lourd par it√©ration).

Role in pipeline: orchestration

Key components: RoleModelConfig, ModelCategory, KNOWN_MODELS, get_model

Inputs: role (analyst/strategist/critic/validator), iteration, allow_heavy flag

Outputs: Mod√®le s√©lectionn√© (al√©atoire parmi configur√©s), fallback si non dispo

Dependencies: utils.log, httpx (Ollama discovery)

Conventions: ANALYST=rapide, STRATEGIST=moyen, CRITIC/VALIDATOR=lourd optionnel; early iterations excluent mod√®les lourds; fallback cascade si mod√®le absent.

Read-if: Ajout mod√®les, configuration par r√¥le, ou r√®gles de s√©lection it√©rative.

Skip-if: Vous utilisez la config par d√©faut.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
import os
import random
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Set

import httpx

from utils.model_loader import get_all_ollama_models

logger = logging.getLogger(__name__)

# Seuil en milliards de param√®tres au-del√† duquel un mod√®le n√©cessite approbation manuelle
MAX_AUTO_SELECT_PARAMS_B: float = 50.0


def _ollama_base_url() -> str:
    """Retourne l'URL de base Ollama (avec fallback local)."""
    base = os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
    return base.rstrip("/")


def _fetch_ollama_tags_with_retries(
    *,
    max_attempts: int = 5,
    timeout_s: float = 3.0,
    base_backoff_s: float = 1.0,
) -> Optional[dict]:
    """R√©cup√®re /api/tags avec retries/backoff (Ollama peut d√©marrer lentement)."""
    url = f"{_ollama_base_url()}/api/tags"
    last_exc: Optional[BaseException] = None
    for attempt in range(max_attempts):
        try:
            resp = httpx.get(url, timeout=timeout_s)
            if resp.status_code == 200:
                return resp.json()
            last_exc = RuntimeError(f"HTTP {resp.status_code}")
        except Exception as exc:  # noqa: BLE001
            last_exc = exc

        if attempt < max_attempts - 1:
            sleep_s = float(base_backoff_s * (2 ** attempt))
            time.sleep(sleep_s)

    if last_exc is not None:
        logger.warning("Impossible de lister les modeles Ollama apres retries: %s", last_exc)
    return None


def _infer_category_from_size(size_gb: float) -> ModelCategory:
    if size_gb < 6:
        return ModelCategory.LIGHT
    if size_gb < 15:
        return ModelCategory.MEDIUM
    return ModelCategory.HEAVY


def _ollama_name_from_library_entry(entry: Dict[str, Any]) -> Optional[str]:
    model_name = entry.get("model_name")
    tag = entry.get("tag")
    if model_name and tag:
        if tag == "latest":
            return model_name
        return f"{model_name}:{tag}"
    if model_name:
        return model_name
    return entry.get("id")


def _model_info_from_library_entry(entry: Dict[str, Any]) -> Optional[ModelInfo]:
    name = _ollama_name_from_library_entry(entry)
    if not name:
        return None

    if name in KNOWN_MODELS:
        return KNOWN_MODELS[name]

    size_gb = float(entry.get("size_gb") or 0)
    category = _infer_category_from_size(size_gb)
    description = entry.get("description") or f"Modele {name} ({size_gb:.1f} GB)"

    return ModelInfo(
        name=name,
        category=category,
        description=description,
        recommended_for=["analyst", "strategist"],
    )


def _normalize_model_name(name: str) -> str:
    """Normalise un nom de mod√®le (supprime le tag latest et garde le complet)."""
    if not name:
        return ""
    if name.endswith(":latest"):
        return name.rsplit(":", 1)[0]
    return name


class ModelCategory(Enum):
    """Cat√©gories de mod√®les par taille/vitesse."""

    LIGHT = "light"      # < 10B params, rapide (< 30s)
    MEDIUM = "medium"    # 10-30B params, mod√©r√© (30s-2min)
    HEAVY = "heavy"      # > 30B params, lent (> 2min)


@dataclass
class ModelInfo:
    """Information sur un mod√®le LLM."""

    name: str                      # Nom Ollama (ex: "deepseek-r1:32b")
    category: ModelCategory        # Cat√©gorie de taille
    description: str = ""          # Description courte
    recommended_for: List[str] = field(default_factory=list)  # R√¥les recommand√©s
    avg_response_time_s: float = 30.0  # Temps de r√©ponse moyen estim√©
    params_billions: float = 0.0   # Nombre de param√®tres en milliards (0 = inconnu)

    @property
    def requires_manual_approval(self) -> bool:
        """True si le mod√®le d√©passe le seuil d'auto-s√©lection (> 50B params)."""
        return self.params_billions > MAX_AUTO_SELECT_PARAMS_B

    def __hash__(self):
        return hash(self.name)

    def __eq__(self, other):
        if isinstance(other, ModelInfo):
            return self.name == other.name
        return False


# Base de donn√©es des mod√®les connus avec leurs caract√©ristiques
KNOWN_MODELS: Dict[str, ModelInfo] = {
    # Light models (< 10B) - Rapides
    "deepseek-r1:8b": ModelInfo(
        name="deepseek-r1:8b",
        category=ModelCategory.LIGHT,
        description="DeepSeek R1 8B - Rapide, bon pour analyses simples",
        recommended_for=["analyst", "strategist"],
        avg_response_time_s=15.0,
        params_billions=8.0,
    ),
    "mistral:7b-instruct": ModelInfo(
        name="mistral:7b-instruct",
        category=ModelCategory.LIGHT,
        description="Mistral 7B Instruct - Tr√®s rapide, polyvalent",
        recommended_for=["analyst", "strategist"],
        avg_response_time_s=10.0,
        params_billions=7.0,
    ),
    "llama3.1:8b-local": ModelInfo(
        name="llama3.1:8b-local",
        category=ModelCategory.LIGHT,
        description="Llama 3.1 8B - Rapide, bonne qualit√©",
        recommended_for=["analyst", "strategist"],
        avg_response_time_s=20.0,
        params_billions=8.0,
    ),
    "martain7r/finance-llama-8b:q4_k_m": ModelInfo(
        name="martain7r/finance-llama-8b:q4_k_m",
        category=ModelCategory.LIGHT,
        description="Finance Llama 8B - Sp√©cialis√© finance/trading",
        recommended_for=["analyst", "critic"],
        avg_response_time_s=15.0,
        params_billions=8.0,
    ),

    # Medium models (10-30B) - √âquilibr√©s
    "gemma3:12b": ModelInfo(
        name="gemma3:12b",
        category=ModelCategory.MEDIUM,
        description="Gemma 3 12B - Bon √©quilibre qualit√©/vitesse",
        recommended_for=["strategist", "critic"],
        avg_response_time_s=45.0,
        params_billions=12.0,
    ),
    "deepseek-r1-distill:14b": ModelInfo(
        name="deepseek-r1-distill:14b",
        category=ModelCategory.MEDIUM,
        description="DeepSeek R1 Distill 14B - Raisonnement efficace",
        recommended_for=["strategist", "critic", "validator"],
        avg_response_time_s=60.0,
        params_billions=14.0,
    ),
    "mistral:22b": ModelInfo(
        name="mistral:22b",
        category=ModelCategory.MEDIUM,
        description="Mistral 22B - Puissant et raisonnablement rapide",
        recommended_for=["critic", "validator"],
        avg_response_time_s=90.0,
        params_billions=22.0,
    ),
    "gemma3:27b": ModelInfo(
        name="gemma3:27b",
        category=ModelCategory.MEDIUM,
        description="Gemma 3 27B - Tr√®s bonne qualit√©",
        recommended_for=["critic", "validator"],
        avg_response_time_s=120.0,
        params_billions=27.0,
    ),

    # Heavy models (> 30B) - Puissants mais lents
    "deepseek-r1:32b": ModelInfo(
        name="deepseek-r1:32b",
        category=ModelCategory.HEAVY,
        description="DeepSeek R1 32B - Excellent raisonnement",
        recommended_for=["critic", "validator"],
        avg_response_time_s=180.0,
        params_billions=32.0,
    ),
    "qwq:32b": ModelInfo(
        name="qwq:32b",
        category=ModelCategory.HEAVY,
        description="QwQ 32B - Raisonnement profond",
        recommended_for=["critic", "validator"],
        avg_response_time_s=200.0,
        params_billions=32.0,
    ),
    "qwen2.5:32b": ModelInfo(
        name="qwen2.5:32b",
        category=ModelCategory.HEAVY,
        description="Qwen 2.5 32B - Polyvalent haute qualit√©",
        recommended_for=["strategist", "critic", "validator"],
        avg_response_time_s=150.0,
        params_billions=32.0,
    ),
    "qwen3-vl:30b": ModelInfo(
        name="qwen3-vl:30b",
        category=ModelCategory.HEAVY,
        description="Qwen 3 VL 30B - Vision + Langage",
        recommended_for=["analyst"],  # Pour analyse de charts
        avg_response_time_s=180.0,
        params_billions=30.0,
    ),
    "deepseek-r1:70b": ModelInfo(
        name="deepseek-r1:70b",
        category=ModelCategory.HEAVY,
        description="DeepSeek R1 70B - Maximum puissance, TR√àS LENT (>50B: approbation manuelle requise)",
        recommended_for=["validator"],  # R√©serv√© aux d√©cisions critiques
        avg_response_time_s=600.0,  # ~10 minutes
        params_billions=70.0,
    ),
    "gpt-oss:20b": ModelInfo(
        name="gpt-oss:20b",
        category=ModelCategory.MEDIUM,
        description="GPT OSS 20B",
        recommended_for=["strategist", "critic"],
        avg_response_time_s=100.0,
        params_billions=20.0,
    ),
    # Llama 3.3 70B - Multi-GPU optimis√©
    "llama3.3:70b-instruct-q4_K_M": ModelInfo(
        name="llama3.3:70b-instruct-q4_K_M",
        category=ModelCategory.HEAVY,
        description="Llama 3.3 70B Instruct Q4 - Multi-GPU (>50B: approbation manuelle requise)",
        recommended_for=["critic", "validator"],
        avg_response_time_s=300.0,
        params_billions=70.0,
    ),
    "llama3.3-70b-optimized": ModelInfo(
        name="llama3.3-70b-optimized",
        category=ModelCategory.HEAVY,
        description="Llama 3.3 70B Optimis√© - Multi-GPU (>50B: approbation manuelle requise)",
        recommended_for=["critic", "validator"],
        avg_response_time_s=300.0,
        params_billions=70.0,
    ),
    "llama3.3-70b-2gpu": ModelInfo(
        name="llama3.3-70b-2gpu",
        category=ModelCategory.HEAVY,
        description="Llama 3.3 70B Multi-GPU (2 GPUs) - RTX 5080+2060 (>50B: approbation manuelle requise)",
        recommended_for=["critic", "validator"],
        avg_response_time_s=180.0,  # Plus rapide avec 2 GPUs
        params_billions=70.0,
    ),
}


@dataclass
class RoleModelAssignment:
    """Configuration des mod√®les pour un r√¥le."""

    role: str
    models: List[str] = field(default_factory=list)
    allow_heavy_after_iteration: int = 3  # N'autoriser les mod√®les lourds qu'apr√®s N it√©rations
    prefer_specialized: bool = True  # Pr√©f√©rer les mod√®les sp√©cialis√©s pour ce r√¥le

    def get_available_models(
        self,
        iteration: int = 1,
        allow_heavy: bool = False,
        installed_models: Optional[Set[str]] = None,
        allow_very_large: bool = False,
    ) -> List[str]:
        """
        Retourne les mod√®les disponibles pour cette it√©ration.

        Args:
            iteration: Num√©ro d'it√©ration actuel
            allow_heavy: Forcer l'autorisation des mod√®les lourds (cat√©gorie HEAVY)
            installed_models: Set des mod√®les install√©s (pour filtrage)
            allow_very_large: Autoriser les mod√®les > 50B params (n√©cessite approbation manuelle)

        Returns:
            Liste des mod√®les utilisables
        """
        available = []

        for model_name in self.models:
            # V√©rifier si install√©
            if installed_models and model_name not in installed_models:
                continue

            # V√©rifier la cat√©gorie et taille
            model_info = KNOWN_MODELS.get(model_name)
            if model_info:
                # Mod√®les > 50B : exclus sauf autorisation explicite
                if model_info.requires_manual_approval and not allow_very_large:
                    logger.debug(
                        f"Mod√®le {model_name} exclu (>{MAX_AUTO_SELECT_PARAMS_B}B params, approbation requise)"
                    )
                    continue

                # Mod√®les lourds (cat√©gorie) : v√©rifier les conditions d'it√©ration
                if model_info.category == ModelCategory.HEAVY:
                    if not allow_heavy and iteration < self.allow_heavy_after_iteration:
                        continue

            available.append(model_name)

        return available


@dataclass
class RoleModelConfig:
    """
    Configuration compl√®te des mod√®les par r√¥le.

    Permet d'assigner plusieurs mod√®les √† chaque r√¥le avec s√©lection
    al√©atoire ou bas√©e sur des crit√®res.
    """

    # Configuration par r√¥le
    analyst: RoleModelAssignment = field(default_factory=lambda: RoleModelAssignment(
        role="analyst",
        models=["deepseek-r1:8b", "mistral:7b-instruct", "martain7r/finance-llama-8b:q4_k_m", "gemma3:12b"],
        allow_heavy_after_iteration=5,
    ))

    strategist: RoleModelAssignment = field(default_factory=lambda: RoleModelAssignment(
        role="strategist",
        models=["deepseek-r1:8b", "gemma3:12b", "deepseek-r1-distill:14b", "mistral:22b"],
        allow_heavy_after_iteration=3,
    ))

    critic: RoleModelAssignment = field(default_factory=lambda: RoleModelAssignment(
        role="critic",
        models=["deepseek-r1-distill:14b", "mistral:22b", "gemma3:27b", "deepseek-r1:32b", "qwq:32b"],
        allow_heavy_after_iteration=2,
    ))

    validator: RoleModelAssignment = field(default_factory=lambda: RoleModelAssignment(
        role="validator",
        models=["deepseek-r1-distill:14b", "gemma3:27b", "deepseek-r1:32b", "qwq:32b"],
        allow_heavy_after_iteration=3,
    ))

    # Cache des mod√®les install√©s
    _installed_models: Optional[Set[str]] = field(default=None, repr=False)

    def __post_init__(self):
        """Initialise le cache des mod√®les install√©s."""
        self._refresh_installed_models()

    def _refresh_installed_models(self) -> Set[str]:
        """Rafra√Æchit la liste des mod√®les Ollama install√©s."""
        names: Set[str] = set()

        # 1) Source principale: API /api/tags (Ollama en cours d'ex√©cution)
        data = _fetch_ollama_tags_with_retries()
        if data:
            for m in data.get("models", []):
                raw = m.get("name", "")
                norm = _normalize_model_name(raw)
                if norm:
                    names.add(raw)
                    names.add(norm)

        # 2) Fallback: models.json (permet d'afficher quelque chose si l'API est indisponible)
        if not names:
            for entry in get_all_ollama_models():
                name = _ollama_name_from_library_entry(entry)
                norm = _normalize_model_name(name)
                if norm:
                    names.add(name)
                    names.add(norm)

        self._installed_models = names
        logger.debug("Modeles consideres comme installes: %s", len(self._installed_models))

        return self._installed_models

    def get_installed_models(self) -> Set[str]:
        """Retourne les mod√®les install√©s (avec cache)."""
        if self._installed_models is None:
            self._refresh_installed_models()
        return self._installed_models or set()

    def get_role_assignment(self, role: str) -> RoleModelAssignment:
        """Retourne l'assignment pour un r√¥le."""
        role = role.lower()
        if role == "analyst":
            return self.analyst
        elif role == "strategist":
            return self.strategist
        elif role == "critic":
            return self.critic
        elif role == "validator":
            return self.validator
        else:
            # D√©faut: utiliser analyst
            logger.warning(f"R√¥le inconnu: {role}, utilisation de analyst")
            return self.analyst

    def get_model(
        self,
        role: str,
        iteration: int = 1,
        allow_heavy: bool = False,
        random_selection: bool = True,
        allow_very_large: bool = False,
    ) -> Optional[str]:
        """
        Obtient un mod√®le pour un r√¥le donn√©.

        Args:
            role: Nom du r√¥le (analyst, strategist, critic, validator)
            iteration: Num√©ro d'it√©ration actuel
            allow_heavy: Forcer l'autorisation des mod√®les lourds (cat√©gorie HEAVY)
            random_selection: Si True, s√©lection al√©atoire parmi les mod√®les disponibles
            allow_very_large: Autoriser les mod√®les > 50B params (approbation manuelle)

        Returns:
            Nom du mod√®le ou None si aucun disponible
        """
        assignment = self.get_role_assignment(role)
        installed = self.get_installed_models()

        # Niveau 1: intersection config role ‚à© installed
        available = assignment.get_available_models(
            iteration=iteration,
            allow_heavy=allow_heavy,
            installed_models=installed,
            allow_very_large=allow_very_large,
        )
        if available:
            return random.choice(available) if (random_selection and len(available) > 1) else available[0]

        # Niveau 2: fallback sur la config du role, meme si Ollama est down / liste vide
        fallback_cfg = assignment.get_available_models(
            iteration=iteration,
            allow_heavy=allow_heavy,
            installed_models=None,
            allow_very_large=allow_very_large,
        )
        if fallback_cfg:
            return (
                random.choice(fallback_cfg)
                if (random_selection and len(fallback_cfg) > 1)
                else fallback_cfg[0]
            )

        # Niveau 3: n'importe quel modele installe
        if installed:
            return next(iter(installed))

        logger.warning("Aucun modele disponible pour %s (iteration=%s)", role, iteration)
        return None

    def get_model_info(self, model_name: str) -> Optional[ModelInfo]:
        """Retourne les infos d'un mod√®le."""
        return KNOWN_MODELS.get(model_name)

    def set_role_models(self, role: str, models: List[str]) -> None:
        """Configure les mod√®les pour un r√¥le."""
        assignment = self.get_role_assignment(role)
        assignment.models = models
        logger.info(f"Mod√®les pour {role}: {models}")

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise la configuration."""
        return {
            "analyst": {
                "models": self.analyst.models,
                "allow_heavy_after_iteration": self.analyst.allow_heavy_after_iteration,
            },
            "strategist": {
                "models": self.strategist.models,
                "allow_heavy_after_iteration": self.strategist.allow_heavy_after_iteration,
            },
            "critic": {
                "models": self.critic.models,
                "allow_heavy_after_iteration": self.critic.allow_heavy_after_iteration,
            },
            "validator": {
                "models": self.validator.models,
                "allow_heavy_after_iteration": self.validator.allow_heavy_after_iteration,
            },
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> RoleModelConfig:
        """D√©s√©rialise la configuration."""
        config = cls()

        for role in ["analyst", "strategist", "critic", "validator"]:
            if role in data:
                role_data = data[role]
                assignment = config.get_role_assignment(role)
                assignment.models = role_data.get("models", assignment.models)
                assignment.allow_heavy_after_iteration = role_data.get(
                    "allow_heavy_after_iteration",
                    assignment.allow_heavy_after_iteration
                )

        return config


def list_available_models() -> List[ModelInfo]:
    """Liste tous les mod√®les install√©s ou pr√©sents dans models.json."""
    result_by_name: Dict[str, ModelInfo] = {}

    for entry in get_all_ollama_models():
        info = _model_info_from_library_entry(entry)
        if info:
            result_by_name[info.name] = info

    data = _fetch_ollama_tags_with_retries()
    if data:
        models = data.get("models", [])
        for m in models:
            name = m.get("name", "")
            if not name:
                continue
            if name.endswith(":latest"):
                name = name.rsplit(":", 1)[0]
            if name in KNOWN_MODELS:
                result_by_name[name] = KNOWN_MODELS[name]
                continue
            if name in result_by_name:
                continue

            size_gb = m.get("size", 0) / (1024**3)
            category = _infer_category_from_size(size_gb)
            result_by_name[name] = ModelInfo(
                name=name,
                category=category,
                description=f"Modele {name} ({size_gb:.1f} GB)",
                recommended_for=["analyst", "strategist"],
            )

    if not result_by_name:
        # Fallback: retourner les mod√®les connus (utile pour l'UI quand Ollama est lent)
        return list(KNOWN_MODELS.values())

    return sorted(result_by_name.values(), key=lambda info: info.name)


def get_models_by_category(category: ModelCategory) -> List[ModelInfo]:
    """Retourne les mod√®les install√©s d'une cat√©gorie."""
    all_models = list_available_models()
    return [m for m in all_models if m.category == category]


# Singleton pour la configuration globale
_global_config: Optional[RoleModelConfig] = None


def get_global_model_config() -> RoleModelConfig:
    """Retourne la configuration globale (singleton)."""
    global _global_config
    if _global_config is None:
        _global_config = RoleModelConfig()
    return _global_config


def set_global_model_config(config: RoleModelConfig) -> None:
    """D√©finit la configuration globale."""
    global _global_config
    _global_config = config


__all__ = [
    "ModelCategory",
    "ModelInfo",
    "RoleModelAssignment",
    "RoleModelConfig",
    "KNOWN_MODELS",
    "MAX_AUTO_SELECT_PARAMS_B",
    "list_available_models",
    "get_models_by_category",
    "get_global_model_config",
    "set_global_model_config",
]
```
<!-- MODULE-END: model_config.py -->

<!-- MODULE-START: ollama_manager.py -->
```json
{
  "name": "ollama_manager.py",
  "path": "agents\\ollama_manager.py",
  "ext": ".py",
  "anchor": "ollama_manager_py"
}
```
## ollama_manager_py
*Chemin* : `agents\ollama_manager.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.ollama_manager

Purpose: G√©rer Ollama (auto-d√©marrage, listage mod√®les, d√©chargement GPU, health checks).

Role in pipeline: orchestration / performance

Key components: LLMMemoryState, GPUMemoryManager, ensure_ollama_running, gpu_compute_context, list_ollama_models

Inputs: Mod√®le name, timeouts, max_attempts

Outputs: √âtat Ollama, mod√®les disponibles, gestion m√©moire GPU (unload/reload)

Dependencies: subprocess, httpx, utils.log, contextlib

Conventions: Ollama lanc√© via subprocess `ollama serve`; retries avec backoff exponentiel; gpu_compute_context d√©charge LLM avant calculs NumPy/CuPy; recharge auto apr√®s.

Read-if: Configuration Ollama, gestion GPU memory, ou troubleshooting service.

Skip-if: Vous utilisez seulement OpenAI.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import platform
import subprocess
import time
from contextlib import contextmanager
from dataclasses import dataclass, field
from typing import Generator, List, Optional, Tuple

import httpx

from utils.log import get_logger

logger = get_logger(__name__)


# ==============================================================================
# GPU Memory Manager - D√©chargement/Rechargement intelligent des LLM
# ==============================================================================


@dataclass
class LLMMemoryState:
    """√âtat m√©moire d'un mod√®le LLM."""

    model_name: str
    was_loaded: bool = False
    context_messages: List[dict] = field(default_factory=list)
    unload_time_ms: float = 0.0
    reload_time_ms: float = 0.0


class GPUMemoryManager:
    """
    Gestionnaire de m√©moire GPU pour les LLM.

    Permet de d√©charger temporairement les LLM du GPU pendant les phases
    de calcul intensif (backtests avec CuPy/NumPy) puis de les recharger
    avec leur contexte pr√©serv√©.

    Features:
    - D√©chargement automatique avant calculs
    - Rechargement automatique apr√®s calculs
    - Pr√©servation du contexte de conversation
    - M√©triques de temps (unload/reload)
    - Mode "dry run" pour tests

    Example:
        >>> manager = GPUMemoryManager("deepseek-r1:32b")
        >>>
        >>> # D√©charger avant calcul
        >>> state = manager.unload()
        >>>
        >>> # ... calculs GPU intensifs ...
        >>>
        >>> # Recharger avec contexte
        >>> manager.reload(state)
    """

    def __init__(
        self,
        model_name: str,
        ollama_host: str = "http://127.0.0.1:11434",
        warmup_prompt: str = "You are ready.",
        verbose: bool = True,
    ):
        """
        Initialise le gestionnaire.

        Args:
            model_name: Nom du mod√®le Ollama (ex: "deepseek-r1:32b")
            ollama_host: URL du serveur Ollama
            warmup_prompt: Prompt court pour "r√©chauffer" le mod√®le au reload
            verbose: Afficher les logs
        """
        self.model_name = model_name
        self.ollama_host = ollama_host
        self.warmup_prompt = warmup_prompt
        self.verbose = verbose
        self._current_state: Optional[LLMMemoryState] = None

    def is_model_loaded(self) -> bool:
        """V√©rifie si le mod√®le est actuellement en m√©moire GPU."""
        try:
            # Utiliser l'API ps pour voir les mod√®les charg√©s
            response = httpx.get(
                f"{self.ollama_host}/api/ps",
                timeout=3.0
            )
            if response.status_code == 200:
                data = response.json()
                models = data.get("models", [])
                for m in models:
                    if m.get("name", "").startswith(self.model_name.split(":")[0]):
                        return True
            return False
        except Exception:
            return False

    def unload(self, context_messages: Optional[List[dict]] = None) -> LLMMemoryState:
        """
        D√©charge le mod√®le du GPU.

        Args:
            context_messages: Messages de contexte √† pr√©server pour le reload

        Returns:
            LLMMemoryState avec les infos pour le rechargement
        """
        start = time.perf_counter()
        was_loaded = self.is_model_loaded()

        state = LLMMemoryState(
            model_name=self.model_name,
            was_loaded=was_loaded,
            context_messages=context_messages or [],
        )

        if was_loaded:
            try:
                response = httpx.post(
                    f"{self.ollama_host}/api/generate",
                    json={
                        "model": self.model_name,
                        "keep_alive": 0,  # 0 = d√©charger imm√©diatement
                        "prompt": "",
                    },
                    timeout=10.0
                )
                if response.status_code == 200:
                    state.unload_time_ms = (time.perf_counter() - start) * 1000
                    if self.verbose:
                        logger.info(
                            f"üíæ LLM d√©charg√©: {self.model_name} "
                            f"({state.unload_time_ms:.0f}ms) ‚Üí GPU libre pour calculs"
                        )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec d√©chargement LLM: {e}")
        else:
            if self.verbose:
                logger.debug(f"üìù LLM {self.model_name} pas en m√©moire, skip unload")

        self._current_state = state
        return state

    def reload(
        self,
        state: Optional[LLMMemoryState] = None,
        restore_context: bool = True,
    ) -> bool:
        """
        Recharge le mod√®le dans le GPU.

        Args:
            state: √âtat pr√©c√©dent (ou utilise _current_state)
            restore_context: Si True, envoie un prompt de warmup

        Returns:
            True si succ√®s
        """
        state = state or self._current_state
        if not state:
            logger.warning("‚ö†Ô∏è Pas d'√©tat √† restaurer")
            return False

        if not state.was_loaded:
            if self.verbose:
                logger.debug(f"üìù LLM {self.model_name} n'√©tait pas charg√©, skip reload")
            return True

        start = time.perf_counter()

        try:
            # Warmup: charger le mod√®le avec un prompt court
            warmup = self.warmup_prompt
            if restore_context and state.context_messages:
                # R√©sum√© du contexte pour le LLM
                warmup = (
                    f"Previous context summary: We were optimizing a trading strategy. "
                    f"Last {len(state.context_messages)} messages exchanged. "
                    f"Ready to continue."
                )

            response = httpx.post(
                f"{self.ollama_host}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": warmup,
                    "keep_alive": "10m",  # Garder 10 minutes
                    "stream": False,
                },
                timeout=120.0  # 2 min pour charger un gros mod√®le
            )

            if response.status_code == 200:
                state.reload_time_ms = (time.perf_counter() - start) * 1000
                if self.verbose:
                    logger.info(
                        f"üîÑ LLM recharg√©: {self.model_name} "
                        f"({state.reload_time_ms:.0f}ms)"
                    )
                return True
            else:
                logger.warning(f"‚ö†Ô∏è √âchec reload LLM: status {response.status_code}")
                return False

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec rechargement LLM: {e}")
            return False

    def get_stats(self) -> dict:
        """Retourne les statistiques de la derni√®re op√©ration."""
        if not self._current_state:
            return {}
        return {
            "model": self._current_state.model_name,
            "was_loaded": self._current_state.was_loaded,
            "unload_time_ms": self._current_state.unload_time_ms,
            "reload_time_ms": self._current_state.reload_time_ms,
            "context_size": len(self._current_state.context_messages),
        }


@contextmanager
def gpu_compute_context(
    model_name: str,
    context_messages: Optional[List[dict]] = None,
    verbose: bool = True,
) -> Generator[GPUMemoryManager, None, None]:
    """
    Context manager pour lib√©rer le GPU pendant les calculs.

    D√©charge automatiquement le LLM avant les calculs et le recharge apr√®s.

    Args:
        model_name: Nom du mod√®le √† d√©charger
        context_messages: Contexte de conversation √† pr√©server
        verbose: Afficher les logs

    Yields:
        GPUMemoryManager pour acc√®s aux stats

    Example:
        >>> with gpu_compute_context("deepseek-r1:32b") as manager:
        ...     # GPU libre pour calculs numpy/cupy
        ...     results = heavy_backtest_computation()
        >>> # LLM automatiquement recharg√©
        >>> print(manager.get_stats())
    """
    manager = GPUMemoryManager(model_name, verbose=verbose)

    # D√©charger
    state = manager.unload(context_messages)

    try:
        yield manager
    finally:
        # Recharger
        manager.reload(state)


def ensure_ollama_running() -> Tuple[bool, str]:
    """
    S'assure qu'Ollama est d√©marr√© et fonctionnel.

    Returns:
        tuple[bool, str]: (succ√®s, message)
    """
    # 1. V√©rifier si Ollama r√©pond
    try:
        response = httpx.get("http://127.0.0.1:11434/api/tags", timeout=2.0)
        if response.status_code == 200:
            logger.info("‚úÖ Ollama d√©j√† actif")
            return True, "‚úÖ Ollama actif"
    except Exception:
        pass  # Ollama pas actif, on va le d√©marrer

    # 2. D√©marrer Ollama
    logger.info("üöÄ D√©marrage d'Ollama...")
    try:
        is_windows = platform.system() == "Windows"

        if is_windows:
            # Windows : Lancer avec flags de cr√©ation console
            kwargs = {"creationflags": subprocess.CREATE_NEW_CONSOLE}

            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                **kwargs
            )
        else:
            # Linux/Mac
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )

        # 3. Attendre qu'Ollama soit pr√™t (max 10s)
        for i in range(10):
            time.sleep(1)
            try:
                response = httpx.get("http://127.0.0.1:11434/api/tags", timeout=1.0)
                if response.status_code == 200:
                    logger.info(f"‚úÖ Ollama d√©marr√© avec succ√®s (apr√®s {i+1}s)")
                    return True, f"‚úÖ Ollama d√©marr√© ({i+1}s)"
            except Exception:
                continue

        return False, "‚è±Ô∏è Timeout - Ollama n'a pas d√©marr√© en 10s"

    except FileNotFoundError:
        return False, "‚ùå Ollama non trouv√© (v√©rifiez l'installation)"
    except Exception as e:
        return False, f"‚ùå Erreur: {str(e)}"


def unload_model(model_name: str) -> bool:
    """
    D√©charge un mod√®le Ollama de la m√©moire GPU/RAM.

    Args:
        model_name: Nom du mod√®le (ex: "deepseek-r1:32b")

    Returns:
        bool: True si succ√®s
    """
    try:
        response = httpx.post(
            "http://127.0.0.1:11434/api/generate",
            json={
                "model": model_name,
                "keep_alive": 0,  # 0 = d√©charger imm√©diatement
                "prompt": "",
            },
            timeout=5.0
        )
        success = response.status_code == 200
        if success:
            logger.info(f"üíæ Mod√®le {model_name} d√©charg√© de la m√©moire")
        return success
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Impossible de d√©charger {model_name}: {e}")
        return False


def cleanup_all_models() -> int:
    """
    D√©charge TOUS les mod√®les Ollama de la m√©moire.

    Returns:
        int: Nombre de mod√®les d√©charg√©s
    """
    try:
        # Lister les mod√®les charg√©s
        response = httpx.get("http://127.0.0.1:11434/api/tags", timeout=5.0)
        if response.status_code != 200:
            return 0

        models = response.json().get("models", [])
        count = 0

        for model in models:
            model_name = model.get("name", "")
            if model_name and unload_model(model_name):
                count += 1

        if count > 0:
            logger.info(f"üßπ {count} mod√®le(s) d√©charg√©(s) de la m√©moire")

        return count

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur cleanup_all_models: {e}")
        return 0


def list_ollama_models() -> List[str]:
    """
    Retourne la liste des mod√®les Ollama install√©s localement.

    Returns:
        list[str]: Noms des mod√®les (ex: ["llama3.2", "mistral"])
    """
    try:
        response = httpx.get("http://127.0.0.1:11434/api/tags", timeout=3.0)
        if response.status_code != 200:
            logger.warning(
                f"‚ö†Ô∏è Impossible de lister les mod√®les Ollama (status={response.status_code})"
            )
            return []

        payload = response.json()
        models = payload.get("models", []) or []

        names: List[str] = []
        for model in models:
            name = model.get("name")
            if isinstance(name, str) and name:
                names.append(name)

        return names
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des mod√®les Ollama: {e}")
        return []


def is_ollama_available() -> bool:
    """
    V√©rifie si Ollama est disponible.

    Returns:
        bool: True si Ollama r√©pond
    """
    try:
        response = httpx.get("http://127.0.0.1:11434/api/tags", timeout=2.0)
        return response.status_code == 200
    except Exception:
        return False


def prepare_for_llm_run() -> Tuple[bool, str]:
    """
    Pr√©pare l'environnement pour un run LLM.

    Actions:
    1. S'assure qu'Ollama est actif
    2. Nettoie les mod√®les pr√©c√©dents en m√©moire

    Returns:
        tuple[bool, str]: (succ√®s, message d√©taill√©)
    """
    messages = []

    # 1. Nettoyer les mod√®les pr√©c√©dents
    cleaned = cleanup_all_models()
    if cleaned > 0:
        messages.append(f"üßπ {cleaned} mod√®le(s) d√©charg√©(s)")

    # 2. S'assurer qu'Ollama est actif
    success, msg = ensure_ollama_running()
    messages.append(msg)

    if success:
        time.sleep(1)  # Petite pause pour stabilit√©
        return True, " | ".join(messages)
    else:
        return False, " | ".join(messages)


__all__ = [
    "ensure_ollama_running",
    "unload_model",
    "cleanup_all_models",
    "list_ollama_models",
    "is_ollama_available",
    "prepare_for_llm_run",
    # GPU Memory Management
    "GPUMemoryManager",
    "LLMMemoryState",
    "gpu_compute_context",
]
```
<!-- MODULE-END: ollama_manager.py -->

<!-- MODULE-START: orchestration_logger.py -->
```json
{
  "name": "orchestration_logger.py",
  "path": "agents\\orchestration_logger.py",
  "ext": ".py",
  "anchor": "orchestration_logger_py"
}
```
## orchestration_logger_py
*Chemin* : `agents\orchestration_logger.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.orchestration_logger

Purpose: Tracer toutes les actions des agents LLM en JSONL avec auto-save thread-safe et callback UI.

Role in pipeline: orchestration / monitoring

Key components: OrchestrationLogger, OrchestrationLogEntry, OrchestrationActionType, get_orchestration_logger

Inputs: action_type, donn√©es contexte, session_id

Outputs: Logs JSONL dans runs/<session>/trace.jsonl, callbacks UI optionnels

Dependencies: pathlib, json, threading, utils.log

Conventions: JSONL auto-flush toutes les N entr√©es; thread-safe via Lock; singleton global; timestamps UTC; callback optionnel pour UI temps r√©el.

Read-if: Ajout types actions, modification format JSONL, ou int√©gration UI.

Skip-if: Vous ne debuggez pas l'orchestration.
"""

# pylint: disable=logging-fstring-interpolation

import json
import threading
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

from utils.log import get_logger

logger = get_logger(__name__)


class OrchestrationActionType(Enum):
    """

Types d'actions d'orchestration."""

    # Cycle de vie orchestration
    RUN_START = "run_start"
    RUN_END = "run_end"
    PHASE_START = "phase_start"

    # Machine √† √©tats
    STATE_ENTER = "state_enter"
    STATE_CHANGE = "state_change"
    STATE_EXIT = "state_exit"

    # Agents LLM
    AGENT_EXECUTE_START = "agent_execute_start"
    AGENT_EXECUTE_END = "agent_execute_end"
    ANALYST_RESULT = "analyst_result"
    PROPOSALS_GENERATED = "proposals_generated"
    CRITIC_RESULT = "critic_result"
    VALIDATOR_DECISION = "validator_decision"

    # Propositions et tests
    PROPOSAL_TEST_STARTED = "proposal_test_started"
    PROPOSAL_TEST_ENDED = "proposal_test_ended"

    # It√©rations
    ITERATION_RECORDED = "iteration_recorded"

    # Analyse
    ANALYSIS_START = "analysis_start"
    ANALYSIS_COMPLETE = "analysis_complete"
    RESULT_EVALUATION = "result_evaluation"

    # Strat√©gie
    STRATEGY_SELECTION = "strategy_selection"
    STRATEGY_MODIFICATION = "strategy_modification"
    STRATEGY_VALIDATION = "strategy_validation"

    # Indicateurs
    INDICATOR_VALUES_CHANGE = "indicator_values_change"
    INDICATOR_ADD = "indicator_add"
    INDICATOR_REMOVE = "indicator_remove"
    INDICATOR_VALIDATION = "indicator_validation"
    INDICATOR_CONTEXT = "indicator_context"

    # Tests
    BACKTEST_START = "backtest_start"
    BACKTEST_END = "backtest_end"
    BACKTEST_LAUNCH = "backtest_launch"
    BACKTEST_COMPLETE = "backtest_complete"
    BACKTEST_FAILED = "backtest_failed"

    # Walk-forward
    WALK_FORWARD_COMPUTED = "walk_forward_computed"

    # D√©cisions
    DECISION_CONTINUE = "decision_continue"
    DECISION_STOP = "decision_stop"
    DECISION_CHANGE_APPROACH = "decision_change_approach"

    # Agents (legacy)
    AGENT_ANALYST_ACTION = "agent_analyst"
    AGENT_STRATEGIST_ACTION = "agent_strategist"
    AGENT_CRITIC_ACTION = "agent_critic"
    AGENT_VALIDATOR_ACTION = "agent_validator"

    # Configuration et validation
    CONFIG_VALID = "config_valid"
    CONFIG_INVALID = "config_invalid"
    INITIAL_BACKTEST_DONE = "initial_backtest_done"

    # Warnings et erreurs
    WARNING = "warning"
    ERROR = "error"


class OrchestrationStatus(Enum):
    """Statuts d'une action d'orchestration."""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    VALIDATED = "validated"
    REJECTED = "rejected"


@dataclass
class OrchestrationLogEntry:
    """Entr√©e de log d'orchestration."""

    timestamp: str
    action_type: OrchestrationActionType
    agent: Optional[str] = None  # Analyst, Strategist, Critic, Validator
    status: OrchestrationStatus = OrchestrationStatus.PENDING
    details: Dict[str, Any] = field(default_factory=dict)
    iteration: int = 0
    session_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour s√©rialisation."""
        return {
            "timestamp": self.timestamp,
            "action_type": self.action_type.value,
            "agent": self.agent,
            "status": self.status.value,
            "details": self.details,
            "iteration": self.iteration,
            "session_id": self.session_id,
        }

    def format_for_ui(self) -> str:
        """Formate pour affichage UI."""
        emoji = self._get_emoji()
        agent_str = f"[{self.agent}]" if self.agent else ""
        status_str = self._get_status_str()

        return f"{emoji} {agent_str} {self.action_type.value}: {status_str}"

    def _get_emoji(self) -> str:
        """Retourne l'emoji appropri√©."""
        if self.status == OrchestrationStatus.COMPLETED:
            return "‚úÖ"
        elif self.status == OrchestrationStatus.FAILED:
            return "‚ùå"
        elif self.status == OrchestrationStatus.VALIDATED:
            return "‚úîÔ∏è"
        elif self.status == OrchestrationStatus.REJECTED:
            return "‚ùå"
        elif self.status == OrchestrationStatus.IN_PROGRESS:
            return "‚è≥"
        else:
            return "‚èπÔ∏è"

    def _get_status_str(self) -> str:
        """Retourne une cha√Æne de statut format√©e."""
        if self.details:
            # Formater les d√©tails importants
            if "strategy" in self.details:
                return f"Strategy={self.details['strategy']}"
            elif "indicator" in self.details:
                return f"Indicator={self.details['indicator']}"
            elif "params" in self.details:
                param_str = str(self.details['params'])[:50]
                return f"Params={param_str}..."
            elif "result" in self.details:
                result = self.details['result']
                if isinstance(result, dict) and 'sharpe' in result:
                    return f"Sharpe={result['sharpe']:.2f}"
        return self.status.value


class OrchestrationLogger:
    """Logger centralis√© pour l'orchestration LLM avec persistance JSONL."""

    def __init__(
        self,
        session_id: Optional[str] = None,
        auto_save: bool = True,
        save_path: Optional[Path] = None,
        on_event: Optional[Callable] = None,
    ):
        """
        Initialize le logger d'orchestration.

        Args:
            session_id: ID unique de session (g√©n√©r√© auto si None)
            auto_save: Si True, sauvegarde auto toutes les 10 entr√©es
            save_path: Chemin personnalis√© pour les logs (d√©faut: runs/{session_id}/trace.jsonl)
            on_event: Callback appel√© √† chaque nouvel √©v√©nement (pour UI temps r√©el)
        """
        self.session_id = session_id or self._generate_session_id()
        self.logs: List[OrchestrationLogEntry] = []
        self.current_iteration = 0
        self._lock = threading.Lock()
        self._auto_save = auto_save
        self._save_path = save_path or Path("runs") / self.session_id / "trace.jsonl"
        self._save_counter = 0
        self._save_interval = 10  # Sauvegarder tous les 10 √©v√©nements
        self._on_event_callback = on_event  # Callback pour mise √† jour live

        # Cr√©er le r√©pertoire si n√©cessaire
        if self._auto_save:
            self._save_path.parent.mkdir(parents=True, exist_ok=True)

    def set_on_event_callback(self, callback: Callable) -> None:
        """D√©finit le callback appel√© √† chaque nouvel √©v√©nement."""
        self._on_event_callback = callback

    def _notify_event(self, entry: OrchestrationLogEntry) -> None:
        """Notifie le callback si d√©fini."""
        if self._on_event_callback:
            try:
                self._on_event_callback(entry)
            except Exception as e:
                logger.debug(f"Event callback error (ignored): {e}")

    def _generate_session_id(self) -> str:
        """G√©n√®re un ID de session unique."""
        return datetime.now().strftime("%Y%m%d_%H%M%S")

    def _now(self) -> str:
        """Timestamp actuel."""
        return datetime.now().isoformat()

    def _add_entry(self, entry: OrchestrationLogEntry) -> None:
        """Ajoute une entr√©e et notifie le callback."""
        with self._lock:
            self.logs.append(entry)
            # Garder current_iteration coh√©rent (utile si l'appelant passe iteration)
            try:
                self.current_iteration = max(self.current_iteration, int(entry.iteration))
            except Exception:
                pass
        self._notify_event(entry)
        self._maybe_auto_save()

    def log_analysis_start(self, agent: str, details: Optional[Dict] = None):
        """Log le d√©but d'une analyse."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.ANALYSIS_START,
            agent=agent,
            status=OrchestrationStatus.IN_PROGRESS,
            details=details or {},
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Analysis started - Iteration {self.current_iteration}")

    def log_analysis_complete(
        self,
        agent: str,
        results: Dict[str, Any],
        status: OrchestrationStatus = OrchestrationStatus.COMPLETED
    ):
        """Log la fin d'une analyse."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.ANALYSIS_COMPLETE,
            agent=agent,
            status=status,
            details={"results": results},
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Analysis complete - Status: {status.value}")

    def log_strategy_selection(
        self,
        agent: str,
        strategy_name: str,
        reason: str
    ):
        """Log la s√©lection d'une strat√©gie."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.STRATEGY_SELECTION,
            agent=agent,
            status=OrchestrationStatus.COMPLETED,
            details={"strategy": strategy_name, "reason": reason},
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Strategy selected: {strategy_name} - {reason}")

    def log_strategy_modification(
        self,
        agent: str,
        old_strategy: str,
        new_strategy: str,
        reason: str,
        status: OrchestrationStatus = OrchestrationStatus.PENDING
    ):
        """Log une modification de strat√©gie."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.STRATEGY_MODIFICATION,
            agent=agent,
            status=status,
            details={
                "old_strategy": old_strategy,
                "new_strategy": new_strategy,
                "reason": reason
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Strategy changed: {old_strategy} ‚Üí {new_strategy}")

    def log_indicator_values_change(
        self,
        agent: str,
        indicator: str,
        old_values: Dict[str, Any],
        new_values: Dict[str, Any],
        reason: str
    ):
        """Log un changement de valeurs d'indicateurs."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.INDICATOR_VALUES_CHANGE,
            agent=agent,
            status=OrchestrationStatus.COMPLETED,
            details={
                "indicator": indicator,
                "old_values": old_values,
                "new_values": new_values,
                "reason": reason
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Indicator {indicator} values changed")

    def log_indicator_add(
        self,
        agent: str,
        indicator: str,
        params: Dict[str, Any],
        reason: str,
        status: OrchestrationStatus = OrchestrationStatus.PENDING
    ):
        """Log l'ajout d'un nouvel indicateur."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.INDICATOR_ADD,
            agent=agent,
            status=status,
            details={
                "indicator": indicator,
                "params": params,
                "reason": reason
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] New indicator proposed: {indicator}")

    def log_indicator_validation(
        self,
        agent: str,
        indicator: str,
        is_valid: bool,
        message: str
    ):
        """Log la validation d'un indicateur."""
        status = OrchestrationStatus.VALIDATED if is_valid else OrchestrationStatus.REJECTED
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.INDICATOR_VALIDATION,
            agent=agent,
            status=status,
            details={
                "indicator": indicator,
                "is_valid": is_valid,
                "message": message
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Indicator {indicator} validation: {is_valid}")

    def log_backtest_launch(
        self,
        agent: str,
        params: Dict[str, Any],
        combination_id: int,
        total_combinations: int
    ):
        """Log le lancement d'un backtest."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.BACKTEST_LAUNCH,
            agent=agent,
            status=OrchestrationStatus.IN_PROGRESS,
            details={
                "params": params,
                "combination_id": combination_id,
                "total_combinations": total_combinations
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Backtest launched: {combination_id}/{total_combinations}")

    def log_backtest_complete(
        self,
        agent: str,
        params: Dict[str, Any],
        results: Dict[str, Any],
        combination_id: int
    ):
        """Log la fin d'un backtest."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.BACKTEST_COMPLETE,
            agent=agent,
            status=OrchestrationStatus.COMPLETED,
            details={
                "params": params,
                "results": results,
                "combination_id": combination_id
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)

        # Extraire m√©triques cl√©s
        pnl = results.get('pnl', 0)
        sharpe = results.get('sharpe', 0)
        logger.info(f"[{agent}] Backtest #{combination_id} complete - PnL: {pnl:.2f}, Sharpe: {sharpe:.2f}")

    def log_backtest_failed(
        self,
        agent: str,
        params: Dict[str, Any],
        error: str,
        combination_id: int
    ):
        """Log l'√©chec d'un backtest."""
        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=OrchestrationActionType.BACKTEST_FAILED,
            agent=agent,
            status=OrchestrationStatus.FAILED,
            details={
                "params": params,
                "error": error,
                "combination_id": combination_id
            },
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.error(f"[{agent}] Backtest #{combination_id} failed: {error}")

    def log_decision(
        self,
        agent: str,
        decision_type: str,  # "continue", "stop", "change_approach"
        reason: str,
        details: Optional[Dict] = None
    ):
        """Log une d√©cision d'agent."""
        action_map = {
            "continue": OrchestrationActionType.DECISION_CONTINUE,
            "stop": OrchestrationActionType.DECISION_STOP,
            "change_approach": OrchestrationActionType.DECISION_CHANGE_APPROACH,
        }

        entry = OrchestrationLogEntry(
            timestamp=self._now(),
            action_type=action_map.get(decision_type, OrchestrationActionType.DECISION_CONTINUE),
            agent=agent,
            status=OrchestrationStatus.COMPLETED,
            details={"reason": reason, **(details or {})},
            iteration=self.current_iteration,
            session_id=self.session_id
        )
        self._add_entry(entry)
        logger.info(f"[{agent}] Decision: {decision_type} - {reason}")

    def next_iteration(self):
        """Passe √† l'it√©ration suivante."""
        self.current_iteration += 1
        logger.info(f"=== Iteration {self.current_iteration} START ===")

    def log(self, event_type: str, data: Dict[str, Any]) -> None:
        """
        API g√©n√©rique pour logger un √©v√©nement (compatible avec orchestrator).

        Args:
            event_type: Type d'√©v√©nement (str)
            data: Donn√©es de l'√©v√©nement incluant tous les champs
        """
        # Essayer de mapper le type √† un enum
        try:
            action_type = OrchestrationActionType(event_type)
        except ValueError:
            # Si non reconnu, utiliser WARNING avec le type en d√©tail
            action_type = OrchestrationActionType.WARNING
            data = {"original_event_type": event_type, **data}

        entry = OrchestrationLogEntry(
            timestamp=data.get("timestamp", self._now()),
            action_type=action_type,
            agent=data.get("role") or data.get("agent"),
            status=OrchestrationStatus.COMPLETED,  # Par d√©faut
            details=data,
            iteration=data.get("iteration", self.current_iteration),
            session_id=data.get("session_id", self.session_id),
        )
        self._add_entry(entry)

    def add_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """Alias pour log() (API alternative)."""
        self.log(event_type, data)

    def append(self, data: Dict[str, Any]) -> None:
        """Alias pour log() qui extrait event_type du dict."""
        event_type = data.get("event_type", "warning")
        self.log(event_type, data)

    def _maybe_auto_save(self) -> None:
        """Sauvegarde automatiquement si le seuil est atteint."""
        if not self._auto_save:
            return
        with self._lock:
            self._save_counter += 1
            should_save = self._save_counter >= self._save_interval
        if should_save:
            try:
                self.save_to_jsonl(self._save_path)
                with self._lock:
                    self._save_counter = 0
            except Exception as e:
                logger.debug(f"Auto-save failed: {e}")

    def get_logs_for_iteration(self, iteration: int) -> List[OrchestrationLogEntry]:
        """R√©cup√®re les logs d'une it√©ration sp√©cifique."""
        return [log for log in self.logs if log.iteration == iteration]

    def get_logs_by_agent(self, agent: str) -> List[OrchestrationLogEntry]:
        """R√©cup√®re tous les logs d'un agent sp√©cifique."""
        return [log for log in self.logs if log.agent == agent]

    def get_logs_by_type(self, action_type: OrchestrationActionType) -> List[OrchestrationLogEntry]:
        """R√©cup√®re tous les logs d'un type d'action."""
        return [log for log in self.logs if log.action_type == action_type]

    def save_to_file(self, filepath: Optional[Path] = None):
        """
        Sauvegarde les logs dans un fichier JSON (legacy, pr√©f√©rer save_to_jsonl).

        Args:
            filepath: Chemin du fichier JSON (d√©faut: orchestration_logs_{session}.json)
        """
        if filepath is None:
            filepath = Path(f"orchestration_logs_{self.session_id}.json")

        data = {
            "session_id": self.session_id,
            "total_iterations": self.current_iteration,
            "total_logs": len(self.logs),
            "logs": [log.to_dict() for log in self.logs]
        }

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info(f"Logs saved to {filepath}")

    def save_to_jsonl(self, filepath: Optional[Path] = None):
        """
        Sauvegarde les logs en format JSONL (une ligne par √©v√©nement).

        Args:
            filepath: Chemin du fichier JSONL (d√©faut: runs/{session}/trace.jsonl)
        """
        if filepath is None:
            filepath = self._save_path

        # Cr√©er le r√©pertoire si n√©cessaire
        filepath.parent.mkdir(parents=True, exist_ok=True)

        with self._lock:
            logs_snapshot = list(self.logs)
            current_iteration = int(self.current_iteration)
            total_logs = len(logs_snapshot)

        with open(filepath, "w", encoding="utf-8") as f:
            header = {
                "event_type": "session_header",
                "session_id": self.session_id,
                "total_iterations": current_iteration,
                "total_logs": total_logs,
                "timestamp": self._now(),
            }
            f.write(json.dumps(header, ensure_ascii=False) + "\n")

            for log in logs_snapshot:
                f.write(json.dumps(log.to_dict(), ensure_ascii=False) + "\n")

        logger.debug(f"Logs saved to {filepath} ({total_logs} entries)")

    @classmethod
    def load_from_file(cls, filepath: Path) -> "OrchestrationLogger":
        """
        Charge les logs depuis un fichier JSON ou JSONL.

        Args:
            filepath: Chemin vers le fichier JSON/JSONL

        Returns:
            Instance OrchestrationLogger avec les logs charg√©s
        """
        if not filepath.exists():
            raise FileNotFoundError(f"File not found: {filepath}")

        # D√©tecter le format
        with open(filepath, "r", encoding="utf-8") as f:
            first_line = f.readline().strip()

        if filepath.suffix == ".jsonl" or first_line.startswith('{"event_type"'):
            return cls._load_from_jsonl(filepath)
        else:
            return cls._load_from_json(filepath)

    @classmethod
    def _load_from_jsonl(cls, filepath: Path) -> "OrchestrationLogger":
        """Charge depuis un fichier JSONL."""
        with open(filepath, "r", encoding="utf-8") as f:
            lines = f.readlines()

        if not lines:
            raise ValueError("Empty JSONL file")

        # Premi√®re ligne = header
        header = json.loads(lines[0])
        session_id = header.get("session_id", "unknown")

        instance = cls(session_id=session_id, auto_save=False)
        instance.current_iteration = header.get("total_iterations", 0)

        # Charger les √©v√©nements
        for line in lines[1:]:
            if not line.strip():
                continue
            data = json.loads(line)
            entry = OrchestrationLogEntry(
                timestamp=data["timestamp"],
                action_type=OrchestrationActionType(data["action_type"]),
                agent=data.get("agent"),
                status=OrchestrationStatus(data["status"]),
                details=data.get("details", {}),
                iteration=data.get("iteration", 0),
                session_id=data.get("session_id"),
            )
            instance.logs.append(entry)

        logger.info(f"Loaded {len(instance.logs)} logs from {filepath}")
        return instance

    @classmethod
    def _load_from_json(cls, filepath: Path) -> "OrchestrationLogger":
        """Charge depuis un fichier JSON (legacy)."""
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)

        session_id = data.get("session_id", "unknown")
        instance = cls(session_id=session_id, auto_save=False)
        instance.current_iteration = data.get("total_iterations", 0)

        for log_data in data.get("logs", []):
            entry = OrchestrationLogEntry(
                timestamp=log_data["timestamp"],
                action_type=OrchestrationActionType(log_data["action_type"]),
                agent=log_data.get("agent"),
                status=OrchestrationStatus(log_data["status"]),
                details=log_data.get("details", {}),
                iteration=log_data.get("iteration", 0),
                session_id=log_data.get("session_id"),
            )
            instance.logs.append(entry)

        logger.info(f"Loaded {len(instance.logs)} logs from {filepath}")
        return instance

    def generate_summary(self) -> str:
        """G√©n√®re un r√©sum√© textuel des logs."""
        lines = ["=" * 80]
        lines.append(f"ORCHESTRATION LOG SUMMARY - Session: {self.session_id}")
        lines.append("=" * 80)
        lines.append(f"Total Iterations: {self.current_iteration}")
        lines.append(f"Total Log Entries: {len(self.logs)}")
        lines.append("")

        # Compter par type d'action
        action_counts = {}
        for log in self.logs:
            action_type = log.action_type.value
            action_counts[action_type] = action_counts.get(action_type, 0) + 1

        lines.append("Actions Count:")
        for action, count in sorted(action_counts.items()):
            lines.append(f"  - {action}: {count}")
        lines.append("")

        # Compter par agent
        agent_counts = {}
        for log in self.logs:
            if log.agent:
                agent_counts[log.agent] = agent_counts.get(log.agent, 0) + 1

        lines.append("Agent Activity:")
        for agent, count in sorted(agent_counts.items()):
            lines.append(f"  - {agent}: {count} actions")

        lines.append("")
        lines.append("=" * 80)

        return "\n".join(lines)


# Instance globale (optionnelle)
_global_logger: Optional[OrchestrationLogger] = None


def generate_session_id() -> str:
    """G√©n√®re un ID de session unique."""
    from datetime import datetime
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def get_orchestration_logger(session_id: Optional[str] = None) -> OrchestrationLogger:
    """R√©cup√®re ou cr√©e le logger d'orchestration global."""
    global _global_logger
    if _global_logger is None:
        _global_logger = OrchestrationLogger(session_id=session_id)
    return _global_logger


def reset_orchestration_logger():
    """R√©initialise le logger d'orchestration global."""
    global _global_logger
    _global_logger = None


__all__ = [
    "OrchestrationActionType",
    "OrchestrationStatus",
    "OrchestrationLogEntry",
    "OrchestrationLogger",
    "generate_session_id",
    "get_orchestration_logger",
    "reset_orchestration_logger",
]
```
<!-- MODULE-END: orchestration_logger.py -->

<!-- MODULE-START: orchestrator.py -->
```json
{
  "name": "orchestrator.py",
  "path": "agents\\orchestrator.py",
  "ext": ".py",
  "anchor": "orchestrator_py"
}
```
## orchestrator_py
*Chemin* : `agents\orchestrator.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.orchestrator

Purpose: Orchestrer le workflow multi-agents (Analyst/Strategist/Critic/Validator) et piloter la boucle d‚Äôoptimisation.

Role in pipeline: orchestration

Key components: OrchestratorConfig, Orchestrator, StateMachine, ValidationResult, run_walk_forward_for_agent

Inputs: LLMConfig/clients, callbacks (on_backtest_needed), donn√©es (path/df), param√®tres initiaux et contraintes

Outputs: D√©cision finale (APPROVED/REJECTED/FAILED), historiques d‚Äôit√©rations, logs/m√©moire LLM, suivi param√®tres

Dependencies: agents.state_machine, agents.*Agent, agents.integration, agents.model_config, utils.llm_memory, utils.session_param_tracker

Conventions: √âtats INIT‚ÜíANALYZE‚ÜíPROPOSE‚ÜíCRITIQUE‚ÜíVALIDATE‚ÜíITERATE; ABORT mappe sur FAILED; timestamps en UTC si utilis√©s.

Read-if: Vous touchez aux transitions, crit√®res d‚Äôarr√™t, m√©moire/logs, ou au wiring des agents.

Skip-if: Vous ne modifiez qu‚Äôun agent isol√© ou le moteur de backtest pur.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import TYPE_CHECKING, Any, Callable, Dict, Iterable, List, Optional

from utils.llm_memory import (
    MAX_INSIGHTS,
    append_history_entry,
    append_session_iteration,
    build_memory_summary,
    delete_session,
    extract_date_range,
    get_history_path,
    split_date_range,
    start_session,
)
from utils.session_param_tracker import SessionParameterTracker

from .analyst import AnalystAgent
from .base_agent import AgentContext, AgentResult, BaseAgent, MetricsSnapshot, ParameterConfig
from .critic import CriticAgent
from .integration import run_walk_forward_for_agent
from .llm_client import LLMConfig, create_llm_client
from .model_config import RoleModelConfig
from .state_machine import AgentState, StateMachine, ValidationResult
from .strategist import StrategistAgent
from .validator import ValidationDecision, ValidatorAgent

# Import optionnel de tqdm pour barres de progression
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    # Fallback: tqdm est une fonction identit√©

    def tqdm(iterable: Iterable[Any], **kwargs: Any) -> Iterable[Any]:
        return iterable

if TYPE_CHECKING:  # pragma: no cover
    import pandas as pd

    from agents.integration import AgentBacktestMetrics


logger = logging.getLogger(__name__)


@dataclass
class OrchestratorConfig:
    """Configuration de l'Orchestrator."""

    # Strat√©gie
    strategy_name: str = ""
    strategy_description: str = ""

    # Donn√©es
    data_path: str = ""
    data: Optional["pd.DataFrame"] = None
    data_symbol: str = ""
    data_timeframe: str = ""
    data_date_range: str = ""
    comparison_context: Optional[Dict[str, Any]] = None

    # Param√®tres initiaux
    initial_params: Dict[str, Any] = field(default_factory=dict)
    param_specs: List[ParameterConfig] = field(default_factory=list)

    # Objectifs d'optimisation
    optimization_target: str = "sharpe_ratio"
    min_sharpe: float = 1.0
    max_drawdown_limit: float = 0.20
    min_trades: int = 30
    max_overfitting_ratio: float = 1.5

    # Limites
    max_iterations: int = 10
    max_proposals_per_iteration: int = 5

    # Ex√©cution
    n_workers: int = 1
    session_id: Optional[str] = None
    orchestration_logger: Optional[Any] = None

    # LLM
    llm_config: Optional[LLMConfig] = None
    role_model_config: Optional[RoleModelConfig] = None
    max_consecutive_llm_failures: int = 3

    # Walk-forward
    use_walk_forward: bool = True
    walk_forward_windows: int = 5
    train_ratio: float = 0.7
    walk_forward_disabled_reason: Optional[str] = None  # Raison si d√©sactiv√© automatiquement

    # Callbacks (optionnels)
    on_state_change: Optional[Callable[[AgentState, AgentState], None]] = None
    on_iteration_complete: Optional[Callable[[int, Dict[str, Any]], None]] = None
    on_backtest_needed: Optional[Callable[[Dict[str, Any]], "AgentBacktestMetrics"]] = None


@dataclass
class OrchestratorResult:
    """R√©sultat final de l'orchestration."""

    success: bool
    final_state: AgentState
    decision: str  # APPROVE, REJECT, ABORT

    # Configuration finale
    final_params: Dict[str, Any] = field(default_factory=dict)
    final_metrics: Optional[MetricsSnapshot] = None

    # M√©triques d'ex√©cution
    total_iterations: int = 0
    total_backtests: int = 0
    total_time_s: float = 0.0
    total_llm_tokens: int = 0
    total_llm_calls: int = 0

    # Historique
    iteration_history: List[Dict[str, Any]] = field(default_factory=list)
    state_history: List[Dict[str, Any]] = field(default_factory=list)

    # Rapport
    final_report: str = ""
    recommendations: List[str] = field(default_factory=list)

    # Erreurs
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


class Orchestrator:
    """
    Orchestrator - Coordonne le workflow d'optimisation LLM.

    Garanties:
    - Transitions valid√©es via State Machine
    - Pas de boucles infinies (max_iterations)
    - Tra√ßabilit√© compl√®te
    - Gestion des erreurs gracieuse

    Example:
        >>> config = OrchestratorConfig(
        ...     strategy_name="ema_cross",
        ...     data_path="data/BTCUSDT_1h.parquet",
        ...     initial_params={"fast_period": 12, "slow_period": 26},
        ...     param_specs=[...],
        ... )
        >>> orchestrator = Orchestrator(config)
        >>> result = orchestrator.run()
        >>> if result.success:
        ...     print(f"Optimized params: {result.final_params}")
    """

    def __init__(self, config: OrchestratorConfig) -> None:
        """
        Initialise l'Orchestrator.

        Args:
            config: Configuration compl√®te
        """
        self.config = config
        if config.session_id:
            self.session_id = str(config.session_id)
        elif config.orchestration_logger is not None and hasattr(config.orchestration_logger, "session_id"):
            self.session_id = str(getattr(config.orchestration_logger, "session_id"))
        else:
            self.session_id = str(uuid.uuid4())[:8]

        # State Machine
        self.state_machine = StateMachine(max_iterations=config.max_iterations)
        self._unlimited_iterations = config.max_iterations <= 0
        self._max_iter_label = "‚àû" if self._unlimited_iterations else str(config.max_iterations)

        # LLM Client
        llm_config = config.llm_config or LLMConfig.from_env()
        self.llm_client = create_llm_client(llm_config)

        # Agents
        self.analyst = AnalystAgent(self.llm_client)
        self.strategist = StrategistAgent(self.llm_client)
        self.critic = CriticAgent(self.llm_client)
        self.validator = ValidatorAgent(self.llm_client)

        # Context partag√©
        self.context = self._create_initial_context()

        # Tracking
        self._start_time: Optional[float] = None
        self._backtests_count = 0
        self._total_combinations_tested = 0  # Compteur de budget (sweep + individual)
        self._sweeps_performed = 0
        self._max_sweeps_per_session = 3  # Limite de sweeps pour √©viter l'abus
        self._errors: List[str] = []
        self._warnings: List[str] = []
        self._indicator_context_cached = False
        self._consecutive_llm_failures = 0

        # Tracker de ranges pour √©viter boucles infinies
        from utils.session_ranges_tracker import SessionRangesTracker
        self._ranges_tracker = SessionRangesTracker(session_id=self.session_id)
        self._memory_session_path: Optional[Path] = None
        self._last_validation_data: Optional[Dict[str, Any]] = None
        self._last_validator_summary: str = ""
        self._role_models: Dict[str, str] = {}

        # Session Parameter Tracker - emp√™che les LLMs de retester les m√™mes param√®tres
        self.param_tracker = SessionParameterTracker(session_id=self.session_id)

        # Donn√©es charg√©es (pour walk-forward)
        self._loaded_data: Optional["pd.DataFrame"] = getattr(config, "data", None)

        # Orchestration logger (optionnel, non bloquant)
        self._orch_logger: Any = None
        self._init_orchestration_logger()

        logger.info(
            f"Orchestrator initialis√©: session={self.session_id}, "
            f"strategy={config.strategy_name}, max_iter={self._max_iter_label}"
        )

    def _create_initial_context(self) -> AgentContext:
        """Cr√©e le contexte initial."""
        return AgentContext(
            session_id=self.session_id,
            iteration=0,
            strategy_name=self.config.strategy_name,
            strategy_description=self.config.strategy_description,
            current_params=self.config.initial_params.copy(),
            param_specs=self.config.param_specs,
            data_path=self.config.data_path,
            data_symbol=self.config.data_symbol,
            data_timeframe=self.config.data_timeframe,
            data_date_range=self.config.data_date_range,
            comparison_context=self.config.comparison_context,
            optimization_target=self.config.optimization_target,
            min_sharpe=self.config.min_sharpe,
            max_drawdown_limit=self.config.max_drawdown_limit,
            min_trades=self.config.min_trades,
            max_overfitting_ratio=self.config.max_overfitting_ratio,
        )

    def _init_orchestration_logger(self) -> None:
        """Initialise un logger d'orchestration s'il est disponible (non bloquant)."""
        # Utilise un logger fourni dans la config si pr√©sent
        if getattr(self.config, "orchestration_logger", None) is not None:
            self._orch_logger = self.config.orchestration_logger
            return
        # Tentative de cr√©ation depuis le module d√©di√© (si disponible)
        try:
            from .orchestration_logger import OrchestrationLogger  # type: ignore
            self._orch_logger = OrchestrationLogger(session_id=self.session_id)
        except Exception:
            self._orch_logger = None  # Mode d√©grad√©: aucune trace persist√©e

    def _log_event(self, event_type: str, **payload: Any) -> None:
        """
        Ajoute un √©v√©nement d'orchestration de mani√®re non bloquante.
        Supporte plusieurs API possibles (log/add_event/append).
        """
        if not self._orch_logger:
            return
        try:
            entry = {
                "event_type": event_type,
                "timestamp": datetime.now().isoformat(),
                "session_id": self.session_id,
                "iteration": getattr(self.state_machine, "iteration", 0),
                **payload,
            }
            if hasattr(self._orch_logger, "log"):
                self._orch_logger.log(event_type, entry)  # type: ignore[attr-defined]
            elif hasattr(self._orch_logger, "add_event"):
                self._orch_logger.add_event(event_type, entry)  # type: ignore[attr-defined]
            elif hasattr(self._orch_logger, "append"):
                self._orch_logger.append(entry)  # type: ignore[attr-defined]
        except Exception as e:
            # Ne jamais bloquer le flux pour la tra√ßabilit√©
            logger.debug("Orchestration log failed: %s", e)

    def _handle_llm_failure(self, result: AgentResult, role: str) -> bool:
        if result.success:
            self._consecutive_llm_failures = 0
            return False

        raw = result.raw_llm_response
        llm_error = False
        parse_error = ""

        if raw and not raw.content and raw.parse_error:
            llm_error = True
            parse_error = raw.parse_error

        if any("LLM n'a pas retourn√© de r√©ponse" in err for err in result.errors):
            llm_error = True

        if not llm_error:
            return False

        self._consecutive_llm_failures += 1
        self._log_event(
            "llm_failure",
            role=role,
            count=self._consecutive_llm_failures,
            message=parse_error or "; ".join(result.errors),
        )

        if self._consecutive_llm_failures >= self.config.max_consecutive_llm_failures:
            reason = (
                "LLM indisponible ou en erreur r√©p√©t√©e "
                f"({self._consecutive_llm_failures} √©checs)"
            )
            self._errors.append(reason)
            self._log_event("llm_abort", role=role, reason=reason)
            self.state_machine.fail(reason)
            return True

        return False

    def _apply_role_model(self, role: str) -> Optional[str]:
        """Select and apply a model for the given role if configured."""
        config = self.config.role_model_config
        if not config:
            model_name = self.llm_client.config.model
            self._role_models[role] = model_name
            return model_name

        iteration = max(1, self.state_machine.iteration)
        model_name = config.get_model(
            role=role,
            iteration=iteration,
            random_selection=True,
        )
        if model_name and self.llm_client.config.model != model_name:
            self.llm_client.config.model = model_name
            logger.info("Role %s model set to %s", role, model_name)
        model_name = self.llm_client.config.model
        self._role_models[role] = model_name
        return model_name

    def _get_memory_identifiers(self) -> tuple[str, str, str]:
        strategy = self.config.strategy_name or self.context.strategy_name
        symbol = self.config.data_symbol or self.context.data_symbol or "unknown"
        timeframe = self.config.data_timeframe or self.context.data_timeframe or "unknown"
        return strategy, symbol, timeframe

    def _resolve_data_info(self) -> tuple[str, str, int]:
        data_rows = self.context.data_rows
        if not data_rows and self._loaded_data is not None:
            try:
                data_rows = len(self._loaded_data)
            except Exception:
                data_rows = 0

        period_start, period_end = extract_date_range(self._loaded_data)
        if not period_start and not period_end:
            period_start, period_end = split_date_range(self.context.data_date_range)

        if not self.context.data_date_range and (period_start or period_end):
            if period_start and period_end:
                self.context.data_date_range = f"{period_start} -> {period_end}"
            else:
                self.context.data_date_range = period_start or period_end

        return period_start, period_end, data_rows

    def _init_memory_session(self) -> None:
        strategy, symbol, timeframe = self._get_memory_identifiers()
        period_start, period_end, data_rows = self._resolve_data_info()
        model = self.llm_client.config.model

        try:
            self._memory_session_path = start_session(
                session_id=self.session_id,
                strategy=strategy,
                symbol=symbol,
                timeframe=timeframe,
                period_start=period_start,
                period_end=period_end,
                model=model,
                data_rows=data_rows,
            )
        except Exception as exc:
            logger.warning("LLM memory session init failed: %s", exc)
            self._memory_session_path = None

        try:
            self.context.memory_summary = build_memory_summary(
                strategy=strategy,
                symbol=symbol,
                timeframe=timeframe,
            )
        except Exception as exc:
            logger.debug("LLM memory summary failed: %s", exc)
            self.context.memory_summary = ""

    def _append_memory_iteration(self, entry: Dict[str, Any]) -> None:
        if not self._memory_session_path:
            return
        try:
            append_session_iteration(self._memory_session_path, entry)
        except Exception as exc:
            logger.debug("LLM memory session update failed: %s", exc)

    def _collect_insights(self) -> List[str]:
        insights: List[str] = []
        if self._last_validator_summary:
            insights.append(self._last_validator_summary)

        if self._last_validation_data:
            approved = self._last_validation_data.get("approved_config", {})
            if isinstance(approved, dict):
                for key in ("deployment_notes", "monitoring_recommendations"):
                    items = approved.get(key, [])
                    if isinstance(items, list):
                        for item in items:
                            if isinstance(item, str) and item:
                                insights.append(item)

        unique: List[str] = []
        seen = set()
        for item in insights:
            if item in seen:
                continue
            seen.add(item)
            unique.append(item)
        return unique[:MAX_INSIGHTS]

    def _build_history_entry(self, result: OrchestratorResult) -> Optional[Dict[str, Any]]:
        strategy, symbol, timeframe = self._get_memory_identifiers()
        period_start, period_end, data_rows = self._resolve_data_info()
        metrics = self.context.best_metrics or self.context.current_metrics
        if metrics is None:
            return None

        metrics_payload = {
            "sharpe_ratio": metrics.sharpe_ratio,
            "total_return_pct": metrics.total_return * 100.0,
            "max_drawdown_pct": metrics.max_drawdown * 100.0,
            "win_rate_pct": metrics.win_rate * 100.0,
            "total_trades": metrics.total_trades,
        }

        params = self.context.best_params or self.context.current_params
        model = self._role_models.get("validator") or self.llm_client.config.model
        insights = self._collect_insights()
        if not insights:
            insights = [
                (
                    f"Sharpe {metrics.sharpe_ratio:.2f}, "
                    f"return {metrics.total_return * 100.0:.1f}%, "
                    f"drawdown {metrics.max_drawdown * 100.0:.1f}%."
                )
            ]

        entry = {
            "timestamp": datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z"),
            "session_id": self.session_id,
            "strategy": strategy,
            "symbol": symbol,
            "timeframe": timeframe,
            "period_start": period_start,
            "period_end": period_end,
            "data_rows": data_rows,
            "model": model,
            "metrics": metrics_payload,
            "params": params,
            "insights": insights[:MAX_INSIGHTS],
            "decision": result.decision,
        }
        if self._last_validation_data:
            entry["validator_confidence"] = self._last_validation_data.get("confidence")

        return entry

    def _finalize_memory(self, result: OrchestratorResult) -> None:
        if result.decision == "APPROVE":
            history_entry = self._build_history_entry(result)
            if history_entry:
                strategy, symbol, timeframe = self._get_memory_identifiers()
                history_path = get_history_path(strategy, symbol, timeframe)
                try:
                    append_history_entry(history_path, history_entry)
                except Exception as exc:
                    logger.warning("LLM memory history update failed: %s", exc)

        if self._memory_session_path:
            delete_session(self._memory_session_path)
            self._memory_session_path = None

    def run(self) -> OrchestratorResult:
        """
        Ex√©cute le workflow d'optimisation complet.

        Returns:
            R√©sultat de l'orchestration
        """
        self._start_time = time.time()
        self._log_event(
            "run_start",
            strategy=self.config.strategy_name,
            max_iterations=self.config.max_iterations,
            data_path=bool(self.config.data_path),
        )
        logger.info(f"=== D√©marrage orchestration {self.session_id} ===")

        self._init_memory_session()

        try:
            # Transition vers INIT ‚Üí ANALYZE
            self._run_workflow()

        except Exception as e:
            logger.error(f"Erreur orchestration: {e}", exc_info=True)
            self._log_event("error", scope="orchestration", message=str(e))
            self.state_machine.fail(str(e), e)
            self._errors.append(str(e))

        # Construire le r√©sultat final
        result = self._build_result()
        self._log_event(
            "run_end",
            success=result.success,
            decision=result.decision,
            total_iterations=result.total_iterations,
            total_backtests=result.total_backtests,
            total_time_s=result.total_time_s,
            total_llm_calls=result.total_llm_calls,
            total_llm_tokens=result.total_llm_tokens,
            errors=len(result.errors),
            warnings=len(result.warnings),
        )

        # Forcer la sauvegarde finale des logs
        if self.config.orchestration_logger:
            try:
                self.config.orchestration_logger.save_to_jsonl()
            except Exception as e:
                logger.warning(f"√âchec de la sauvegarde finale des logs: {e}")

        self._finalize_memory(result)

        return result

        # Docstring update summary
        # - Docstring de module normalis√©e (LLM-friendly) et orient√©e orchestration
        # - Conventions d‚Äô√©tats/terminaison explicit√©es pour √©viter les ambigu√Øt√©s
        # - Read-if/Skip-if ajout√©s pour acc√©l√©rer le tri des fichiers

    def _run_workflow(self) -> None:
        """Ex√©cute la boucle principale du workflow."""

        while not self.state_machine.is_terminal:
            current = self.state_machine.current_state
            self._log_event("state_enter", state=current.name)
            logger.info(f"√âtat actuel: {current.name}")

            # Dispatch selon l'√©tat
            if current == AgentState.INIT:
                self._handle_init()
            elif current == AgentState.ANALYZE:
                self._handle_analyze()
            elif current == AgentState.PROPOSE:
                self._handle_propose()
            elif current == AgentState.CRITIQUE:
                self._handle_critique()
            elif current == AgentState.VALIDATE:
                self._handle_validate()
            elif current == AgentState.ITERATE:
                self._handle_iterate()
            else:
                logger.error(f"√âtat non g√©r√©: {current}")
                self.state_machine.fail(f"√âtat non g√©r√©: {current}")
                break

            # Callback + log de transition
            if self.config.on_state_change:
                self.config.on_state_change(current, self.state_machine.current_state)
            self._log_event(
                "state_change",
                state_from=current.name,
                state_to=self.state_machine.current_state.name,
            )

    def _handle_init(self) -> None:
        """G√®re l'√©tat INIT - Initialisation et validation."""
        self._log_event("phase_start", phase="INIT")
        logger.info("Phase INIT: Validation configuration et backtest initial")

        # Valider la configuration
        validation = self._validate_config()
        if not validation.is_valid:
            self._log_event("config_invalid", errors=validation.errors or [], message=validation.message)
            self.state_machine.fail(f"Configuration invalide: {validation.message}")
            return
        self._log_event("config_valid")

        # Ex√©cuter le backtest initial
        initial_metrics = None
        try:
            initial_metrics = self._run_backtest(self.context.current_params)
            if initial_metrics:
                self.context.current_metrics = initial_metrics
                self.context.best_metrics = initial_metrics
                self.context.best_params = self.context.current_params.copy()
                self._log_event(
                    "initial_backtest_done",
                    sharpe=initial_metrics.sharpe_ratio,
                    total_return=initial_metrics.total_return,
                    max_drawdown=initial_metrics.max_drawdown,
                )
                logger.info(
                    f"Backtest initial: Sharpe={initial_metrics.sharpe_ratio:.3f}, "
                    f"Return={initial_metrics.total_return:.2%}"
                )
            else:
                self._warnings.append("Backtest initial sans m√©triques")
                self._log_event("warning", message="Backtest initial sans m√©triques")
        except Exception as e:
            self._warnings.append(f"Erreur backtest initial: {e}")
            self._log_event("warning", message=f"Erreur backtest initial: {e}")
            logger.error(f"Erreur backtest initial: {e}", exc_info=True)

        # Fallback: cr√©er des m√©triques √† z√©ro si le backtest a √©chou√©
        if initial_metrics is None:
            logger.warning("Backtest initial √©chou√©, utilisation de m√©triques par d√©faut (z√©ro)")
            initial_metrics = MetricsSnapshot(
                sharpe_ratio=0.0,
                sortino_ratio=0.0,
                total_return=0.0,
                max_drawdown=0.0,
                win_rate=0.0,
                profit_factor=0.0,
                total_trades=0,
            )
            self.context.current_metrics = initial_metrics
            self._warnings.append("Utilisation de m√©triques par d√©faut (backtest √©chou√©)")
            self._log_event("warning", message="M√©triques par d√©faut utilis√©es")

        # Calculer les m√©triques walk-forward si donn√©es disponibles
        self._compute_walk_forward_metrics()

        # Contexte indicateurs (une seule fois par run)
        if not self._indicator_context_cached and self._loaded_data is not None:
            try:
                from .indicator_context import build_indicator_context
                indicator_ctx = build_indicator_context(
                    df=self._loaded_data,
                    strategy_name=self.context.strategy_name,
                    params=self.context.current_params,
                )
                self.context.strategy_indicators_context = indicator_ctx.get("strategy", "")
                self.context.readonly_indicators_context = indicator_ctx.get("read_only", "")
                self.context.indicator_context_warnings = indicator_ctx.get("warnings", [])
                self._indicator_context_cached = True
                self._log_event(
                    "indicator_context",
                    strategy_indicators_context=self.context.strategy_indicators_context,
                    readonly_indicators_context=self.context.readonly_indicators_context,
                    warnings=self.context.indicator_context_warnings,
                )
            except Exception as exc:
                self._warnings.append(f"Contexte indicateurs indisponible: {exc}")
                self.context.strategy_indicators_context = ""
                self.context.readonly_indicators_context = ""
                self.context.indicator_context_warnings = []
                self._indicator_context_cached = True

        # Transition vers ANALYZE
        self.state_machine.transition_to(AgentState.ANALYZE)

    def _handle_analyze(self) -> None:
        """G√®re l'√©tat ANALYZE - Ex√©cution de l'Agent Analyst."""
        self._log_event("phase_start", phase="ANALYZE")
        logger.info("Phase ANALYZE: Ex√©cution Agent Analyst")

        # Mettre √† jour l'it√©ration dans le contexte
        self.context.iteration = self.state_machine.iteration

        # Ajouter le r√©sum√© du tracker de session pour informer l'Analyst
        if hasattr(self, 'param_tracker'):
            # Ajouter dynamiquement au contexte (pour ne pas modifier base_agent.py)
            setattr(
                self.context,
                'session_params_summary',
                self.param_tracker.get_summary()
            )

        # Contexte indicateurs (strat√©gie vs lecture seule) - calcul√© une seule fois par run
        if not self._indicator_context_cached and self._loaded_data is not None:
            try:
                from .indicator_context import build_indicator_context
                indicator_ctx = build_indicator_context(
                    df=self._loaded_data,
                    strategy_name=self.context.strategy_name,
                    params=self.context.current_params,
                )
                self.context.strategy_indicators_context = indicator_ctx.get("strategy", "")
                self.context.readonly_indicators_context = indicator_ctx.get("read_only", "")
                self.context.indicator_context_warnings = indicator_ctx.get("warnings", [])
                self._indicator_context_cached = True
                self._log_event(
                    "indicator_context",
                    strategy_indicators_context=self.context.strategy_indicators_context,
                    readonly_indicators_context=self.context.readonly_indicators_context,
                    warnings=self.context.indicator_context_warnings,
                )
            except Exception as exc:
                self._warnings.append(f"Contexte indicateurs indisponible: {exc}")
                self.context.strategy_indicators_context = ""
                self.context.readonly_indicators_context = ""
                self.context.indicator_context_warnings = []
                self._indicator_context_cached = True

        # Ex√©cuter l'Analyst
        self._apply_role_model("analyst")
        self._log_event("agent_execute_start", role="analyst", model=self.llm_client.config.model)
        t0 = time.time()
        result = self.analyst.execute(self.context)
        dt = int((time.time() - t0) * 1000)
        self._log_event("agent_execute_end", role="analyst", success=result.success, latency_ms=dt)

        if self._handle_llm_failure(result, "analyst"):
            return

        if not result.success:
            logger.error(f"Analyst √©chou√©: {result.errors}")
            self._log_event("error", scope="analyst", message=str(result.errors))
            self._errors.extend(result.errors)
            # Continuer quand m√™me - l'analyse n'est pas bloquante
            self.context.analyst_report = "Analyse non disponible"
        else:
            # Stocker le rapport
            self.context.analyst_report = result.content

            # V√©rifier si on doit continuer l'optimisation
            proceed = result.data.get("proceed_to_optimization", True)
            self._log_event("analyst_result", proceed=bool(proceed))
            if not proceed:
                logger.info("Analyst recommande de ne pas optimiser")
                transition = self.state_machine.transition_to(AgentState.VALIDATE)
                if not transition.is_valid:
                    logger.warning(
                        "Transition ANALYZE -> VALIDATE refusee: %s",
                        transition.message,
                    )
                    self.state_machine.transition_to(AgentState.VALIDATE, force=True)
                return

        # Transition vers PROPOSE
        self.state_machine.transition_to(AgentState.PROPOSE)

    def _handle_propose(self) -> None:
        """G√®re l'√©tat PROPOSE - Ex√©cution de l'Agent Strategist."""
        self._log_event("phase_start", phase="PROPOSE")
        logger.info("Phase PROPOSE: Ex√©cution Agent Strategist")

        # Ajouter le r√©sum√© du tracker de session pour informer le Strategist
        if hasattr(self, 'param_tracker'):
            setattr(
                self.context,
                'session_params_summary',
                self.param_tracker.get_summary()
            )

        # Ex√©cuter le Strategist
        self._apply_role_model("strategist")
        self._log_event("agent_execute_start", role="strategist", model=self.llm_client.config.model)
        t0 = time.time()
        result = self.strategist.execute(self.context)
        dt = int((time.time() - t0) * 1000)
        self._log_event("agent_execute_end", role="strategist", success=result.success, latency_ms=dt)

        if self._handle_llm_failure(result, "strategist"):
            return

        if not result.success:
            logger.error(f"Strategist √©chou√©: {result.errors}")
            self._log_event("error", scope="strategist", message=str(result.errors))
            self._errors.extend(result.errors)
            # Sans propositions, on va directement √† la validation
            self.context.strategist_proposals = []
            self.state_machine.transition_to(AgentState.VALIDATE)
            return

        # D√©tecter si Strategist demande un sweep au lieu de proposals
        sweep_request = result.data.get("sweep", None)
        if sweep_request:
            logger.info("üîç Strategist demande un grid search (sweep)")
            self._handle_sweep_proposal(sweep_request)
            return

        # Stocker les propositions
        proposals = result.data.get("proposals", [])
        proposals = proposals[:self.config.max_proposals_per_iteration]

        # Filtrer les propositions d√©j√† test√©es dans cette session
        filtered_proposals = []
        duplicates_count = 0
        for proposal in proposals:
            params = proposal.get("parameters", {})
            if not params:
                continue

            # V√©rifier si d√©j√† test√©
            if self.param_tracker.was_tested(params):
                duplicates_count += 1
                logger.info(
                    f"  ‚ö†Ô∏è Proposition ignor√©e (d√©j√† test√©e): {proposal.get('name', 'N/A')}"
                )
                continue

            filtered_proposals.append(proposal)

        self.context.strategist_proposals = filtered_proposals
        self._log_event(
            "proposals_generated",
            count=len(self.context.strategist_proposals),
            duplicates_filtered=duplicates_count
        )
        logger.info(
            f"Strategist: {len(proposals)} propositions g√©n√©r√©es, "
            f"{duplicates_count} duplications filtr√©es, "
            f"{len(filtered_proposals)} nouvelles"
        )

        # Si toutes les propositions √©taient des duplications
        if proposals and not filtered_proposals:
            logger.warning("Toutes les propositions sont des duplications - passage √† VALIDATE")
            self.state_machine.transition_to(AgentState.VALIDATE)
            return

        # Transition vers CRITIQUE
        self.state_machine.transition_to(AgentState.CRITIQUE)

    def _handle_sweep_proposal(self, sweep_request: Dict[str, Any]) -> None:
        """
        G√®re un sweep request du Strategist (grid search).

        Args:
            sweep_request: Dict avec ranges, rationale, optimize_for, max_combinations
        """
        self._log_event("sweep_request", details=sweep_request)
        logger.info(f"  Sweep rationale: {sweep_request.get('rationale', 'N/A')}")

        # V√©rifier la limite de sweeps
        if self._sweeps_performed >= self._max_sweeps_per_session:
            logger.warning(
                f"‚ö†Ô∏è Limite de sweeps atteinte ({self._max_sweeps_per_session}). "
                f"Sweep request ignor√©."
            )
            self._warnings.append(
                f"Sweep limit reached ({self._sweeps_performed}/{self._max_sweeps_per_session})"
            )
            # Passer √† VALIDATE sans proposals
            self.context.strategist_proposals = []
            self.state_machine.transition_to(AgentState.VALIDATE)
            return

        # V√©rifier si ces ranges ont d√©j√† √©t√© test√©es
        ranges = sweep_request.get("ranges", {})
        if self._ranges_tracker.was_tested(ranges):
            logger.warning(
                f"‚ö†Ô∏è Ranges d√©j√† test√©es dans cette session! | "
                f"Params={list(ranges.keys())} | "
                f"Forcing diversification..."
            )
            self._warnings.append(
                f"Ranges already tested: {list(ranges.keys())}"
            )
            # Passer √† VALIDATE sans proposals
            self.context.strategist_proposals = []
            self.state_machine.transition_to(AgentState.VALIDATE)
            return

        try:
            # Importer run_llm_sweep
            from utils.parameters import RangeProposal

            from .integration import run_llm_sweep

            # Cr√©er RangeProposal depuis sweep_request
            range_proposal = RangeProposal(
                ranges=sweep_request.get("ranges", {}),
                rationale=sweep_request.get("rationale", ""),
                optimize_for=sweep_request.get("optimize_for", "sharpe_ratio"),
                max_combinations=sweep_request.get("max_combinations", 100),
            )

            # Extraire param_specs depuis le contexte
            param_specs = []
            if hasattr(self.context, 'param_specs'):
                param_specs = self.context.param_specs
            elif hasattr(self.context, 'parameter_configs'):
                # Convertir ParameterConfig ‚Üí ParameterSpec
                from utils.parameters import ParameterSpec
                for pc in self.context.parameter_configs:
                    param_specs.append(ParameterSpec(
                        name=pc.name,
                        min_val=pc.bounds[0],
                        max_val=pc.bounds[1],
                        default=pc.current_value,
                        step=pc.step,
                        param_type="int" if pc.value_type == "int" else "float"
                    ))

            if not param_specs:
                raise ValueError("Impossible d'extraire param_specs du contexte")

            # R√©cup√©rer les donn√©es
            if self._loaded_data is None:
                logger.error("Sweep impossible: donn√©es non disponibles dans orchestrator")
                raise ValueError("Donn√©es non disponibles pour sweep")

            # Ex√©cuter le sweep
            logger.info(
                f"  Lancement sweep: {len(range_proposal.ranges)} param√®tres, "
                f"max {range_proposal.max_combinations} combinaisons"
            )
            self._log_event("sweep_start", n_params=len(range_proposal.ranges))

            sweep_results = run_llm_sweep(
                range_proposal=range_proposal,
                param_specs=param_specs,
                data=self._loaded_data,
                strategy_name=self.context.strategy_name,
                initial_capital=10000.0,  # Utiliser capital depuis contexte si disponible
                n_workers=None,  # Auto-detect
            )

            # Incr√©menter les compteurs de budget
            n_combinations = sweep_results['n_combinations']
            self._sweeps_performed += 1
            self._total_combinations_tested += n_combinations

            # Enregistrer les ranges test√©es dans le tracker
            best_sharpe = sweep_results['best_metrics'].get('sharpe_ratio', 0)
            self._ranges_tracker.register(
                ranges=range_proposal.ranges,
                n_combinations=n_combinations,
                best_sharpe=best_sharpe,
                rationale=range_proposal.rationale
            )

            logger.info(
                f"‚úÖ Sweep #{self._sweeps_performed} termin√©: {n_combinations} combinaisons test√©es | "
                f"Best {range_proposal.optimize_for}={sweep_results['best_metrics'].get(range_proposal.optimize_for, 0):.3f} | "
                f"Budget: {self._total_combinations_tested}/{self._max_iter_label} combos"
            )
            self._log_event(
                "sweep_complete",
                n_combinations=n_combinations,
                sweeps_performed=self._sweeps_performed,
                total_combinations_tested=self._total_combinations_tested,
                best_metrics=sweep_results['best_metrics']
            )

            # Stocker les r√©sultats dans le contexte
            self.context.sweep_results = sweep_results
            self.context.sweep_summary = sweep_results['summary']

            # Cr√©er une proposition artificielle depuis le meilleur config
            best_proposal = {
                "id": 1,
                "name": f"Sweep Best Config ({range_proposal.optimize_for}={sweep_results['best_metrics'].get(range_proposal.optimize_for, 0):.3f})",
                "priority": "HIGH",
                "risk_level": "LOW",
                "parameters": sweep_results['best_params'],
                "rationale": f"Best config from grid search: {range_proposal.rationale}",
                "expected_impact": sweep_results['best_metrics'],
                "risks": ["Config from grid search, may not generalize"],
            }

            self.context.strategist_proposals = [best_proposal]
            logger.info(f"  Meilleurs param√®tres: {sweep_results['best_params']}")

            # Transition vers CRITIQUE pour valider le meilleur config
            self.state_machine.transition_to(AgentState.CRITIQUE)

        except Exception as e:
            logger.error(f"Erreur durant le sweep: {e}")
            self._log_event("sweep_failed", error=str(e))
            self._errors.append(f"Sweep failed: {str(e)}")

            # En cas d'erreur, passer √† VALIDATE sans proposals
            self.context.strategist_proposals = []
            self.state_machine.transition_to(AgentState.VALIDATE)

    def _handle_critique(self) -> None:
        """G√®re l'√©tat CRITIQUE - Ex√©cution de l'Agent Critic."""
        self._log_event("phase_start", phase="CRITIQUE")
        logger.info("Phase CRITIQUE: Ex√©cution Agent Critic")

        if not self.context.strategist_proposals:
            logger.warning("Aucune proposition √† critiquer")
            self._log_event("warning", message="Aucune proposition √† critiquer")
            self.state_machine.transition_to(AgentState.VALIDATE)
            return

        # Ex√©cuter le Critic
        self._apply_role_model("critic")
        self._log_event("agent_execute_start", role="critic", model=self.llm_client.config.model)
        t0 = time.time()
        result = self.critic.execute(self.context)
        dt = int((time.time() - t0) * 1000)
        self._log_event("agent_execute_end", role="critic", success=result.success, latency_ms=dt)

        if self._handle_llm_failure(result, "critic"):
            return

        if not result.success:
            logger.error(f"Critic √©chou√©: {result.errors}")
            self._log_event("error", scope="critic", message=str(result.errors))
            self._errors.extend(result.errors)
            # Continuer avec les propositions non filtr√©es
            self.context.critic_concerns = []
        else:
            # Mettre √† jour avec les propositions filtr√©es
            approved = result.data.get("approved_proposals", [])
            if approved:
                self.context.strategist_proposals = approved

            self.context.critic_assessment = result.content
            self.context.critic_concerns = result.data.get("concerns", [])
            self._log_event(
                "critic_result",
                approved_count=len(approved),
                concerns_count=len(self.context.critic_concerns),
            )
            logger.info(
                f"Critic: {len(approved)} propositions approuv√©es, "
                f"{len(self.context.critic_concerns)} concerns"
            )

        # Tester les propositions approuv√©es
        self._test_proposals()

        # Transition vers VALIDATE
        self.state_machine.transition_to(AgentState.VALIDATE)

    def _handle_validate(self) -> None:
        """G√®re l'√©tat VALIDATE - Ex√©cution de l'Agent Validator."""
        self._log_event("phase_start", phase="VALIDATE")
        logger.info("Phase VALIDATE: Ex√©cution Agent Validator")

        # Ex√©cuter le Validator
        self._apply_role_model("validator")
        self._log_event("agent_execute_start", role="validator", model=self.llm_client.config.model)
        t0 = time.time()
        result = self.validator.execute(self.context)
        dt = int((time.time() - t0) * 1000)
        self._log_event("agent_execute_end", role="validator", success=result.success, latency_ms=dt)

        if self._handle_llm_failure(result, "validator"):
            return

        if not result.success:
            logger.error(f"Validator √©chou√©: {result.errors}")
            self._log_event("error", scope="validator", message=str(result.errors))
            self._errors.extend(result.errors)
            # Par d√©faut, on it√®re si le validator √©choue
            decision = ValidationDecision.ITERATE
            self._last_validation_data = None
            self._last_validator_summary = ""
        else:
            decision_str = result.data.get("decision", "ITERATE")
            try:
                decision = ValidationDecision(decision_str)
            except ValueError:
                decision = ValidationDecision.ITERATE
            self._last_validation_data = result.data
            self._last_validator_summary = result.content or ""

        logger.info(f"Validator d√©cision: {decision.value}")
        self._log_event("validator_decision", decision=decision.value)

        # Enregistrer l'historique de l'it√©ration
        self._record_iteration(decision.value)

        # Transition selon la d√©cision
        if decision == ValidationDecision.APPROVE:
            self.state_machine.transition_to(AgentState.APPROVED)
        elif decision == ValidationDecision.REJECT:
            self.state_machine.transition_to(AgentState.REJECTED)
        elif decision == ValidationDecision.ABORT:
            self.state_machine.fail("Validator a d√©cid√© ABORT")
        else:  # ITERATE
            # V√©rifier si on peut encore it√©rer
            if self.state_machine.can_transition_to(AgentState.ITERATE):
                self.state_machine.transition_to(AgentState.ITERATE)
            else:
                logger.info("Max iterations atteint, passage en REJECTED")
                self.state_machine.transition_to(AgentState.REJECTED)

    def _handle_iterate(self) -> None:
        """G√®re l'√©tat ITERATE - Pr√©paration de l'it√©ration suivante."""
        self._log_event("phase_start", phase="ITERATE")
        logger.info("Phase ITERATE: Pr√©paration it√©ration suivante")

        # S√©lectionner la meilleure configuration test√©e
        best_tested = self._get_best_tested_config()
        if best_tested:
            self.context.current_params = best_tested["params"]
            if best_tested.get("metrics"):
                self.context.current_metrics = best_tested["metrics"]

                # Mettre √† jour le best si meilleur
                if (
                    self.context.best_metrics is None
                    or best_tested["metrics"].sharpe_ratio
                    > self.context.best_metrics.sharpe_ratio
                ):
                    self.context.best_metrics = best_tested["metrics"]
                    self.context.best_params = best_tested["params"].copy()

        # Nettoyer les propositions
        self.context.strategist_proposals = []
        self.context.critic_concerns = []

        # Callback it√©ration compl√®te
        if self.config.on_iteration_complete:
            self.config.on_iteration_complete(
                self.state_machine.iteration,
                {"metrics": self.context.current_metrics, "params": self.context.current_params}
            )

        # V√©rifier le budget de combinaisons test√©es avant la prochaine it√©ration
        if (not self._unlimited_iterations) and self._total_combinations_tested >= self.config.max_iterations:
            logger.warning(
                f"‚ö†Ô∏è Budget √©puis√©: {self._total_combinations_tested} combos test√©es "
                f"(limite: {self.config.max_iterations}, dont {self._sweeps_performed} sweeps)"
            )
            self._warnings.append(
                f"Budget √©puis√©: {self._total_combinations_tested}/{self.config.max_iterations} combos"
            )
            # Transition vers REJECTED car budget √©puis√©
            self.state_machine.transition_to(AgentState.REJECTED)
            return

        # Transition vers ANALYZE
        self.state_machine.transition_to(AgentState.ANALYZE)

    def _validate_config(self) -> ValidationResult:
        """Valide la configuration initiale."""
        errors = []

        if not self.config.strategy_name:
            errors.append("strategy_name requis")

        if self.config.data_path:
            if not Path(self.config.data_path).exists():
                errors.append(f"data_path n'existe pas: {self.config.data_path}")
        elif self.config.on_backtest_needed is None:
            errors.append("data_path requis")

        if not self.config.param_specs:
            errors.append("param_specs requis (au moins un param√®tre)")

        if errors:
            return ValidationResult.failure("; ".join(errors), errors)

        return ValidationResult.success()

    def _run_backtest(self, params: Dict[str, Any]) -> Optional[MetricsSnapshot]:
        """
        Ex√©cute un backtest avec les param√®tres donn√©s.

        Utilise le callback on_backtest_needed si fourni,
        sinon retourne None.
        """
        self._backtests_count += 1
        self._total_combinations_tested += 1  # Compter cette combinaison vers le budget
        self._log_event("backtest_start", source="orchestrator", params=params)

        if self.config.on_backtest_needed:
            try:
                result = self.config.on_backtest_needed(params)
                if result:
                    metrics = MetricsSnapshot.from_dict(result)
                    self._log_event(
                        "backtest_end",
                        success=True,
                        sharpe=metrics.sharpe_ratio,
                        total_return=metrics.total_return,
                        max_drawdown=metrics.max_drawdown,
                    )
                    return metrics
            except Exception as e:
                logger.error(f"Erreur backtest: {e}")
                self._warnings.append(f"Backtest √©chou√©: {e}")
                self._log_event("backtest_end", success=False, error=str(e))

        return None

    def _compute_walk_forward_metrics(self) -> None:
        """
        Calcule les m√©triques de walk-forward validation et met √† jour le contexte.

        Charge les donn√©es si n√©cessaire et ex√©cute une validation walk-forward
        pour d√©tecter l'overfitting avec les m√©triques robustes.
        """
        # Si on a d√©j√† des donn√©es en m√©moire (UI), on les utilise.
        if self._loaded_data is not None:
            data_df = self._loaded_data
            try:
                self.context.data_rows = len(data_df)
            except Exception:
                pass

            try:
                wf_metrics = run_walk_forward_for_agent(
                    strategy_name=self.config.strategy_name,
                    params=self.context.current_params,
                    data=data_df,
                    n_windows=6,
                    train_ratio=0.75,
                    n_workers=self.config.n_workers,
                )

                self.context.overfitting_ratio = wf_metrics["overfitting_ratio"]
                self.context.classic_ratio = wf_metrics["classic_ratio"]
                self.context.degradation_pct = wf_metrics["degradation_pct"]
                self.context.test_stability_std = wf_metrics["test_stability_std"]
                self.context.n_valid_folds = wf_metrics["n_valid_folds"]
                self.context.walk_forward_windows = 6

                self._log_event(
                    "walk_forward_computed",
                    overfitting_ratio=float(wf_metrics["overfitting_ratio"]),
                    classic_ratio=float(wf_metrics["classic_ratio"]),
                    degradation_pct=float(wf_metrics["degradation_pct"]),
                    test_stability_std=float(wf_metrics["test_stability_std"]),
                    n_valid_folds=int(wf_metrics["n_valid_folds"]),
                )
            except Exception as e:
                logger.warning(f"√âchec du calcul des m√©triques walk-forward: {e}")
                self._warnings.append(f"Walk-forward √©chou√©: {e}")
                self._log_event("warning", message=f"Walk-forward √©chou√©: {e}")

            return

        # V√©rifier si un chemin de donn√©es est fourni
        if not self.config.data_path:
            logger.debug("Pas de data/data_path configur√©, skip walk-forward metrics")
            return

        data_path = Path(self.config.data_path)
        if not data_path.exists():
            logger.warning(f"Fichier de donn√©es introuvable: {data_path}")
            return

        try:
            # Charger les donn√©es si pas d√©j√† fait
            if self._loaded_data is None:
                logger.info(f"Chargement des donn√©es depuis {data_path}")
                import pandas as pd

                # Charger selon l'extension
                if data_path.suffix == '.csv':
                    self._loaded_data = pd.read_csv(data_path)
                elif data_path.suffix == '.parquet':
                    self._loaded_data = pd.read_parquet(data_path)
                else:
                    logger.warning(f"Format non support√© pour walk-forward: {data_path.suffix}")
                    return

                logger.info(f"  Donn√©es charg√©es: {len(self._loaded_data)} lignes")

            # Mettre √† jour le contexte avec les infos sur les donn√©es
            self.context.data_rows = len(self._loaded_data)

            # Extraire la plage de dates si disponible
            if 'timestamp' in self._loaded_data.columns or 'date' in self._loaded_data.columns:
                date_col = 'timestamp' if 'timestamp' in self._loaded_data.columns else 'date'
                try:
                    import pandas as pd
                    dates = pd.to_datetime(self._loaded_data[date_col])
                    self.context.data_date_range = f"{dates.min()} ‚Üí {dates.max()}"
                except Exception:
                    pass

            # Ex√©cuter la validation walk-forward
            logger.info("Ex√©cution de la validation walk-forward...")
            wf_metrics = run_walk_forward_for_agent(
                strategy_name=self.config.strategy_name,
                params=self.context.current_params,
                data=self._loaded_data,
                n_windows=6,
                train_ratio=0.75,
                n_workers=self.config.n_workers,
            )

            # Mettre √† jour le contexte avec les m√©triques
            self.context.overfitting_ratio = wf_metrics["overfitting_ratio"]
            self.context.classic_ratio = wf_metrics["classic_ratio"]
            self.context.degradation_pct = wf_metrics["degradation_pct"]
            self.context.test_stability_std = wf_metrics["test_stability_std"]
            self.context.n_valid_folds = wf_metrics["n_valid_folds"]
            self.context.walk_forward_windows = 6

            logger.info(
                f"Walk-forward termin√©: "
                f"overfitting_ratio={wf_metrics['overfitting_ratio']:.3f}, "
                f"degradation={wf_metrics['degradation_pct']:.1f}%, "
                f"stability_std={wf_metrics['test_stability_std']:.3f}"
            )

            # Journaliser l'√©v√©nement
            self._log_event(
                "walk_forward_computed",
                overfitting_ratio=float(wf_metrics["overfitting_ratio"]),
                classic_ratio=float(wf_metrics["classic_ratio"]),
                degradation_pct=float(wf_metrics["degradation_pct"]),
                test_stability_std=float(wf_metrics["test_stability_std"]),
                n_valid_folds=int(wf_metrics["n_valid_folds"]),
            )

        except Exception as e:
            logger.warning(f"√âchec du calcul des m√©triques walk-forward: {e}")
            self._warnings.append(f"Walk-forward √©chou√©: {e}")
            self._log_event("warning", message=f"Walk-forward √©chou√©: {e}")

    def _test_proposals(self) -> None:
        """Teste les propositions approuv√©es via backtest."""
        proposals = list(self.context.strategist_proposals or [])
        if not proposals:
            return

        def _eval_one(proposal: Dict[str, Any]) -> tuple[Dict[str, Any], Optional[MetricsSnapshot]]:
            params = proposal.get("parameters", {})
            if not params:
                return proposal, None
            return proposal, self._run_backtest(params)

        n_workers = int(getattr(self.config, "n_workers", 1) or 1)

        # S√©quentiel par d√©faut
        if n_workers <= 1 or len(proposals) <= 1:
            # Barre de progression pour les tests de propositions
            proposal_iterator = tqdm(
                proposals,
                desc="Testing proposals",
                unit="proposal",
                disable=not TQDM_AVAILABLE,
                leave=False
            ) if len(proposals) > 1 else proposals

            for proposal in proposal_iterator:
                params = proposal.get("parameters", {})
                if not params:
                    continue

                self._log_event(
                    "proposal_test_started",
                    proposal_id=proposal.get("id"),
                    proposal_name=proposal.get("name"),
                )
                logger.info(f"Test proposition {proposal.get('id')}: {proposal.get('name')}")

                metrics = self._run_backtest(params)
                if metrics:
                    proposal["tested_metrics"] = metrics.to_dict()
                    proposal["tested"] = True

                    # Enregistrer dans le tracker de session
                    self.param_tracker.register(
                        params=params,
                        sharpe_ratio=metrics.sharpe_ratio,
                        total_return=metrics.total_return
                    )

                    self._log_event(
                        "proposal_test_ended",
                        proposal_id=proposal.get("id"),
                        tested=True,
                        sharpe=metrics.sharpe_ratio,
                        total_return=metrics.total_return,
                    )
                else:
                    proposal["tested"] = False
                    self._log_event(
                        "proposal_test_ended",
                        proposal_id=proposal.get("id"),
                        tested=False,
                    )
            return

        # Parall√®le: le slider workers a enfin un effet r√©el en multi-agents
        from concurrent.futures import ThreadPoolExecutor, as_completed

        for proposal in proposals:
            if proposal.get("parameters", {}):
                self._log_event(
                    "proposal_test_started",
                    proposal_id=proposal.get("id"),
                    proposal_name=proposal.get("name"),
                )

        futures = {}
        with ThreadPoolExecutor(max_workers=n_workers) as pool:
            for proposal in proposals:
                if not proposal.get("parameters", {}):
                    continue
                futures[pool.submit(_eval_one, proposal)] = proposal

            for fut in as_completed(futures):
                proposal = futures[fut]
                try:
                    _, metrics = fut.result()
                except Exception as e:
                    metrics = None
                    self._warnings.append(f"Backtest proposition √©chou√©: {e}")
                    self._log_event(
                        "proposal_test_ended",
                        proposal_id=proposal.get("id"),
                        tested=False,
                        error=str(e),
                    )
                    continue

                if metrics:
                    proposal["tested_metrics"] = metrics.to_dict()
                    proposal["tested"] = True

                    # Enregistrer dans le tracker de session
                    self.param_tracker.register(
                        params=proposal.get("parameters", {}),
                        sharpe_ratio=metrics.sharpe_ratio,
                        total_return=metrics.total_return
                    )

                    self._log_event(
                        "proposal_test_ended",
                        proposal_id=proposal.get("id"),
                        tested=True,
                        sharpe=metrics.sharpe_ratio,
                        total_return=metrics.total_return,
                    )
                else:
                    proposal["tested"] = False
                    self._log_event(
                        "proposal_test_ended",
                        proposal_id=proposal.get("id"),
                        tested=False,
                    )

    def _get_best_tested_config(self) -> Optional[Dict[str, Any]]:
        """Retourne la meilleure configuration test√©e."""
        best = None
        best_sharpe = float("-inf")

        for proposal in self.context.strategist_proposals:
            if not proposal.get("tested"):
                continue

            metrics_dict = proposal.get("tested_metrics", {})
            sharpe = metrics_dict.get("sharpe_ratio", 0)

            if sharpe > best_sharpe:
                best_sharpe = sharpe
                best = {
                    "params": proposal.get("parameters", {}),
                    "metrics": MetricsSnapshot.from_dict(metrics_dict),
                }

        return best

    def _record_iteration(self, decision: Optional[str] = None) -> None:
        """Enregistre l'it√©ration actuelle dans l'historique."""
        entry = {
            "iteration": self.state_machine.iteration,
            "timestamp": datetime.now().isoformat(),
            "params": self.context.current_params.copy(),
        }

        if self.context.current_metrics:
            entry.update({
                "sharpe_ratio": self.context.current_metrics.sharpe_ratio,
                "total_return": self.context.current_metrics.total_return,
                "max_drawdown": self.context.current_metrics.max_drawdown,
            })

        entry["proposals_count"] = len(self.context.strategist_proposals)
        entry["concerns_count"] = len(self.context.critic_concerns)
        if decision:
            entry["decision"] = decision

        self.context.iteration_history.append(entry)

        # Journalisation non bloquante
        self._log_event(
            "iteration_recorded",
            iteration=entry["iteration"],
            sharpe=entry.get("sharpe_ratio"),
            total_return=entry.get("total_return"),
            max_drawdown=entry.get("max_drawdown"),
            proposals_count=entry.get("proposals_count", 0),
            concerns_count=entry.get("concerns_count", 0),
            decision=decision,
        )
        self._append_memory_iteration(entry)

    def _generate_final_report(self) -> str:
        """G√©n√®re un rapport final d√©taill√© incluant les statistiques du tracker."""
        lines = [
            "=" * 80,
            "üìä RAPPORT FINAL D'OPTIMISATION MULTI-AGENTS",
            "=" * 80,
            "",
            f"üîñ Session ID: {self.session_id}",
            f"üìà Strat√©gie: {self.config.strategy_name}",
            f"üîÑ It√©rations totales: {self.state_machine.iteration}",
            f"üß™ Backtests ex√©cut√©s: {self._backtests_count}",
            f"ü§ñ Combinaisons test√©es: {self._total_combinations_tested}",
            f"üîç Sweeps effectu√©s: {self._sweeps_performed}/{self._max_sweeps_per_session}",
            "",
        ]

        # √âtat final de la machine √† √©tats
        final_state = self.state_machine.current_state
        lines.extend([
            "üìå D√âCISION FINALE:",
            f"  √âtat: {final_state.name}",
            f"  D√©cision: {'‚úÖ APPROUV√â' if final_state == AgentState.APPROVED else '‚ùå REJET√â' if final_state == AgentState.REJECTED else '‚ö†Ô∏è AVORT√â'}",
            "",
        ])

        # Walk-forward validation status
        if self.config.walk_forward_disabled_reason:
            lines.extend([
                "‚ö†Ô∏è WALK-FORWARD VALIDATION:",
                "  Status: D√âSACTIV√â AUTOMATIQUEMENT",
                f"  Raison: {self.config.walk_forward_disabled_reason}",
                "",
            ])
        elif self.config.use_walk_forward:
            lines.extend([
                "‚úÖ WALK-FORWARD VALIDATION:",
                "  Status: ACTIV√â",
                f"  Windows: {self.config.walk_forward_windows}",
                f"  Train ratio: {self.config.train_ratio:.0%}",
                "",
            ])

        # R√©sultats finaux
        if self.context.best_metrics:
            lines.extend([
                "üèÜ MEILLEURS R√âSULTATS OBTENUS:",
                f"  üìä Sharpe Ratio: {self.context.best_metrics.sharpe_ratio:.3f}",
                f"  üí∞ Total Return: {self.context.best_metrics.total_return:.2%}",
                f"  üìâ Max Drawdown: {self.context.best_metrics.max_drawdown:.2%}",
                f"  üéØ Win Rate: {self.context.best_metrics.win_rate:.1%}" if hasattr(self.context.best_metrics, 'win_rate') else "",
                f"  üî¢ Total Trades: {self.context.best_metrics.total_trades}",
                "",
                "‚öôÔ∏è  Param√®tres optimaux:",
            ])
            for k, v in (self.context.best_params or {}).items():
                if isinstance(v, float):
                    lines.append(f"    ‚Ä¢ {k}: {v:.4f}")
                else:
                    lines.append(f"    ‚Ä¢ {k}: {v}")
            lines.append("")

        # Activit√© des agents multi-agents
        lines.extend([
            "=" * 80,
            "ü§ñ ACTIVIT√â DES AGENTS",
            "=" * 80,
            "",
        ])

        # Statistiques par agent
        def _get_agent_stats(agent: BaseAgent, name: str) -> List[str]:
            stats = getattr(agent, "stats", {})
            tokens = stats.get("total_tokens", 0)
            calls = stats.get("execution_count", 0)
            return [
                f"üîπ {name}:",
                f"    Appels LLM: {calls}",
                f"    Tokens utilis√©s: {tokens:,}",
            ]

        lines.extend(_get_agent_stats(self.analyst, "Agent Analyst"))
        lines.extend(_get_agent_stats(self.strategist, "Agent Strategist"))
        lines.extend(_get_agent_stats(self.critic, "Agent Critic"))
        lines.extend(_get_agent_stats(self.validator, "Agent Validator"))
        lines.append("")

        # Historique des it√©rations
        if self.context.iteration_history:
            lines.extend([
                "=" * 80,
                "üìú HISTORIQUE DES IT√âRATIONS",
                "=" * 80,
                "",
            ])
            for i, hist in enumerate(self.context.iteration_history[-10:], 1):  # Derni√®res 10
                iter_num = hist.get("iteration", i)
                sharpe = hist.get("sharpe_ratio", 0)
                ret = hist.get("total_return", 0)
                params = hist.get("params", {})
                decision = hist.get("decision", "N/A")

                lines.extend([
                    f"It√©ration #{iter_num}:",
                    f"  Sharpe: {sharpe:.3f} | Return: {ret:.2%}",
                    f"  D√©cision: {decision}",
                ])
                if params and len(params) <= 5:  # Afficher params si peu nombreux
                    param_str = ", ".join(f"{k}={v}" for k, v in params.items())
                    lines.append(f"  Params: {param_str}")
                lines.append("")

        # Statistiques de sweep (si utilis√©s)
        if self._sweeps_performed > 0:
            lines.extend([
                "=" * 80,
                "üîç STATISTIQUES GRID SEARCH (SWEEPS)",
                "=" * 80,
                "",
                f"  Nombre de sweeps: {self._sweeps_performed}",
                f"  Limite par session: {self._max_sweeps_per_session}",
                f"  Combinaisons test√©es via sweeps: {self._total_combinations_tested - self._backtests_count}",
                "",
            ])

            # Ranges test√©es (si tracker disponible)
            if hasattr(self, '_ranges_tracker'):
                ranges_summary = self._ranges_tracker.get_summary(max_ranges=5)
                if ranges_summary != "Aucune range test√©e dans cette session.":
                    lines.extend([
                        "Ranges explor√©es:",
                        ranges_summary,
                        "",
                    ])

        # Statistiques du tracker de param√®tres
        if hasattr(self, 'param_tracker'):
            lines.extend([
                "=" * 80,
                "üìä STATISTIQUES DE SESSION",
                "=" * 80,
                "",
                f"  ‚úÖ Tests uniques: {self.param_tracker.get_tested_count()}",
                f"  üîÑ Duplications √©vit√©es: {self.param_tracker.get_duplicates_prevented()}",
                "",
            ])

            # Meilleurs param√®tres selon le tracker
            best_sharpe = self.param_tracker.get_best_params("sharpe_ratio")
            if best_sharpe:
                lines.extend([
                    "üèÖ Meilleur Sharpe Ratio test√©:",
                    f"    Valeur: {best_sharpe.sharpe_ratio:.3f}",
                    f"    Return: {best_sharpe.total_return:.2%}" if hasattr(best_sharpe, 'total_return') and best_sharpe.total_return else "",
                    "    Param√®tres:",
                ])
                for k, v in best_sharpe.params.items():
                    if isinstance(v, float):
                        lines.append(f"      ‚Ä¢ {k}: {v:.4f}")
                    else:
                        lines.append(f"      ‚Ä¢ {k}: {v}")
                lines.append("")

        # Warnings et erreurs
        if self._warnings or self._errors:
            lines.extend([
                "=" * 80,
                "‚ö†Ô∏è  AVERTISSEMENTS ET ERREURS",
                "=" * 80,
                "",
            ])
            if self._warnings:
                lines.extend([
                    "Avertissements:",
                    *[f"  ‚ö†Ô∏è  {w}" for w in self._warnings],
                    "",
                ])
            if self._errors:
                lines.extend([
                    "Erreurs:",
                    *[f"  ‚ùå {e}" for e in self._errors],
                    "",
                ])

        lines.append("=" * 80)
        return "\n".join(lines)

    def _build_result(self) -> OrchestratorResult:
        """Construit le r√©sultat final."""
        elapsed = time.time() - self._start_time if self._start_time else 0

        # D√©terminer la d√©cision finale
        final_state = self.state_machine.current_state
        if final_state == AgentState.APPROVED:
            decision = "APPROVE"
            success = True
        elif final_state == AgentState.REJECTED:
            decision = "REJECT"
            success = False
        else:
            decision = "ABORT"
            success = False

        # Statistiques LLM (avec fallback si agent n'a pas de stats)
        def _get_agent_stats(agent: BaseAgent) -> Dict[str, int]:
            """R√©cup√®re les stats d'un agent de mani√®re s√ªre."""
            stats = getattr(agent, "stats", {})
            return {
                "total_tokens": stats.get("total_tokens", 0),
                "execution_count": stats.get("execution_count", 0),
            }

        agents = [self.analyst, self.strategist, self.critic, self.validator]
        total_tokens = sum(_get_agent_stats(a)["total_tokens"] for a in agents)
        total_calls = sum(_get_agent_stats(a)["execution_count"] for a in agents)

        # G√©n√©rer le rapport final avec statistiques du tracker
        final_report = self._generate_final_report()

        # Recommandations bas√©es sur le tracker
        recommendations = []
        if hasattr(self, 'param_tracker'):
            duplicates = self.param_tracker.get_duplicates_prevented()
            if duplicates > 0:
                recommendations.append(
                    f"‚úÖ {duplicates} duplications de param√®tres √©vit√©es durant la session"
                )
            if self.param_tracker.get_tested_count() > 0:
                recommendations.append(
                    f"üìä {self.param_tracker.get_tested_count()} combinaisons uniques test√©es"
                )

        return OrchestratorResult(
            success=success,
            final_state=final_state,
            decision=decision,
            final_params=self.context.best_params or self.context.current_params,
            final_metrics=self.context.best_metrics,
            total_iterations=self.state_machine.iteration,
            total_backtests=self._backtests_count,
            total_time_s=elapsed,
            total_llm_tokens=total_tokens,
            total_llm_calls=total_calls,
            iteration_history=self.context.iteration_history,
            state_history=self.state_machine.get_summary()["history"],
            final_report=final_report,
            recommendations=recommendations,
            errors=self._errors,
            warnings=self._warnings,
        )
```
<!-- MODULE-END: orchestrator.py -->

<!-- MODULE-START: state_machine.py -->
```json
{
  "name": "state_machine.py",
  "path": "agents\\state_machine.py",
  "ext": ".py",
  "anchor": "state_machine_py"
}
```
## state_machine_py
*Chemin* : `agents\state_machine.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.state_machine

Purpose: Machine √† √©tats rigide pour le workflow LLM avec transitions valid√©es et tra√ßabilit√©.

Role in pipeline: orchestration

Key components: AgentState (enum), StateMachine, StateTransition, ValidationResult

Inputs: √âtat courant, action demand√©e, validateurs optionnels

Outputs: Nouvel √©tat, historique transitions, dur√©es, erreurs

Dependencies: utils.log, dataclasses

Conventions: √âtats INIT‚ÜíANALYZE‚ÜíPROPOSE‚ÜíCRITIQUE‚ÜíVALIDATE‚Üí[APPROVED|REJECTED|ITERATE]; ITERATE reboucle √† ANALYZE; *‚ÜíFAILED sur erreur; iteration incr√©ment√© sur transition ITERATE.

Read-if: Modification transitions, ajout √©tats, ou int√©gration validateurs custom.

Skip-if: Vous ne touchez qu'aux agents isol√©s.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from typing import Any, Callable, Dict, List, Optional, Set

logger = logging.getLogger(__name__)


class AgentState(Enum):
    """√âtats du workflow d'optimisation."""

    # √âtats de travail
    INIT = auto()       # Initialisation
    ANALYZE = auto()    # Analyse en cours
    PROPOSE = auto()    # Proposition en cours
    CRITIQUE = auto()   # Critique en cours
    VALIDATE = auto()   # Validation en cours
    ITERATE = auto()    # Pr√©paration it√©ration suivante

    # √âtats terminaux
    APPROVED = auto()   # ‚úÖ Optimisation valid√©e
    REJECTED = auto()   # ‚ùå Optimisation rejet√©e
    FAILED = auto()     # üí• Erreur syst√®me

    def is_terminal(self) -> bool:
        """V√©rifie si l'√©tat est terminal."""
        return self in (AgentState.APPROVED, AgentState.REJECTED, AgentState.FAILED)

    def is_working(self) -> bool:
        """V√©rifie si l'√©tat est un √©tat de travail."""
        return not self.is_terminal()


@dataclass
class ValidationResult:
    """R√©sultat de validation d'une transition."""

    is_valid: bool
    message: str = ""
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    data: Dict[str, Any] = field(default_factory=dict)

    @classmethod
    def success(cls, message: str = "OK", **data) -> ValidationResult:
        """Cr√©e un r√©sultat de succ√®s."""
        return cls(is_valid=True, message=message, data=data)

    @classmethod
    def failure(cls, message: str, errors: List[str] = None) -> ValidationResult:
        """Cr√©e un r√©sultat d'√©chec."""
        return cls(is_valid=False, message=message, errors=errors or [message])

    def __bool__(self) -> bool:
        return self.is_valid


@dataclass
class StateTransition:
    """D√©finition d'une transition entre √©tats."""

    from_state: AgentState
    to_state: AgentState
    condition: str  # Description de la condition
    validator: Optional[Callable[[Dict[str, Any]], ValidationResult]] = None

    def validate(self, context: Dict[str, Any]) -> ValidationResult:
        """Valide si la transition est permise."""
        if self.validator:
            return self.validator(context)
        return ValidationResult.success()


@dataclass
class StateHistoryEntry:
    """Entr√©e dans l'historique des √©tats."""

    timestamp: datetime
    from_state: Optional[AgentState]
    to_state: AgentState
    validation: ValidationResult
    iteration: int
    duration_ms: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class StateMachine:
    """
    Machine √† √©tats pour le workflow d'optimisation.

    Garantit:
    - Transitions valides uniquement
    - Tra√ßabilit√© compl√®te
    - Gestion des erreurs
    - Pas de boucles infinies

    Example:
        >>> sm = StateMachine(max_iterations=10)
        >>> sm.transition_to(AgentState.ANALYZE, context)
        >>> if sm.can_transition_to(AgentState.PROPOSE):
        ...     sm.transition_to(AgentState.PROPOSE, context)
    """

    # D√©finition des transitions valides
    VALID_TRANSITIONS: Dict[AgentState, Set[AgentState]] = {
        AgentState.INIT: {AgentState.ANALYZE, AgentState.FAILED},
        AgentState.ANALYZE: {AgentState.PROPOSE, AgentState.VALIDATE, AgentState.FAILED},
        AgentState.PROPOSE: {AgentState.CRITIQUE, AgentState.FAILED},
        AgentState.CRITIQUE: {AgentState.VALIDATE, AgentState.FAILED},
        AgentState.VALIDATE: {AgentState.APPROVED, AgentState.REJECTED, AgentState.ITERATE, AgentState.FAILED},
        AgentState.ITERATE: {AgentState.ANALYZE, AgentState.REJECTED, AgentState.FAILED},
        # √âtats terminaux - pas de transition sortante
        AgentState.APPROVED: set(),
        AgentState.REJECTED: set(),
        AgentState.FAILED: set(),
    }

    def __init__(
        self,
        max_iterations: int = 10,
        initial_state: AgentState = AgentState.INIT,
    ):
        """
        Initialise la machine √† √©tats.

        Args:
            max_iterations: Nombre maximum d'it√©rations (anti-boucle infinie)
            initial_state: √âtat initial
        """
        self._current_state = initial_state
        self._max_iterations = max_iterations
        self._has_iteration_limit = max_iterations > 0
        self._current_iteration = 0
        self._history: List[StateHistoryEntry] = []
        self._context: Dict[str, Any] = {}
        self._transition_validators: Dict[tuple, Callable] = {}
        self._last_transition_time: Optional[datetime] = None

        # Enregistrer l'√©tat initial
        self._record_transition(None, initial_state, ValidationResult.success("Initial state"))

        max_iter_label = "‚àû" if not self._has_iteration_limit else str(max_iterations)
        logger.info(f"StateMachine initialis√©e: √©tat={initial_state.name}, max_iter={max_iter_label}")

    @property
    def current_state(self) -> AgentState:
        """√âtat actuel."""
        return self._current_state

    @property
    def iteration(self) -> int:
        """Num√©ro d'it√©ration actuel."""
        return self._current_iteration

    @property
    def is_terminal(self) -> bool:
        """V√©rifie si l'√©tat actuel est terminal."""
        return self._current_state.is_terminal()

    @property
    def history(self) -> List[StateHistoryEntry]:
        """Historique des transitions."""
        return self._history.copy()

    def register_validator(
        self,
        from_state: AgentState,
        to_state: AgentState,
        validator: Callable[[Dict[str, Any]], ValidationResult],
    ) -> None:
        """
        Enregistre un validateur pour une transition sp√©cifique.

        Args:
            from_state: √âtat source
            to_state: √âtat destination
            validator: Fonction de validation
        """
        self._transition_validators[(from_state, to_state)] = validator

    def can_transition_to(self, target_state: AgentState) -> bool:
        """
        V√©rifie si une transition vers l'√©tat cible est possible.

        Args:
            target_state: √âtat cible

        Returns:
            True si la transition est possible
        """
        # V√©rifier si la transition est valide structurellement
        valid_targets = self.VALID_TRANSITIONS.get(self._current_state, set())
        if target_state not in valid_targets:
            return False

        # V√©rifier le max iterations pour ITERATE ‚Üí ANALYZE
        if self._current_state == AgentState.ITERATE and target_state == AgentState.ANALYZE:
            if self._has_iteration_limit and self._current_iteration >= self._max_iterations:
                return False

        return True

    def get_valid_transitions(self) -> Set[AgentState]:
        """Retourne les transitions valides depuis l'√©tat actuel."""
        valid = self.VALID_TRANSITIONS.get(self._current_state, set())

        # Filtrer selon les contraintes
        result = set()
        for state in valid:
            if self.can_transition_to(state):
                result.add(state)

        return result

    def transition_to(
        self,
        target_state: AgentState,
        context: Optional[Dict[str, Any]] = None,
        force: bool = False,
    ) -> ValidationResult:
        """
        Effectue une transition vers un nouvel √©tat.

        Args:
            target_state: √âtat cible
            context: Contexte pour la validation
            force: Forcer la transition (ignorer validation)

        Returns:
            R√©sultat de la validation

        Raises:
            StateTransitionError: Si la transition est invalide
        """
        context = context or {}
        self._context.update(context)

        # V√©rifier si d√©j√† en √©tat terminal
        if self.is_terminal:
            return ValidationResult.failure(
                f"Impossible de quitter l'√©tat terminal {self._current_state.name}"
            )

        # V√©rifier si la transition est structurellement valide
        if not self.can_transition_to(target_state) and not force:
            valid = self.get_valid_transitions()
            return ValidationResult.failure(
                f"Transition {self._current_state.name} ‚Üí {target_state.name} invalide. "
                f"Transitions valides: {[s.name for s in valid]}"
            )

        # Ex√©cuter le validateur sp√©cifique si pr√©sent
        validator_key = (self._current_state, target_state)
        if validator_key in self._transition_validators and not force:
            validation = self._transition_validators[validator_key](self._context)
            if not validation.is_valid:
                logger.warning(
                    f"Validation √©chou√©e: {self._current_state.name} ‚Üí {target_state.name}: "
                    f"{validation.message}"
                )
                return validation
        else:
            validation = ValidationResult.success()

        # Effectuer la transition
        old_state = self._current_state
        self._current_state = target_state

        # Incr√©menter le compteur d'it√©ration si on entre dans ANALYZE
        if target_state == AgentState.ANALYZE and old_state == AgentState.ITERATE:
            self._current_iteration += 1

        # Enregistrer dans l'historique
        self._record_transition(old_state, target_state, validation)

        logger.info(
            f"Transition: {old_state.name} ‚Üí {target_state.name} "
            f"(iter={self._current_iteration})"
        )

        return validation

    def fail(self, error: str, exception: Optional[Exception] = None) -> None:
        """
        Transition vers l'√©tat FAILED.

        Args:
            error: Message d'erreur
            exception: Exception optionnelle
        """
        validation = ValidationResult.failure(
            error,
            errors=[str(exception)] if exception else [error]
        )

        self._current_state = AgentState.FAILED
        self._record_transition(self._current_state, AgentState.FAILED, validation)

        logger.error(f"StateMachine FAILED: {error}")

    def _record_transition(
        self,
        from_state: Optional[AgentState],
        to_state: AgentState,
        validation: ValidationResult,
    ) -> None:
        """Enregistre une transition dans l'historique."""
        now = datetime.now()
        duration = None

        if self._last_transition_time:
            duration = (now - self._last_transition_time).total_seconds() * 1000

        entry = StateHistoryEntry(
            timestamp=now,
            from_state=from_state,
            to_state=to_state,
            validation=validation,
            iteration=self._current_iteration,
            duration_ms=duration,
        )

        self._history.append(entry)
        self._last_transition_time = now

    def get_summary(self) -> Dict[str, Any]:
        """Retourne un r√©sum√© de l'ex√©cution."""
        total_duration = 0.0
        if len(self._history) >= 2:
            total_duration = (
                self._history[-1].timestamp - self._history[0].timestamp
            ).total_seconds()

        return {
            "current_state": self._current_state.name,
            "is_terminal": self.is_terminal,
            "iterations": self._current_iteration,
            "max_iterations": self._max_iterations,
            "total_transitions": len(self._history),
            "total_duration_s": total_duration,
            "history": [
                {
                    "from": e.from_state.name if e.from_state else None,
                    "to": e.to_state.name,
                    "iteration": e.iteration,
                    "valid": e.validation.is_valid,
                    "duration_ms": e.duration_ms,
                }
                for e in self._history
            ],
        }

    def reset(self) -> None:
        """Remet la machine √† l'√©tat initial."""
        self._current_state = AgentState.INIT
        self._current_iteration = 0
        self._history.clear()
        self._context.clear()
        self._last_transition_time = None

        self._record_transition(None, AgentState.INIT, ValidationResult.success("Reset"))
        logger.info("StateMachine reset")


class StateTransitionError(Exception):
    """Erreur de transition d'√©tat."""

    def __init__(self, message: str, from_state: AgentState, to_state: AgentState):
        super().__init__(message)
        self.from_state = from_state
        self.to_state = to_state
```
<!-- MODULE-END: state_machine.py -->

<!-- MODULE-START: strategist.py -->
```json
{
  "name": "strategist.py",
  "path": "agents\\strategist.py",
  "ext": ".py",
  "anchor": "strategist_py"
}
```
## strategist_py
*Chemin* : `agents\strategist.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.strategist

Purpose: Proposer des ajustements cr√©atifs mais r√©alistes des param√®tres bas√©s sur l'analyse.

Role in pipeline: orchestration

Key components: StrategistAgent, ParameterProposal, ProposalList

Inputs: AgentContext (analyst_result, param_bounds, param_specs)

Outputs: Liste de ParameterProposal (params valid√©s, justifications, priorit√©s)

Dependencies: agents.base_agent, utils.template, utils.parameters

Conventions: Propositions clamp√©es aux bornes; bornes min < max obligatoires; justifications exig√©es; template Jinja2.

Read-if: Modification propositions, cr√©ativit√©/conservatisme, ou cl√©mence des contraintes.

Skip-if: Vous ne touchez qu'√† analyze/critique/validate.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
import time
from typing import Any, Dict, List

from utils.template import render_prompt

from .base_agent import (
    AgentContext,
    AgentResult,
    AgentRole,
    BaseAgent,
)

logger = logging.getLogger(__name__)


class StrategistAgent(BaseAgent):
    """
    Agent Strategist - Expert en optimisation de strat√©gies.

    Propose:
    - Ajustements de param√®tres bas√©s sur l'analyse
    - Combinaisons cr√©atives mais r√©alistes
    - Prioritisation par impact/risque
    - Justifications d√©taill√©es
    """

    @property
    def role(self) -> AgentRole:
        return AgentRole.STRATEGIST

    @property
    def system_prompt(self) -> str:
        return """You are a senior quantitative strategist specializing in algorithmic trading strategy optimization.

Your expertise includes:
- Parameter optimization for trading strategies
- Understanding indicator behavior across different settings
- Balancing risk/reward trade-offs
- Creative but grounded strategy improvements
- Avoiding overfitting while maximizing performance

When proposing parameter changes:
1. Consider the analyst's findings and recommendations
2. Propose changes that address identified weaknesses
3. Stay within reasonable parameter bounds
4. Prioritize robustness over maximum performance
5. Consider how parameters interact with each other
6. Avoid drastic changes that might cause instability

IMPORTANT CONSTRAINTS:
- Each parameter must stay within its min/max bounds
- Propose 3-5 parameter sets, ordered by priority
- First proposal should be conservative, later ones more aggressive
- Always explain the rationale for each change

Respond ONLY in valid JSON format with this exact structure:
{
    "analysis_summary": "Brief summary of analyst findings you're addressing",
    "optimization_strategy": "Overall approach to optimization",
    "proposals": [
        {
            "id": 1,
            "name": "Conservative Adjustment",
            "priority": "HIGH|MEDIUM|LOW",
            "risk_level": "LOW|MEDIUM|HIGH",
            "parameters": {
                "param_name": value,
                ...
            },
            "changes_from_current": {
                "param_name": {"from": old_value, "to": new_value, "change_percent": X}
            },
            "rationale": "Why this configuration might improve performance",
            "expected_impact": {
                "sharpe_ratio": "+X% to +Y%",
                "drawdown": "similar|reduced|increased",
                "trade_frequency": "similar|higher|lower"
            },
            "risks": ["risk1", "risk2"]
        }
    ],
    "constraints_respected": true,
    "fallback_recommendation": "What to do if all proposals fail"
}"""

    def execute(self, context: AgentContext) -> AgentResult:
        """
        G√©n√®re des propositions de param√®tres.

        Args:
            context: Contexte avec rapport analyst

        Returns:
            Liste de propositions ordonn√©es
        """
        start_time = time.time()

        # Construire le prompt
        user_prompt = self._build_proposal_prompt(context)

        # Appeler le LLM
        response = self._call_llm(user_prompt, json_mode=True, temperature=0.7)

        execution_time = (time.time() - start_time) * 1000

        # V√©rifier la r√©ponse
        if not response.content:
            return AgentResult.failure_result(
                self.role,
                "LLM n'a pas retourn√© de r√©ponse",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Parser le JSON
        proposals_data = response.parse_json()
        if proposals_data is None:
            return AgentResult.failure_result(
                self.role,
                f"√âchec parsing JSON: {response.parse_error}",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Valider et corriger les propositions
        proposals = proposals_data.get("proposals", [])
        validated_proposals = self._validate_and_fix_proposals(proposals, context)

        if not validated_proposals:
            return AgentResult.failure_result(
                self.role,
                "Aucune proposition valide g√©n√©r√©e",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Cr√©er le r√©sultat
        return AgentResult.success_result(
            self.role,
            content=proposals_data.get("optimization_strategy", ""),
            data={
                "proposals": validated_proposals,
                "analysis_summary": proposals_data.get("analysis_summary", ""),
                "optimization_strategy": proposals_data.get("optimization_strategy", ""),
                "fallback_recommendation": proposals_data.get("fallback_recommendation", ""),
                "total_proposals": len(validated_proposals),
            },
            execution_time_ms=execution_time,
            tokens_used=response.total_tokens,
            llm_calls=1,
            raw_llm_response=response,
        )

    def _build_proposal_prompt(self, context: AgentContext) -> str:
        """Construit le prompt de proposition via template Jinja2."""

        # Convertir MetricsSnapshot en dict pour le template
        current_metrics_dict = None
        if context.current_metrics:
            current_metrics_dict = context.current_metrics.to_dict()

        best_metrics_dict = None
        if context.best_metrics:
            best_metrics_dict = context.best_metrics.to_dict()

        template_context = {
            "strategy_name": context.strategy_name,
            "strategy_description": context.strategy_description,
            "iteration": context.iteration,
            "comparison_context": context.comparison_context,
            "param_specs": context.param_specs,
            "current_params": context.current_params,
            "current_metrics": current_metrics_dict,
            "overfitting_ratio": context.overfitting_ratio,
            "max_overfitting_ratio": context.max_overfitting_ratio,
            "analyst_report": context.analyst_report,
            "best_metrics": best_metrics_dict,
            "best_params": context.best_params,
            "optimization_target": context.optimization_target,
            "min_sharpe": context.min_sharpe,
            "max_drawdown_limit": context.max_drawdown_limit,
            "min_trades": context.min_trades,
            "iteration_history": context.iteration_history,
            # R√©sum√© des param√®tres d√©j√† test√©s dans cette session
            "session_params_summary": getattr(context, 'session_params_summary', None),
            "memory_summary": context.memory_summary,
            "strategy_indicators_context": context.strategy_indicators_context,
            "readonly_indicators_context": context.readonly_indicators_context,
            "indicator_context_warnings": context.indicator_context_warnings,
        }

        return render_prompt("strategist.jinja2", template_context)

    def _validate_and_fix_proposals(
        self,
        proposals: List[Dict[str, Any]],
        context: AgentContext,
    ) -> List[Dict[str, Any]]:
        """
        Valide et corrige les propositions.

        S'assure que tous les param√®tres respectent les contraintes.
        """
        validated = []

        # Cr√©er un dict des specs pour lookup rapide
        specs_dict = {spec.name: spec for spec in context.param_specs}

        for proposal in proposals:
            params = proposal.get("parameters", {})
            fixed_params = {}

            # V√©rifier chaque param√®tre
            for param_name, value in params.items():
                if param_name not in specs_dict:
                    # Param√®tre inconnu - ignorer
                    logger.warning(f"Param√®tre inconnu ignor√©: {param_name}")
                    continue

                spec = specs_dict[param_name]

                # Forcer les contraintes
                if spec.min_value is not None and value < spec.min_value:
                    logger.warning(
                        f"Param√®tre {param_name}={value} < min={spec.min_value}, corrig√©"
                    )
                    value = spec.min_value

                if spec.max_value is not None and value > spec.max_value:
                    logger.warning(
                        f"Param√®tre {param_name}={value} > max={spec.max_value}, corrig√©"
                    )
                    value = spec.max_value

                # Arrondir au step si sp√©cifi√©
                if spec.step is not None and spec.step > 0:
                    if isinstance(value, float) and isinstance(spec.step, (int, float)):
                        value = round(value / spec.step) * spec.step
                    elif isinstance(value, int) and isinstance(spec.step, int):
                        value = (value // spec.step) * spec.step

                fixed_params[param_name] = value

            # Ajouter les param√®tres manquants avec valeurs actuelles
            for param_name in specs_dict:
                if param_name not in fixed_params:
                    fixed_params[param_name] = context.current_params.get(
                        param_name,
                        specs_dict[param_name].current_value
                    )

            if fixed_params:
                proposal["parameters"] = fixed_params
                proposal["validated"] = True
                validated.append(proposal)

        return validated
```
<!-- MODULE-END: strategist.py -->

<!-- MODULE-START: validator.py -->
```json
{
  "name": "validator.py",
  "path": "agents\\validator.py",
  "ext": ".py",
  "anchor": "validator_py"
}
```
## validator_py
*Chemin* : `agents\validator.py`  
*Type* : `.py`  

```python
"""
Module-ID: agents.validator

Purpose: Prendre la d√©cision finale (APPROVE/REJECT/ITERATE/ABORT) avec synth√®se des agents.

Role in pipeline: orchestration

Key components: ValidatorAgent, ValidationDecision, ValidatorResponse

Inputs: AgentContext complet (analyst_result, propositions, critic_evaluation)

Outputs: ValidationDecision (APPROVE/REJECT/ITERATE/ABORT) avec justifications

Dependencies: agents.base_agent, agents.state_machine, utils.template

Conventions: Decision irr√©vocable une fois APPROVED/REJECTED; ITERATE remet √† ANALYZE; ABORT ‚Üí FAILED; template Jinja2.

Read-if: Modification crit√®res d√©cision, seuils approbation, ou logique d'it√©ration.

Skip-if: Vous ne changez que analyze/propose/critique.
"""

from __future__ import annotations

# pylint: disable=logging-fstring-interpolation
import logging
import time
from enum import Enum
from typing import Any, Dict

from utils.template import render_prompt

from .base_agent import (
    AgentContext,
    AgentResult,
    AgentRole,
    BaseAgent,
)

logger = logging.getLogger(__name__)


class ValidationDecision(Enum):
    """D√©cisions possibles du Validator."""
    APPROVE = "APPROVE"      # Accepter la configuration
    REJECT = "REJECT"        # Rejeter d√©finitivement
    ITERATE = "ITERATE"      # Continuer l'optimisation
    ABORT = "ABORT"          # Arr√™ter (probl√®me grave)


class ValidatorAgent(BaseAgent):
    """
    Agent Validator - D√©cideur final.

    Responsabilit√©s:
    - Synth√©tiser les avis des agents
    - V√©rifier les crit√®res objectifs
    - Prendre la d√©cision finale
    - Justifier clairement le verdict
    """

    @property
    def role(self) -> AgentRole:
        return AgentRole.VALIDATOR

    @property
    def system_prompt(self) -> str:
        return """You are the final decision-maker for trading strategy optimization.

Your role is to synthesize all agent reports and make the final call.

Decision criteria:
1. APPROVE: Configuration meets ALL requirements and is production-ready
   - Sharpe ratio >= minimum threshold
   - Drawdown <= maximum allowed
   - Overfitting ratio <= threshold
   - Sufficient trades for statistical validity
   - Approved by Critic with reasonable confidence

2. ITERATE: Promising but needs more optimization
   - Shows potential but doesn't meet all criteria
   - Clear path to improvement exists
   - Not at max iterations yet
   - Risk of overfitting is manageable

3. REJECT: Should stop optimization entirely
   - Fundamental strategy issues identified
   - Max iterations reached without meeting criteria
   - High overfitting that can't be fixed
   - Market regime mismatch

4. ABORT: Critical error requiring human intervention
   - System malfunction
   - Data quality issues
   - Inconsistent results

Your decision MUST be based on objective criteria, not feelings.
Be conservative - when in doubt, ITERATE rather than APPROVE.

Respond ONLY in valid JSON format with this exact structure:
{
    "decision": "APPROVE|REJECT|ITERATE|ABORT",
    "confidence": 0-100,
    "summary": "Brief summary of the decision rationale",

    "criteria_check": {
        "sharpe_meets_minimum": true/false,
        "drawdown_within_limit": true/false,
        "overfitting_acceptable": true/false,
        "sufficient_trades": true/false,
        "critic_approved": true/false
    },

    "agent_synthesis": {
        "analyst_key_points": ["point1", "point2"],
        "strategist_contribution": "summary",
        "critic_concerns_addressed": true/false
    },

    "if_approved": {
        "final_parameters": {"param": value},
        "expected_performance": {"metric": value},
        "deployment_notes": ["note1", "note2"],
        "monitoring_recommendations": ["rec1", "rec2"]
    },

    "if_iterate": {
        "focus_areas": ["area1", "area2"],
        "suggested_approach": "what to try next",
        "max_more_iterations": 3
    },

    "if_rejected": {
        "primary_reasons": ["reason1", "reason2"],
        "fundamental_issues": ["issue1"],
        "recommendations": ["what to do instead"]
    },

    "final_report": "Comprehensive final report paragraph"
}"""

    def execute(self, context: AgentContext) -> AgentResult:
        """
        Effectue la validation finale.

        Args:
            context: Contexte complet

        Returns:
            D√©cision finale
        """
        start_time = time.time()

        # V√©rification pr√©liminaire des crit√®res objectifs
        objective_check = self._check_objective_criteria(context)

        # Construire le prompt
        user_prompt = self._build_validation_prompt(context, objective_check)

        # Appeler le LLM
        response = self._call_llm(user_prompt, json_mode=True, temperature=0.2)

        execution_time = (time.time() - start_time) * 1000

        # V√©rifier la r√©ponse
        if not response.content:
            return AgentResult.failure_result(
                self.role,
                "LLM n'a pas retourn√© de r√©ponse",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Parser le JSON
        validation = response.parse_json()
        if validation is None:
            return AgentResult.failure_result(
                self.role,
                f"√âchec parsing JSON: {response.parse_error}",
                execution_time_ms=execution_time,
                raw_llm_response=response,
            )

        # Extraire la d√©cision
        decision_str = validation.get("decision", "ITERATE")
        try:
            decision = ValidationDecision(decision_str)
        except ValueError:
            decision = ValidationDecision.ITERATE
            validation["decision"] = "ITERATE"

        # Valider la coh√©rence d√©cision/crit√®res
        decision = self._validate_decision_coherence(decision, objective_check, validation)
        validation["decision"] = decision.value

        # Extraire les donn√©es selon la d√©cision
        result_data = {
            "validation": validation,
            "decision": decision.value,
            "confidence": validation.get("confidence", 50),
            "criteria_check": validation.get("criteria_check", objective_check),
            "final_report": validation.get("final_report", ""),
        }

        if decision == ValidationDecision.APPROVE:
            result_data["approved_config"] = validation.get("if_approved", {})
        elif decision == ValidationDecision.ITERATE:
            result_data["iterate_guidance"] = validation.get("if_iterate", {})
        elif decision == ValidationDecision.REJECT:
            result_data["rejection_details"] = validation.get("if_rejected", {})

        return AgentResult.success_result(
            self.role,
            content=validation.get("summary", ""),
            data=result_data,
            execution_time_ms=execution_time,
            tokens_used=response.total_tokens,
            llm_calls=1,
            raw_llm_response=response,
        )

    def _check_objective_criteria(self, context: AgentContext) -> Dict[str, bool]:
        """V√©rifie les crit√®res objectifs."""
        checks = {
            "sharpe_meets_minimum": False,
            "drawdown_within_limit": False,
            "overfitting_acceptable": False,
            "sufficient_trades": False,
            "critic_approved": False,
        }

        if context.current_metrics:
            metrics = context.current_metrics
            checks["sharpe_meets_minimum"] = metrics.sharpe_ratio >= context.min_sharpe
            checks["drawdown_within_limit"] = abs(metrics.max_drawdown) <= context.max_drawdown_limit
            checks["sufficient_trades"] = metrics.total_trades >= context.min_trades

        # V√©rifier overfitting
        if context.overfitting_ratio > 0:
            checks["overfitting_acceptable"] = context.overfitting_ratio <= context.max_overfitting_ratio
        else:
            # Si pas de walk-forward, consid√©rer acceptable par d√©faut
            checks["overfitting_acceptable"] = True

        # V√©rifier si le critic a approuv√©
        if context.strategist_proposals:
            # Chercher des propositions approuv√©es par le critic
            for prop in context.strategist_proposals:
                eval_data = prop.get("critic_evaluation", {})
                if eval_data.get("recommendation") == "APPROVE":
                    checks["critic_approved"] = True
                    break

        return checks

    def _build_validation_prompt(
        self,
        context: AgentContext,
        objective_check: Dict[str, bool],
    ) -> str:
        """Construit le prompt de validation via template Jinja2."""

        # Convertir MetricsSnapshot en dict pour le template
        current_metrics_dict = None
        if context.current_metrics:
            current_metrics_dict = context.current_metrics.to_dict()

        train_metrics_dict = None
        if context.train_metrics:
            train_metrics_dict = context.train_metrics.to_dict()

        test_metrics_dict = None
        if context.test_metrics:
            test_metrics_dict = context.test_metrics.to_dict()

        best_metrics_dict = None
        if context.best_metrics:
            best_metrics_dict = context.best_metrics.to_dict()

        template_context = {
            "strategy_name": context.strategy_name,
            "strategy_description": context.strategy_description,
            "iteration": context.iteration,
            "comparison_context": context.comparison_context,
            "objective_check": objective_check,
            "current_metrics": current_metrics_dict,
            "min_sharpe": context.min_sharpe,
            "max_drawdown_limit": context.max_drawdown_limit,
            "min_trades": context.min_trades,
            "overfitting_ratio": context.overfitting_ratio,
            "max_overfitting_ratio": context.max_overfitting_ratio,
            "classic_ratio": context.classic_ratio,
            "degradation_pct": context.degradation_pct,
            "test_stability_std": context.test_stability_std,
            "n_valid_folds": context.n_valid_folds,
            "walk_forward_windows": context.walk_forward_windows,
            "train_metrics": train_metrics_dict,
            "test_metrics": test_metrics_dict,
            "analyst_report": context.analyst_report,
            "strategist_proposals": context.strategist_proposals,
            "critic_concerns": context.critic_concerns,
            "iteration_history": context.iteration_history,
            "best_metrics": best_metrics_dict,
            "current_params": context.current_params,
            "memory_summary": context.memory_summary,
            "strategy_indicators_context": context.strategy_indicators_context,
            "readonly_indicators_context": context.readonly_indicators_context,
            "indicator_context_warnings": context.indicator_context_warnings,
        }

        return render_prompt("validator.jinja2", template_context)

    def _validate_decision_coherence(
        self,
        decision: ValidationDecision,
        objective_check: Dict[str, bool],
        validation: Dict[str, Any],
    ) -> ValidationDecision:
        """
        Valide la coh√©rence entre la d√©cision et les crit√®res.

        Emp√™che les d√©cisions incoh√©rentes (ex: APPROVE sans meeting criteria).
        """
        all_criteria_met = all(objective_check.values())

        # Ne pas APPROVE si tous les crit√®res ne sont pas remplis
        if decision == ValidationDecision.APPROVE and not all_criteria_met:
            logger.warning(
                "D√©cision APPROVE incoh√©rente avec crit√®res non remplis. "
                "Changement en ITERATE."
            )
            return ValidationDecision.ITERATE

        # Ne pas REJECT si on peut encore it√©rer et que c'est prometteur
        # (ceci est g√©r√© par l'orchestrator)

        return decision
```
<!-- MODULE-END: validator.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "agents\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `agents\__init__.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Agents LLM Module
=================================

Syst√®me d'optimisation autonome par agents LLM.

Architecture:
- Orchestrator: State machine du workflow multi-agents
- 4 Agents specialises: Analyst, Strategist, Critic, Validator
- AutonomousStrategist: agent autonome capable de lancer des backtests
- BacktestExecutor: interface pour executer des backtests depuis les agents
- State Machine: transitions validees a chaque etape

Workflows:

1. Mode Orchestre (multi-agents, backtests si callback fourni):
    INIT -> ANALYZE -> PROPOSE -> CRITIQUE -> VALIDATE -> ITERATE -> ...
    Terminaison: APPROVED / REJECTED / FAILED

2. Mode Autonome (avec backtests r√©els):
    >>> strategist.optimize(executor, params, bounds) ‚Üí OptimizationSession

Usage Mode Autonome (RECOMMAND√â):
    >>> from agents import create_autonomous_optimizer
    >>> from agents.llm_client import LLMConfig, LLMProvider
    >>>
    >>> config = LLMConfig(provider=LLMProvider.OLLAMA, model="llama3.2")
    >>> strategist, executor = create_autonomous_optimizer(
    ...     llm_config=config,
    ...     backtest_fn=my_backtest_function,
    ...     strategy_name="ema_cross",
    ...     data=ohlcv_df,
    ... )
    >>>
    >>> session = strategist.optimize(
    ...     executor=executor,
    ...     initial_params={"fast": 10, "slow": 21},
    ...     param_bounds={"fast": (5, 20), "slow": (15, 50)},
    ...     max_iterations=10,
    ... )
    >>> print(f"Best: {session.best_result.sharpe_ratio}")

Usage Mode Orchestre (analysis-only si aucun callback de backtest):
    >>> from agents import Orchestrator, OrchestratorConfig
    >>>
    >>> config = OrchestratorConfig(
    ...     strategy_name="ema_cross",
    ...     data_path="data/BTCUSDT_1h.parquet",
    ...     on_backtest_needed=my_backtest_callback,
    ...     max_iterations=10,
    ... )
    >>> orchestrator = Orchestrator(config)
    >>> result = orchestrator.run()
"""

import logging
import os
import sys


def _configure_agents_logger() -> None:
    """
    Force un handler stdout d√©di√© pour les logs des agents afin de contourner
    une configuration du logger racine trop restrictive.
    """
    if os.getenv("AGENTS_FORCE_STDOUT", "1") == "0":
        return

    level_name = os.getenv("AGENTS_LOG_LEVEL", "INFO").upper()
    level = getattr(logging, level_name, logging.INFO)

    logger = logging.getLogger("agents")

    # √âviter les handlers en double si d√©j√† configur√©
    if any(getattr(h, "_agents_force_stdout", False) for h in logger.handlers):
        return

    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(level)
    handler.setFormatter(logging.Formatter(
        "[AGENTS] %(asctime)s | %(levelname)s | %(name)s | %(message)s",
        datefmt="%H:%M:%S",
    ))
    handler._agents_force_stdout = True  # type: ignore[attr-defined]

    logger.addHandler(handler)
    logger.setLevel(level)
    logger.propagate = False


_configure_agents_logger()

from .analyst import AnalystAgent  # noqa: E402
from .autonomous_strategist import (  # noqa: E402
    AutonomousStrategist,
    IterationDecision,
    OptimizationSession,
    create_autonomous_optimizer,
)
from .backtest_executor import (  # noqa: E402
    BacktestExecutor,
    BacktestRequest,
    BacktestResult,
    ExperimentHistory,
)
from .base_agent import AgentContext, AgentResult, BaseAgent  # noqa: E402
from .critic import CriticAgent  # noqa: E402
from .integration import (  # noqa: E402
    create_optimizer_from_engine,
    create_orchestrator_with_backtest,
    get_strategy_param_bounds,
    get_strategy_param_space,
    quick_optimize,
    run_backtest_for_agent,
    run_walk_forward_for_agent,
)
from .llm_client import (  # noqa: E402
    LLMClient,
    LLMConfig,
    LLMProvider,
    LLMResponse,
    OllamaClient,
    OpenAIClient,
    create_llm_client,
)
from .model_config import (  # noqa: E402
    KNOWN_MODELS,
    ModelCategory,
    ModelInfo,
    RoleModelAssignment,
    RoleModelConfig,
    get_global_model_config,
    get_models_by_category,
    list_available_models,
    set_global_model_config,
)
from .ollama_manager import (  # noqa: E402
    # GPU Memory Management
    GPUMemoryManager,
    LLMMemoryState,
    cleanup_all_models,
    ensure_ollama_running,
    gpu_compute_context,
    is_ollama_available,
    list_ollama_models,
    prepare_for_llm_run,
    unload_model,
)
from .orchestrator import Orchestrator, OrchestratorConfig, OrchestratorResult  # noqa: E402
from .state_machine import (  # noqa: E402
    AgentState,
    StateMachine,
    StateTransition,
    ValidationResult,
)
from .strategist import StrategistAgent  # noqa: E402
from .validator import ValidatorAgent  # noqa: E402

__all__ = [
    # State Machine
    "AgentState",
    "StateTransition",
    "StateMachine",
    "ValidationResult",
    # LLM
    "LLMClient",
    "LLMConfig",
    "LLMResponse",
    "LLMProvider",
    "OllamaClient",
    "OpenAIClient",
    "create_llm_client",
    # Agents
    "BaseAgent",
    "AgentContext",
    "AgentResult",
    "AnalystAgent",
    "StrategistAgent",
    "CriticAgent",
    "ValidatorAgent",
    # Autonomous Mode (RECOMMENDED)
    "AutonomousStrategist",
    "BacktestExecutor",
    "BacktestRequest",
    "BacktestResult",
    "ExperimentHistory",
    "IterationDecision",
    "OptimizationSession",
    "create_autonomous_optimizer",
    # Integration (FULL STACK)
    "run_backtest_for_agent",
    "run_walk_forward_for_agent",
    "create_optimizer_from_engine",
    "get_strategy_param_bounds",
    "get_strategy_param_space",
    "quick_optimize",
    "create_orchestrator_with_backtest",
    # Orchestrator (Static Mode)
    "Orchestrator",
    "OrchestratorConfig",
    "OrchestratorResult",
    # Ollama Manager
    "ensure_ollama_running",
    "unload_model",
    "cleanup_all_models",
    "list_ollama_models",
    "is_ollama_available",
    "prepare_for_llm_run",
    # GPU Memory Management
    "GPUMemoryManager",
    "LLMMemoryState",
    "gpu_compute_context",
    # Multi-Model Configuration
    "ModelCategory",
    "ModelInfo",
    "RoleModelAssignment",
    "RoleModelConfig",
    "KNOWN_MODELS",
    "list_available_models",
    "get_models_by_category",
    "get_global_model_config",
    "set_global_model_config",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: engine.py -->
```json
{
  "name": "engine.py",
  "path": "backtest\\engine.py",
  "ext": ".py",
  "anchor": "engine_py"
}
```
## engine_py
*Chemin* : `backtest\engine.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Backtest Engine
===============================

Moteur de backtesting simplifi√© et robuste.

Pipeline:
1. Charger les donn√©es (ou recevoir un DataFrame)
2. Calculer les indicateurs requis par la strat√©gie
3. G√©n√©rer les signaux de trading
4. Simuler les trades
5. Calculer les m√©triques de performance
6. Retourner le r√©sultat complet
"""

from __future__ import annotations

import time
from dataclasses import dataclass, field
from typing import Any, Dict, Optional, Union

import numpy as np
import pandas as pd

from strategies.base import StrategyBase

from backtest.performance import calculate_metrics

# Import simulateur rapide (Numba) avec fallback
try:
    from backtest.simulator_fast import (
        simulate_trades_fast,
        calculate_equity_fast,
        calculate_returns_fast,
        HAS_NUMBA,
    )
    USE_FAST_SIMULATOR = True
except ImportError:
    USE_FAST_SIMULATOR = False
    HAS_NUMBA = False

# Import simulateur standard (fallback)
from backtest.simulator import (
    calculate_equity_curve,
    calculate_returns,
    simulate_trades,
)
from indicators.registry import calculate_indicator
from utils.config import Config
from utils.observability import (
    get_obs_logger,
    generate_run_id,
    trace_span,
    safe_stats_df,
    PerfCounters,
    build_diagnostic_summary,
)

# Logger par d√©faut (sans run_id)
_default_logger = get_obs_logger(__name__)


@dataclass
class RunResult:
    """
    R√©sultat d'ex√©cution d'un backtest.

    Attributes:
        equity: Courbe d'√©quit√© (pd.Series index√©e par datetime)
        returns: Rendements par p√©riode (pd.Series)
        trades: DataFrame des trades ex√©cut√©s
        metrics: Dict des m√©triques de performance calcul√©es
        meta: M√©tadonn√©es d'ex√©cution (dur√©e, param√®tres, etc.)
    """
    equity: pd.Series
    returns: pd.Series
    trades: pd.DataFrame
    metrics: Dict[str, Any] = field(default_factory=dict)
    meta: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Validation des donn√©es."""
        if not isinstance(self.equity, pd.Series):
            raise TypeError("equity doit √™tre une pd.Series")
        if not isinstance(self.returns, pd.Series):
            raise TypeError("returns doit √™tre une pd.Series")
        if not isinstance(self.trades, pd.DataFrame):
            raise TypeError("trades doit √™tre un pd.DataFrame")

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel du r√©sultat."""
        n_trades = len(self.trades)
        total_pnl = self.metrics.get("total_pnl", 0)
        sharpe = self.metrics.get("sharpe_ratio", 0)
        max_dd = self.metrics.get("max_drawdown", 0)
        win_rate = self.metrics.get("win_rate", 0)

        return f"""
Backtest Summary
================
Trades: {n_trades}
Total P&L: ${total_pnl:,.2f}
Sharpe Ratio: {sharpe:.2f}
Max Drawdown: {max_dd:.1f}%
Win Rate: {win_rate:.1f}%
"""


class BacktestEngine:
    """
    Moteur de backtesting principal.

    Orchestrateur simplifi√© qui ex√©cute le pipeline complet:
    donn√©es ‚Üí indicateurs ‚Üí signaux ‚Üí trades ‚Üí m√©triques

    Usage:
        engine = BacktestEngine()
        result = engine.run(
            df=ohlcv_data,
            strategy=BollingerATRStrategy(),
            params={"entry_z": 2.0, "k_sl": 1.5, "leverage": 3}
        )
        print(result.summary())

    Architecture modulaire pour extension future:
    - Strat√©gies interchangeables via interface StrategyBase
    - Indicateurs via registre extensible
    - Pr√™t pour r√©int√©gration LLM (strategy_instance param√®tre)
    """

    def __init__(
        self,
        initial_capital: float = 10000.0,
        config: Optional[Config] = None,
        run_id: Optional[str] = None,
    ):
        """
        Initialise le moteur.

        Args:
            initial_capital: Capital de d√©part
            config: Configuration (optionnel)
            run_id: Identifiant de corr√©lation (g√©n√©r√© si None)
        """
        self.initial_capital = initial_capital
        self.config = config or Config()
        self.run_id = run_id or generate_run_id()
        self.logger = get_obs_logger(__name__, run_id=self.run_id)
        self.last_run_meta: Dict[str, Any] = {}
        self.counters: Optional[PerfCounters] = None

        self.logger.info("BacktestEngine init capital=%s", initial_capital)

    def run(
        self,
        df: pd.DataFrame,
        strategy: Union[StrategyBase, str],
        params: Optional[Dict[str, Any]] = None,
        *,
        symbol: str = "UNKNOWN",
        timeframe: str = "1m",
        seed: int = 42,
        silent_mode: bool = False,
        fast_metrics: bool = False
    ) -> RunResult:
        """
        Ex√©cute un backtest complet.

        Args:
            df: DataFrame OHLCV avec colonnes (open, high, low, close, volume)
            strategy: Instance de strat√©gie ou nom de strat√©gie
            params: Param√®tres de trading et strat√©gie
            symbol: Symbole de l'actif (pour logging)
            timeframe: Timeframe des donn√©es (pour ajustements)
            seed: Seed pour reproductibilit√©
            silent_mode: Si True, d√©sactive les logs structur√©s pour am√©liorer les performances en grid search
            fast_metrics: Si True, utilise calculs rapides (ignor√© dans version restaur√©e)

        Returns:
            RunResult avec equity, returns, trades, metrics et meta

        Raises:
            ValueError: Si donn√©es ou param√®tres invalides
        """
        # Initialiser counters et contexte
        self.counters = PerfCounters()
        self.counters.start("total")

        # Enrichir le logger avec contexte
        self.logger = self.logger.with_context(symbol=symbol, timeframe=timeframe)
        if not silent_mode:
            self.logger.info("pipeline_start strategy=%s bars=%s",
                             strategy if isinstance(strategy, str) else getattr(strategy, 'name', 'custom'),
                             len(df))

        # Seed pour d√©terminisme
        np.random.seed(seed)

        try:
            # 1. Validation des entr√©es
            with trace_span(self.logger, "validation"):
                self._validate_inputs(df, strategy, params)

            # 2. Pr√©parer la strat√©gie
            if isinstance(strategy, str):
                strategy = self._get_strategy_by_name(strategy)

            strategy_name = strategy.name
            self.logger = self.logger.with_context(strategy=strategy_name)

            # 3. Fusionner param√®tres
            final_params = {
                "initial_capital": self.initial_capital,
                "fees_bps": self.config.fees_bps,
                "slippage_bps": self.config.slippage_bps,
                **strategy.default_params,
                **(params or {})
            }

            self.logger.debug("params=%s", final_params)

            # 4. Calculer les indicateurs requis
            self.counters.start("indicators")
            with trace_span(self.logger, "indicators", count=len(strategy.required_indicators)):
                indicators = self._calculate_indicators(df, strategy, final_params)
            self.counters.stop("indicators")

            # 5. G√©n√©rer les signaux
            self.counters.start("signals")
            with trace_span(self.logger, "signals"):
                signals = strategy.generate_signals(df, indicators, final_params)
                n_signals = int((signals != 0).sum())
            self.counters.stop("signals")
            self.counters.increment("signals_count", n_signals)
            self.logger.debug("signals_generated count=%s", n_signals)

            # 6. Simuler les trades (utilise version rapide si disponible)
            self.counters.start("simulation")
            with trace_span(self.logger, "simulation"):
                if USE_FAST_SIMULATOR:
                    trades_df = simulate_trades_fast(df, signals, final_params)
                else:
                    trades_df = simulate_trades(df, signals, final_params)
            self.counters.stop("simulation")
            self.counters.increment("trades_count", len(trades_df))

            # 7. Calculer √©quit√© et rendements (version rapide si disponible)
            self.counters.start("equity")
            if USE_FAST_SIMULATOR:
                equity = calculate_equity_fast(df, trades_df, self.initial_capital)
                returns = calculate_returns_fast(equity)
            else:
                equity = calculate_equity_curve(df, trades_df, self.initial_capital)
                returns = calculate_returns(equity)
            self.counters.stop("equity")

            # 8. Calculer les m√©triques
            self.counters.start("metrics")
            periods_per_year = self._get_periods_per_year(timeframe)
            metrics = calculate_metrics(
                equity=equity,
                returns=returns,
                trades_df=trades_df,
                initial_capital=self.initial_capital,
                periods_per_year=periods_per_year
            )

            # BUGFIX CRITIQUE: Invalider m√©triques si compte ruin√©
            account_ruined = metrics.get("account_ruined", False)
            if account_ruined:
                self.logger.warning(
                    "account_ruined_detected invalidating_performance_metrics original_sharpe=%.2f",
                    metrics.get("sharpe_ratio", 0)
                )
                # Forcer m√©triques de performance √† z√©ro pour coh√©rence
                metrics["sharpe_ratio"] = -20.0  # P√©nalit√© maximale
                metrics["sortino_ratio"] = -20.0
                metrics["calmar_ratio"] = -20.0
                # Note: garder total_pnl pour analyse, mais signaler danger

            # Couverture des donn√©es: ratio barres r√©elles vs barres attendues
            try:
                period_days = max(
                    1,
                    int((df.index[-1] - df.index[0]).total_seconds() / 86400)
                )
                bars_per_day = periods_per_year / 365
                expected_bars = period_days * bars_per_day
                if expected_bars > 0:
                    coverage_ratio = min(1.0, len(df) / expected_bars)
                    metrics["data_coverage_pct"] = coverage_ratio * 100.0
            except Exception:
                pass

            self.counters.stop("metrics")

            # 9. Construire les m√©tadonn√©es
            self.counters.stop("total")
            total_ms = self.counters.get_duration("total")

            meta = {
                "run_id": self.run_id,
                "symbol": symbol,
                "timeframe": timeframe,
                "strategy": strategy_name,
                "params": final_params,
                "duration_sec": total_ms / 1000,
                "n_bars": len(df),
                "period_start": str(df.index[0]),
                "period_end": str(df.index[-1]),
                "seed": seed,
                "perf_counters": self.counters.summary(),
            }

            self.last_run_meta = meta

            # 10. Construire le r√©sultat
            result = RunResult(
                equity=equity,
                returns=returns,
                trades=trades_df,
                metrics=metrics,
                meta=meta
            )

            if not silent_mode:
                self.logger.info(
                    "pipeline_end duration_ms=%.1f trades=%s sharpe=%.2f pnl=%.2f",
                    total_ms, len(trades_df), metrics.get('sharpe_ratio', 0), metrics.get('total_pnl', 0)
                )

            return result

        except Exception as e:
            self.counters.stop("total")
            self.logger.error("pipeline_error error=%s", str(e))
            raise

    def _validate_inputs(
        self,
        df: pd.DataFrame,
        strategy: Union[StrategyBase, str],
        params: Optional[Dict[str, Any]]
    ) -> None:
        """Valide les entr√©es du backtest."""

        # Validation DataFrame
        if df.empty:
            raise ValueError("DataFrame vide")

        required_cols = ["open", "high", "low", "close", "volume"]
        missing = [col for col in required_cols if col not in df.columns]
        if missing:
            raise ValueError(f"Colonnes manquantes: {missing}")

        if not isinstance(df.index, pd.DatetimeIndex):
            raise ValueError("L'index doit √™tre DatetimeIndex")

        # Validation strat√©gie
        if not isinstance(strategy, (StrategyBase, str)):
            raise TypeError("strategy doit √™tre StrategyBase ou str")

        self.logger.debug("‚úÖ Validation des entr√©es OK")

    def _get_strategy_by_name(self, name: str) -> StrategyBase:
        """R√©cup√®re une strat√©gie par son nom depuis le registre global."""
        from strategies.base import get_strategy, list_strategies

        name_lower = name.lower().replace("-", "_").replace(" ", "_")

        try:
            strategy_class = get_strategy(name_lower)
            return strategy_class()
        except ValueError:
            available = ", ".join(list_strategies())
            raise ValueError(f"Strat√©gie inconnue: '{name}'. Disponibles: {available}")

    def _calculate_indicators(
        self,
        df: pd.DataFrame,
        strategy: StrategyBase,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Calcule les indicateurs requis par la strat√©gie."""
        indicators = {}

        for indicator_name in strategy.required_indicators:
            self.logger.debug(f"  Calcul indicateur: {indicator_name}")

            # Extraire les param√®tres sp√©cifiques √† l'indicateur
            indicator_params = self._extract_indicator_params(indicator_name, params)

            try:
                indicators[indicator_name] = calculate_indicator(
                    indicator_name, df, indicator_params
                )
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è Erreur calcul {indicator_name}: {e}")
                indicators[indicator_name] = None

        return indicators

    def _extract_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extrait les param√®tres sp√©cifiques √† un indicateur."""

        # Mapping des pr√©fixes de param√®tres
        prefix_map = {
            "bollinger": "bb_",
            "atr": "atr_",
            "rsi": "rsi_",
            "ema": "ema_"
        }

        prefix = prefix_map.get(indicator_name, f"{indicator_name}_")
        indicator_params = {}

        # Extraire les param√®tres avec le pr√©fixe
        for key, value in params.items():
            if key.startswith(prefix):
                # Enlever le pr√©fixe
                param_name = key[len(prefix):]
                indicator_params[param_name] = value

        # Param√®tres directs (sans pr√©fixe mais reconnus)
        direct_params = {
            "bollinger": ["period", "std_dev"],
            "atr": ["period", "method"],
            "rsi": ["period"],
            "ema": ["period"]
        }

        for param in direct_params.get(indicator_name, []):
            if param in params and param not in indicator_params:
                indicator_params[param] = params[param]

        return indicator_params

    def _get_periods_per_year(self, timeframe: str) -> int:
        """Retourne le nombre de p√©riodes par an pour un timeframe."""
        timeframe_periods = {
            "1m": 365 * 24 * 60,      # 525600
            "5m": 365 * 24 * 12,      # 105120
            "15m": 365 * 24 * 4,      # 35040
            "30m": 365 * 24 * 2,      # 17520
            "1h": 365 * 24,           # 8760
            "4h": 365 * 6,            # 2190
            "1d": 365,                # 365
            "1w": 52                  # 52
        }

        return timeframe_periods.get(timeframe, 365 * 24 * 60)


# Fonction utilitaire pour usage simplifi√©
def quick_backtest(
    df: pd.DataFrame,
    strategy_name: str = "bollinger_atr",
    **params
) -> RunResult:
    """
    Lance un backtest rapide avec param√®tres par d√©faut.

    Usage:
        result = quick_backtest(df, "bollinger_atr", leverage=3)
    """
    engine = BacktestEngine()
    return engine.run(df, strategy_name, params)


__all__ = ["BacktestEngine", "RunResult", "quick_backtest"]
```
<!-- MODULE-END: engine.py -->

<!-- MODULE-START: errors.py -->
```json
{
  "name": "errors.py",
  "path": "backtest\\errors.py",
  "ext": ".py",
  "anchor": "errors_py"
}
```
## errors_py
*Chemin* : `backtest\errors.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.errors

Purpose: Hi√©rarchie structur√©e d'exceptions pour distinguer erreurs utilisateur/syst√®me et messages UI coh√©rents.

Role in pipeline: error handling

Key components: BacktestError, UserInputError, DataError, BackendInternalError, LLMUnavailableError

Inputs: message, code, hint, details

Outputs: Exceptions s√©rialisables en dict (code, message, hint, details)

Dependencies: dataclasses, typing

Conventions: Codes error en UPPER_SNAKE_CASE; hints destin√©s utilisateurs (non techniques); details pour logs/debug; to_dict() pour s√©rialisation UI.

Read-if: Gestion erreurs backend/UI, codes erreur, ou messages utilisateur.

Skip-if: Vous n'ajoutez pas de nouveaux types d'erreurs.
"""

from __future__ import annotations

from typing import Any, Dict, Optional


class BacktestError(Exception):
    """
    Exception de base pour toutes les erreurs du moteur de backtest.

    Attributes:
        message: Message d'erreur
        code: Code d'erreur court (pour logs)
        hint: Suggestion de correction pour l'utilisateur
        details: D√©tails techniques (optionnel)
    """

    def __init__(
        self,
        message: str,
        code: str = "BACKTEST_ERROR",
        hint: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(message)
        self.message = message
        self.code = code
        self.hint = hint
        self.details = details or {}

    def __str__(self) -> str:
        return f"[{self.code}] {self.message}"

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise l'erreur en dict."""
        return {
            "code": self.code,
            "message": self.message,
            "hint": self.hint,
            "details": self.details,
        }


class UserInputError(BacktestError):
    """
    Erreur due √† une entr√©e utilisateur invalide.

    Exemples:
    - Param√®tre hors limites
    - Strat√©gie inconnue
    - fast_period >= slow_period
    """

    def __init__(
        self,
        message: str,
        param_name: Optional[str] = None,
        expected: Optional[str] = None,
        got: Optional[Any] = None,
        hint: Optional[str] = None
    ):
        details = {}
        if param_name:
            details["param_name"] = param_name
        if expected:
            details["expected"] = expected
        if got is not None:
            details["got"] = got

        super().__init__(
            message=message,
            code="INVALID_INPUT",
            hint=hint,
            details=details
        )
        self.param_name = param_name
        self.expected = expected
        self.got = got


class DataError(BacktestError):
    """
    Erreur li√©e aux donn√©es OHLCV.

    Exemples:
    - Fichier non trouv√©
    - Colonnes manquantes
    - Index invalide
    - Donn√©es corrompues
    """

    def __init__(
        self,
        message: str,
        symbol: Optional[str] = None,
        timeframe: Optional[str] = None,
        missing_columns: Optional[list] = None,
        hint: Optional[str] = None
    ):
        details = {}
        if symbol:
            details["symbol"] = symbol
        if timeframe:
            details["timeframe"] = timeframe
        if missing_columns:
            details["missing_columns"] = missing_columns

        super().__init__(
            message=message,
            code="DATA_ERROR",
            hint=hint or "V√©rifiez le format et l'emplacement des donn√©es",
            details=details
        )
        self.symbol = symbol
        self.timeframe = timeframe
        self.missing_columns = missing_columns


class InsufficientDataError(DataError):
    """
    Erreur lorsque les donn√©es sont insuffisantes pour le warmup des indicateurs.

    Exemples:
    - Fen√™tre temporelle trop courte (49 barres < 200 requis)
    - P√©riode d'indicateur > donn√©es disponibles
    """

    def __init__(
        self,
        message: str,
        available_bars: Optional[int] = None,
        required_bars: Optional[int] = None,
        symbol: Optional[str] = None,
        timeframe: Optional[str] = None,
        hint: Optional[str] = None
    ):
        details = {}
        if available_bars is not None:
            details["available_bars"] = available_bars
        if required_bars is not None:
            details["required_bars"] = required_bars

        default_hint = "Utilisez une p√©riode plus longue ou v√©rifiez la disponibilit√© des donn√©es"

        super().__init__(
            message=message,
            symbol=symbol,
            timeframe=timeframe,
            hint=hint or default_hint
        )
        self.details.update(details)
        self.available_bars = available_bars
        self.required_bars = required_bars


class BackendInternalError(BacktestError):
    """
    Erreur interne du backend (bug).

    Ces erreurs ne devraient pas arriver en usage normal.
    Elles indiquent un probl√®me dans le code du moteur.
    """

    def __init__(
        self,
        message: str,
        original_exception: Optional[Exception] = None,
        trace_id: Optional[str] = None
    ):
        details = {}
        if original_exception:
            details["original_type"] = type(original_exception).__name__
            details["original_message"] = str(original_exception)
        if trace_id:
            details["trace_id"] = trace_id

        super().__init__(
            message=message,
            code="INTERNAL_ERROR",
            hint="Contactez le support avec le trace_id",
            details=details
        )
        self.original_exception = original_exception
        self.trace_id = trace_id


class LLMUnavailableError(BacktestError):
    """
    Erreur lorsque le module LLM n'est pas disponible.

    Peut √™tre caus√©e par:
    - Import manquant
    - Ollama non d√©marr√©
    - Cl√© API invalide
    """

    def __init__(
        self,
        message: str,
        provider: Optional[str] = None,
        reason: Optional[str] = None
    ):
        details = {}
        if provider:
            details["provider"] = provider
        if reason:
            details["reason"] = reason

        hint = "V√©rifiez l'installation des d√©pendances agents"
        if provider and provider.lower() == "ollama":
            hint = "V√©rifiez que Ollama est install√© et d√©marr√© (ollama serve)"
        elif provider and provider.lower() == "openai":
            hint = "V√©rifiez votre cl√© API OpenAI"

        super().__init__(
            message=message,
            code="LLM_UNAVAILABLE",
            hint=hint,
            details=details
        )
        self.provider = provider
        self.reason = reason


class StrategyNotFoundError(UserInputError):
    """
    Erreur lorsqu'une strat√©gie n'existe pas.
    """

    def __init__(self, strategy_name: str, available: list = None):
        available_str = ", ".join(available) if available else "?"
        super().__init__(
            message=f"Strat√©gie '{strategy_name}' non trouv√©e",
            param_name="strategy",
            expected=f"Une parmi: {available_str}",
            got=strategy_name,
            hint=f"Strat√©gies disponibles: {available_str}"
        )
        self.strategy_name = strategy_name
        self.available = available or []


class ParameterValidationError(UserInputError):
    """
    Erreur de validation d'un param√®tre sp√©cifique.
    """

    def __init__(
        self,
        param_name: str,
        message: str,
        min_value: Optional[float] = None,
        max_value: Optional[float] = None,
        current_value: Optional[Any] = None
    ):
        expected = None
        if min_value is not None and max_value is not None:
            expected = f"[{min_value}, {max_value}]"
        elif min_value is not None:
            expected = f">= {min_value}"
        elif max_value is not None:
            expected = f"<= {max_value}"

        super().__init__(
            message=message,
            param_name=param_name,
            expected=expected,
            got=current_value,
            hint=f"Ajustez '{param_name}' pour qu'il soit dans la plage valide"
        )


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur hi√©rarchie d'exceptions
# - Conventions codes et s√©rialisation to_dict() explicit√©es
# - Read-if/Skip-if ajout√©s pour tri rapide
        self.min_value = min_value
        self.max_value = max_value
        self.current_value = current_value
```
<!-- MODULE-END: errors.py -->

<!-- MODULE-START: execution.py -->
```json
{
  "name": "execution.py",
  "path": "backtest\\execution.py",
  "ext": ".py",
  "anchor": "execution_py"
}
```
## execution_py
*Chemin* : `backtest\execution.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.execution

Purpose: Mod√©liser l'ex√©cution r√©aliste (spread bid/ask, slippage, latence, impact march√©).

Role in pipeline: execution

Key components: ExecutionModel, ExecutionConfig, SpreadCalculator, SlippageCalculator

Inputs: Prix OHLCV, volatilit√©, volume, mod√®le (IDEAL/FIXED/DYNAMIC/REALISTIC)

Outputs: Spread/slippage appliqu√©s au prix d'ex√©cution

Dependencies: numpy, pandas, utils.log, optionnel: backtest.execution_fast (Numba)

Conventions: Spread en bps; slippage en fractions; latence en ms; mod√®les IDEAL < FIXED < DYNAMIC < REALISTIC en r√©alisme; optimisation 50-100x via Numba si dispo.

Read-if: Configuration r√©alisme ex√©cution, calcul spread/slippage, ou modification frais/latence.

Skip-if: Backtests acad√©miques (IDEAL model suffisant).
"""

from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, Optional, Tuple

import numpy as np
import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)

# Import fonctions optimis√©es (Numba si disponible)
try:
    from backtest.execution_fast import (
        HAS_NUMBA,
        high_low_spread,
        roll_spread,
    )
    USE_FAST_EXECUTION = True
    logger.debug(f"Execution optimizations: Numba={'available' if HAS_NUMBA else 'unavailable'}")
except ImportError:
    USE_FAST_EXECUTION = False
    HAS_NUMBA = False
    logger.debug("Execution optimizations: disabled")


class ExecutionModel(Enum):
    """Mod√®les d'ex√©cution disponibles."""
    IDEAL = "ideal"           # Ex√©cution instantan√©e au prix demand√©
    FIXED = "fixed"           # Spread/slippage fixes
    DYNAMIC = "dynamic"       # Spread/slippage dynamiques
    REALISTIC = "realistic"   # Mod√®le complet avec impact


@dataclass
class ExecutionConfig:
    """
    Configuration du mod√®le d'ex√©cution.

    Attributes:
        model: Type de mod√®le d'ex√©cution
        spread_bps: Spread fixe en basis points (pour FIXED)
        slippage_bps: Slippage fixe en basis points (pour FIXED)
        latency_ms: Latence d'ex√©cution en millisecondes
        use_volatility_spread: Ajuster spread selon volatilit√©
        use_volume_slippage: Ajuster slippage selon volume
        market_impact_bps: Impact de march√© par unit√© de taille
        min_spread_bps: Spread minimum
        max_spread_bps: Spread maximum
        volatility_window: Fen√™tre pour calcul volatilit√©
        volume_window: Fen√™tre pour calcul volume moyen
    """
    model: ExecutionModel = ExecutionModel.DYNAMIC

    # Param√®tres fixes
    spread_bps: float = 5.0
    slippage_bps: float = 3.0
    latency_ms: float = 50.0

    # Param√®tres dynamiques
    use_volatility_spread: bool = True
    use_volume_slippage: bool = True
    market_impact_bps: float = 0.0  # D√©sactiv√© par d√©faut

    # Bornes
    min_spread_bps: float = 1.0
    max_spread_bps: float = 50.0
    min_slippage_bps: float = 0.5
    max_slippage_bps: float = 30.0

    # Fen√™tres de calcul
    volatility_window: int = 20
    volume_window: int = 20

    # Facteurs de scaling
    volatility_spread_factor: float = 2.0  # Multiplie la volatilit√© normalis√©e
    volume_slippage_factor: float = 1.5    # Impact du ratio de volume

    # Optional partial fills (only for REALISTIC)
    partial_fill_prob: float = 0.0
    partial_fill_min: float = 0.5
    partial_fill_max: float = 1.0

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "model": self.model.value,
            "spread_bps": self.spread_bps,
            "slippage_bps": self.slippage_bps,
            "latency_ms": self.latency_ms,
            "use_volatility_spread": self.use_volatility_spread,
            "use_volume_slippage": self.use_volume_slippage,
            "market_impact_bps": self.market_impact_bps,
            "min_spread_bps": self.min_spread_bps,
            "max_spread_bps": self.max_spread_bps,
            "partial_fill_prob": self.partial_fill_prob,
            "partial_fill_min": self.partial_fill_min,
            "partial_fill_max": self.partial_fill_max,
        }


@dataclass
class ExecutionResult:
    """
    R√©sultat d'une ex√©cution.

    Attributes:
        executed_price: Prix d'ex√©cution final
        requested_price: Prix demand√© original
        spread_cost: Co√ªt du spread en valeur absolue
        slippage_cost: Co√ªt du slippage en valeur absolue
        market_impact: Impact de march√© en valeur absolue
        latency_bars: Nombre de barres de latence appliqu√©es
        total_cost_bps: Co√ªt total en basis points
    """
    executed_price: float
    requested_price: float
    spread_cost: float = 0.0
    slippage_cost: float = 0.0
    market_impact: float = 0.0
    latency_bars: int = 0
    filled_size: float = 0.0
    fill_ratio: float = 1.0

    @property
    def total_cost(self) -> float:
        """Co√ªt total d'ex√©cution."""
        return self.spread_cost + self.slippage_cost + self.market_impact

    @property
    def total_cost_bps(self) -> float:
        """Co√ªt total en basis points."""
        if self.requested_price == 0:
            return 0.0
        return (self.total_cost / self.requested_price) * 10000

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "executed_price": self.executed_price,
            "requested_price": self.requested_price,
            "spread_cost": self.spread_cost,
            "slippage_cost": self.slippage_cost,
            "market_impact": self.market_impact,
            "latency_bars": self.latency_bars,
            "total_cost_bps": self.total_cost_bps,
            "filled_size": self.filled_size,
            "fill_ratio": self.fill_ratio,
        }


class ExecutionEngine:
    """
    Moteur d'ex√©cution r√©aliste.

    Calcule les prix d'ex√©cution en tenant compte du spread,
    slippage, latence et impact de march√©.

    Example:
        >>> config = ExecutionConfig(model=ExecutionModel.DYNAMIC)
        >>> engine = ExecutionEngine(config)
        >>> engine.prepare(df)  # Pr√©calcule volatilit√©, volume
        >>> result = engine.execute_order(price=100.0, side=1, bar_idx=50)
    """

    def __init__(self, config: Optional[ExecutionConfig] = None):
        """
        Initialise le moteur d'ex√©cution.

        Args:
            config: Configuration d'ex√©cution (d√©faut: ExecutionConfig())
        """
        self.config = config or ExecutionConfig()
        self._prepared = False

        # Donn√©es pr√©calcul√©es
        self._volatility: Optional[np.ndarray] = None
        self._normalized_volatility: Optional[np.ndarray] = None
        self._volume_ratio: Optional[np.ndarray] = None
        self._bar_duration_ms: float = 0.0

        logger.debug(f"ExecutionEngine initialis√©: {self.config.model.value}")

    def prepare(self, df: pd.DataFrame) -> None:
        """
        Pr√©calcule les m√©triques n√©cessaires √† partir des donn√©es OHLCV.

        Args:
            df: DataFrame OHLCV avec colonnes 'close', 'high', 'low', 'volume'
        """
        n = len(df)

        if n < 2:
            logger.warning("Donn√©es insuffisantes pour prepare()")
            self._prepared = False
            return

        # Calculer la dur√©e d'une barre en ms
        if isinstance(df.index, pd.DatetimeIndex) and len(df.index) >= 2:
            delta = (df.index[1] - df.index[0]).total_seconds() * 1000
            self._bar_duration_ms = delta
        else:
            self._bar_duration_ms = 60000  # D√©faut: 1 minute

        closes = df["close"].values

        # === Volatilit√© (VECTORIS√â) ===
        if self.config.use_volatility_spread:
            returns = np.zeros(n)
            returns[1:] = np.diff(closes) / closes[:-1]

            window = self.config.volatility_window

            # Calcul vectoris√© avec pandas rolling (100x plus rapide)
            returns_series = pd.Series(returns)
            volatility_series = returns_series.rolling(window=window, min_periods=window).std()
            self._volatility = volatility_series.bfill().values

            # Normaliser (0-1 scale bas√© sur percentiles)
            if np.max(self._volatility) > 0:
                # S'assurer que la tranche n'est pas vide
                start_idx = min(window, len(self._volatility) - 1)
                vol_slice = self._volatility[start_idx:]

                if len(vol_slice) > 0:
                    p10 = np.percentile(vol_slice, 10)
                    p90 = np.percentile(vol_slice, 90)
                    self._normalized_volatility = np.clip(
                        (self._volatility - p10) / (p90 - p10 + 1e-10),
                        0, 1
                    )
                else:
                    # Fen√™tre trop grande, utiliser des valeurs par d√©faut
                    self._normalized_volatility = np.ones_like(self._volatility) * 0.5
            else:
                self._normalized_volatility = np.zeros(n)
        else:
            self._volatility = np.zeros(n)
            self._normalized_volatility = np.zeros(n)

        # === Volume ratio (VECTORIS√â) ===
        if self.config.use_volume_slippage and "volume" in df.columns:
            volumes = df["volume"].values
            window = self.config.volume_window

            # Calcul vectoris√© avec pandas rolling (100x plus rapide)
            volumes_series = pd.Series(volumes)
            avg_volume = volumes_series.rolling(window=window, min_periods=window).mean()
            avg_volume = avg_volume.bfill().values

            # √âviter division par z√©ro
            avg_volume = np.where(avg_volume == 0, 1.0, avg_volume)

            # Ratio = volume_courant / volume_moyen
            # Faible volume = plus de slippage
            with np.errstate(divide='ignore', invalid='ignore'):
                volume_ratio = volumes / avg_volume
                # Inverser: faible volume = ratio > 1 = plus de slippage
                self._volume_ratio = np.where(volume_ratio > 0, 1.0 / volume_ratio, 1.0)

            # Limiter entre 0.5 et 3.0
            self._volume_ratio = np.clip(self._volume_ratio, 0.5, 3.0)
        else:
            self._volume_ratio = np.ones(n)

        self._prepared = True
        logger.debug(f"ExecutionEngine pr√©par√©: {n} barres")

    def _calculate_spread_bps(self, bar_idx: int) -> float:
        """Calcule le spread en BPS pour une barre donn√©e."""
        if self.config.model == ExecutionModel.IDEAL:
            return 0.0

        if self.config.model == ExecutionModel.FIXED:
            return self.config.spread_bps

        # Mod√®le dynamique
        base_spread = self.config.spread_bps

        if self.config.use_volatility_spread and self._normalized_volatility is not None:
            vol_factor = self._normalized_volatility[bar_idx]
            # Plus de volatilit√© = plus de spread
            spread_adjustment = vol_factor * self.config.volatility_spread_factor
            base_spread *= (1 + spread_adjustment)

        return np.clip(
            base_spread,
            self.config.min_spread_bps,
            self.config.max_spread_bps
        )

    def _calculate_slippage_bps(self, bar_idx: int, size: float = 1.0) -> float:
        """Calcule le slippage en BPS pour une barre donn√©e."""
        if self.config.model == ExecutionModel.IDEAL:
            return 0.0

        if self.config.model == ExecutionModel.FIXED:
            return self.config.slippage_bps

        # Mod√®le dynamique
        base_slippage = self.config.slippage_bps

        if self.config.use_volume_slippage and self._volume_ratio is not None:
            vol_ratio = self._volume_ratio[bar_idx]
            # Faible volume (ratio > 1) = plus de slippage
            base_slippage *= vol_ratio * self.config.volume_slippage_factor

        return np.clip(
            base_slippage,
            self.config.min_slippage_bps,
            self.config.max_slippage_bps
        )

    def _calculate_market_impact_bps(self, size: float, price: float) -> float:
        """Calcule l'impact de march√© en BPS."""
        if self.config.market_impact_bps == 0:
            return 0.0

        # Impact proportionnel √† la taille de l'ordre
        # Plus l'ordre est gros, plus l'impact est important
        return self.config.market_impact_bps * np.sqrt(size)

    def _calculate_latency_bars(self) -> int:
        """Calcule le nombre de barres de latence."""
        if self.config.latency_ms == 0 or self._bar_duration_ms == 0:
            return 0

        # Latence en nombre de barres (arrondi sup√©rieur)
        return int(np.ceil(self.config.latency_ms / self._bar_duration_ms))

    def execute_order(
        self,
        price: float,
        side: int,
        bar_idx: int,
        size: float = 1.0
    ) -> ExecutionResult:
        """
        Simule l'ex√©cution d'un ordre.

        Args:
            price: Prix demand√© (mid-price)
            side: Direction (1 = achat/long, -1 = vente/short)
            bar_idx: Index de la barre courante
            size: Taille de l'ordre (pour impact de march√©)

        Returns:
            ExecutionResult avec tous les d√©tails d'ex√©cution
        """
        if not self._prepared and self.config.model in (ExecutionModel.DYNAMIC, ExecutionModel.REALISTIC):
            logger.warning("ExecutionEngine non pr√©par√© - utilisation valeurs fixes")

        # Borner l'index
        if self._normalized_volatility is not None:
            bar_idx = min(bar_idx, len(self._normalized_volatility) - 1)
        bar_idx = max(0, bar_idx)

        size = abs(size)

        # Calculer les composantes
        spread_bps = self._calculate_spread_bps(bar_idx)
        slippage_bps = self._calculate_slippage_bps(bar_idx, size)
        impact_bps = self._calculate_market_impact_bps(size, price)
        latency_bars = self._calculate_latency_bars()

        # Convertir en co√ªts absolus
        spread_cost = price * (spread_bps / 10000) / 2  # Demi-spread
        slippage_cost = price * (slippage_bps / 10000)
        impact_cost = price * (impact_bps / 10000)

        # Prix d'ex√©cution (ajust√© selon direction)
        # Achat: prix + co√ªts, Vente: prix - co√ªts
        total_adjustment = spread_cost + slippage_cost + impact_cost
        executed_price = price + (side * total_adjustment)

        # Optional partial fills
        fill_ratio = 1.0
        filled_size = size
        if self.config.model == ExecutionModel.REALISTIC and self.config.partial_fill_prob > 0:
            if np.random.random() < self.config.partial_fill_prob:
                fill_ratio = np.random.uniform(
                    self.config.partial_fill_min,
                    self.config.partial_fill_max
                )
                filled_size = size * fill_ratio

        return ExecutionResult(
            executed_price=executed_price,
            requested_price=price,
            spread_cost=spread_cost,
            slippage_cost=slippage_cost,
            market_impact=impact_cost,
            latency_bars=latency_bars,
            filled_size=filled_size,
            fill_ratio=fill_ratio,
        )

    def get_bid_ask(self, mid_price: float, bar_idx: int) -> Tuple[float, float]:
        """
        Calcule les prix bid/ask √† partir du mid-price.

        Args:
            mid_price: Prix m√©dian
            bar_idx: Index de la barre

        Returns:
            Tuple (bid, ask)
        """
        spread_bps = self._calculate_spread_bps(bar_idx)
        half_spread = mid_price * (spread_bps / 10000) / 2

        bid = mid_price - half_spread
        ask = mid_price + half_spread

        return bid, ask

    def get_execution_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques d'ex√©cution."""
        stats = {
            "model": self.config.model.value,
            "prepared": self._prepared,
            "bar_duration_ms": self._bar_duration_ms,
        }

        if self._volatility is not None:
            stats["avg_volatility"] = float(np.mean(self._volatility))
            stats["max_volatility"] = float(np.max(self._volatility))

        if self._volume_ratio is not None:
            stats["avg_volume_ratio"] = float(np.mean(self._volume_ratio))

        return stats


class SpreadCalculator:
    """
    Calculateur de spread bid/ask.

    Fournit plusieurs m√©thodes pour estimer le spread:
    - Fixe
    - Bas√© sur volatilit√©
    - Bas√© sur volume
    - High-Low estimator (Roll)
    """

    @staticmethod
    def fixed_spread(base_bps: float = 5.0) -> float:
        """Spread fixe en BPS."""
        return base_bps

    @staticmethod
    def volatility_spread(
        returns: np.ndarray,
        base_bps: float = 5.0,
        vol_factor: float = 2.0
    ) -> np.ndarray:
        """
        Spread bas√© sur la volatilit√© r√©cente.

        Args:
            returns: Array des rendements
            base_bps: Spread de base
            vol_factor: Facteur multiplicateur de volatilit√©

        Returns:
            Array des spreads en BPS
        """
        vol = np.abs(returns) * 10000  # En BPS
        return np.maximum(base_bps, vol * vol_factor)

    @staticmethod
    def roll_spread(
        closes: np.ndarray,
        window: int = 20
    ) -> np.ndarray:
        """
        Estimateur de Roll pour le spread bid/ask.

        Bas√© sur l'autocovariance des rendements.
        Roll (1984): spread = 2 * sqrt(-cov(r_t, r_{t-1}))

        Args:
            closes: Array des prix de cl√¥ture
            window: Fen√™tre de calcul

        Returns:
            Array des spreads estim√©s (en valeur, pas en BPS)

        Notes:
            Utilise impl√©mentation optimis√©e (Numba si disponible, sinon pandas rolling)
        """
        returns = np.zeros(len(closes))
        returns[1:] = np.diff(closes) / closes[:-1]

        # Utiliser version optimis√©e si disponible
        if USE_FAST_EXECUTION:
            return roll_spread(closes, returns, window)

        # Fallback: pandas rolling (vectoris√©, 50x plus rapide que boucle Python)
        returns_series = pd.Series(returns)
        returns_lag = returns_series.shift(1)
        cov = returns_series.rolling(window).cov(returns_lag).fillna(0).values

        spreads = np.zeros(len(closes))
        negative_cov = cov < 0
        spreads[negative_cov] = 2 * np.sqrt(-cov[negative_cov]) * closes[negative_cov]

        return spreads

        # CODE ANCIEN (boucle Python - 100x plus lent)
        # n = len(closes)
        # spreads = np.zeros(n)
        # for i in range(window + 1, n):
        #     r_window = returns[i-window:i]
        #     r_lag = returns[i-window-1:i-1]
        #
        #     cov = np.cov(r_window, r_lag)[0, 1]
        #
        #     if cov < 0:
        #         spreads[i] = 2 * np.sqrt(-cov) * closes[i]
        #     else:
        #         spreads[i] = 0
        #
        # return spreads

    @staticmethod
    def high_low_spread(
        highs: np.ndarray,
        lows: np.ndarray,
        closes: np.ndarray = None  # Pas utilis√© mais gard√© pour compatibilit√© API
    ) -> np.ndarray:
        """
        Estimateur Corwin-Schultz bas√© sur High-Low.

        Args:
            highs: Array des hauts
            lows: Array des bas
            closes: Array des cl√¥tures (non utilis√©, pour compatibilit√©)

        Returns:
            Array des spreads estim√©s en BPS

        Notes:
            Utilise impl√©mentation optimis√©e (Numba si disponible, sinon boucle Python)
        """
        # Utiliser version optimis√©e si disponible (Numba JIT-compiled)
        if USE_FAST_EXECUTION and HAS_NUMBA:
            return high_low_spread(highs, lows)

        # Fallback: boucle Python (difficilement vectorisable √† cause de max/min imbriqu√©s)
        n = len(highs)
        spreads = np.zeros(n)
        sqrt_2 = np.sqrt(2.0)

        for i in range(2, n):
            # Beta = (ln(H_t/L_t))^2 + (ln(H_{t-1}/L_{t-1}))^2
            beta = (np.log(highs[i] / lows[i])) ** 2 + (np.log(highs[i-1] / lows[i-1])) ** 2

            # Gamma = (ln(max(H_t, H_{t-1}) / min(L_t, L_{t-1})))^2
            gamma = (np.log(max(highs[i], highs[i-1]) / min(lows[i], lows[i-1]))) ** 2

            # Alpha
            denom = 3.0 - 2.0 * sqrt_2
            if abs(denom) > 1e-10:
                alpha = (np.sqrt(2 * beta) - np.sqrt(beta)) / denom - np.sqrt(gamma / denom)

                # Spread = 2 * (e^alpha - 1) / (1 + e^alpha)
                if alpha > -10:  # √âviter overflow
                    exp_alpha = np.exp(alpha)
                    spread_pct = 2 * (exp_alpha - 1) / (1 + exp_alpha)
                    spreads[i] = max(0, spread_pct * 10000)  # En BPS

        return spreads


class SlippageCalculator:
    """
    Calculateur de slippage.

    Fournit plusieurs mod√®les de slippage:
    - Fixe
    - Proportionnel au volume
    - Bas√© sur volatilit√©
    - Impact de march√© (Almgren-Chriss)
    """

    @staticmethod
    def fixed_slippage(base_bps: float = 3.0) -> float:
        """Slippage fixe en BPS."""
        return base_bps

    @staticmethod
    def volume_slippage(
        order_size: float,
        avg_volume: float,
        base_bps: float = 3.0,
        impact_factor: float = 0.1
    ) -> float:
        """
        Slippage bas√© sur le ratio taille_ordre / volume_moyen.

        Args:
            order_size: Taille de l'ordre
            avg_volume: Volume moyen
            base_bps: Slippage de base
            impact_factor: Facteur d'impact

        Returns:
            Slippage en BPS
        """
        if avg_volume <= 0:
            return base_bps

        participation_rate = order_size / avg_volume
        return base_bps * (1 + impact_factor * participation_rate)

    @staticmethod
    def volatility_slippage(
        volatility: float,
        base_bps: float = 3.0,
        vol_multiplier: float = 100.0
    ) -> float:
        """
        Slippage bas√© sur la volatilit√©.

        Args:
            volatility: Volatilit√© (√©cart-type des rendements)
            base_bps: Slippage de base
            vol_multiplier: Multiplicateur de volatilit√©

        Returns:
            Slippage en BPS
        """
        return base_bps + volatility * vol_multiplier

    @staticmethod
    def almgren_chriss_impact(
        order_size: float,
        daily_volume: float,
        daily_volatility: float,
        eta: float = 0.1,
        gamma: float = 0.5
    ) -> float:
        """
        Mod√®le d'impact de march√© Almgren-Chriss.

        Temporary impact = eta * sigma * (Q / V)^gamma

        Args:
            order_size: Taille de l'ordre (Q)
            daily_volume: Volume journalier (V)
            daily_volatility: Volatilit√© journali√®re (sigma)
            eta: Param√®tre d'impact
            gamma: Exposant (g√©n√©ralement 0.5 pour sqrt)

        Returns:
            Impact temporaire en fraction de prix
        """
        if daily_volume <= 0:
            return 0.0

        return eta * daily_volatility * (order_size / daily_volume) ** gamma


def create_execution_engine(
    model: str = "dynamic",
    spread_bps: float = 5.0,
    slippage_bps: float = 3.0,
    latency_ms: float = 50.0,
    **kwargs
) -> ExecutionEngine:
    """
    Factory pour cr√©er un ExecutionEngine configur√©.

    Args:
        model: Type de mod√®le ('ideal', 'fixed', 'dynamic', 'realistic')
        spread_bps: Spread de base en BPS
        slippage_bps: Slippage de base en BPS
        latency_ms: Latence en millisecondes
        **kwargs: Param√®tres additionnels pour ExecutionConfig

    Returns:
        ExecutionEngine configur√©

    Example:
        >>> engine = create_execution_engine(model="dynamic", spread_bps=3.0)
        >>> engine.prepare(df)
        >>> result = engine.execute_order(price=100, side=1, bar_idx=50)
    """
    model_enum = ExecutionModel(model.lower())

    config = ExecutionConfig(
        model=model_enum,
        spread_bps=spread_bps,
        slippage_bps=slippage_bps,
        latency_ms=latency_ms,
        **kwargs
    )

    return ExecutionEngine(config)


__all__ = [
    "ExecutionModel",
    "ExecutionConfig",
    "ExecutionResult",
    "ExecutionEngine",
    "SpreadCalculator",
    "SlippageCalculator",
    "create_execution_engine",
]


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur ex√©cution r√©aliste
# - Conventions spread (bps), slippage (fractions), mod√®les (IDEAL...REALISTIC) explicit√©es
# - Read-if/Skip-if ajout√©s pour tri rapide
```
<!-- MODULE-END: execution.py -->

<!-- MODULE-START: execution_fast.py -->
```json
{
  "name": "execution_fast.py",
  "path": "backtest\\execution_fast.py",
  "ext": ".py",
  "anchor": "execution_fast_py"
}
```
## execution_fast_py
*Chemin* : `backtest\execution_fast.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.execution_fast

Purpose: Optimisations Numba JIT pour calculs spread/slippage dynamiques (50-100x acc√©l√©ration).

Role in pipeline: execution / performance

Key components: roll_spread_numba, high_low_spread_numba, HAS_NUMBA flag

Inputs: closes array, returns array, volatilit√©, volume

Outputs: Spreads/slippages vectoris√©s (arrays numpy)

Dependencies: numpy, optionnel: numba (JIT compilation); fallback Python si numba absent

Conventions: HAS_NUMBA = False si numba non install√© (fallback OK); spreads en fractions; cache=True pour r√©utilisation.

Read-if: Optimisation ex√©cution ou modification calculs spread/slippage.

Skip-if: Performances acceptables avec execution.py pur Python.
"""

import numpy as np

try:
    from numba import njit
    HAS_NUMBA = True
except ImportError:
    HAS_NUMBA = False


if HAS_NUMBA:
    @njit(cache=True, fastmath=True)
    def roll_spread_numba(
        closes: np.ndarray,
        returns: np.ndarray,
        window: int = 20
    ) -> np.ndarray:
        """
        Estimateur Roll vectoris√© avec Numba.

        Calcule le spread effectif bas√© sur l'auto-covariance des returns.
        Version JIT-compiled pour performance maximale.
        """
        n = len(closes)
        spreads = np.zeros(n)

        for i in range(window + 1, n):
            # Fen√™tre de returns
            r_window = returns[i-window:i]
            r_lag = returns[i-window-1:i-1]

            # Covariance manuelle (plus rapide que np.cov en boucle)
            mean_window = np.mean(r_window)
            mean_lag = np.mean(r_lag)

            cov = 0.0
            for j in range(len(r_window)):
                cov += (r_window[j] - mean_window) * (r_lag[j] - mean_lag)
            cov /= len(r_window)

            if cov < 0:
                spreads[i] = 2 * np.sqrt(-cov) * closes[i]
            else:
                spreads[i] = 0.0

        return spreads

    @njit(cache=True, fastmath=True)
    def high_low_spread_numba(
        highs: np.ndarray,
        lows: np.ndarray
    ) -> np.ndarray:
        """
        Estimateur Corwin-Schultz vectoris√© avec Numba.

        Version JIT-compiled pour performance maximale.
        """
        n = len(highs)
        spreads = np.zeros(n)
        sqrt_2 = np.sqrt(2.0)

        for i in range(2, n):
            # Beta
            log_hl_t = np.log(highs[i] / lows[i])
            log_hl_t1 = np.log(highs[i-1] / lows[i-1])
            beta = log_hl_t ** 2 + log_hl_t1 ** 2

            # Gamma
            max_high = max(highs[i], highs[i-1])
            min_low = min(lows[i], lows[i-1])
            gamma = (np.log(max_high / min_low)) ** 2

            # Alpha
            denom = 3.0 - 2.0 * sqrt_2
            if abs(denom) > 1e-10:
                term1 = (np.sqrt(2.0 * beta) - np.sqrt(beta)) / denom
                term2 = np.sqrt(gamma / denom)
                alpha = term1 - term2

                # Spread
                if alpha > -10.0 and alpha < 10.0:  # √âviter overflow
                    exp_alpha = np.exp(alpha)
                    spread_pct = 2.0 * (exp_alpha - 1.0) / (1.0 + exp_alpha)
                    spreads[i] = max(0.0, spread_pct * 10000.0)  # En BPS

        return spreads

    @njit(cache=True, parallel=True, fastmath=True)
    def calculate_volatility_fast(
        returns: np.ndarray,
        window: int
    ) -> np.ndarray:
        """
        Calcul de volatilit√© rolling vectoris√© avec Numba.

        Parall√©lis√© pour performance maximale sur grandes s√©ries.
        """
        n = len(returns)
        volatility = np.zeros(n)

        for i in range(window, n):
            volatility[i] = np.std(returns[i-window:i])

        # Remplir le d√©but
        if window < n and volatility[window] > 0:
            volatility[:window] = volatility[window]

        return volatility

    @njit(cache=True, parallel=True, fastmath=True)
    def calculate_volume_ratio_fast(
        volumes: np.ndarray,
        window: int
    ) -> np.ndarray:
        """
        Calcul de volume ratio rolling vectoris√© avec Numba.

        Ratio = 1 / (volume_courant / volume_moyen)
        Faible volume -> ratio √©lev√© -> plus de slippage
        """
        n = len(volumes)
        volume_ratio = np.ones(n)

        for i in range(window, n):
            avg_vol = np.mean(volumes[i-window:i])
            if avg_vol > 0 and volumes[i] > 0:
                ratio = volumes[i] / avg_vol
                if ratio > 0:
                    volume_ratio[i] = 1.0 / ratio

        # Clip entre 0.5 et 3.0
        volume_ratio = np.clip(volume_ratio, 0.5, 3.0)

        return volume_ratio


# =============================================================================
# FALLBACK NUMPY (si Numba non disponible)
# =============================================================================

def roll_spread_numpy(
    closes: np.ndarray,
    returns: np.ndarray,
    window: int = 20
) -> np.ndarray:
    """Version numpy pure (fallback)."""
    import pandas as pd

    n = len(closes)
    spreads = np.zeros(n)

    # Utiliser pandas rolling pour covariance
    returns_series = pd.Series(returns)
    returns_lag = returns_series.shift(1)

    # Rolling covariance
    cov = returns_series.rolling(window).cov(returns_lag)
    cov = cov.fillna(0).values

    # Appliquer formule Roll
    negative_cov = cov < 0
    spreads[negative_cov] = 2 * np.sqrt(-cov[negative_cov]) * closes[negative_cov]

    return spreads


def high_low_spread_numpy(
    highs: np.ndarray,
    lows: np.ndarray
) -> np.ndarray:
    """Version numpy pure (fallback) - garde la boucle car logique complexe."""
    n = len(highs)
    spreads = np.zeros(n)
    sqrt_2 = np.sqrt(2.0)

    for i in range(2, n):
        beta = (np.log(highs[i] / lows[i])) ** 2 + (np.log(highs[i-1] / lows[i-1])) ** 2
        gamma = (np.log(max(highs[i], highs[i-1]) / min(lows[i], lows[i-1]))) ** 2

        denom = 3.0 - 2.0 * sqrt_2
        if abs(denom) > 1e-10:
            alpha = (np.sqrt(2.0 * beta) - np.sqrt(beta)) / denom - np.sqrt(gamma / denom)

            if -10 < alpha < 10:
                exp_alpha = np.exp(alpha)
                spread_pct = 2.0 * (exp_alpha - 1.0) / (1.0 + exp_alpha)
                spreads[i] = max(0.0, spread_pct * 10000.0)

    return spreads


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur optimisations Numba JIT
# - Conventions HAS_NUMBA flag et fallback explicit√©es
# - Read-if/Skip-if ajout√©s pour guider la lecture


# =============================================================================
# INTERFACE UNIFI√âE
# =============================================================================

# S√©lectionner automatiquement la meilleure impl√©mentation
if HAS_NUMBA:
    roll_spread = roll_spread_numba
    high_low_spread = high_low_spread_numba
    calculate_volatility = calculate_volatility_fast
    calculate_volume_ratio = calculate_volume_ratio_fast
else:
    roll_spread = roll_spread_numpy
    high_low_spread = high_low_spread_numpy
    # Pas d'√©quivalent numpy pour ces deux, on garde pandas dans execution.py
    calculate_volatility = None
    calculate_volume_ratio = None
```
<!-- MODULE-END: execution_fast.py -->

<!-- MODULE-START: facade.py -->
```json
{
  "name": "facade.py",
  "path": "backtest\\facade.py",
  "ext": ".py",
  "anchor": "facade_py"
}
```
## facade_py
*Chemin* : `backtest\facade.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.facade

Purpose: Interface stable et typ√©e entre l'UI et le backend (BacktestEngine + agents LLM).

Role in pipeline: orchestration / api

Key components: BackendFacade, BacktestRequest, BackendResponse, ResponseStatus, ErrorCode

Inputs: BacktestRequest (params, strat√©gie, donn√©es), validation_fn optionnel

Outputs: BackendResponse (format unifi√©), erreurs structur√©es (jamais de traceback brut UI)

Dependencies: backtest.engine, backtest.errors, utils.config, dataclasses

Conventions: Erreurs via Response.status/error_code/error_message (jamais exceptions UI); contrats Request/Response immuables; warmup auto >= 200.

Read-if: Modification l'API UI‚Üîbackend, erreurs struct, ou contrats de r√©ponse.

Skip-if: Vous ne touchez qu'au moteur backtest pur.
"""

from __future__ import annotations

import traceback
import uuid
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional

import pandas as pd

from backtest.engine import BacktestEngine, RunResult
from backtest.errors import (
    DataError,
    InsufficientDataError,
    UserInputError,
)
from metrics_types import UIMetricsPct, normalize_metrics
from utils.config import Config
from utils.log import get_logger

logger = get_logger(__name__)

# Warmup minimal par d√©faut (conservateur pour couvrir la plupart des strat√©gies)
WARMUP_MIN_DEFAULT = 200


# =============================================================================
# ENUMS & STATUS
# =============================================================================

class ResponseStatus(Enum):
    """Status de r√©ponse du backend."""
    SUCCESS = "success"
    ERROR = "error"
    PARTIAL = "partial"  # Succ√®s partiel (ex: grille avec quelques √©checs)


class ErrorCode(Enum):
    """Codes d'erreur pour l'UI."""
    INVALID_PARAMS = "invalid_params"
    INVALID_DATA = "invalid_data"
    DATA_NOT_FOUND = "data_not_found"
    INSUFFICIENT_DATA = "insufficient_data"
    STRATEGY_NOT_FOUND = "strategy_not_found"
    BACKEND_INTERNAL = "backend_internal"
    LLM_UNAVAILABLE = "llm_unavailable"
    LLM_CONNECTION_FAILED = "llm_connection_failed"
    OPTIMIZATION_FAILED = "optimization_failed"


# =============================================================================
# REQUEST DATACLASSES
# =============================================================================

@dataclass
class BacktestRequest:
    """
    Requ√™te pour un backtest simple.

    Attributes:
        strategy_name: Nom de la strat√©gie (ex: "ema_cross")
        params: Param√®tres de la strat√©gie
        data: DataFrame OHLCV OU None (si symbol/timeframe fournis)
        symbol: Symbole pour charger les donn√©es
        timeframe: Timeframe pour charger les donn√©es
        initial_capital: Capital de d√©part
        date_start: Date de d√©but (optionnel)
        date_end: Date de fin (optionnel)
    """
    strategy_name: str
    params: Dict[str, Any]
    data: Optional[pd.DataFrame] = None
    symbol: Optional[str] = None
    timeframe: Optional[str] = None
    initial_capital: float = 10000.0
    date_start: Optional[str] = None
    date_end: Optional[str] = None

    def __post_init__(self):
        """Validation √† la cr√©ation."""
        if self.data is None and (self.symbol is None or self.timeframe is None):
            raise ValueError("Soit 'data' soit 'symbol'+'timeframe' requis")


@dataclass
class GridOptimizationRequest:
    """
    Requ√™te pour une optimisation en grille.

    Attributes:
        strategy_name: Nom de la strat√©gie
        param_grid: Liste de dicts de param√®tres √† tester
        data: DataFrame OHLCV
        initial_capital: Capital de d√©part
        max_combinations: Limite de combinaisons
        metric_to_optimize: M√©trique √† maximiser ("sharpe", "return", etc.)
    """
    strategy_name: str
    param_grid: List[Dict[str, Any]]
    data: pd.DataFrame
    initial_capital: float = 10000.0
    max_combinations: int = 10000
    metric_to_optimize: str = "sharpe_ratio"
    symbol: str = "UNKNOWN"
    timeframe: str = "1h"


@dataclass
class LLMOptimizationRequest:
    """
    Requ√™te pour une optimisation LLM autonome.

    Attributes:
        strategy_name: Nom de la strat√©gie
        initial_params: Param√®tres de d√©part
        param_bounds: Bornes {param: (min, max)}
        data: DataFrame OHLCV
        llm_provider: "ollama" ou "openai"
        llm_model: Nom du mod√®le
        llm_api_key: Cl√© API (pour OpenAI)
        llm_base_url: URL (pour Ollama)
        max_iterations: Nombre max d'it√©rations
        use_walk_forward: Activer validation anti-overfitting
        initial_capital: Capital de d√©part
    """
    strategy_name: str
    initial_params: Dict[str, Any]
    param_bounds: Dict[str, tuple]
    data: pd.DataFrame
    llm_provider: str = "ollama"
    llm_model: str = "llama3.2"
    llm_api_key: Optional[str] = None
    llm_base_url: str = "http://localhost:11434"
    max_iterations: int = 10
    use_walk_forward: bool = True
    initial_capital: float = 10000.0
    target_sharpe: float = 2.0


# =============================================================================
# RESPONSE DATACLASSES
# =============================================================================

@dataclass
class UIMetrics:
    """
    M√©triques format√©es pour l'affichage UI.

    Format stable garanti - l'UI peut d√©pendre de ces champs.
    """
    # Rendement
    total_pnl: float = 0.0
    total_return_pct: float = 0.0
    annualized_return: float = 0.0

    # Risque
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    calmar_ratio: float = 0.0
    max_drawdown_pct: float = 0.0
    volatility_annual: float = 0.0

    # Trading
    total_trades: int = 0
    win_rate_pct: float = 0.0
    profit_factor: float = 0.0
    expectancy: float = 0.0

    # Avanc√© (optionnel)
    sqn: Optional[float] = None
    recovery_factor: Optional[float] = None

    @classmethod
    def from_run_result(cls, result: RunResult) -> "UIMetrics":
        """Cr√©e UIMetrics depuis un RunResult."""
        m = normalize_metrics(result.metrics, "pct")
        return cls(
            total_pnl=m.get("total_pnl", 0.0),
            total_return_pct=m.get("total_return_pct", 0.0),
            annualized_return=m.get("annualized_return", 0.0),
            sharpe_ratio=m.get("sharpe_ratio", 0.0),
            sortino_ratio=m.get("sortino_ratio", 0.0),
            calmar_ratio=m.get("calmar_ratio", 0.0),
            max_drawdown_pct=m.get("max_drawdown_pct", 0.0),
            volatility_annual=m.get("volatility_annual", 0.0),
            total_trades=m.get("total_trades", 0),
            win_rate_pct=m.get("win_rate_pct", 0.0),
            profit_factor=m.get("profit_factor", 0.0),
            expectancy=m.get("expectancy", 0.0),
            sqn=m.get("sqn"),
            recovery_factor=m.get("recovery_factor"),
        )

    def to_dict(self) -> UIMetricsPct:
        """Convertit en dict pour s√©rialisation."""
        return {
            "total_pnl": self.total_pnl,
            "total_return_pct": self.total_return_pct,
            "annualized_return": self.annualized_return,
            "sharpe_ratio": self.sharpe_ratio,
            "sortino_ratio": self.sortino_ratio,
            "calmar_ratio": self.calmar_ratio,
            "max_drawdown_pct": self.max_drawdown_pct,
            "volatility_annual": self.volatility_annual,
            "total_trades": self.total_trades,
            "win_rate_pct": self.win_rate_pct,
            "profit_factor": self.profit_factor,
            "expectancy": self.expectancy,
            "sqn": self.sqn,
            "recovery_factor": self.recovery_factor,
        }


@dataclass
class UIPayload:
    """
    Payload complet pour l'affichage UI.

    Contient toutes les donn√©es n√©cessaires pour afficher un r√©sultat de backtest.
    """
    metrics: UIMetrics
    equity_series: Optional[pd.Series] = None
    trades_df: Optional[pd.DataFrame] = None
    params_used: Dict[str, Any] = field(default_factory=dict)
    meta: Dict[str, Any] = field(default_factory=dict)

    @classmethod
    def from_run_result(cls, result: RunResult) -> "UIPayload":
        """Cr√©e UIPayload depuis un RunResult."""
        return cls(
            metrics=UIMetrics.from_run_result(result),
            equity_series=result.equity,
            trades_df=result.trades,
            params_used=result.meta.get("params", {}),
            meta=result.meta,
        )


@dataclass
class ErrorInfo:
    """
    Information d'erreur structur√©e.

    L'UI utilise ces champs pour afficher un message coh√©rent.
    """
    code: ErrorCode
    message_user: str  # Message compr√©hensible pour l'utilisateur
    hint: Optional[str] = None  # Suggestion de correction
    trace_id: Optional[str] = None  # ID pour debug/logs
    details: Optional[str] = None  # Stack trace (mode debug)

    def __post_init__(self):
        if self.trace_id is None:
            self.trace_id = str(uuid.uuid4())[:8]


@dataclass
class BackendResponse:
    """
    R√©ponse unifi√©e du backend vers l'UI.

    Contrat stable:
    - status: toujours pr√©sent
    - payload: pr√©sent si SUCCESS
    - error: pr√©sent si ERROR
    """
    status: ResponseStatus
    payload: Optional[UIPayload] = None
    error: Optional[ErrorInfo] = None
    message: str = ""  # Message de statut court
    duration_ms: float = 0.0

    @property
    def is_success(self) -> bool:
        return self.status == ResponseStatus.SUCCESS

    @property
    def is_error(self) -> bool:
        return self.status == ResponseStatus.ERROR


@dataclass
class GridOptimizationResponse:
    """R√©ponse d'une optimisation en grille."""
    status: ResponseStatus
    results: List[Dict[str, Any]] = field(default_factory=list)  # Tous les r√©sultats
    best_result: Optional[UIPayload] = None  # Meilleur r√©sultat
    best_params: Dict[str, Any] = field(default_factory=dict)
    error: Optional[ErrorInfo] = None
    total_tested: int = 0
    total_success: int = 0
    total_failed: int = 0
    duration_ms: float = 0.0


@dataclass
class LLMOptimizationResponse:
    """R√©ponse d'une optimisation LLM."""
    status: ResponseStatus
    best_result: Optional[UIPayload] = None
    best_params: Dict[str, Any] = field(default_factory=dict)
    iterations_history: List[Dict[str, Any]] = field(default_factory=list)
    total_iterations: int = 0
    convergence_reason: Optional[str] = None
    improvement_pct: float = 0.0
    error: Optional[ErrorInfo] = None
    duration_ms: float = 0.0


# =============================================================================
# FACADE PRINCIPALE
# =============================================================================

class BackendFacade:
    """
    Fa√ßade principale pour toutes les interactions UI ‚Üî Backend.

    Point d'entr√©e unique garantissant:
    - Validation des entr√©es
    - Gestion d'erreurs centralis√©e
    - Format de sortie unifi√©
    - Tra√ßabilit√©

    Usage:
        facade = BackendFacade()
        response = facade.run_backtest(request)

        if response.is_success:
            display_results(response.payload)
        else:
            show_error(response.error)
    """

    def __init__(self, config: Optional[Config] = None, debug: bool = False):
        """
        Initialise la fa√ßade.

        Args:
            config: Configuration globale
            debug: Inclure les stack traces dans les erreurs
        """
        self.config = config or Config()
        self.debug = debug
        self._logger = get_logger(__name__)

    # =========================================================================
    # BACKTEST SIMPLE
    # =========================================================================

    def run_backtest(self, request: BacktestRequest) -> BackendResponse:
        """
        Ex√©cute un backtest simple.

        Args:
            request: BacktestRequest avec strat√©gie, params, data

        Returns:
            BackendResponse avec payload ou erreur
        """
        import time
        start = time.time()
        trace_id = str(uuid.uuid4())[:8]

        self._logger.info(f"[{trace_id}] run_backtest: {request.strategy_name}")

        try:
            # 1. Charger les donn√©es si n√©cessaire
            if request.data is None:
                df = self._load_data(
                    request.symbol,
                    request.timeframe,
                    request.date_start,
                    request.date_end
                )
            else:
                df = request.data

            # 2. Valider les donn√©es
            self._validate_dataframe(df)

            # 3. Cr√©er et ex√©cuter le backtest
            engine = BacktestEngine(
                initial_capital=request.initial_capital,
                config=self.config
            )

            result = engine.run(
                df=df,
                strategy=request.strategy_name,
                params=request.params,
                symbol=request.symbol or "UNKNOWN",
                timeframe=request.timeframe or "1h",
            )

            # 4. Convertir en payload UI
            payload = UIPayload.from_run_result(result)
            duration_ms = (time.time() - start) * 1000

            return BackendResponse(
                status=ResponseStatus.SUCCESS,
                payload=payload,
                message=f"Backtest termin√© | Sharpe: {payload.metrics.sharpe_ratio:.2f}",
                duration_ms=duration_ms,
            )

        except UserInputError as e:
            return self._error_response(
                ErrorCode.INVALID_PARAMS, str(e),
                hint="V√©rifiez les param√®tres de strat√©gie",
                trace_id=trace_id, start_time=start
            )
        except InsufficientDataError as e:
            return self._error_response(
                ErrorCode.INSUFFICIENT_DATA,
                str(e),
                hint=e.hint,
                trace_id=trace_id,
                start_time=start
            )
        except DataError as e:
            return self._error_response(
                ErrorCode.INVALID_DATA, str(e),
                hint="V√©rifiez le format des donn√©es OHLCV",
                trace_id=trace_id, start_time=start
            )
        except ValueError as e:
            error_str = str(e).lower()
            if "strat√©gie" in error_str or "strategy" in error_str:
                return self._error_response(
                    ErrorCode.STRATEGY_NOT_FOUND, str(e),
                    hint="Utilisez list_strategies() pour voir les disponibles",
                    trace_id=trace_id, start_time=start
                )
            return self._error_response(
                ErrorCode.INVALID_PARAMS, str(e),
                trace_id=trace_id, start_time=start
            )
        except Exception:
            self._logger.exception(f"[{trace_id}] Erreur inattendue")
            return self._error_response(
                ErrorCode.BACKEND_INTERNAL,
                "Erreur interne du moteur de backtest",
                details=traceback.format_exc() if self.debug else None,
                trace_id=trace_id, start_time=start
            )

    # =========================================================================
    # OPTIMISATION GRILLE
    # =========================================================================

    def run_grid_optimization(
        self,
        request: GridOptimizationRequest,
        progress_callback: Optional[callable] = None
    ) -> GridOptimizationResponse:
        """
        Ex√©cute une optimisation en grille.

        Args:
            request: GridOptimizationRequest
            progress_callback: Fonction appel√©e √† chaque it√©ration (i, total)

        Returns:
            GridOptimizationResponse avec tous les r√©sultats
        """
        import time
        start = time.time()
        trace_id = str(uuid.uuid4())[:8]

        self._logger.info(
            f"[{trace_id}] run_grid_optimization: {request.strategy_name}, "
            f"{len(request.param_grid)} combinaisons"
        )

        try:
            # Valider les donn√©es
            self._validate_dataframe(request.data)

            # Limiter les combinaisons
            param_grid = request.param_grid[:request.max_combinations]

            engine = BacktestEngine(
                initial_capital=request.initial_capital,
                config=self.config
            )

            results = []
            best_metric = float("-inf")
            best_result = None
            best_params = {}
            success_count = 0
            fail_count = 0

            for i, params in enumerate(param_grid):
                if progress_callback:
                    progress_callback(i + 1, len(param_grid))

                try:
                    result = engine.run(
                        df=request.data,
                        strategy=request.strategy_name,
                        params=params,
                        symbol=request.symbol,
                        timeframe=request.timeframe,
                    )

                    metric_value = result.metrics.get(request.metric_to_optimize, 0)

                    results.append({
                        "params": params,
                        "metrics": UIMetrics.from_run_result(result).to_dict(),
                        "success": True,
                    })

                    if metric_value > best_metric:
                        best_metric = metric_value
                        best_result = UIPayload.from_run_result(result)
                        best_params = params

                    success_count += 1

                except Exception as e:
                    results.append({
                        "params": params,
                        "error": str(e),
                        "success": False,
                    })
                    fail_count += 1

            duration_ms = (time.time() - start) * 1000

            status = ResponseStatus.SUCCESS if fail_count == 0 else ResponseStatus.PARTIAL

            return GridOptimizationResponse(
                status=status,
                results=results,
                best_result=best_result,
                best_params=best_params,
                total_tested=len(param_grid),
                total_success=success_count,
                total_failed=fail_count,
                duration_ms=duration_ms,
            )

        except InsufficientDataError as e:
            return GridOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.INSUFFICIENT_DATA,
                    message_user=str(e),
                    hint=e.hint,
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )
        except DataError as e:
            return GridOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.INVALID_DATA,
                    message_user=str(e),
                    hint="V√©rifiez le format des donn√©es OHLCV",
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )
        except Exception:
            self._logger.exception(f"[{trace_id}] Erreur optimisation grille")
            return GridOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.BACKEND_INTERNAL,
                    message_user="Erreur lors de l'optimisation",
                    details=traceback.format_exc() if self.debug else None,
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )

    # =========================================================================
    # OPTIMISATION LLM
    # =========================================================================

    def run_llm_optimization(
        self,
        request: LLMOptimizationRequest,
        progress_callback: Optional[callable] = None
    ) -> LLMOptimizationResponse:
        """
        Ex√©cute une optimisation LLM autonome.

        Args:
            request: LLMOptimizationRequest
            progress_callback: Fonction appel√©e √† chaque it√©ration

        Returns:
            LLMOptimizationResponse
        """
        import time
        start = time.time()
        trace_id = str(uuid.uuid4())[:8]

        self._logger.info(
            f"[{trace_id}] run_llm_optimization: {request.strategy_name}, "
            f"provider={request.llm_provider}"
        )

        try:
            # V√©rifier disponibilit√© LLM
            from agents.integration import create_optimizer_from_engine
            from agents.llm_client import LLMConfig, LLMProvider
        except ImportError:
            return LLMOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.LLM_UNAVAILABLE,
                    message_user="Module agents LLM non disponible",
                    hint="V√©rifiez l'installation des d√©pendances agents",
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )

        try:
            # Valider les donn√©es
            self._validate_dataframe(request.data)

            # Configurer le LLM
            provider = (
                LLMProvider.OLLAMA
                if request.llm_provider.lower() == "ollama"
                else LLMProvider.OPENAI
            )

            llm_config = LLMConfig(
                provider=provider,
                model=request.llm_model,
                openai_api_key=request.llm_api_key,
                ollama_host=request.llm_base_url,
            )

            # Cr√©er l'optimiseur
            strategist, executor = create_optimizer_from_engine(
                llm_config=llm_config,
                strategy_name=request.strategy_name,
                data=request.data,
                initial_capital=request.initial_capital,
                use_walk_forward=request.use_walk_forward,
                verbose=True,
            )

            # Ex√©cuter l'optimisation
            session = strategist.optimize(
                executor=executor,
                initial_params=request.initial_params,
                param_bounds=request.param_bounds,
                max_iterations=request.max_iterations,
                target_sharpe=request.target_sharpe,
            )

            # Convertir l'historique
            history = []
            for exp in session.history:
                history.append({
                    "params": exp.request.parameters,
                    "sharpe_ratio": exp.sharpe_ratio,
                    "total_pnl": exp.total_pnl,
                })

            # Calculer l'am√©lioration
            improvement = 0.0
            if history and history[0]["sharpe_ratio"] != 0:
                initial = history[0]["sharpe_ratio"]
                final = session.best_result.sharpe_ratio
                improvement = ((final - initial) / abs(initial)) * 100

            # Reconstruire le meilleur r√©sultat complet
            engine = BacktestEngine(
                initial_capital=request.initial_capital,
                config=self.config
            )
            best_run = engine.run(
                df=request.data,
                strategy=request.strategy_name,
                params=session.best_result.request.parameters,
            )
            best_payload = UIPayload.from_run_result(best_run)

            duration_ms = (time.time() - start) * 1000

            return LLMOptimizationResponse(
                status=ResponseStatus.SUCCESS,
                best_result=best_payload,
                best_params=session.best_result.request.parameters,
                iterations_history=history,
                total_iterations=session.total_iterations,
                convergence_reason=session.convergence_reason,
                improvement_pct=improvement,
                duration_ms=duration_ms,
            )

        except InsufficientDataError as e:
            return LLMOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.INSUFFICIENT_DATA,
                    message_user=str(e),
                    hint=e.hint,
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )
        except DataError as e:
            return LLMOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.INVALID_DATA,
                    message_user=str(e),
                    hint="V√©rifiez le format des donn√©es OHLCV",
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )
        except ConnectionError as e:
            return LLMOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.LLM_CONNECTION_FAILED,
                    message_user=f"Impossible de se connecter au LLM: {e}",
                    hint="V√©rifiez que Ollama est d√©marr√© ou que la cl√© API est valide",
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )
        except Exception as e:
            self._logger.exception(f"[{trace_id}] Erreur optimisation LLM")
            return LLMOptimizationResponse(
                status=ResponseStatus.ERROR,
                error=ErrorInfo(
                    code=ErrorCode.OPTIMIZATION_FAILED,
                    message_user=f"Erreur lors de l'optimisation LLM: {str(e)}",
                    details=traceback.format_exc() if self.debug else None,
                    trace_id=trace_id,
                ),
                duration_ms=(time.time() - start) * 1000,
            )

    # =========================================================================
    # HELPERS PRIV√âS
    # =========================================================================

    def _estimate_bars_between(
        self,
        start: str,
        end: str,
        timeframe: str
    ) -> int:
        """
        Estime le nombre de barres entre deux dates pour un timeframe donn√©.

        Args:
            start: Date de d√©but ISO (ex: "2024-01-01")
            end: Date de fin ISO
            timeframe: Timeframe (1m, 5m, 15m, 30m, 1h, 4h, 1d, etc.)

        Returns:
            Nombre approximatif de barres
        """
        from datetime import datetime

        try:
            # Parser les dates (supporter diff√©rents formats)
            start_dt = datetime.fromisoformat(start.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(end.replace('Z', '+00:00'))

            # Calculer la dur√©e en heures
            duration_hours = (end_dt - start_dt).total_seconds() / 3600

            # Conversion timeframe -> heures par barre
            timeframe_hours = {
                '1m': 1/60, '5m': 5/60, '15m': 15/60, '30m': 0.5,
                '1h': 1, '2h': 2, '4h': 4, '6h': 6, '8h': 8, '12h': 12,
                '1d': 24, '1w': 24*7,
            }

            hours_per_bar = timeframe_hours.get(timeframe, 1)
            estimated_bars = int(duration_hours / hours_per_bar)

            return estimated_bars

        except Exception as e:
            self._logger.warning(f"Impossible d'estimer les barres: {e}")
            return 0  # En cas d'erreur, retourner 0 (pas de validation)

    def _load_data(
        self,
        symbol: str,
        timeframe: str,
        start: Optional[str],
        end: Optional[str],
        warmup_required: Optional[int] = None
    ) -> pd.DataFrame:
        """
        Charge les donn√©es OHLCV avec validation de warmup minimal.

        Args:
            symbol: Symbole √† charger (ex: "BTCUSDT")
            timeframe: Timeframe (1h, 4h, 1d, etc.)
            start: Date de d√©but (optionnel)
            end: Date de fin (optionnel)
            warmup_required: Nombre minimal de barres requis (d√©faut: WARMUP_MIN_DEFAULT)

        Returns:
            DataFrame OHLCV valid√©

        Raises:
            InsufficientDataError: Si les donn√©es sont insuffisantes
            DataError: Si les donn√©es sont introuvables
        """
        from data.loader import load_ohlcv

        # 1. D√©terminer le warmup minimal requis
        warmup_min = warmup_required or WARMUP_MIN_DEFAULT

        # 2. Valider la coh√©rence de la fen√™tre temporelle
        if start and end:
            expected_bars = self._estimate_bars_between(start, end, timeframe)

            if expected_bars > 0 and expected_bars < warmup_min:
                self._logger.warning(
                    f"Fen√™tre trop courte d√©tect√©e: {expected_bars} barres estim√©es < {warmup_min} requis. "
                    f"Neutralisation des dates pour charger toutes les donn√©es disponibles."
                )
                # Neutraliser les dates pour recharger tout
                start = None
                end = None

        # 3. Charger les donn√©es
        df = load_ohlcv(symbol, timeframe, start=start, end=end)

        # 4. V√©rifier que les donn√©es existent
        if df is None or df.empty:
            raise DataError(
                f"Donn√©es non trouv√©es: {symbol}_{timeframe}",
                symbol=symbol,
                timeframe=timeframe
            )

        # 5. Validation finale: v√©rifier que nous avons assez de barres
        actual_bars = len(df)
        if actual_bars < warmup_min:
            raise InsufficientDataError(
                message=f"Donn√©es insuffisantes: {actual_bars} barres < {warmup_min} requis pour {symbol}_{timeframe}",
                available_bars=actual_bars,
                required_bars=warmup_min,
                symbol=symbol,
                timeframe=timeframe,
                hint=f"Le warmup des indicateurs n√©cessite au minimum {warmup_min} barres. "
                     f"Disponibles: {actual_bars}. Utilisez une p√©riode plus longue."
            )

        self._logger.debug(
            f"Donn√©es charg√©es avec succ√®s: {actual_bars} barres (warmup requis: {warmup_min})"
        )

        return df

    def _validate_dataframe(
        self,
        df: pd.DataFrame,
        warmup_required: Optional[int] = None,
        symbol: str = "UNKNOWN",
        timeframe: str = "UNKNOWN"
    ) -> None:
        """
        Valide un DataFrame OHLCV.

        Args:
            df: DataFrame √† valider
            warmup_required: Nombre minimal de barres requis (optionnel)
            symbol: Symbole pour les messages d'erreur
            timeframe: Timeframe pour les messages d'erreur

        Raises:
            DataError: Si le format est invalide
            InsufficientDataError: Si les donn√©es sont insuffisantes
        """
        if df is None or df.empty:
            raise DataError("DataFrame vide ou None")

        required = ["open", "high", "low", "close", "volume"]
        missing = [c for c in required if c not in df.columns]
        if missing:
            raise DataError(f"Colonnes manquantes: {missing}")

        if not isinstance(df.index, pd.DatetimeIndex):
            raise DataError("L'index doit √™tre un DatetimeIndex")

        # Validation warmup optionnelle
        if warmup_required is not None:
            actual_bars = len(df)
            if actual_bars < warmup_required:
                raise InsufficientDataError(
                    message=f"Donn√©es insuffisantes: {actual_bars} barres < {warmup_required} requis pour {symbol}_{timeframe}",
                    available_bars=actual_bars,
                    required_bars=warmup_required,
                    symbol=symbol,
                    timeframe=timeframe,
                    hint=f"Le warmup des indicateurs n√©cessite au minimum {warmup_required} barres. "
                         f"Disponibles: {actual_bars}. Utilisez une p√©riode plus longue."
                )

    def _error_response(
        self,
        code: ErrorCode,
        message: str,
        hint: Optional[str] = None,
        details: Optional[str] = None,
        trace_id: Optional[str] = None,
        start_time: float = 0,
    ) -> BackendResponse:
        """Cr√©e une r√©ponse d'erreur standardis√©e."""
        import time
        return BackendResponse(
            status=ResponseStatus.ERROR,
            error=ErrorInfo(
                code=code,
                message_user=message,
                hint=hint,
                details=details,
                trace_id=trace_id,
            ),
            duration_ms=(time.time() - start_time) * 1000 if start_time else 0,
        )


# =============================================================================
# FACTORY & HELPERS
# =============================================================================

# Instance globale (singleton)
_facade_instance: Optional[BackendFacade] = None


def get_facade(config: Optional[Config] = None, debug: bool = False) -> BackendFacade:
    """
    Retourne l'instance globale de la fa√ßade.

    Args:
        config: Configuration (utilis√©e seulement √† la premi√®re cr√©ation)
        debug: Mode debug

    Returns:
        BackendFacade instance
    """
    global _facade_instance
    if _facade_instance is None:
        _facade_instance = BackendFacade(config=config, debug=debug)
    return _facade_instance


def to_ui_payload(result: RunResult) -> UIPayload:
    """
    Convertit un RunResult en UIPayload.

    Fonction utilitaire pour la compatibilit√© avec le code existant.

    Args:
        result: RunResult du moteur

    Returns:
        UIPayload pr√™t pour l'affichage
    """
    return UIPayload.from_run_result(result)


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur l'interface stable UI‚Üîbackend
# - Conventions contrats Request/Response et erreurs structur√©es explicit√©es
# - Read-if/Skip-if ajout√©s pour guider la lecture
```
<!-- MODULE-END: facade.py -->

<!-- MODULE-START: metrics_tier_s.py -->
```json
{
  "name": "metrics_tier_s.py",
  "path": "backtest\\metrics_tier_s.py",
  "ext": ".py",
  "anchor": "metrics_tier_s_py"
}
```
## metrics_tier_s_py
*Chemin* : `backtest\metrics_tier_s.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.metrics_tier_s

Purpose: Calcul des m√©triques avanc√©es (Sortino, Calmar, SQN, Recovery Factor, Ulcer Index, etc.) pour analyse institutionnelle.

Role in pipeline: metrics

Key components: TierSMetrics, calculate_tier_s_metrics, format_tier_s_report, grade_tier_s

Inputs: Returns array, trades list, max_drawdown, PnL

Outputs: TierSMetrics (dataclass), tier_s_score (0-100), tier_s_grade (A/B/C/D/F)

Dependencies: numpy, pandas, optionnel: tabulate (formatage)

Conventions: Toutes les m√©triques normalis√©es (fractions 0-1 pour retours); scores 0-100; grades A=excellent, F=faible.

Read-if: Analyse m√©triques avanc√©es, scores institutionnels, ou grading strat√©gies.

Skip-if: Vous n'utilisez que les m√©triques standards (Sharpe, Sortino basique).
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import numpy as np
import pandas as pd

# Import optionnel de tabulate pour tableaux format√©s
try:
    from tabulate import tabulate
    TABULATE_AVAILABLE = True
except ImportError:
    TABULATE_AVAILABLE = False

# Import des optimisations Numba
from backtest.performance_numba import (
    _expanding_max_numba,
    _ulcer_index_numba,
    _recovery_factor_numba,
    _sortino_downside_deviation_numba,
)


@dataclass
class TierSMetrics:
    """Container pour les m√©triques Tier S."""

    # Ratios de risque ajust√©
    sortino_ratio: float
    calmar_ratio: float
    sqn: float
    martin_ratio: float

    # Facteurs de r√©cup√©ration
    recovery_factor: float
    gain_pain_ratio: float

    # Indices de stress
    ulcer_index: float

    # M√©triques R-Multiple
    avg_r_multiple: float
    expectancy_r: float

    # Sharpe ajust√©
    outlier_adjusted_sharpe: float

    # Qualit√©
    tier_s_score: float  # Score composite 0-100
    tier_s_grade: str    # A, B, C, D, F

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "sortino_ratio": self.sortino_ratio,
            "calmar_ratio": self.calmar_ratio,
            "sqn": self.sqn,
            "martin_ratio": self.martin_ratio,
            "recovery_factor": self.recovery_factor,
            "gain_pain_ratio": self.gain_pain_ratio,
            "ulcer_index": self.ulcer_index,
            "avg_r_multiple": self.avg_r_multiple,
            "expectancy_r": self.expectancy_r,
            "outlier_adjusted_sharpe": self.outlier_adjusted_sharpe,
            "tier_s_score": self.tier_s_score,
            "tier_s_grade": self.tier_s_grade,
        }


def sortino_ratio(
    returns: pd.Series,
    risk_free: float = 0.0,
    periods_per_year: int = 365 * 24,
    target_return: float = 0.0
) -> float:
    """
    Ratio de Sortino am√©lior√©.

    Ne p√©nalise que la volatilit√© baissi√®re (downside deviation).

    Formula: (R - Rf) / œÉ_downside

    Args:
        returns: S√©rie de rendements
        risk_free: Taux sans risque annuel
        periods_per_year: P√©riodes par an
        target_return: Rendement cible (d√©faut: 0)

    Returns:
        Ratio de Sortino annualis√©
    """
    if returns.empty or len(returns) < 2:
        return 0.0

    returns_clean = returns.dropna()
    if returns_clean.empty:
        return 0.0

    # Rendement exc√©dentaire moyen
    rf_period = risk_free / periods_per_year
    target_period = target_return / periods_per_year
    excess_returns = returns_clean - rf_period
    mean_excess = excess_returns.mean()

    # Downside deviation - version Numba optimis√©e (10√ó speedup)
    downside_deviation = _sortino_downside_deviation_numba(
        returns_clean.values,
        target_period
    )

    if downside_deviation <= 1e-10:
        # Pas de volatilit√© baissi√®re significative
        return float('inf') if mean_excess > 0 else 0.0

    # Annualisation
    sortino = (mean_excess * np.sqrt(periods_per_year)) / downside_deviation

    return float(np.clip(sortino, -100, 100))


def calmar_ratio(
    returns: pd.Series,
    equity: pd.Series,
    periods_per_year: int = 365 * 24
) -> float:
    """
    Ratio de Calmar: CAGR / Max Drawdown absolu.

    Mesure le rendement par unit√© de drawdown maximum.
    Bon indicateur de la relation risque/rendement sur le long terme.

    Args:
        returns: S√©rie de rendements
        equity: Courbe d'√©quit√©
        periods_per_year: P√©riodes par an

    Returns:
        Ratio de Calmar

    Note:
        Version optimis√©e Numba pour calcul running_max (100√ó speedup)
    """
    if returns.empty or equity.empty:
        return 0.0

    # CAGR (Compound Annual Growth Rate)
    initial_value = equity.iloc[0]
    final_value = equity.iloc[-1]

    if initial_value <= 0 or final_value <= 0:
        return 0.0

    n_periods = len(equity)
    years = n_periods / periods_per_year

    if years <= 0:
        return 0.0

    cagr = (final_value / initial_value) ** (1 / years) - 1

    # Max Drawdown - version Numba optimis√©e
    running_max = _expanding_max_numba(equity.values)
    drawdown = (equity.values / running_max) - 1.0
    max_dd = abs(np.min(drawdown))

    if max_dd <= 1e-10:
        return float('inf') if cagr > 0 else 0.0

    calmar = cagr / max_dd

    return float(np.clip(calmar, -100, 100))


def sqn(trades_pnl: pd.Series, min_trades: int = 30) -> float:
    """
    System Quality Number (SQN) de Van Tharp.

    Mesure la qualit√© d'un syst√®me de trading.
    Formula: ‚àöN √ó (Mean R / StdDev R)

    Interpr√©tation:
    - SQN < 1.6: Pauvre
    - 1.6 ‚â§ SQN < 2.0: En dessous de la moyenne
    - 2.0 ‚â§ SQN < 2.5: Moyenne
    - 2.5 ‚â§ SQN < 3.0: Bon
    - 3.0 ‚â§ SQN < 5.0: Excellent
    - 5.0 ‚â§ SQN < 7.0: Superbe
    - SQN ‚â• 7.0: Saint Graal

    Args:
        trades_pnl: S√©rie des P&L par trade
        min_trades: Minimum de trades pour calcul valide

    Returns:
        SQN (plafonn√© √† 10 pour √©viter les outliers)
    """
    if trades_pnl.empty or len(trades_pnl) < min_trades:
        return 0.0

    n = len(trades_pnl)
    mean_r = trades_pnl.mean()
    std_r = trades_pnl.std(ddof=1)

    if std_r <= 1e-10:
        return 0.0

    # SQN = ‚àöN √ó (Mean / Std)
    sqn_value = np.sqrt(n) * (mean_r / std_r)

    # Plafonnement selon Van Tharp
    return float(np.clip(sqn_value, -10, 10))


def recovery_factor(
    equity: pd.Series,
    initial_capital: float
) -> float:
    """
    Recovery Factor: Net Profit / Max Drawdown absolu.

    Mesure combien de fois le syst√®me a r√©cup√©r√© son pire drawdown.

    Args:
        equity: Courbe d'√©quit√©
        initial_capital: Capital initial

    Returns:
        Recovery Factor

    Note:
        Version optimis√©e Numba (100√ó plus rapide)
    """
    if equity.empty:
        return 0.0

    # Utiliser version Numba optimis√©e (100√ó speedup)
    return float(_recovery_factor_numba(equity.values, initial_capital))


def ulcer_index(equity: pd.Series) -> float:
    """
    Ulcer Index: Mesure du stress li√© aux drawdowns.

    Plus sensible aux drawdowns prolong√©s que le max drawdown simple.
    Formula: ‚àö(Œ£ D¬≤ / N) o√π D = drawdown en %

    Args:
        equity: Courbe d'√©quit√©

    Returns:
        Ulcer Index (plus bas = mieux)

    Note:
        Version optimis√©e Numba (100√ó plus rapide)
    """
    if equity.empty or len(equity) < 2:
        return 0.0

    # Utiliser version Numba optimis√©e (100√ó speedup)
    return float(_ulcer_index_numba(equity.values))


def martin_ratio(
    returns: pd.Series,
    equity: pd.Series,
    risk_free: float = 0.0,
    periods_per_year: int = 365 * 24
) -> float:
    """
    Martin Ratio (UPI - Ulcer Performance Index).

    Ratio rendement/ulcer index. Alternative au Sharpe utilisant
    l'Ulcer Index comme mesure de risque.

    Formula: (Return - Rf) / Ulcer Index

    Args:
        returns: S√©rie de rendements
        equity: Courbe d'√©quit√©
        risk_free: Taux sans risque annuel
        periods_per_year: P√©riodes par an

    Returns:
        Martin Ratio (plus haut = mieux)
    """
    if returns.empty or equity.empty:
        return 0.0

    # Rendement annualis√©
    total_return = (equity.iloc[-1] / equity.iloc[0]) - 1
    n_periods = len(equity)
    years = n_periods / periods_per_year

    if years <= 0:
        return 0.0

    annualized_return = ((1 + total_return) ** (1 / years) - 1) * 100
    excess_return = annualized_return - risk_free * 100

    # Ulcer Index
    ui = ulcer_index(equity)

    if ui <= 1e-10:
        return float('inf') if excess_return > 0 else 0.0

    return float(np.clip(excess_return / ui, -100, 100))


def gain_pain_ratio(trades_pnl: pd.Series) -> float:
    """
    Gain/Pain Ratio: Somme des gains / Somme des pertes.

    Simple mais efficace pour √©valuer l'asym√©trie gains/pertes.

    Args:
        trades_pnl: S√©rie des P&L par trade

    Returns:
        Gain/Pain ratio (> 1 = profitable)
    """
    if trades_pnl.empty:
        return 0.0

    gains = trades_pnl[trades_pnl > 0].sum()
    losses = abs(trades_pnl[trades_pnl < 0].sum())

    if losses <= 1e-10:
        return float('inf') if gains > 0 else 1.0

    return float(gains / losses)


def r_multiple_stats(
    trades_pnl: pd.Series,
    initial_risk_per_trade: float
) -> Tuple[float, float]:
    """
    Statistiques R-Multiple.

    R = Profit / Risque Initial
    Permet de normaliser les trades par rapport au risque.

    Args:
        trades_pnl: S√©rie des P&L par trade
        initial_risk_per_trade: Risque initial par trade (ex: stop loss)

    Returns:
        Tuple (avg_r_multiple, expectancy_r)
    """
    if trades_pnl.empty or initial_risk_per_trade <= 0:
        return 0.0, 0.0

    # Convertir en R-multiples
    r_multiples = trades_pnl / initial_risk_per_trade

    avg_r = float(r_multiples.mean())

    # Expectancy en R
    wins = r_multiples[r_multiples > 0]
    losses = r_multiples[r_multiples < 0]

    win_rate = len(wins) / len(r_multiples) if len(r_multiples) > 0 else 0
    avg_win_r = wins.mean() if len(wins) > 0 else 0
    avg_loss_r = abs(losses.mean()) if len(losses) > 0 else 0

    expectancy_r = (win_rate * avg_win_r) - ((1 - win_rate) * avg_loss_r)

    return avg_r, float(expectancy_r)


def outlier_adjusted_sharpe(
    returns: pd.Series,
    risk_free: float = 0.0,
    periods_per_year: int = 365 * 24,
    percentile_cutoff: float = 2.5
) -> float:
    """
    Sharpe Ratio ajust√© pour les outliers.

    Exclut les rendements extr√™mes qui peuvent fausser le ratio.

    Args:
        returns: S√©rie de rendements
        risk_free: Taux sans risque annuel
        periods_per_year: P√©riodes par an
        percentile_cutoff: Percentile √† exclure des deux c√¥t√©s

    Returns:
        Sharpe ratio ajust√©
    """
    if returns.empty or len(returns) < 10:
        return 0.0

    returns_clean = returns.dropna()

    # Exclure les outliers
    lower = np.percentile(returns_clean, percentile_cutoff)
    upper = np.percentile(returns_clean, 100 - percentile_cutoff)

    trimmed_returns = returns_clean[(returns_clean >= lower) & (returns_clean <= upper)]

    if len(trimmed_returns) < 2:
        return 0.0

    # Calcul du Sharpe
    rf_period = risk_free / periods_per_year
    excess_returns = trimmed_returns - rf_period
    mean_excess = excess_returns.mean()
    std_returns = trimmed_returns.std(ddof=1)

    if std_returns <= 1e-10:
        return 0.0

    sharpe = (mean_excess * np.sqrt(periods_per_year)) / std_returns

    return float(np.clip(sharpe, -100, 100))


def calculate_tier_s_score(metrics: Dict[str, float]) -> Tuple[float, str]:
    """
    Calcule un score composite Tier S (0-100) et une note (A-F).

    Pond√©ration:
    - Sortino: 20%
    - Calmar: 15%
    - SQN: 25%
    - Recovery Factor: 15%
    - Gain/Pain: 10%
    - Martin Ratio: 15%

    Args:
        metrics: Dict des m√©triques Tier S

    Returns:
        Tuple (score 0-100, grade A-F)
    """
    # Normalisation des m√©triques (0-100 chacune)
    def normalize(value: float, bad: float, good: float) -> float:
        if good == bad:
            return 50.0
        normalized = (value - bad) / (good - bad) * 100
        return float(np.clip(normalized, 0, 100))

    # Seuils (bad, good) pour chaque m√©trique
    thresholds = {
        "sortino_ratio": (0, 3),
        "calmar_ratio": (0, 2),
        "sqn": (0, 5),
        "recovery_factor": (0, 5),
        "gain_pain_ratio": (0.5, 3),
        "martin_ratio": (0, 5),
    }

    weights = {
        "sortino_ratio": 0.20,
        "calmar_ratio": 0.15,
        "sqn": 0.25,
        "recovery_factor": 0.15,
        "gain_pain_ratio": 0.10,
        "martin_ratio": 0.15,
    }

    score = 0.0
    for metric, (bad, good) in thresholds.items():
        value = metrics.get(metric, 0)
        if np.isinf(value):
            value = good * 2  # Traiter inf comme excellent
        normalized = normalize(value, bad, good)
        score += normalized * weights[metric]

    # Grade
    if score >= 90:
        grade = "A"
    elif score >= 75:
        grade = "B"
    elif score >= 60:
        grade = "C"
    elif score >= 40:
        grade = "D"
    else:
        grade = "F"

    return score, grade


def calculate_tier_s_metrics(
    returns: pd.Series,
    equity: pd.Series,
    trades_pnl: pd.Series,
    initial_capital: float = 10000.0,
    initial_risk_per_trade: Optional[float] = None,
    periods_per_year: int = 365 * 24,
    risk_free: float = 0.0
) -> TierSMetrics:
    """
    Calcule toutes les m√©triques Tier S.

    Args:
        returns: S√©rie de rendements
        equity: Courbe d'√©quit√©
        trades_pnl: P&L par trade
        initial_capital: Capital initial
        initial_risk_per_trade: Risque initial par trade (pour R-multiple)
        periods_per_year: P√©riodes par an
        risk_free: Taux sans risque annuel

    Returns:
        TierSMetrics avec toutes les m√©triques
    """
    # Calcul individuel de chaque m√©trique
    sortino = sortino_ratio(returns, risk_free, periods_per_year)
    calmar = calmar_ratio(returns, equity, periods_per_year)
    sqn_val = sqn(trades_pnl)
    recovery = recovery_factor(equity, initial_capital)
    ulcer = ulcer_index(equity)
    martin = martin_ratio(returns, equity, risk_free, periods_per_year)
    gain_pain = gain_pain_ratio(trades_pnl)

    # R-Multiple stats
    if initial_risk_per_trade is None:
        # Estimer le risque comme 2% du capital
        initial_risk_per_trade = initial_capital * 0.02
    avg_r, exp_r = r_multiple_stats(trades_pnl, initial_risk_per_trade)

    # Sharpe ajust√©
    adj_sharpe = outlier_adjusted_sharpe(returns, risk_free, periods_per_year)

    # Score composite
    metrics_dict = {
        "sortino_ratio": sortino,
        "calmar_ratio": calmar,
        "sqn": sqn_val,
        "recovery_factor": recovery,
        "gain_pain_ratio": gain_pain,
        "martin_ratio": martin,
    }
    tier_score, tier_grade = calculate_tier_s_score(metrics_dict)

    return TierSMetrics(
        sortino_ratio=sortino,
        calmar_ratio=calmar,
        sqn=sqn_val,
        martin_ratio=martin,
        recovery_factor=recovery,
        gain_pain_ratio=gain_pain,
        ulcer_index=ulcer,
        avg_r_multiple=avg_r,
        expectancy_r=exp_r,
        outlier_adjusted_sharpe=adj_sharpe,
        tier_s_score=tier_score,
        tier_s_grade=tier_grade,
    )


def format_tier_s_report(metrics: TierSMetrics, use_table: bool = True) -> str:
    """
    Formate un rapport des m√©triques Tier S.

    Args:
        metrics: M√©triques Tier S √† formater
        use_table: Utiliser tabulate pour un format tableau (d√©faut: True)

    Returns:
        Rapport format√© en texte
    """
    grade_colors = {"A": "üü¢", "B": "üîµ", "C": "üü°", "D": "üü†", "F": "üî¥"}
    grade_emoji = grade_colors.get(metrics.tier_s_grade, "‚ö™")

    if TABULATE_AVAILABLE and use_table:
        # Version avec tabulate (format tableau √©l√©gant)
        header = f"\n{'='*70}\n  M√âTRIQUES TIER S (INSTITUTIONNEL)\n{'='*70}"
        grade_line = f"\n  GRADE: {grade_emoji} {metrics.tier_s_grade}  |  SCORE: {metrics.tier_s_score:.1f}/100\n"

        # Tableau des ratios de risque
        risk_ratios = [
            ["Sortino Ratio", f"{metrics.sortino_ratio:.3f}"],
            ["Calmar Ratio", f"{metrics.calmar_ratio:.3f}"],
            ["SQN (Van Tharp)", f"{metrics.sqn:.3f}"],
            ["Martin Ratio (UPI)", f"{metrics.martin_ratio:.3f}"],
        ]

        # Tableau r√©cup√©ration & stress
        recovery = [
            ["Recovery Factor", f"{metrics.recovery_factor:.3f}"],
            ["Gain/Pain Ratio", f"{metrics.gain_pain_ratio:.3f}"],
            ["Ulcer Index", f"{metrics.ulcer_index:.3f}%"],
        ]

        # Tableau R-Multiple
        r_multiple = [
            ["Avg R-Multiple", f"{metrics.avg_r_multiple:.3f}R"],
            ["Expectancy (R)", f"{metrics.expectancy_r:.3f}R"],
        ]

        # Tableau ajustements
        adjustments = [
            ["Outlier-Adj Sharpe", f"{metrics.outlier_adjusted_sharpe:.3f}"],
        ]

        report = header + grade_line
        report += f"\n{'‚îÄ'*70}\n  RATIOS DE RISQUE AJUST√â\n{'‚îÄ'*70}\n"
        report += tabulate(risk_ratios, tablefmt="simple", colalign=("left", "right"))
        report += f"\n\n{'‚îÄ'*70}\n  R√âCUP√âRATION & STRESS\n{'‚îÄ'*70}\n"
        report += tabulate(recovery, tablefmt="simple", colalign=("left", "right"))
        report += f"\n\n{'‚îÄ'*70}\n  R-MULTIPLE\n{'‚îÄ'*70}\n"
        report += tabulate(r_multiple, tablefmt="simple", colalign=("left", "right"))
        report += f"\n\n{'‚îÄ'*70}\n  AJUSTEMENTS\n{'‚îÄ'*70}\n"
        report += tabulate(adjustments, tablefmt="simple", colalign=("left", "right"))
        report += f"\n{'='*70}\n"

        return report
    else:
        # Fallback: version ASCII originale
        report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          M√âTRIQUES TIER S (INSTITUTIONNEL)               ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë GRADE: {grade_emoji} {metrics.tier_s_grade}  |  SCORE: {metrics.tier_s_score:>5.1f}/100                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë RATIOS DE RISQUE AJUST√â                                  ‚ïë
‚ïë   Sortino Ratio:       {metrics.sortino_ratio:>10.3f}                     ‚ïë
‚ïë   Calmar Ratio:        {metrics.calmar_ratio:>10.3f}                     ‚ïë
‚ïë   SQN (Van Tharp):     {metrics.sqn:>10.3f}                     ‚ïë
‚ïë   Martin Ratio (UPI):  {metrics.martin_ratio:>10.3f}                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë R√âCUP√âRATION & STRESS                                    ‚ïë
‚ïë   Recovery Factor:     {metrics.recovery_factor:>10.3f}                     ‚ïë
‚ïë   Gain/Pain Ratio:     {metrics.gain_pain_ratio:>10.3f}                     ‚ïë
‚ïë   Ulcer Index:         {metrics.ulcer_index:>10.3f}%                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë R-MULTIPLE                                               ‚ïë
‚ïë   Avg R-Multiple:      {metrics.avg_r_multiple:>10.3f}R                    ‚ïë
‚ïë   Expectancy (R):      {metrics.expectancy_r:>10.3f}R                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë AJUSTEMENTS                                              ‚ïë
‚ïë   Outlier-Adj Sharpe:  {metrics.outlier_adjusted_sharpe:>10.3f}                     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
        return report


__all__ = [
    "TierSMetrics",
    "calculate_tier_s_metrics",
    "format_tier_s_report",
    "sortino_ratio",
    "calmar_ratio",
    "sqn",
    "recovery_factor",
    "ulcer_index",
    "martin_ratio",
    "gain_pain_ratio",
    "r_multiple_stats",
    "outlier_adjusted_sharpe",
]
```
<!-- MODULE-END: metrics_tier_s.py -->

<!-- MODULE-START: monte_carlo.py -->
```json
{
  "name": "monte_carlo.py",
  "path": "backtest\\monte_carlo.py",
  "ext": ".py",
  "anchor": "monte_carlo_py"
}
```
## monte_carlo_py
*Chemin* : `backtest\monte_carlo.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.monte_carlo

Purpose: √âchantillonnage intelligent de l'espace des param√®tres (random/LHS/Sobol) pour optimisation plus rapide.

Role in pipeline: optimization

Key components: SamplingMethod, ParameterSpace, sample_parameters, MonteCarlo

Inputs: param_space Dict, n_samples, m√©thode (RANDOM/LATIN_HYPERCUBE/SOBOL)

Outputs: √âchantillons (liste de dicts de param√®tres)

Dependencies: numpy, optionnel: scipy.stats (LHS)

Conventions: Param√®tres en fractions [0,1] puis redimensionn√©s; log_scale si demand√©; √©chantillonnage uniforme sur l'espace.

Read-if: Optimisation via Monte Carlo au lieu de sweep exhaustif, ou √©chantillonnage intelligent.

Skip-if: Vous utilisez sweep/optuna/pareto au lieu d'√©chantillonnage al√©atoire.
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple

import numpy as np

from utils.log import get_logger

logger = get_logger(__name__)


class SamplingMethod(Enum):
    """M√©thodes d'√©chantillonnage disponibles."""
    RANDOM = "random"
    LATIN_HYPERCUBE = "latin_hypercube"
    SOBOL = "sobol"


@dataclass
class ParameterSpace:
    """
    D√©finition de l'espace des param√®tres √† √©chantillonner.

    Attributes:
        name: Nom du param√®tre
        min_val: Valeur minimale
        max_val: Valeur maximale
        param_type: 'int' ou 'float'
        log_scale: Si True, √©chantillonnage en √©chelle log
    """
    name: str
    min_val: float
    max_val: float
    param_type: str = "float"
    log_scale: bool = False

    def sample(self, u: float) -> Any:
        """
        Convertit une valeur uniforme [0,1] en valeur du param√®tre.

        Args:
            u: Valeur uniforme entre 0 et 1

        Returns:
            Valeur dans l'espace du param√®tre
        """
        if self.log_scale and self.min_val > 0:
            # √âchantillonnage log-uniforme
            log_min = np.log(self.min_val)
            log_max = np.log(self.max_val)
            value = np.exp(log_min + u * (log_max - log_min))
        else:
            # √âchantillonnage lin√©aire
            value = self.min_val + u * (self.max_val - self.min_val)

        if self.param_type == "int":
            return int(round(value))
        return value


@dataclass
class MonteCarloSampler:
    """
    √âchantillonneur Monte Carlo pour optimisation param√©trique.

    Attributes:
        param_spaces: Liste des espaces de param√®tres
        n_samples: Nombre d'√©chantillons √† g√©n√©rer
        method: M√©thode d'√©chantillonnage
        seed: Seed pour reproductibilit√©
    """
    param_spaces: List[ParameterSpace]
    n_samples: int = 100
    method: SamplingMethod = SamplingMethod.LATIN_HYPERCUBE
    seed: Optional[int] = 42

    def __post_init__(self):
        if self.seed is not None:
            np.random.seed(self.seed)
        self._dim = len(self.param_spaces)

    def generate_samples(self) -> List[Dict[str, Any]]:
        """
        G√©n√®re les √©chantillons selon la m√©thode choisie.

        Returns:
            Liste de dictionnaires {param_name: value}
        """
        if self.method == SamplingMethod.RANDOM:
            uniform_samples = self._random_sampling()
        elif self.method == SamplingMethod.LATIN_HYPERCUBE:
            uniform_samples = self._latin_hypercube_sampling()
        elif self.method == SamplingMethod.SOBOL:
            uniform_samples = self._sobol_sampling()
        else:
            raise ValueError(f"M√©thode inconnue: {self.method}")

        # Convertir les valeurs uniformes en valeurs de param√®tres
        samples = []
        for row in uniform_samples:
            sample = {}
            for i, space in enumerate(self.param_spaces):
                sample[space.name] = space.sample(row[i])
            samples.append(sample)

        logger.info(
            f"Monte Carlo: {len(samples)} √©chantillons g√©n√©r√©s "
            f"({self.method.value}, {self._dim} dimensions)"
        )

        return samples

    def _random_sampling(self) -> np.ndarray:
        """√âchantillonnage al√©atoire uniforme."""
        return np.random.rand(self.n_samples, self._dim)

    def _latin_hypercube_sampling(self) -> np.ndarray:
        """
        Latin Hypercube Sampling (LHS).

        Garantit une meilleure couverture de l'espace que l'al√©atoire pur.
        Chaque dimension est divis√©e en n_samples intervalles √©gaux,
        et on place exactement un point dans chaque intervalle.
        """
        result = np.zeros((self.n_samples, self._dim))

        for dim in range(self._dim):
            # Cr√©er n_samples intervalles
            cut_points = np.linspace(0, 1, self.n_samples + 1)

            # √âchantillonner uniform√©ment dans chaque intervalle
            for i in range(self.n_samples):
                low = cut_points[i]
                high = cut_points[i + 1]
                result[i, dim] = np.random.uniform(low, high)

            # M√©langer pour √©viter les corr√©lations
            np.random.shuffle(result[:, dim])

        return result

    def _sobol_sampling(self) -> np.ndarray:
        """
        S√©quence de Sobol (quasi-random).

        Meilleure distribution que l'al√©atoire, propri√©t√©s de
        low-discrepancy pour une couverture uniforme.

        Impl√©mentation simplifi√©e - pour production, utiliser scipy.stats.qmc
        """
        try:
            from scipy.stats import qmc
            sampler = qmc.Sobol(d=self._dim, scramble=True, seed=self.seed)
            return sampler.random(self.n_samples)
        except ImportError:
            logger.warning("scipy non disponible, fallback vers LHS")
            return self._latin_hypercube_sampling()


@dataclass
class MonteCarloResult:
    """
    R√©sultat d'une optimisation Monte Carlo.

    Attributes:
        samples: Param√®tres test√©s
        scores: Scores obtenus (ex: Sharpe ratio)
        best_params: Meilleurs param√®tres trouv√©s
        best_score: Meilleur score
        convergence_history: √âvolution du meilleur score
    """
    samples: List[Dict[str, Any]]
    scores: List[float]
    best_params: Dict[str, Any]
    best_score: float
    convergence_history: List[float] = field(default_factory=list)

    @property
    def n_evaluated(self) -> int:
        """Nombre d'√©valuations effectu√©es."""
        return len(self.scores)

    def top_k(self, k: int = 5) -> List[Tuple[Dict[str, Any], float]]:
        """
        Retourne les k meilleures configurations.

        Args:
            k: Nombre de configurations √† retourner

        Returns:
            Liste de tuples (params, score) tri√©s par score d√©croissant
        """
        paired = list(zip(self.samples, self.scores))
        paired.sort(key=lambda x: x[1], reverse=True)
        return paired[:k]

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour export."""
        return {
            "n_samples": self.n_evaluated,
            "best_params": self.best_params,
            "best_score": self.best_score,
            "convergence": self.convergence_history,
            "top_5": [
                {"params": p, "score": s}
                for p, s in self.top_k(5)
            ],
        }


class MonteCarloOptimizer:
    """
    Optimiseur Monte Carlo pour recherche de param√®tres.

    Utilise l'√©chantillonnage intelligent pour explorer l'espace
    des param√®tres sans tester toutes les combinaisons.

    Example:
        >>> optimizer = MonteCarloOptimizer(
        ...     param_spaces=[
        ...         ParameterSpace("fast_period", 5, 20, "int"),
        ...         ParameterSpace("slow_period", 20, 50, "int"),
        ...     ],
        ...     n_samples=100,
        ... )
        >>> result = optimizer.optimize(evaluate_fn)
        >>> print(f"Best: {result.best_params} -> {result.best_score}")
    """

    def __init__(
        self,
        param_spaces: List[ParameterSpace],
        n_samples: int = 100,
        method: SamplingMethod = SamplingMethod.LATIN_HYPERCUBE,
        seed: Optional[int] = 42,
        early_stop_patience: int = 20,
        early_stop_threshold: float = 0.001,
    ):
        """
        Initialise l'optimiseur.

        Args:
            param_spaces: Espaces des param√®tres
            n_samples: Nombre d'√©chantillons
            method: M√©thode d'√©chantillonnage
            seed: Seed pour reproductibilit√©
            early_stop_patience: Arr√™t si pas d'am√©lioration apr√®s N √©vals
            early_stop_threshold: Seuil d'am√©lioration minimum
        """
        self.param_spaces = param_spaces
        self.n_samples = n_samples
        self.method = method
        self.seed = seed
        self.early_stop_patience = early_stop_patience
        self.early_stop_threshold = early_stop_threshold

        self._sampler = MonteCarloSampler(
            param_spaces=param_spaces,
            n_samples=n_samples,
            method=method,
            seed=seed,
        )

    def optimize(
        self,
        evaluate_fn: Callable[[Dict[str, Any]], float],
        constraints_fn: Optional[Callable[[Dict[str, Any]], bool]] = None,
        progress_callback: Optional[Callable[[int, int, float], None]] = None,
    ) -> MonteCarloResult:
        """
        Lance l'optimisation Monte Carlo.

        Args:
            evaluate_fn: Fonction d'√©valuation (params -> score)
            constraints_fn: Fonction de validation des contraintes (optionnel)
            progress_callback: Callback de progression (current, total, best_score)

        Returns:
            MonteCarloResult avec les meilleurs param√®tres
        """
        # G√©n√©rer les √©chantillons
        all_samples = self._sampler.generate_samples()

        # Filtrer par contraintes si sp√©cifi√©es
        if constraints_fn is not None:
            samples = [s for s in all_samples if constraints_fn(s)]
            logger.info(
                f"Monte Carlo: {len(samples)}/{len(all_samples)} "
                f"√©chantillons valides apr√®s contraintes"
            )
        else:
            samples = all_samples

        if not samples:
            raise ValueError("Aucun √©chantillon valide apr√®s filtrage des contraintes")

        # √âvaluer les √©chantillons
        scores = []
        best_score = float('-inf')
        best_params = None
        convergence = []
        no_improvement_count = 0

        for i, params in enumerate(samples):
            try:
                score = evaluate_fn(params)
                scores.append(score)

                # Tracking du meilleur
                if score > best_score + self.early_stop_threshold:
                    best_score = score
                    best_params = params.copy()
                    no_improvement_count = 0
                else:
                    no_improvement_count += 1

                convergence.append(best_score)

                # Callback de progression
                if progress_callback is not None:
                    progress_callback(i + 1, len(samples), best_score)

                # Early stopping
                if no_improvement_count >= self.early_stop_patience:
                    logger.info(
                        f"Monte Carlo: Early stop apr√®s {i + 1} √©valuations "
                        f"(pas d'am√©lioration depuis {self.early_stop_patience})"
                    )
                    break

            except Exception as e:
                logger.warning(f"Erreur √©valuation {params}: {e}")
                scores.append(float('-inf'))

        # Tronquer les samples si early stop
        evaluated_samples = samples[:len(scores)]

        logger.info(
            f"Monte Carlo termin√©: {len(scores)} √©valuations, "
            f"meilleur score = {best_score:.4f}"
        )

        return MonteCarloResult(
            samples=evaluated_samples,
            scores=scores,
            best_params=best_params or {},
            best_score=best_score,
            convergence_history=convergence,
        )

    @classmethod
    def from_strategy(
        cls,
        strategy_name: str,
        n_samples: int = 100,
        method: SamplingMethod = SamplingMethod.LATIN_HYPERCUBE,
        **kwargs
    ) -> "MonteCarloOptimizer":
        """
        Cr√©e un optimiseur √† partir d'une strat√©gie enregistr√©e.

        Args:
            strategy_name: Nom de la strat√©gie
            n_samples: Nombre d'√©chantillons
            method: M√©thode d'√©chantillonnage
            **kwargs: Arguments additionnels

        Returns:
            MonteCarloOptimizer configur√©
        """
        from strategies.base import get_strategy

        strategy_class = get_strategy(strategy_name)
        strategy = strategy_class()

        param_spaces = []

        if hasattr(strategy, 'parameter_specs'):
            for name, spec in strategy.parameter_specs.items():
                param_spaces.append(ParameterSpace(
                    name=name,
                    min_val=spec.min_val,
                    max_val=spec.max_val,
                    param_type=spec.param_type,
                ))

        if not param_spaces:
            raise ValueError(
                f"Strat√©gie {strategy_name} n'a pas de parameter_specs"
            )

        return cls(
            param_spaces=param_spaces,
            n_samples=n_samples,
            method=method,
            **kwargs
        )


def monte_carlo_sweep(
    strategy_name: str,
    data,
    n_samples: int = 100,
    method: SamplingMethod = SamplingMethod.LATIN_HYPERCUBE,
    metric: str = "sharpe_ratio",
    seed: Optional[int] = 42,
    constraints_fn: Optional[Callable[[Dict[str, Any]], bool]] = None,
) -> MonteCarloResult:
    """
    Lance un sweep Monte Carlo sur une strat√©gie.

    Fonction de convenance qui combine MonteCarloOptimizer
    avec le BacktestEngine.

    Args:
        strategy_name: Nom de la strat√©gie
        data: DataFrame OHLCV
        n_samples: Nombre d'√©chantillons
        method: M√©thode d'√©chantillonnage
        metric: M√©trique √† optimiser
        seed: Seed reproductibilit√©
        constraints_fn: Contraintes sur les param√®tres

    Returns:
        MonteCarloResult

    Example:
        >>> result = monte_carlo_sweep(
        ...     "ema_cross",
        ...     data,
        ...     n_samples=50,
        ...     constraints_fn=lambda p: p["slow_period"] > p["fast_period"]
        ... )
        >>> print(result.best_params)
    """
    from backtest.engine import BacktestEngine
    from strategies.base import get_strategy

    # Cr√©er l'optimiseur
    optimizer = MonteCarloOptimizer.from_strategy(
        strategy_name,
        n_samples=n_samples,
        method=method,
        seed=seed,
    )

    # Cr√©er le moteur de backtest
    engine = BacktestEngine(initial_capital=10000.0)
    strategy_class = get_strategy(strategy_name)

    def evaluate(params: Dict[str, Any]) -> float:
        """√âvalue une configuration de param√®tres."""
        strategy = strategy_class()
        result = engine.run(data, strategy, params)

        # R√©cup√©rer la m√©trique demand√©e
        metrics = result.metrics
        if hasattr(metrics, metric):
            return getattr(metrics, metric)
        elif hasattr(metrics, 'to_dict'):
            return metrics.to_dict().get(metric, 0.0)
        return 0.0


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur √©chantillonnage intelligent
# - Conventions m√©thodes (RANDOM/LHS/SOBOL) et log_scale explicit√©es
# - Read-if/Skip-if ajout√©s pour guider la lecture

    # Lancer l'optimisation
    return optimizer.optimize(
        evaluate_fn=evaluate,
        constraints_fn=constraints_fn,
    )
```
<!-- MODULE-END: monte_carlo.py -->

<!-- MODULE-START: optuna_optimizer.py -->
```json
{
  "name": "optuna_optimizer.py",
  "path": "backtest\\optuna_optimizer.py",
  "ext": ".py",
  "anchor": "optuna_optimizer_py"
}
```
## optuna_optimizer_py
*Chemin* : `backtest\optuna_optimizer.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.optuna_optimizer

Purpose: Optimiser les param√®tres via Optuna (bay√©sien TPE/CMA-ES) avec pruning et support multi-objectif.

Role in pipeline: optimization

Key components: OptunaOptimizer, OptunaResult, OptunaStudyConfig

Inputs: strategy_name, DataFrame OHLCV, param_space Dict, n_trials, m√©trique(s) √† optimiser, contraintes optionnelles

Outputs: OptunaResult (best_params, best_value, study, history)

Dependencies: optuna (TPE/CMA-ES samplers), backtest.engine, utils.observability

Conventions: param_space Dict avec {"param_name": {"type": "int"/"float", "low": X, "high": Y}}; metric "sharpe_ratio" par d√©faut; directions {"metric": 1/-1}; pruning via MedianPruner/HyperbandPruner.

Read-if: Configuration optimisation bay√©sienne, pruning, multi-objectif (Pareto) ou gestion des trials.

Skip-if: Vous utilisez sweep/pareto au lieu d'optuna.
"""

from __future__ import annotations

import gc
import logging
import time
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple

import pandas as pd

if TYPE_CHECKING:
    from utils.config import Config

try:
    import optuna
    from optuna.pruners import HyperbandPruner, MedianPruner
    from optuna.samplers import CmaEsSampler, TPESampler
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    optuna = None

from backtest.engine import BacktestEngine
from metrics_types import PerformanceMetricsPct, normalize_metrics
from utils.observability import (
    PerfCounters,
    generate_run_id,
    get_obs_logger,
)

logger = logging.getLogger(__name__)


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class ParamSpec:
    """Sp√©cification d'un param√®tre √† optimiser."""
    name: str
    param_type: str  # "int", "float", "categorical"
    low: Optional[float] = None
    high: Optional[float] = None
    choices: Optional[List[Any]] = None
    step: Optional[float] = None
    log: bool = False  # √âchelle logarithmique

    def suggest(self, trial: "optuna.Trial") -> Any:
        """Sugg√®re une valeur pour ce param√®tre."""
        if self.param_type == "int":
            return trial.suggest_int(
                self.name,
                int(self.low),
                int(self.high),
                step=int(self.step) if self.step else 1,
                log=self.log,
            )
        elif self.param_type == "float":
            return trial.suggest_float(
                self.name,
                self.low,
                self.high,
                step=self.step,
                log=self.log,
            )
        elif self.param_type == "categorical":
            return trial.suggest_categorical(self.name, self.choices)
        else:
            raise ValueError(f"Type de param√®tre inconnu: {self.param_type}")


@dataclass
class OptimizationResult:
    """R√©sultat d'une optimisation Optuna."""
    best_params: Dict[str, Any]
    best_value: float
    best_metrics: PerformanceMetricsPct
    n_trials: int
    n_completed: int
    n_pruned: int
    total_time: float
    history: List[Dict[str, Any]] = field(default_factory=list)
    study: Optional[Any] = None  # optuna.Study

    def to_dataframe(self) -> pd.DataFrame:
        """Convertit l'historique en DataFrame."""
        return pd.DataFrame(self.history)

    def get_top_n(
        self, n: int = 10, ascending: bool = False
    ) -> pd.DataFrame:
        """Retourne les N meilleurs trials."""
        df = self.to_dataframe()
        if "value" in df.columns:
            return df.nsmallest(n, "value") if ascending else df.nlargest(
                n, "value"
            )
        return df.head(n)

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel."""
        return f"""
Optuna Optimization Results
===========================
Trials: {self.n_completed}/{self.n_trials} completed, {self.n_pruned} pruned
Total time: {self.total_time:.1f}s
Avg time/trial: {self.total_time / max(1, self.n_completed):.2f}s

Best Value: {self.best_value:.4f}
Best Parameters:
{self.best_params}

Best Metrics:
  Sharpe: {self.best_metrics.get('sharpe_ratio', 'N/A')}
  Total Return: {self.best_metrics.get('total_return_pct', 'N/A')}
  Max Drawdown: {self.best_metrics.get('max_drawdown_pct', 'N/A')}
"""


@dataclass
class MultiObjectiveResult:
    """R√©sultat d'une optimisation multi-objectif."""
    pareto_front: List[Dict[str, Any]]
    n_trials: int
    total_time: float
    study: Optional[Any] = None

    def to_dataframe(self) -> pd.DataFrame:
        """Convertit le front de Pareto en DataFrame."""
        return pd.DataFrame(self.pareto_front)


# ============================================================================
# OPTIMIZER CLASS
# ============================================================================

class OptunaOptimizer:
    """
    Optimiseur bay√©sien pour strat√©gies de trading.

    Utilise Optuna (TPE sampler par d√©faut) pour explorer efficacement
    l'espace des param√®tres avec moins d'√©valuations que le grid search.

    Features:
    - Optimisation single/multi-objectif
    - Pruning automatique (early stopping)
    - Contraintes sur les param√®tres
    - Int√©gration walk-forward
    - Logs structur√©s avec run_id

    Example:
        >>> optimizer = OptunaOptimizer(
        ...     strategy_name="ema_cross",
        ...     data=ohlcv_df,
        ...     param_space={
        ...         "fast_period": {"type": "int", "low": 5, "high": 50},
        ...         "slow_period": {"type": "int", "low": 20, "high": 200},
        ...     },
        ...     constraints=[("slow_period", ">", "fast_period")],
        ... )
        >>> result = optimizer.optimize(n_trials=100)
    """

    def __init__(
        self,
        strategy_name: str,
        data: pd.DataFrame,
        param_space: Dict[str, Dict[str, Any]],
        *,
        initial_capital: float = 10000.0,
        constraints: Optional[List[Tuple[str, str, str]]] = None,
        seed: int = 42,
        early_stop_patience: Optional[int] = None,
        config: Optional["Config"] = None,
        symbol: str = "UNKNOWN",
        timeframe: str = "1m",
    ):
        """
        Initialise l'optimiseur.

        Args:
            strategy_name: Nom de la strat√©gie √† optimiser
            data: DataFrame OHLCV
            param_space: Espace des param√®tres √† explorer
                Format: {"param_name": {"type": "int/float/categorical", ...}}
            initial_capital: Capital de d√©part
            constraints: Contraintes entre param√®tres
                Format: [("param1", ">", "param2"), ...]
            seed: Seed pour reproductibilit√©
            early_stop_patience: Arr√™t anticip√© apr√®s N trials sans am√©lioration (None = d√©sactiv√©)
            config: Configuration du moteur (frais, slippage, etc.)
            symbol: Symbole pour les metadonnees
            timeframe: Timeframe pour les metadonnees
        """
        if not OPTUNA_AVAILABLE:
            raise ImportError(
                "Optuna n'est pas install√©. "
                "Installez-le avec: pip install optuna"
            )

        self.strategy_name = strategy_name
        self.data = data
        self.initial_capital = initial_capital
        self.constraints = constraints or []
        self.seed = seed
        self.early_stop_patience = early_stop_patience
        self.config = config
        self.symbol = symbol
        self.timeframe = timeframe
        self.run_id = generate_run_id()

        # Parser l'espace des param√®tres
        self.param_specs = self._parse_param_space(param_space)

        # Logger avec contexte
        self.logger = get_obs_logger(
            __name__, run_id=self.run_id, strategy=strategy_name
        )

        # Compteurs de performance
        self.counters = PerfCounters()

        # Cache pour √©viter les recalculs
        self._engine: Optional[BacktestEngine] = None
        self._best_metrics: PerformanceMetricsPct = {}

        # Tracking en temps r√©el pour l'UI (accessible depuis callbacks)
        self.best_pnl: float = float("-inf")
        self.best_return_pct: float = float("-inf")
        self.last_pnl: float = 0.0
        self.last_return_pct: float = 0.0

        self.logger.info(
            "optuna_optimizer_init params=%s constraints=%s early_stop=%s",
            len(self.param_specs), len(self.constraints), early_stop_patience or "disabled"
        )

    def _parse_param_space(
        self, param_space: Dict[str, Dict[str, Any]]
    ) -> List[ParamSpec]:
        """Parse l'espace des param√®tres en ParamSpec."""
        specs = []
        for name, config in param_space.items():
            spec = ParamSpec(
                name=name,
                param_type=config.get("type", "float"),
                low=config.get("low"),
                high=config.get("high"),
                choices=config.get("choices"),
                step=config.get("step"),
                log=config.get("log", False),
            )
            specs.append(spec)
        return specs

    def _check_constraints(self, params: Dict[str, Any]) -> bool:
        """V√©rifie que les contraintes sont respect√©es."""
        for left, op, right in self.constraints:
            left_val = params.get(left, 0)
            right_val = params.get(right, 0) if isinstance(right, str) else right

            if op == ">":
                if not left_val > right_val:
                    return False
            elif op == ">=":
                if not left_val >= right_val:
                    return False
            elif op == "<":
                if not left_val < right_val:
                    return False
            elif op == "<=":
                if not left_val <= right_val:
                    return False
            elif op == "!=":
                if not left_val != right_val:
                    return False
            elif op == "==":
                if not left_val == right_val:
                    return False

        return True

    def _create_early_stop_callback(
        self, patience: int, direction: str = "maximize", metric_index: int = 0
    ) -> Callable[["optuna.Study", "optuna.Trial"], None]:
        """
        Cr√©e un callback d'early stopping pour Optuna.

        Arr√™te l'optimisation apr√®s 'patience' trials sans am√©lioration.

        Args:
            patience: Nombre de trials sans am√©lioration avant arr√™t
            direction: "maximize" ou "minimize"
            metric_index: Index de la m√©trique pour multi-objectif (0 par d√©faut)

        Returns:
            Callback Optuna
        """
        best_score: Optional[float] = None
        no_improve_trials = 0

        def callback(study: "optuna.Study", trial: "optuna.Trial") -> None:
            nonlocal best_score, no_improve_trials

            # Ignorer les trials pruned ou failed
            if trial.state != optuna.trial.TrialState.COMPLETE:
                return

            # Support multi-objectif : utiliser trial.values[metric_index]
            try:
                score = trial.values[metric_index] if hasattr(trial, "values") and trial.values else trial.value
            except (AttributeError, IndexError):
                # Fallback pour single-objectif
                score = trial.value

            # Premi√®re it√©ration ou am√©lioration d√©tect√©e
            if best_score is None:
                best_score = score
                no_improve_trials = 0
                self.logger.debug(
                    "early_stop_init best_score=%.4f trial=%s",
                    score, trial.number
                )
            else:
                improved = (
                    score > best_score if direction == "maximize"
                    else score < best_score
                )

                if improved:
                    self.logger.debug(
                        "early_stop_improve old=%.4f new=%.4f trial=%s",
                        best_score, score, trial.number
                    )
                    best_score = score
                    no_improve_trials = 0
                else:
                    no_improve_trials += 1
                    self.logger.debug(
                        "early_stop_no_improve count=%s/%s trial=%s",
                        no_improve_trials, patience, trial.number
                    )

            # Arr√™t anticip√© si patience d√©pass√©e
            if no_improve_trials >= patience:
                self.logger.info(
                    "early_stop_triggered trials_without_improvement=%s best_score=%.4f",
                    no_improve_trials, best_score
                )
                study.stop()

        return callback

    def _create_objective(
        self,
        metric: str = "sharpe_ratio",
        direction: str = "maximize",
        use_walk_forward: bool = False,
    ) -> Callable[["optuna.Trial"], float]:
        """
        Cr√©e la fonction objectif pour Optuna.

        Args:
            metric: M√©trique √† optimiser
            direction: "maximize" ou "minimize"
            use_walk_forward: Utiliser validation walk-forward

        Returns:
            Fonction objectif callable
        """
        # Cr√©er l'engine une seule fois
        if self._engine is None:
            engine_kwargs = {
                "initial_capital": self.initial_capital,
                "run_id": self.run_id,
            }
            if self.config is not None:
                engine_kwargs["config"] = self.config
            self._engine = BacktestEngine(**engine_kwargs)

        def objective(trial: "optuna.Trial") -> float:
            # Sugg√©rer les param√®tres
            params = {}
            for spec in self.param_specs:
                params[spec.name] = spec.suggest(trial)

            # V√©rifier les contraintes
            if not self._check_constraints(params):
                # P√©naliser les combinaisons invalides
                return float("-inf") if direction == "maximize" else float("inf")

            try:
                # Ex√©cuter le backtest avec mode rapide pour optimisation
                result = self._engine.run(
                    df=self.data,
                    strategy=self.strategy_name,
                    params=params,
                    symbol=self.symbol,
                    timeframe=self.timeframe,
                    silent_mode=True,     # Pas de logs pour performance
                    fast_metrics=True,    # Mode NumPy pur pour Sharpe (10x plus rapide)
                )

                # Log des m√©triques disponibles au premier trial
                if trial.number == 0:
                    available_metrics = sorted(result.metrics.keys())
                    self.logger.info(
                        "trial_0_metrics_available count=%s metrics=[%s]",
                        len(available_metrics),
                        ", ".join(available_metrics)
                    )

                # Extraire la m√©trique (STRICT: crash si absente)
                if metric not in result.metrics:
                    available = ", ".join(sorted(result.metrics.keys()))
                    msg = (
                        f"Optuna metric '{metric}' not found in result.metrics. "
                        f"Available metrics: [{available}]. "
                        f"trial={trial.number} params={params}"
                    )
                    self.logger.error(msg)
                    raise KeyError(msg)

                value = float(result.metrics[metric])

                # Extraire P&L et Return pour tracking temps r√©el UI
                current_pnl = float(result.metrics.get("total_pnl", 0.0))
                current_return = float(result.metrics.get("total_return_pct", 0.0))
                self.last_pnl = current_pnl
                self.last_return_pct = current_return

                # Mettre √† jour les meilleurs scores (bas√© sur P&L, pas sur la m√©trique optimis√©e)
                if current_pnl > self.best_pnl:
                    self.best_pnl = current_pnl
                    self.best_return_pct = current_return

                # Stocker dans trial.user_attrs pour acc√®s depuis callbacks
                # OPTIMISATION: Ne stocker que les infos essentielles pour r√©duire la m√©moire
                trial.set_user_attr("pnl", current_pnl)
                trial.set_user_attr("return_pct", current_return)
                # Supprim√©: best_pnl_so_far et best_return_so_far (redondant, accessible via optimizer)

                # OPTIMISATION: Garbage collection p√©riodique pour les gros runs
                if trial.number > 0 and trial.number % 500 == 0:
                    gc.collect()

                # Stocker les meilleures m√©triques
                if (direction == "maximize" and value > self._best_metrics.get(
                    metric, float("-inf")
                )) or (direction == "minimize" and value < self._best_metrics.get(
                    metric, float("inf")
                )):
                    self._best_metrics = normalize_metrics(result.metrics, "pct")

                # Log pour debug
                self.logger.debug(
                    "trial_%s params=%s %s=%.4f",
                    trial.number, params, metric, value
                )

                return value

            except KeyError:
                raise
            except Exception as e:
                self.logger.warning(
                    "trial_%s_failed error=%s", trial.number, str(e)
                )
                # Retourner une valeur tr√®s mauvaise
                return float("-inf") if direction == "maximize" else float("inf")

        return objective

    def optimize(
        self,
        n_trials: int = 100,
        metric: str = "sharpe_ratio",
        direction: str = "maximize",
        *,
        timeout: Optional[float] = None,
        sampler: str = "tpe",
        pruner: str = "median",
        n_startup_trials: int = 10,
        show_progress: bool = True,
        callbacks: Optional[List[Callable]] = None,
        early_stop_patience: Optional[int] = None,
    ) -> OptimizationResult:
        """
        Lance l'optimisation.

        Args:
            n_trials: Nombre de trials √† ex√©cuter
            metric: M√©trique √† optimiser
            direction: "maximize" ou "minimize"
            timeout: Timeout en secondes (optionnel)
            sampler: Algorithme ("tpe", "cmaes", "random")
            pruner: Strat√©gie de pruning ("median", "hyperband", "none")
            n_startup_trials: Trials al√©atoires avant TPE
            show_progress: Afficher la progression
            callbacks: Callbacks Optuna optionnels
            early_stop_patience: Arr√™t apr√®s N trials sans am√©lioration (None = utiliser valeur __init__)

        Returns:
            OptimizationResult avec les meilleurs param√®tres
        """
        self.logger.info(
            "optimization_start n_trials=%s metric=%s direction=%s",
            n_trials, metric, direction
        )

        self.counters.start("total")
        start_time = time.time()

        # Cr√©er le sampler
        # OPTIMISATION: Pour les gros runs (>1000 trials), limiter l'historique TPE
        # pour √©viter le ralentissement O(n¬≤)
        if sampler == "tpe":
            # n_ei_candidates: nombre de candidats √©valu√©s (d√©faut 24, on garde)
            # consider_prior: utiliser la distribution prior
            # consider_magic_clip: √©viter les valeurs extr√™mes
            optuna_sampler = TPESampler(
                seed=self.seed,
                n_startup_trials=n_startup_trials,
                # Limiter l'historique pour les gros runs (garde les 500 meilleurs trials r√©cents)
                consider_prior=True,
                consider_magic_clip=True,
            )
        elif sampler == "cmaes":
            optuna_sampler = CmaEsSampler(seed=self.seed)
        else:
            optuna_sampler = optuna.samplers.RandomSampler(seed=self.seed)

        # Cr√©er le pruner
        if pruner == "median":
            optuna_pruner = MedianPruner(
                n_startup_trials=n_startup_trials,
                n_warmup_steps=5,
            )
        elif pruner == "hyperband":
            optuna_pruner = HyperbandPruner()
        else:
            optuna_pruner = optuna.pruners.NopPruner()

        # Cr√©er l'√©tude
        study = optuna.create_study(
            direction=direction,
            sampler=optuna_sampler,
            pruner=optuna_pruner,
        )

        # Configurer le logging Optuna
        if not show_progress:
            optuna.logging.set_verbosity(optuna.logging.WARNING)

        # Cr√©er l'objectif
        objective = self._create_objective(metric, direction)

        # Pr√©parer les callbacks (early stopping si configur√©)
        final_callbacks = callbacks or []

        # Utiliser early_stop_patience de l'argument ou de l'instance
        patience = early_stop_patience if early_stop_patience is not None else self.early_stop_patience

        if patience and patience > 0:
            early_stop_cb = self._create_early_stop_callback(patience, direction)
            final_callbacks.append(early_stop_cb)
            self.logger.info(
                "early_stop_enabled patience=%s direction=%s",
                patience, direction
            )

        # Lancer l'optimisation
        study.optimize(
            objective,
            n_trials=n_trials,
            timeout=timeout,
            callbacks=final_callbacks if final_callbacks else None,
            show_progress_bar=show_progress,
        )

        self.counters.stop("total")
        total_time = time.time() - start_time

        # Construire l'historique
        history = []
        for trial in study.trials:
            if trial.state == optuna.trial.TrialState.COMPLETE:
                history.append({
                    "trial": trial.number,
                    "value": trial.value,
                    **trial.params,
                })

        # Compter les trials
        n_completed = len([
            t for t in study.trials
            if t.state == optuna.trial.TrialState.COMPLETE
        ])
        n_pruned = len([
            t for t in study.trials
            if t.state == optuna.trial.TrialState.PRUNED
        ])

        result = OptimizationResult(
            best_params=study.best_params,
            best_value=study.best_value,
            best_metrics=self._best_metrics,
            n_trials=n_trials,
            n_completed=n_completed,
            n_pruned=n_pruned,
            total_time=total_time,
            history=history,
            study=study,
        )

        self.logger.info(
            "optimization_end duration=%.1fs best_%s=%.4f",
            total_time, metric, study.best_value
        )

        return result

    def optimize_multi_objective(
        self,
        n_trials: int = 100,
        metrics: List[str] = None,
        directions: List[str] = None,
        *,
        timeout: Optional[float] = None,
        show_progress: bool = True,
        early_stop_patience: Optional[int] = None,
    ) -> MultiObjectiveResult:
        """
        Optimisation multi-objectif (front de Pareto).

        Args:
            n_trials: Nombre de trials
            metrics: Liste des m√©triques √† optimiser
            directions: Liste des directions ("maximize"/"minimize")
            timeout: Timeout en secondes
            show_progress: Afficher la progression
            early_stop_patience: Arr√™t apr√®s N trials sans am√©lioration (None = utiliser valeur __init__)

        Returns:
            MultiObjectiveResult avec le front de Pareto

        Example:
            >>> result = optimizer.optimize_multi_objective(
            ...     n_trials=100,
            ...     metrics=["sharpe_ratio", "max_drawdown_pct"],
            ...     directions=["maximize", "minimize"],
            ... )
        """
        metrics = metrics or ["sharpe_ratio", "max_drawdown_pct"]
        directions = directions or ["maximize", "minimize"]

        self.logger.info(
            "multi_objective_start n_trials=%s metrics=%s",
            n_trials, metrics
        )

        start_time = time.time()

        # Cr√©er l'engine
        if self._engine is None:
            engine_kwargs = {
                "initial_capital": self.initial_capital,
                "run_id": self.run_id,
            }
            if self.config is not None:
                engine_kwargs["config"] = self.config
            self._engine = BacktestEngine(**engine_kwargs)

        def multi_objective(trial: "optuna.Trial") -> List[float]:
            # Sugg√©rer les param√®tres
            params = {}
            for spec in self.param_specs:
                params[spec.name] = spec.suggest(trial)

            # V√©rifier les contraintes
            if not self._check_constraints(params):
                return [
                    float("-inf") if d == "maximize" else float("inf")
                    for d in directions
                ]

            try:
                result = self._engine.run(
                    df=self.data,
                    strategy=self.strategy_name,
                    params=params,
                    symbol=self.symbol,
                    timeframe=self.timeframe,
                )

                # Log des m√©triques disponibles au premier trial
                if trial.number == 0:
                    available_metrics = sorted(result.metrics.keys())
                    self.logger.info(
                        "multi_obj_trial_0_metrics count=%s metrics=[%s]",
                        len(available_metrics),
                        ", ".join(available_metrics)
                    )

                # Extraire les m√©triques (STRICT: crash si absente)
                values = []
                for m in metrics:
                    if m not in result.metrics:
                        available = ", ".join(sorted(result.metrics.keys()))
                        msg = (
                            f"Multi-objective metric '{m}' not found in result.metrics. "
                            f"Available metrics: [{available}]. "
                            f"trial={trial.number} params={params}"
                        )
                        self.logger.error(msg)
                        raise KeyError(msg)
                    values.append(float(result.metrics[m]))

                # Log des valeurs extraites
                self.logger.debug(
                    "trial_%s metrics_extracted %s",
                    trial.number,
                    dict(zip(metrics, values))
                )

                return values

            except KeyError:
                raise
            except Exception as e:
                self.logger.warning(
                    "trial_%s_failed error=%s", trial.number, str(e)
                )
                return [
                    float("-inf") if d == "maximize" else float("inf")
                    for d in directions
                ]

        # Cr√©er l'√©tude multi-objectif
        study = optuna.create_study(
            directions=directions,
            sampler=TPESampler(seed=self.seed),
        )

        if not show_progress:
            optuna.logging.set_verbosity(optuna.logging.WARNING)

        # Early stopping pour multi-objectif (sur m√©trique primaire)
        callbacks = []
        patience = early_stop_patience if early_stop_patience is not None else self.early_stop_patience

        if patience and patience > 0:
            # Utiliser la premi√®re m√©trique (index 0) comme r√©f√©rence pour early stopping
            early_stop_cb = self._create_early_stop_callback(
                patience,
                directions[0],
                metric_index=0  # Premi√®re m√©trique
            )
            callbacks.append(early_stop_cb)
            self.logger.info(
                "early_stop_enabled patience=%s primary_metric=%s",
                patience, metrics[0]
            )

        study.optimize(
            multi_objective,
            n_trials=n_trials,
            timeout=timeout,
            callbacks=callbacks if callbacks else None,
            show_progress_bar=show_progress,
        )

        total_time = time.time() - start_time

        # Extraire le front de Pareto
        pareto_front = []
        for trial in study.best_trials:
            entry = {
                "trial": trial.number,
                **{m: v for m, v in zip(metrics, trial.values)},
                **trial.params,
            }
            pareto_front.append(entry)

        result = MultiObjectiveResult(
            pareto_front=pareto_front,
            n_trials=n_trials,
            total_time=total_time,
            study=study,
        )

        self.logger.info(
            "multi_objective_end duration=%.1fs pareto_size=%s",
            total_time, len(pareto_front)
        )

        return result


# ============================================================================
# CONVENIENCE FUNCTIONS
# ============================================================================

def quick_optimize(
    strategy_name: str,
    data: pd.DataFrame,
    param_space: Dict[str, Dict[str, Any]],
    n_trials: int = 100,
    metric: str = "sharpe_ratio",
    **kwargs,
) -> OptimizationResult:
    """
    Raccourci pour une optimisation rapide.

    Args:
        strategy_name: Nom de la strat√©gie
        data: DataFrame OHLCV
        param_space: Espace des param√®tres
        n_trials: Nombre de trials
        metric: M√©trique √† optimiser
        **kwargs: Arguments additionnels pour OptunaOptimizer

    Returns:
        OptimizationResult

    Example:
        >>> result = quick_optimize(
        ...     "ema_cross",
        ...     df,
        ...     param_space={
        ...         "fast_period": {"type": "int", "low": 5, "high": 50},
        ...         "slow_period": {"type": "int", "low": 20, "high": 200},
        ...     },
        ...     n_trials=50,
        ...     constraints=[("slow_period", ">", "fast_period")],
        ... )
    """
    if not OPTUNA_AVAILABLE:
        raise ImportError("Optuna non install√©: pip install optuna")

    constraints = kwargs.pop("constraints", None)

    optimizer = OptunaOptimizer(
        strategy_name=strategy_name,
        data=data,
        param_space=param_space,
        constraints=constraints,
        **kwargs,
    )

    return optimizer.optimize(n_trials=n_trials, metric=metric)


def suggest_param_space(strategy_name: str) -> Dict[str, Dict[str, Any]]:
    """
    Sugg√®re un espace de param√®tres pour une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        Dict avec l'espace des param√®tres sugg√©r√©
    """
    # Espaces par d√©faut pour les strat√©gies connues
    default_spaces = {
        "ema_cross": {
            "fast_period": {"type": "int", "low": 5, "high": 50},
            "slow_period": {"type": "int", "low": 20, "high": 200},
        },
        "bollinger_atr": {
            "bb_period": {"type": "int", "low": 10, "high": 50},
            "bb_std": {"type": "float", "low": 1.5, "high": 3.0, "step": 0.1},
            "atr_period": {"type": "int", "low": 7, "high": 28},
            "atr_mult": {"type": "float", "low": 1.0, "high": 3.0, "step": 0.1},
        },
        "rsi_reversal": {
            "rsi_period": {"type": "int", "low": 7, "high": 28},
            "oversold_level": {"type": "int", "low": 20, "high": 40},
            "overbought_level": {"type": "int", "low": 60, "high": 80},
        },
        "macd_cross": {
            "fast_period": {"type": "int", "low": 8, "high": 20},
            "slow_period": {"type": "int", "low": 20, "high": 35},
            "signal_period": {"type": "int", "low": 5, "high": 15},
        },
    }

    if strategy_name in default_spaces:
        return default_spaces[strategy_name]

    # Espace g√©n√©rique
    return {
        "param1": {"type": "float", "low": 0.1, "high": 10.0},
        "param2": {"type": "int", "low": 5, "high": 50},
    }


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    "OptunaOptimizer",
    "OptimizationResult",
    "MultiObjectiveResult",
    "ParamSpec",
    "quick_optimize",
    "suggest_param_space",
    "OPTUNA_AVAILABLE",
]


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur optimisation bay√©sienne
# - Conventions Optuna (param_space format, directions, pruning) explicit√©es
# - Read-if/Skip-if ajout√©s pour tri rapide
```
<!-- MODULE-END: optuna_optimizer.py -->

<!-- MODULE-START: pareto.py -->
```json
{
  "name": "pareto.py",
  "path": "backtest\\pareto.py",
  "ext": ".py",
  "anchor": "pareto_py"
}
```
## pareto_py
*Chemin* : `backtest\pareto.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.pareto

Purpose: Optimiser multi-objectif avec d√©tection domination Pareto et early stopping automatique.

Role in pipeline: optimization

Key components: ParetoPoint, ParetoFrontier, pareto_optimize, is_dominated

Inputs: points (params + m√©triques), directions optimisation (1=max, -1=min)

Outputs: ParetoFrontier (fronti√®re optimale), points domin√©s exclu

Dependencies: numpy

Conventions: Point domine si >= sur tous les objectifs et > sur au moins un; fronti√®re mise √† jour dynamiquement; early stop si nouvelle solution non-domin√©e.

Read-if: Multi-objectif (ex: Sharpe ET max_drawdown), pruning automatique, or fronti√®re de Pareto.

Skip-if: Single-objectif uniquement (sweep/optuna simple).
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional

import numpy as np

logger = logging.getLogger(__name__)


@dataclass
class ParetoPoint:
    """
    Point dans l'espace des objectifs.

    Attributes:
        params: Param√®tres de la strat√©gie
        objectives: Dict des valeurs d'objectifs (nom -> valeur)
        metadata: Donn√©es additionnelles
    """
    params: Dict[str, Any]
    objectives: Dict[str, float]
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Convertit les objectifs en float."""
        self.objectives = {k: float(v) for k, v in self.objectives.items()}

    def dominates(self, other: "ParetoPoint", directions: Dict[str, int]) -> bool:
        """
        V√©rifie si ce point domine l'autre.

        Un point A domine B si:
        - A est au moins aussi bon que B sur tous les objectifs
        - A est strictement meilleur sur au moins un objectif

        Args:
            other: Autre point √† comparer
            directions: Dict objectif -> direction (1=maximiser, -1=minimiser)

        Returns:
            True si self domine other
        """
        dominated_keys = set(self.objectives.keys()) & set(other.objectives.keys())

        at_least_as_good = True
        strictly_better = False

        for key in dominated_keys:
            direction = directions.get(key, 1)  # D√©faut: maximiser
            self_val = self.objectives[key] * direction
            other_val = other.objectives[key] * direction

            if self_val < other_val:
                at_least_as_good = False
                break
            elif self_val > other_val:
                strictly_better = True

        return at_least_as_good and strictly_better

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "params": self.params,
            "objectives": self.objectives,
            "metadata": self.metadata,
        }


@dataclass
class ParetoFrontier:
    """
    Fronti√®re de Pareto dynamique.

    Maintient l'ensemble des points non-domin√©s.
    """
    directions: Dict[str, int] = field(default_factory=dict)
    points: List[ParetoPoint] = field(default_factory=list)

    def __post_init__(self):
        """Initialise les directions par d√©faut."""
        # Objectifs standards
        default_directions = {
            "sharpe_ratio": 1,      # Maximiser
            "sortino_ratio": 1,     # Maximiser
            "total_return": 1,      # Maximiser
            "profit_factor": 1,     # Maximiser
            "win_rate": 1,          # Maximiser
            "max_drawdown": -1,     # Minimiser
            "volatility": -1,       # Minimiser
            "sqn": 1,               # Maximiser
            "calmar_ratio": 1,      # Maximiser
        }

        for key, direction in default_directions.items():
            if key not in self.directions:
                self.directions[key] = direction

    def add_point(self, point: ParetoPoint) -> bool:
        """
        Ajoute un point √† la fronti√®re si non-domin√©.

        Met √† jour la fronti√®re en supprimant les points domin√©s.

        Args:
            point: Point √† ajouter

        Returns:
            True si le point a √©t√© ajout√© (non-domin√©)
        """
        # V√©rifier si le nouveau point est domin√©
        for existing in self.points:
            if existing.dominates(point, self.directions):
                return False

        # Supprimer les points domin√©s par le nouveau
        self.points = [
            p for p in self.points
            if not point.dominates(p, self.directions)
        ]

        # Ajouter le nouveau point
        self.points.append(point)
        return True

    def is_dominated(self, point: ParetoPoint) -> bool:
        """V√©rifie si un point est domin√© par la fronti√®re."""
        for existing in self.points:
            if existing.dominates(point, self.directions):
                return True
        return False

    def get_best(self, objective: str) -> Optional[ParetoPoint]:
        """Retourne le meilleur point pour un objectif donn√©."""
        if not self.points:
            return None

        direction = self.directions.get(objective, 1)

        return max(
            self.points,
            key=lambda p: p.objectives.get(objective, float('-inf')) * direction
        )

    def size(self) -> int:
        """Retourne le nombre de points sur la fronti√®re."""
        return len(self.points)

    def to_list(self) -> List[Dict[str, Any]]:
        """Convertit la fronti√®re en liste de dicts."""
        return [p.to_dict() for p in self.points]


class ParetoPruner:
    """
    Pruner bas√© sur la dominance de Pareto.

    Permet d'arr√™ter l'√©valuation de combinaisons de param√®tres
    qui sont clairement domin√©es.

    Example:
        >>> pruner = ParetoPruner(objectives=["sharpe_ratio", "max_drawdown"])
        >>>
        >>> for params in param_grid:
        >>>     # Estimation rapide (partielle)
        >>>     quick_result = quick_evaluate(params)
        >>>
        >>>     if pruner.should_prune(quick_result):
        >>>         continue  # Skip cette combinaison
        >>>
        >>>     # √âvaluation compl√®te
        >>>     full_result = full_evaluate(params)
        >>>     pruner.report(params, full_result)
    """

    def __init__(
        self,
        objectives: List[str],
        directions: Optional[Dict[str, int]] = None,
        prune_threshold: float = 0.8,
        min_frontier_size: int = 5,
    ):
        """
        Args:
            objectives: Liste des objectifs √† optimiser
            directions: Dict objectif -> direction (1=max, -1=min)
            prune_threshold: Seuil de pruning (0-1)
            min_frontier_size: Taille min de fronti√®re avant pruning
        """
        self.objectives = objectives
        self.prune_threshold = prune_threshold
        self.min_frontier_size = min_frontier_size

        # Configurer les directions
        dir_config = directions or {}
        self.frontier = ParetoFrontier(directions=dir_config)

        # Stats
        self._total_evaluated = 0
        self._total_pruned = 0
        self._total_reported = 0

    def should_prune(
        self,
        partial_objectives: Dict[str, float],
        params: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        D√©termine si une combinaison devrait √™tre pruned.

        Args:
            partial_objectives: Estimation partielle des objectifs
            params: Param√®tres (optionnel, pour logging)

        Returns:
            True si la combinaison devrait √™tre ignor√©e
        """
        self._total_evaluated += 1

        # Pas de pruning si fronti√®re trop petite
        if self.frontier.size() < self.min_frontier_size:
            return False

        # Cr√©er un point avec les objectifs partiels
        point = ParetoPoint(
            params=params or {},
            objectives=partial_objectives,
        )

        # V√©rifier la domination
        if self.frontier.is_dominated(point):
            # Appliquer le seuil de pruning (probabiliste)
            if np.random.random() < self.prune_threshold:
                self._total_pruned += 1
                return True

        return False

    def report(
        self,
        params: Dict[str, Any],
        objectives: Dict[str, float],
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        Rapporte les r√©sultats complets d'une √©valuation.

        Args:
            params: Param√®tres √©valu√©s
            objectives: Valeurs des objectifs
            metadata: Donn√©es additionnelles

        Returns:
            True si le point a √©t√© ajout√© √† la fronti√®re
        """
        self._total_reported += 1

        point = ParetoPoint(
            params=params,
            objectives={k: objectives.get(k, 0) for k in self.objectives},
            metadata=metadata or {},
        )

        return self.frontier.add_point(point)

    def get_frontier(self) -> ParetoFrontier:
        """Retourne la fronti√®re de Pareto."""
        return self.frontier

    def get_best_params(self, objective: str) -> Optional[Dict[str, Any]]:
        """Retourne les meilleurs param√®tres pour un objectif."""
        best = self.frontier.get_best(objective)
        return best.params if best else None

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de pruning."""
        return {
            "total_evaluated": self._total_evaluated,
            "total_pruned": self._total_pruned,
            "total_reported": self._total_reported,
            "frontier_size": self.frontier.size(),
            "prune_rate": self._total_pruned / max(1, self._total_evaluated),
        }


class MultiObjectiveOptimizer:
    """
    Optimiseur multi-objectif avec Pareto pruning.

    Combine grid search avec pruning intelligent pour
    r√©duire le nombre d'√©valuations n√©cessaires.

    Example:
        >>> optimizer = MultiObjectiveOptimizer(
        >>>     objectives=["sharpe_ratio", "max_drawdown"],
        >>>     directions={"sharpe_ratio": 1, "max_drawdown": -1}
        >>> )
        >>>
        >>> results = optimizer.optimize(
        >>>     param_grid={"fast": [5,10,15], "slow": [20,30,40]},
        >>>     evaluate_fn=run_backtest,
        >>>     quick_evaluate_fn=quick_backtest,  # Optional
        >>> )
    """

    def __init__(
        self,
        objectives: List[str],
        directions: Optional[Dict[str, int]] = None,
        prune_threshold: float = 0.7,
        min_samples_before_prune: int = 10,
    ):
        """
        Args:
            objectives: Objectifs √† optimiser
            directions: Directions d'optimisation
            prune_threshold: Agressivit√© du pruning
            min_samples_before_prune: √âchantillons minimum avant pruning
        """
        self.objectives = objectives
        self.directions = directions or {}
        self.prune_threshold = prune_threshold
        self.min_samples_before_prune = min_samples_before_prune

        self._pruner: Optional[ParetoPruner] = None
        self._results: List[Dict[str, Any]] = []

    def optimize(
        self,
        param_grid: Dict[str, List[Any]],
        evaluate_fn: Callable[[Dict[str, Any]], Dict[str, float]],
        quick_evaluate_fn: Optional[Callable[[Dict[str, Any]], Dict[str, float]]] = None,
        constraints_fn: Optional[Callable[[Dict[str, Any]], bool]] = None,
        progress_callback: Optional[Callable[[int, int, Dict], None]] = None,
        max_evaluations: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        Ex√©cute l'optimisation multi-objectif.

        Args:
            param_grid: Grille de param√®tres
            evaluate_fn: Fonction d'√©valuation compl√®te
            quick_evaluate_fn: Fonction d'√©valuation rapide (pour pruning)
            constraints_fn: Fonction de contraintes (retourne True si valide)
            progress_callback: Callback de progression
            max_evaluations: Nombre max d'√©valuations

        Returns:
            Dict avec frontier, stats, all_results
        """
        # Initialiser le pruner
        self._pruner = ParetoPruner(
            objectives=self.objectives,
            directions=self.directions,
            prune_threshold=self.prune_threshold,
            min_frontier_size=self.min_samples_before_prune,
        )
        self._results = []

        # G√©n√©rer toutes les combinaisons
        combinations = self._generate_combinations(param_grid)
        total = len(combinations)

        if max_evaluations:
            combinations = combinations[:max_evaluations]

        evaluated = 0
        pruned = 0

        for i, params in enumerate(combinations):
            # V√©rifier contraintes
            if constraints_fn and not constraints_fn(params):
                continue

            # Quick evaluation pour d√©cider du pruning
            if quick_evaluate_fn and evaluated >= self.min_samples_before_prune:
                quick_result = quick_evaluate_fn(params)

                if self._pruner.should_prune(quick_result, params):
                    pruned += 1
                    if progress_callback:
                        progress_callback(i + 1, total, {"status": "pruned"})
                    continue

            # √âvaluation compl√®te
            try:
                result = evaluate_fn(params)
                self._pruner.report(params, result, {"index": evaluated})

                self._results.append({
                    "params": params,
                    "objectives": result,
                    "on_frontier": True,  # Sera mis √† jour
                })

                evaluated += 1

                if progress_callback:
                    progress_callback(i + 1, total, {
                        "status": "evaluated",
                        "frontier_size": self._pruner.frontier.size(),
                    })

            except Exception as e:
                logger.warning(f"√âvaluation √©chou√©e pour {params}: {e}")

        # Marquer les points sur la fronti√®re
        frontier_params = [p.params for p in self._pruner.frontier.points]
        for result in self._results:
            result["on_frontier"] = result["params"] in frontier_params

        return {
            "frontier": self._pruner.frontier.to_list(),
            "stats": {
                **self._pruner.get_stats(),
                "total_combinations": total,
                "evaluated": evaluated,
                "pruned": pruned,
            },
            "all_results": self._results,
            "best_per_objective": {
                obj: self._pruner.get_best_params(obj)
                for obj in self.objectives
            },
        }

    def _generate_combinations(
        self,
        param_grid: Dict[str, List[Any]]
    ) -> List[Dict[str, Any]]:
        """G√©n√®re toutes les combinaisons de param√®tres."""
        import itertools

        keys = list(param_grid.keys())
        values = [param_grid[k] for k in keys]

        combinations = []
        for combo in itertools.product(*values):
            combinations.append(dict(zip(keys, combo)))

        # M√©langer pour √©viter les biais
        np.random.shuffle(combinations)

        return combinations


def pareto_optimize(
    param_grid: Dict[str, List[Any]],
    evaluate_fn: Callable[[Dict[str, Any]], Dict[str, float]],
    objectives: List[str] = ["sharpe_ratio", "max_drawdown"],
    **kwargs
) -> Dict[str, Any]:
    """
    Fonction utilitaire pour optimisation Pareto rapide.

    Args:
        param_grid: Grille de param√®tres
        evaluate_fn: Fonction d'√©valuation
        objectives: Objectifs √† optimiser
        **kwargs: Arguments additionnels pour MultiObjectiveOptimizer

    Returns:
        R√©sultats d'optimisation

    Example:
        >>> results = pareto_optimize(
        >>>     param_grid={"fast": [5,10,15], "slow": [20,30,40]},
        >>>     evaluate_fn=lambda p: backtest(p).metrics,
        >>> )
        >>> print(f"Frontier size: {len(results['frontier'])}")
    """
    optimizer = MultiObjectiveOptimizer(objectives=objectives, **kwargs)
    return optimizer.optimize(param_grid, evaluate_fn)


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur multi-objectif/domination Pareto
# - Conventions domination et fronti√®re explicit√©es (>= tous, > au moins un)
# - Read-if/Skip-if ajout√©s pour guider la lecture


__all__ = [
    "ParetoPoint",
    "ParetoFrontier",
    "ParetoPruner",
    "MultiObjectiveOptimizer",
    "pareto_optimize",
]
```
<!-- MODULE-END: pareto.py -->

<!-- MODULE-START: performance.py -->
```json
{
  "name": "performance.py",
  "path": "backtest\\performance.py",
  "ext": ".py",
  "anchor": "performance_py"
}
```
## performance_py
*Chemin* : `backtest\performance.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Performance Calculator
======================================

Calcul des m√©triques de performance standard et avanc√©es.
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import numpy as np
import pandas as pd

from utils.log import get_logger

# Import des m√©triques Tier S
from backtest.metrics_tier_s import (
    TierSMetrics,
    calculate_tier_s_metrics,
    format_tier_s_report,
)

# Import des optimisations Numba
from backtest.performance_numba import (
    _drawdown_series_numba,
    _max_drawdown_numba,
)

logger = get_logger(__name__)


@dataclass
class PerformanceMetrics:
    """Container pour les m√©triques de performance."""

    # Rendement
    total_pnl: float
    total_return_pct: float
    annualized_return: float

    # Risque
    sharpe_ratio: float
    sortino_ratio: float
    max_drawdown: float
    max_drawdown_duration_days: float
    volatility_annual: float

    # Trades
    total_trades: int
    win_rate: float
    profit_factor: float
    avg_win: float
    avg_loss: float
    largest_win: float
    largest_loss: float
    avg_trade_duration_hours: float

    # Ratios avanc√©s
    calmar_ratio: float
    risk_reward_ratio: float
    expectancy: float

    # M√©triques Tier S (optionnelles)
    tier_s: Optional[TierSMetrics] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "total_pnl": self.total_pnl,
            "total_return_pct": self.total_return_pct,
            "annualized_return": self.annualized_return,
            "sharpe_ratio": self.sharpe_ratio,
            "sortino_ratio": self.sortino_ratio,
            "max_drawdown": self.max_drawdown,
            "max_drawdown_duration_days": self.max_drawdown_duration_days,
            "volatility_annual": self.volatility_annual,
            "total_trades": self.total_trades,
            "win_rate": self.win_rate,
            "profit_factor": self.profit_factor,
            "avg_win": self.avg_win,
            "avg_loss": self.avg_loss,
            "largest_win": self.largest_win,
            "largest_loss": self.largest_loss,
            "avg_trade_duration_hours": self.avg_trade_duration_hours,
            "calmar_ratio": self.calmar_ratio,
            "risk_reward_ratio": self.risk_reward_ratio,
            "expectancy": self.expectancy,
            "tier_s": self.tier_s.to_dict() if self.tier_s else None
        }


def equity_curve(
    returns: pd.Series,
    initial_capital: float = 10000.0
) -> pd.Series:
    """
    Calcule la courbe d'√©quit√© √† partir des rendements.

    Args:
        returns: S√©rie de rendements (fractionnaires)
        initial_capital: Capital initial

    Returns:
        S√©rie d'√©quit√©
    """
    if returns.empty:
        return pd.Series([], dtype=np.float64)

    # Nettoyer les donn√©es
    returns_clean = returns.dropna()
    returns_clean = returns_clean.clip(-1.0, 10.0)  # Limites raisonnables

    # Calcul cumulatif
    cumulative = (1 + returns_clean).cumprod()
    equity = initial_capital * cumulative

    return equity


def drawdown_series(equity: pd.Series) -> pd.Series:
    """
    Calcule la s√©rie de drawdown.

    Args:
        equity: Courbe d'√©quit√©

    Returns:
        S√©rie de drawdown (valeurs n√©gatives, 0 = au pic)

    Note:
        Version optimis√©e Numba (100√ó plus rapide que pandas.expanding().max())
    """
    if equity.empty:
        return pd.Series([], dtype=np.float64)

    # Utiliser version Numba optimis√©e (100√ó speedup)
    drawdown_values = _drawdown_series_numba(equity.values)

    return pd.Series(drawdown_values, index=equity.index, dtype=np.float64)


def max_drawdown(equity: pd.Series) -> float:
    """
    Calcule le drawdown maximum.

    Note:
        Version optimis√©e Numba (100√ó plus rapide)
    """
    if equity.empty:
        return 0.0

    # Utiliser version Numba directe (√©vite cr√©ation Series interm√©diaire)
    return float(_max_drawdown_numba(equity.values))




def sharpe_ratio(
    returns: pd.Series,
    risk_free: float = 0.0,
    periods_per_year: int = 252,  # Jours de trading par defaut
    method: str = "daily_resample",  # "standard", "trading_days" ou "daily_resample"
    equity: Optional[pd.Series] = None  # Necessaire pour daily_resample
) -> float:
    '''
    Calcule le ratio de Sharpe annualise.

    Pour limiter les biais des equity curves "sparse", la methode daily_resample
    peut resampler l'equity en quotidien avant de calculer les rendements.
    Des gardes supplmentaires evitent les valeurs aberrantes lorsque seules
    quelques trades non nuls sont disponibles.
    '''
    returns_series = returns.copy() if isinstance(returns, pd.Series) else pd.Series(returns)
    if returns_series.empty:
        return 0.0

    if method == "daily_resample":
        if equity is None or (hasattr(equity, "empty") and equity.empty):
            logger.warning("daily_resample necessite equity, fallback sur standard")
            method = "standard"
        elif not isinstance(equity.index, pd.DatetimeIndex):
            logger.warning("equity.index n'est pas DatetimeIndex, fallback sur standard")
            method = "standard"
        else:
            equity_daily = equity.resample('D').last().dropna()
            if len(equity_daily) >= 2:
                returns_series = equity_daily.pct_change().dropna()
                periods_per_year = 252  # Annualisation coherente avec des returns quotidiens
            else:
                logger.debug(
                    "sharpe_ratio_insufficient_daily_data days=%s, fallback to provided returns",
                    len(equity_daily),
                )
            method = "standard"

    returns_clean = (
        pd.Series(returns_series, dtype=np.float64)
        .replace([np.inf, -np.inf], np.nan)
        .dropna()
    )

    MIN_SAMPLES_FOR_SHARPE = 3  # Minimum pour un std ddof=1 un minimum de stabilite
    MIN_NON_ZERO_RETURNS = 3    # Eviter ratios irreels avec 1-2 trades
    if len(returns_clean) < MIN_SAMPLES_FOR_SHARPE:
        logger.debug(
            "sharpe_ratio_insufficient_samples samples=%s < min=%s, returning 0.0",
            len(returns_clean),
            MIN_SAMPLES_FOR_SHARPE,
        )
        return 0.0

    if method == "trading_days":
        returns_clean = returns_clean[returns_clean != 0.0]
        if len(returns_clean) < MIN_SAMPLES_FOR_SHARPE:
            logger.debug(
                "sharpe_ratio_insufficient_samples_after_filter samples=%s < min=%s, returning 0.0",
                len(returns_clean),
                MIN_SAMPLES_FOR_SHARPE,
            )
            return 0.0
    non_zero_count = int((returns_clean != 0.0).sum())
    if non_zero_count < MIN_NON_ZERO_RETURNS:
        logger.debug(
            "sharpe_ratio_insufficient_non_zero non_zero=%s < min=%s, returning 0.0",
            non_zero_count,
            MIN_NON_ZERO_RETURNS,
        )
        return 0.0

    periods_per_year = periods_per_year or 0
    rf_period = risk_free / periods_per_year if periods_per_year else 0.0

    excess_returns = returns_clean - rf_period
    mean_excess = excess_returns.mean()
    std_returns = float(returns_clean.std(ddof=1))

    min_annual_vol = 0.001  # 0.1% minimum de volatilite annualisee
    min_period_std = min_annual_vol / np.sqrt(periods_per_year or 1)

    if not np.isfinite(std_returns) or std_returns < min_period_std:
        logger.debug(
            "sharpe_ratio_zero_volatility std=%.6f < min=%.6f, returns=%s samples",
            std_returns,
            min_period_std,
            len(returns_clean),
        )
        return 0.0

    sharpe = (mean_excess * np.sqrt(periods_per_year)) / std_returns if periods_per_year else 0.0

    MAX_SHARPE = 20.0
    if abs(sharpe) > MAX_SHARPE:
        logger.warning(
            "sharpe_ratio_clamped value=%.2f clamped_to=+/-%.1f std=%.6f mean=%.6f samples=%s",
            sharpe,
            MAX_SHARPE,
            std_returns,
            mean_excess,
            len(returns_clean),
        )
        sharpe = np.sign(sharpe) * MAX_SHARPE

    # Protection critique : Sharpe forc√© √† 0 si impossible
    if not np.isfinite(sharpe):
        logger.error("sharpe_ratio_infinite value=%.2f, forced_to_zero", sharpe)
        sharpe = 0.0

    return float(sharpe)


def sortino_ratio(
    returns: pd.Series,
    risk_free: float = 0.0,
    periods_per_year: int = 252,
    method: str = "daily_resample",
    equity: Optional[pd.Series] = None
) -> float:
    """
    Calcule le ratio de Sortino (ne p√©nalise que la volatilit√© baissi√®re).

    Args:
        returns: S√©rie de rendements
        risk_free: Taux sans risque annuel
        periods_per_year: Nombre de p√©riodes par an pour l'annualisation
        method: "standard", "trading_days" ou "daily_resample"
        equity: S√©rie d'equity (requis si method="daily_resample")

    Returns:
        Ratio de Sortino annualis√©
    """
    if returns.empty:
        return 0.0

    # M√©thode daily_resample : resample equity en quotidien
    if method == "daily_resample":
        if equity is None or equity.empty:
            logger.warning("daily_resample n√©cessite equity, fallback sur standard")
            method = "standard"
        else:
            if not isinstance(equity.index, pd.DatetimeIndex):
                logger.warning("equity.index n'est pas DatetimeIndex, fallback sur standard")
                method = "standard"
            else:
                equity_daily = equity.resample('D').last().dropna()
                if len(equity_daily) < 2:
                    return 0.0
                returns = equity_daily.pct_change().dropna()
                method = "standard"
                # ‚ö†Ô∏è IMPORTANT: Apr√®s resample quotidien, forcer periods_per_year = 252 (jours de trading)
                periods_per_year = 252

    returns_clean = returns.dropna()
    if returns_clean.empty:
        return 0.0

    # Filtrer returns nuls si m√©thode trading_days
    if method == "trading_days":
        returns_clean = returns_clean[returns_clean != 0.0]
        if len(returns_clean) < 2:
            return 0.0

    rf_period = risk_free / periods_per_year
    excess_returns = returns_clean - rf_period
    mean_excess = excess_returns.mean()

    # Volatilit√© baissi√®re seulement
    downside_returns = returns_clean[returns_clean < 0]
    if len(downside_returns) < 2:
        return 0.0

    downside_std = downside_returns.std(ddof=1)

    if downside_std <= 1e-10:
        return 0.0

    sortino = (mean_excess * np.sqrt(periods_per_year)) / downside_std

    return float(sortino)


def profit_factor(trades_df: pd.DataFrame) -> float:
    """
    Calcule le profit factor (gains bruts / pertes brutes).
    """
    if trades_df.empty or "pnl" not in trades_df.columns:
        return 0.0

    gross_profits = trades_df[trades_df["pnl"] > 0]["pnl"].sum()
    gross_losses = abs(trades_df[trades_df["pnl"] < 0]["pnl"].sum())

    if gross_losses == 0:
        return float("inf") if gross_profits > 0 else 1.0

    return gross_profits / gross_losses


def calculate_metrics(
    equity: pd.Series,
    returns: pd.Series,
    trades_df: pd.DataFrame,
    initial_capital: float = 10000.0,
    periods_per_year: int = 252,  # Jours de trading par d√©faut
    include_tier_s: bool = False,
    sharpe_method: str = "daily_resample"  # "standard", "trading_days" ou "daily_resample"
) -> Dict[str, Any]:
    """
    Calcule toutes les m√©triques de performance.

    Args:
        equity: Courbe d'√©quit√©
        returns: S√©rie de rendements (par barre)
        trades_df: DataFrame des trades
        initial_capital: Capital initial
        periods_per_year: P√©riodes par an pour annualisation du Sharpe
                         (d√©faut: 252 jours de trading, standard industrie)
        include_tier_s: Inclure m√©triques Tier S avanc√©es
        sharpe_method: M√©thode de calcul du Sharpe/Sortino:
                      - "daily_resample": Resample equity en quotidien (RECOMMAND√â, standard industrie)
                      - "trading_days": Filtre les returns nuls (incomplet, non recommand√©)
                      - "standard": Utilise tous les returns (peut donner valeurs aberrantes)

    Returns:
        Dict de toutes les m√©triques

    Notes:
        - Le Sharpe/Sortino sont calcul√©s avec periods_per_year=252 par d√©faut
          (jours de trading), ind√©pendamment du timeframe des donn√©es
        - La m√©thode "daily_resample" √©vite les biais li√©s aux equity "sparse"
          (qui ne changent qu'aux trades, cr√©ant beaucoup de returns nuls)
    """
    metrics = {}

    # === M√©triques de rendement ===
    if not equity.empty:
        final_equity = equity.iloc[-1]
        total_pnl = final_equity - initial_capital
        total_return_pct = (total_pnl / initial_capital) * 100

        # Rendement annualis√© (calendrier si index datetime)
        annualized_return = 0.0
        years = 0.0
        if isinstance(equity.index, pd.DatetimeIndex) and len(equity) > 1:
            elapsed_days = (equity.index[-1] - equity.index[0]).total_seconds() / 86400
            years = elapsed_days / 365 if elapsed_days > 0 else 0.0
        elif periods_per_year and len(equity) > 1:
            years = len(equity) / periods_per_year

        if years > 0 and final_equity > 0:
            annualized_return = ((final_equity / initial_capital) ** (1 / years) - 1) * 100
    else:
        total_pnl = 0.0
        total_return_pct = 0.0
        annualized_return = 0.0

    metrics["total_pnl"] = total_pnl
    metrics["total_return_pct"] = total_return_pct
    metrics["annualized_return"] = annualized_return

    # === M√©triques de risque ===
    metrics["sharpe_ratio"] = sharpe_ratio(
        returns,
        periods_per_year=periods_per_year,
        method=sharpe_method,
        equity=equity  # Passer equity pour daily_resample
    )
    metrics["sortino_ratio"] = sortino_ratio(
        returns,
        periods_per_year=periods_per_year,
        method=sharpe_method,
        equity=equity  # Passer equity pour daily_resample
    )
    # Plafonner le drawdown √† -100% (ruine totale maximum)
    # Un drawdown de -925% n'a pas de sens, √ßa indique probablement une equity n√©gative
    metrics["max_drawdown"] = max(-100.0, max_drawdown(equity) * 100)  # En %, plafonn√© √† -100%

    # Volatilit√© annualis√©e
    volatility_returns = returns
    vol_annualization = periods_per_year
    if sharpe_method == "daily_resample" and isinstance(equity.index, pd.DatetimeIndex):
        daily_equity = equity.resample("D").last().dropna()
        if len(daily_equity) >= 2:
            volatility_returns = daily_equity.pct_change().dropna()
            vol_annualization = 252

    if not volatility_returns.empty and vol_annualization:
        vol = volatility_returns.std(ddof=1) * np.sqrt(vol_annualization) * 100
        metrics["volatility_annual"] = vol
    else:
        metrics["volatility_annual"] = 0.0

    # Dur√©e max du drawdown
    if not equity.empty:
        dd = drawdown_series(equity)
        if (dd < 0).any():
            if isinstance(dd.index, pd.DatetimeIndex):
                dd_periods = []
                start_ts = None
                last_ts = None
                for ts, in_dd in (dd < 0).items():
                    if in_dd and start_ts is None:
                        start_ts = ts
                    elif not in_dd and start_ts is not None:
                        end_ts = last_ts if last_ts is not None else ts
                        dd_periods.append(end_ts - start_ts)
                        start_ts = None
                    last_ts = ts
                if start_ts is not None and last_ts is not None:
                    dd_periods.append(last_ts - start_ts)

                metrics["max_drawdown_duration_days"] = (
                    max((p.total_seconds() / 86400 for p in dd_periods))
                    if dd_periods else 0.0
                )
            else:
                in_dd = dd < 0
                dd_lengths = []
                current = 0
                for val in in_dd:
                    if val:
                        current += 1
                    else:
                        if current > 0:
                            dd_lengths.append(current)
                        current = 0
                if current > 0:
                    dd_lengths.append(current)

                max_dd_bars = max(dd_lengths) if dd_lengths else 0
                metrics["max_drawdown_duration_days"] = max_dd_bars / (periods_per_year or 1)
        else:
            metrics["max_drawdown_duration_days"] = 0.0
    else:
        metrics["max_drawdown_duration_days"] = 0.0

    # === M√©triques de trades ===
    if not trades_df.empty and "pnl" in trades_df.columns:
        n_trades = len(trades_df)
        winning_trades = trades_df[trades_df["pnl"] > 0]
        losing_trades = trades_df[trades_df["pnl"] < 0]

        metrics["total_trades"] = n_trades
        metrics["win_rate"] = len(winning_trades) / n_trades * 100 if n_trades > 0 else 0
        metrics["profit_factor"] = profit_factor(trades_df)

        metrics["avg_win"] = winning_trades["pnl"].mean() if len(winning_trades) > 0 else 0
        metrics["avg_loss"] = losing_trades["pnl"].mean() if len(losing_trades) > 0 else 0
        metrics["largest_win"] = winning_trades["pnl"].max() if len(winning_trades) > 0 else 0
        metrics["largest_loss"] = losing_trades["pnl"].min() if len(losing_trades) > 0 else 0

        # Dur√©e moyenne des trades
        if "entry_ts" in trades_df.columns and "exit_ts" in trades_df.columns:
            durations = (trades_df["exit_ts"] - trades_df["entry_ts"]).dt.total_seconds() / 3600
            metrics["avg_trade_duration_hours"] = durations.mean()
        else:
            metrics["avg_trade_duration_hours"] = 0

        # Expectancy (esp√©rance math√©matique par trade)
        metrics["expectancy"] = trades_df["pnl"].mean() if n_trades > 0 else 0

        # Risk/Reward ratio
        if metrics["avg_loss"] != 0:
            metrics["risk_reward_ratio"] = abs(metrics["avg_win"] / metrics["avg_loss"])
        else:
            metrics["risk_reward_ratio"] = 0
    else:
        metrics["total_trades"] = 0
        metrics["win_rate"] = 0
        metrics["profit_factor"] = 0
        metrics["avg_win"] = 0
        metrics["avg_loss"] = 0
        metrics["largest_win"] = 0
        metrics["largest_loss"] = 0
        metrics["avg_trade_duration_hours"] = 0
        metrics["expectancy"] = 0
        metrics["risk_reward_ratio"] = 0

    # === Ratios avanc√©s ===
    # Calmar ratio (rendement annualis√© / max drawdown)
    if metrics["max_drawdown"] != 0:
        metrics["calmar_ratio"] = metrics["annualized_return"] / abs(metrics["max_drawdown"])
    else:
        metrics["calmar_ratio"] = 0

    # === M√©triques Tier S (optionnel) ===
    if include_tier_s:
        trades_pnl = trades_df["pnl"] if not trades_df.empty and "pnl" in trades_df.columns else pd.Series([])
        tier_s_metrics = calculate_tier_s_metrics(
            returns=returns,
            equity=equity,
            trades_pnl=trades_pnl,
            initial_capital=initial_capital,
            periods_per_year=periods_per_year
        )
        metrics["tier_s"] = tier_s_metrics.to_dict()
        # Ajouter les m√©triques cl√©s au niveau sup√©rieur
        metrics["sqn"] = tier_s_metrics.sqn
        metrics["recovery_factor"] = tier_s_metrics.recovery_factor
        metrics["ulcer_index"] = tier_s_metrics.ulcer_index
        metrics["martin_ratio"] = tier_s_metrics.martin_ratio
        metrics["gain_pain_ratio"] = tier_s_metrics.gain_pain_ratio
        metrics["tier_s_score"] = tier_s_metrics.tier_s_score
        metrics["tier_s_grade"] = tier_s_metrics.tier_s_grade
    else:
        metrics["tier_s"] = None

    return metrics


class PerformanceCalculator:
    """
    Calculateur de performance avec API orient√©e objet.
    """

    def __init__(self, initial_capital: float = 10000.0, include_tier_s: bool = False):
        self.initial_capital = initial_capital
        self.include_tier_s = include_tier_s
        self._last_metrics: Optional[Dict[str, Any]] = None
        self._last_tier_s: Optional[TierSMetrics] = None

    def summarize(
        self,
        returns: pd.Series,
        trades_df: pd.DataFrame,
        periods_per_year: int = 252,
        sharpe_method: str = "daily_resample"
    ) -> Dict[str, Any]:
        """
        Calcule un r√©sum√© complet des performances.

        Args:
            returns: S√©rie de rendements
            trades_df: DataFrame des trades
            periods_per_year: P√©riodes par an (d√©faut: 252 jours de trading)
            sharpe_method: M√©thode de calcul Sharpe ("daily_resample", "trading_days" ou "standard")

        Returns:
            Dict des m√©triques calcul√©es
        """
        # Calculer l'√©quit√©
        eq = equity_curve(returns, self.initial_capital)

        # Calculer toutes les m√©triques
        metrics = calculate_metrics(
            equity=eq,
            returns=returns,
            trades_df=trades_df,
            initial_capital=self.initial_capital,
            periods_per_year=periods_per_year,
            include_tier_s=self.include_tier_s,
            sharpe_method=sharpe_method
        )

        self._last_metrics = metrics

        # Stocker les m√©triques Tier S si calcul√©es
        if self.include_tier_s and metrics.get("tier_s"):
            trades_pnl = trades_df["pnl"] if not trades_df.empty and "pnl" in trades_df.columns else pd.Series([])
            self._last_tier_s = calculate_tier_s_metrics(
                returns=returns,
                equity=eq,
                trades_pnl=trades_pnl,
                initial_capital=self.initial_capital,
                periods_per_year=periods_per_year
            )

        return metrics

    def format_report(self, metrics: Optional[Dict[str, Any]] = None) -> str:
        """
        Formate un rapport lisible des m√©triques.
        """
        if metrics is None:
            metrics = self._last_metrics
        if metrics is None:
            return "Aucune m√©trique disponible"

        report = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              RAPPORT DE PERFORMANCE                       ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë RENDEMENT                                                 ‚ïë
‚ïë   P&L Total:           ${total_pnl:>12,.2f}               ‚ïë
‚ïë   Rendement Total:     {total_return_pct:>12.2f}%         ‚ïë
‚ïë   Rendement Annualis√©: {annualized_return:>12.2f}%        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë RISQUE                                                    ‚ïë
‚ïë   Sharpe Ratio:        {sharpe_ratio:>12.2f}              ‚ïë
‚ïë   Sortino Ratio:       {sortino_ratio:>12.2f}             ‚ïë
‚ïë   Max Drawdown:        {max_drawdown:>12.2f}%             ‚ïë
‚ïë   Volatilit√© Ann.:     {volatility_annual:>12.2f}%        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë TRADES                                                    ‚ïë
‚ïë   Nombre de Trades:    {total_trades:>12d}                ‚ïë
‚ïë   Win Rate:            {win_rate:>12.1f}%                 ‚ïë
‚ïë   Profit Factor:       {profit_factor:>12.2f}             ‚ïë
‚ïë   Gain Moyen:          ${avg_win:>12,.2f}                 ‚ïë
‚ïë   Perte Moyenne:       ${avg_loss:>12,.2f}                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""".format(**metrics)

        # Ajouter rapport Tier S si disponible
        if self._last_tier_s:
            report += format_tier_s_report(self._last_tier_s)

        return report


__all__ = [
    "PerformanceCalculator",
    "PerformanceMetrics",
    "TierSMetrics",
    "calculate_metrics",
    "calculate_tier_s_metrics",
    "equity_curve",
    "drawdown_series",
    "max_drawdown",
    "sharpe_ratio",
    "sortino_ratio",
    "profit_factor",
    "format_tier_s_report",
]
```
<!-- MODULE-END: performance.py -->

<!-- MODULE-START: performance_numba.py -->
```json
{
  "name": "performance_numba.py",
  "path": "backtest\\performance_numba.py",
  "ext": ".py",
  "anchor": "performance_numba_py"
}
```
## performance_numba_py
*Chemin* : `backtest\performance_numba.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Performance Optimizations with Numba
=====================================================

Fonctions optimis√©es Numba pour calculs de performance critiques.

Gain attendu: 100√ó speedup sur op√©rations vectoris√©es.
"""

import numpy as np
from numba import njit


@njit(cache=True, fastmath=True)
def _expanding_max_numba(arr: np.ndarray) -> np.ndarray:
    """
    Calcul vectoris√© du maximum cumulatif (running maximum).

    Remplace: pandas.Series.expanding().max()
    Gain: 100√ó plus rapide (5-10ms ‚Üí 0.05ms sur 116k barres)

    Args:
        arr: Array numpy de valeurs

    Returns:
        Array des maximums cumulatifs

    Example:
        >>> arr = np.array([1.0, 3.0, 2.0, 5.0, 4.0])
        >>> _expanding_max_numba(arr)
        array([1., 3., 3., 5., 5.])
    """
    n = len(arr)
    if n == 0:
        return np.empty(0, dtype=np.float64)

    result = np.empty(n, dtype=np.float64)
    current_max = arr[0]

    for i in range(n):
        if arr[i] > current_max:
            current_max = arr[i]
        result[i] = current_max

    return result


@njit(cache=True, fastmath=True)
def _drawdown_series_numba(equity_values: np.ndarray) -> np.ndarray:
    """
    Calcul ultra-rapide de la s√©rie de drawdown.

    Remplace: drawdown_series() avec pandas
    Gain: 100√ó plus rapide (7-12ms ‚Üí 0.07ms)

    Args:
        equity_values: Array numpy de la courbe d'√©quit√©

    Returns:
        Array des drawdowns (valeurs n√©gatives, 0 = au pic)

    Formula:
        DD[i] = (Equity[i] / RunningMax[i]) - 1.0

    Example:
        >>> equity = np.array([100., 110., 105., 120., 115.])
        >>> dd = _drawdown_series_numba(equity)
        >>> dd[2]  # Drawdown √† 105 depuis pic de 110
        -0.04545...
    """
    n = len(equity_values)
    if n == 0:
        return np.empty(0, dtype=np.float64)

    # Calculer running max avec fonction optimis√©e
    running_max = _expanding_max_numba(equity_values)

    # Calculer drawdown
    drawdown = np.empty(n, dtype=np.float64)
    for i in range(n):
        if running_max[i] > 0:
            drawdown[i] = (equity_values[i] / running_max[i]) - 1.0
        else:
            drawdown[i] = 0.0

    return drawdown


@njit(cache=True, fastmath=True)
def _max_drawdown_numba(equity_values: np.ndarray) -> float:
    """
    Calcul ultra-rapide du drawdown maximum.

    Gain: 100√ó plus rapide que version pandas

    Args:
        equity_values: Array numpy de la courbe d'√©quit√©

    Returns:
        Drawdown maximum (valeur n√©gative, ex: -0.15 pour -15%)
    """
    if len(equity_values) == 0:
        return 0.0

    drawdown = _drawdown_series_numba(equity_values)
    return np.min(drawdown)


@njit(cache=True, fastmath=True)
def _ulcer_index_numba(equity_values: np.ndarray) -> float:
    """
    Ulcer Index optimis√©: mesure du stress li√© aux drawdowns.

    Remplace: ulcer_index() de metrics_tier_s.py
    Gain: 100√ó plus rapide (8-12ms ‚Üí 0.08ms)

    Plus sensible aux drawdowns prolong√©s que le max drawdown simple.

    Formula:
        UI = ‚àö(Œ£ DD¬≤[i] / N)  o√π DD = drawdown en %

    Args:
        equity_values: Array numpy de la courbe d'√©quit√©

    Returns:
        Ulcer Index (plus bas = mieux, ~5-10 = bon)

    Example:
        >>> equity = np.array([100., 110., 105., 120., 115.])
        >>> ui = _ulcer_index_numba(equity)
        >>> ui
        2.03...  # Faible stress
    """
    n = len(equity_values)
    if n < 2:
        return 0.0

    # Calculer running max
    running_max = _expanding_max_numba(equity_values)

    # Calculer drawdowns en %
    squared_sum = 0.0
    for i in range(n):
        if running_max[i] > 0:
            dd_pct = ((equity_values[i] / running_max[i]) - 1.0) * 100.0
            squared_sum += dd_pct * dd_pct

    # Ulcer Index
    ulcer = np.sqrt(squared_sum / n)

    return ulcer


@njit(cache=True, fastmath=True)
def _recovery_factor_numba(equity_values: np.ndarray, initial_capital: float) -> float:
    """
    Recovery Factor optimis√©: Net Profit / Max Drawdown absolu.

    Gain: 100√ó plus rapide (6-10ms ‚Üí 0.06ms)

    Mesure combien de fois le syst√®me a r√©cup√©r√© son pire drawdown.

    Formula:
        RF = (Equity_final - Equity_initial) / Max_DD_Absolu

    Args:
        equity_values: Array numpy de la courbe d'√©quit√©
        initial_capital: Capital initial

    Returns:
        Recovery Factor (> 2.0 = bon, > 5.0 = excellent)

    Example:
        >>> equity = np.array([100., 110., 90., 120.])  # +20 net, -20 max DD
        >>> rf = _recovery_factor_numba(equity, 100.0)
        >>> rf
        1.0  # R√©cup√©r√© 1√ó son pire DD
    """
    if len(equity_values) == 0:
        return 0.0

    net_profit = equity_values[-1] - initial_capital

    # Max Drawdown en valeur absolue
    running_max = _expanding_max_numba(equity_values)
    max_dd_abs = 0.0

    for i in range(len(equity_values)):
        dd_abs = running_max[i] - equity_values[i]
        if dd_abs > max_dd_abs:
            max_dd_abs = dd_abs

    if max_dd_abs <= 1e-10:
        # Pas de drawdown significatif
        if net_profit > 0:
            return 100.0  # Plafond arbitraire pour inf
        else:
            return 0.0

    recovery = net_profit / max_dd_abs

    # Plafonner pour √©viter valeurs aberrantes
    if recovery > 100.0:
        return 100.0
    elif recovery < -100.0:
        return -100.0
    else:
        return recovery


@njit(cache=True, fastmath=True)
def _sortino_downside_deviation_numba(
    returns: np.ndarray,
    target_return: float = 0.0
) -> float:
    """
    Calcul optimis√© de la downside deviation pour Sortino Ratio.

    Gain: 10√ó plus rapide (5-10ms ‚Üí 0.5ms)

    Ne p√©nalise que les √©carts n√©gatifs par rapport au target.

    Formula:
        œÉ_downside = ‚àö(Œ£ min(R[i] - target, 0)¬≤ / N)

    Args:
        returns: Array numpy des rendements
        target_return: Rendement cible (d√©faut: 0)

    Returns:
        Downside deviation

    Example:
        >>> returns = np.array([0.01, -0.02, 0.03, -0.01, 0.02])
        >>> dd = _sortino_downside_deviation_numba(returns, 0.0)
        >>> dd
        0.0122...  # Seulement volatilit√© baissi√®re
    """
    n = len(returns)
    if n < 2:
        return 0.0

    squared_sum = 0.0
    for i in range(n):
        diff = returns[i] - target_return
        if diff < 0:
            squared_sum += diff * diff

    if squared_sum < 1e-10:
        return 0.0

    downside_dev = np.sqrt(squared_sum / n)

    return downside_dev


@njit(cache=True, fastmath=True)
def _max_drawdown_duration_numba(
    equity_values: np.ndarray,
    timestamps_days: np.ndarray
) -> float:
    """
    Calcul optimis√© de la dur√©e maximale d'un drawdown.

    Gain: 10-20√ó plus rapide (3-8ms ‚Üí 0.3ms)

    Args:
        equity_values: Array numpy de la courbe d'√©quit√©
        timestamps_days: Array numpy des timestamps en jours (float)

    Returns:
        Dur√©e max du drawdown en jours

    Example:
        >>> equity = np.array([100., 90., 85., 95., 100.])
        >>> days = np.array([0., 1., 2., 3., 4.])
        >>> duration = _max_drawdown_duration_numba(equity, days)
        >>> duration
        4.0  # 4 jours de DD
    """
    n = len(equity_values)
    if n < 2:
        return 0.0

    # Calculer drawdown series
    dd = _drawdown_series_numba(equity_values)

    # Trouver p√©riodes de drawdown
    max_duration = 0.0
    start_idx = -1

    for i in range(n):
        if dd[i] < 0:  # En drawdown
            if start_idx < 0:
                start_idx = i
        else:  # Sorti du drawdown
            if start_idx >= 0:
                duration = timestamps_days[i - 1] - timestamps_days[start_idx]
                if duration > max_duration:
                    max_duration = duration
                start_idx = -1

    # V√©rifier si encore en drawdown √† la fin
    if start_idx >= 0:
        duration = timestamps_days[n - 1] - timestamps_days[start_idx]
        if duration > max_duration:
            max_duration = duration

    return max_duration


__all__ = [
    "_expanding_max_numba",
    "_drawdown_series_numba",
    "_max_drawdown_numba",
    "_ulcer_index_numba",
    "_recovery_factor_numba",
    "_sortino_downside_deviation_numba",
    "_max_drawdown_duration_numba",
]
```
<!-- MODULE-END: performance_numba.py -->

<!-- MODULE-START: report_generator.py -->
```json
{
  "name": "report_generator.py",
  "path": "backtest\\report_generator.py",
  "ext": ".py",
  "anchor": "report_generator_py"
}
```
## report_generator_py
*Chemin* : `backtest\report_generator.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.report_generator

Purpose: G√©n√©rer des rapports de backtest lisibles, organis√©s et facilement interpr√©tables.

Role in pipeline: reporting / visualization

Key components: generate_summary_report, generate_comparison_table, rank_results

Inputs: Liste de r√©sultats de backtest (StoredResultMetadata ou RunResult)

Outputs: Rapports Markdown/HTML, tableaux comparatifs, classements

Dependencies: pandas, pathlib, json

Conventions: G√©n√®re des rapports auto-document√©s avec m√©triques cl√©s en premier.

Read-if: G√©n√©ration de rapports ou analyse comparative de r√©sultats.

Skip-if: Vous n'avez besoin que des r√©sultats bruts sans rapport.
"""

from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime
import json

import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

# M√©triques cl√©s √† afficher en priorit√© dans les rapports
KEY_METRICS = [
    "total_return_pct",
    "sharpe_ratio",
    "max_drawdown_pct",
    "win_rate_pct",
    "profit_factor",
    "total_trades",
]

# Seuils pour classification automatique
PROFITABLE_THRESHOLD = 5.0  # Return > 5%
EXCELLENT_SHARPE = 2.0
GOOD_SHARPE = 1.0
MIN_TRADES = 10  # Nombre minimum de trades pour consid√©rer le r√©sultat valide


# =============================================================================
# FONCTIONS DE CLASSEMENT
# =============================================================================

def classify_result(metrics: Dict[str, Any]) -> Tuple[str, str]:
    """
    Classifie un r√©sultat de backtest selon ses performances.

    Args:
        metrics: Dict des m√©triques de performance

    Returns:
        (category, emoji) o√π category in ["excellent", "good", "mediocre", "failed"]

    Example:
        >>> metrics = {"total_return_pct": 18.5, "sharpe_ratio": 2.3}
        >>> classify_result(metrics)
        ("excellent", "üèÜ")
    """
    total_return = metrics.get("total_return_pct", 0)
    sharpe = metrics.get("sharpe_ratio", 0)
    account_ruined = metrics.get("account_ruined", False)
    total_trades = metrics.get("total_trades", 0)

    # Cas d'√©chec total
    if account_ruined:
        return "ruined", "üíÄ"

    if total_return <= -20:
        return "failed", "‚ùå"

    # Trop peu de trades
    if total_trades < MIN_TRADES:
        return "insufficient_data", "‚ö†Ô∏è"

    # Classification par performance
    if total_return >= PROFITABLE_THRESHOLD and sharpe >= EXCELLENT_SHARPE:
        return "excellent", "üèÜ"
    elif total_return >= PROFITABLE_THRESHOLD and sharpe >= GOOD_SHARPE:
        return "good", "‚úÖ"
    elif total_return >= 0:
        return "mediocre", "üìä"
    else:
        return "unprofitable", "‚ùå"


def rank_results(results: List[Dict[str, Any]], sort_by: str = "total_return_pct") -> pd.DataFrame:
    """
    Classe les r√©sultats de backtest par ordre de performance.

    Args:
        results: Liste de m√©tadonn√©es de r√©sultats
        sort_by: M√©trique pour le tri (d√©faut: total_return_pct)

    Returns:
        DataFrame tri√© avec classification et emoji

    Example:
        >>> results = [{"run_id": "abc", "metrics": {...}}, ...]
        >>> df = rank_results(results)
        >>> print(df[["run_id", "category", "total_return_pct"]].head())
    """
    rows = []
    for result in results:
        metrics = result.get("metrics", {})
        category, emoji = classify_result(metrics)

        row = {
            "run_id": result.get("run_id", "unknown"),
            "strategy": result.get("strategy", "unknown"),
            "symbol": result.get("symbol", ""),
            "timeframe": result.get("timeframe", ""),
            "timestamp": result.get("timestamp", ""),
            "category": category,
            "emoji": emoji,
            **{k: metrics.get(k, 0) for k in KEY_METRICS},
        }
        rows.append(row)

    df = pd.DataFrame(rows)

    # Trier par m√©trique choisie
    if sort_by in df.columns:
        df = df.sort_values(sort_by, ascending=False)

    return df


# =============================================================================
# G√âN√âRATION DE RAPPORTS MARKDOWN
# =============================================================================

def generate_summary_report(
    results: List[Dict[str, Any]],
    output_path: Optional[Path] = None,
    title: str = "üìä Rapport de Backtest - R√©sum√©",
) -> str:
    """
    G√©n√®re un rapport Markdown r√©sumant les r√©sultats de backtest.

    Args:
        results: Liste de m√©tadonn√©es de r√©sultats
        output_path: Chemin optionnel pour sauvegarder le rapport
        title: Titre du rapport

    Returns:
        Contenu Markdown du rapport

    Example:
        >>> results = storage.load_all_results()
        >>> report = generate_summary_report(results)
        >>> print(report)
    """
    df = rank_results(results)

    # En-t√™te
    report_lines = [
        f"# {title}",
        "",
        f"**Date de g√©n√©ration:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Nombre total de backtests:** {len(results)}",
        "",
    ]

    # Statistiques globales
    report_lines.extend([
        "## üìà Statistiques Globales",
        "",
        f"- **Excellents (üèÜ):** {len(df[df['category'] == 'excellent'])}",
        f"- **Bons (‚úÖ):** {len(df[df['category'] == 'good'])}",
        f"- **M√©diocres (üìä):** {len(df[df['category'] == 'mediocre'])}",
        f"- **Non rentables (‚ùå):** {len(df[df['category'] == 'unprofitable'])}",
        f"- **√âchecs catastrophiques (üíÄ):** {len(df[df['category'] == 'ruined'])}",
        f"- **Donn√©es insuffisantes (‚ö†Ô∏è):** {len(df[df['category'] == 'insufficient_data'])}",
        "",
    ])

    # Top 10 meilleurs r√©sultats
    top10 = df.head(10)
    report_lines.extend([
        "## üèÜ Top 10 des Meilleurs R√©sultats",
        "",
        "| Rang | Emoji | Strat√©gie | Symbole | TF | Return % | Sharpe | Max DD % | Win Rate % | Trades |",
        "|------|-------|-----------|---------|----|---------:|-------:|---------:|-----------:|-------:|",
    ])

    for idx, (_, row) in enumerate(top10.iterrows(), 1):
        report_lines.append(
            f"| {idx} | {row['emoji']} | {row['strategy']} | {row['symbol']} | {row['timeframe']} | "
            f"{row['total_return_pct']:.2f} | {row['sharpe_ratio']:.2f} | "
            f"{row['max_drawdown_pct']:.2f} | {row['win_rate_pct']:.2f} | {int(row['total_trades'])} |"
        )

    report_lines.append("")

    # Pires r√©sultats (Bottom 5)
    bottom5 = df.tail(5).sort_values("total_return_pct", ascending=True)
    report_lines.extend([
        "## ‚ö†Ô∏è Les 5 Pires R√©sultats",
        "",
        "| Rang | Emoji | Strat√©gie | Symbole | TF | Return % | Sharpe | Max DD % | Raison |",
        "|------|-------|-----------|---------|----|---------:|-------:|---------:|--------|",
    ])

    for idx, (_, row) in enumerate(bottom5.iterrows(), 1):
        reason = "Compte ruin√©" if row.get("category") == "ruined" else "Pertes importantes"
        report_lines.append(
            f"| {idx} | {row['emoji']} | {row['strategy']} | {row['symbol']} | {row['timeframe']} | "
            f"{row['total_return_pct']:.2f} | {row['sharpe_ratio']:.2f} | "
            f"{row['max_drawdown_pct']:.2f} | {reason} |"
        )

    report_lines.append("")

    # Performance par strat√©gie
    strategy_stats = df.groupby("strategy").agg({
        "total_return_pct": ["mean", "std", "count"],
        "sharpe_ratio": "mean",
        "win_rate_pct": "mean",
    }).round(2)

    report_lines.extend([
        "## üìä Performance par Strat√©gie",
        "",
        "| Strat√©gie | Backtests | Return Moyen % | Return Std % | Sharpe Moyen | Win Rate Moyen % |",
        "|-----------|----------:|---------------:|-------------:|-------------:|-----------------:|",
    ])

    for strategy, row in strategy_stats.iterrows():
        report_lines.append(
            f"| {strategy} | {int(row[('total_return_pct', 'count')])} | "
            f"{row[('total_return_pct', 'mean')]:.2f} | {row[('total_return_pct', 'std')]:.2f} | "
            f"{row[('sharpe_ratio', 'mean')]:.2f} | {row[('win_rate_pct', 'mean')]:.2f} |"
        )

    report_lines.append("")

    # Recommandations
    report_lines.extend([
        "## üöÄ Recommandations",
        "",
    ])

    excellent_count = len(df[df['category'] == 'excellent'])
    if excellent_count > 0:
        top_strategy = top10.iloc[0]
        report_lines.extend([
            f"### ‚úÖ Production Imm√©diate",
            "",
            f"**{top_strategy['strategy']}** sur **{top_strategy['symbol']}** ({top_strategy['timeframe']}) :",
            f"- Return: **{top_strategy['total_return_pct']:.2f}%**",
            f"- Sharpe: **{top_strategy['sharpe_ratio']:.2f}**",
            f"- Max Drawdown: **{top_strategy['max_drawdown_pct']:.2f}%**",
            "",
        ])
    else:
        report_lines.extend([
            "‚ö†Ô∏è Aucune configuration excellente trouv√©e. Optimisation n√©cessaire.",
            "",
        ])

    # Avertissements
    ruined_count = len(df[df['category'] == 'ruined'])
    if ruined_count > 0:
        report_lines.extend([
            "### ‚ö†Ô∏è Configurations Dangereuses",
            "",
            f"**{ruined_count} configuration(s)** ont men√© √† la ruine du compte. √Ä √©viter absolument :",
            "",
        ])
        for _, row in df[df['category'] == 'ruined'].head(3).iterrows():
            report_lines.append(
                f"- {row['strategy']} sur {row['symbol']} ({row['timeframe']}) : "
                f"Return {row['total_return_pct']:.2f}%"
            )
        report_lines.append("")

    report_lines.extend([
        "---",
        "",
        "*Rapport g√©n√©r√© automatiquement par backtest_core*",
    ])

    report_content = "\n".join(report_lines)

    # Sauvegarder si chemin fourni
    if output_path:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report_content, encoding="utf-8")
        logger.info(f"Rapport sauvegard√© : {output_path}")

    return report_content


def generate_comparison_table(
    results: List[Dict[str, Any]],
    filter_category: Optional[str] = None,
    output_format: str = "markdown",
) -> str:
    """
    G√©n√®re un tableau comparatif des r√©sultats.

    Args:
        results: Liste de m√©tadonn√©es de r√©sultats
        filter_category: Filtrer par cat√©gorie (ex: "excellent", "good")
        output_format: Format de sortie ("markdown", "html", "csv")

    Returns:
        Tableau format√©

    Example:
        >>> results = storage.load_all_results()
        >>> table = generate_comparison_table(results, filter_category="excellent")
        >>> print(table)
    """
    df = rank_results(results)

    if filter_category:
        df = df[df["category"] == filter_category]

    if output_format == "markdown":
        return df.to_markdown(index=False, floatfmt=".2f")
    elif output_format == "html":
        return df.to_html(index=False, classes="table table-striped")
    elif output_format == "csv":
        return df.to_csv(index=False)
    else:
        raise ValueError(f"Format non support√©: {output_format}")


# =============================================================================
# SCRIPT PRINCIPAL (si ex√©cut√© directement)
# =============================================================================

if __name__ == "__main__":
    print("=== G√©n√©rateur de Rapports de Backtest ===\n")

    # Charger l'index des r√©sultats
    index_path = Path("backtest_results") / "index.json"
    if not index_path.exists():
        print(f"‚ùå Fichier index introuvable: {index_path}")
        exit(1)

    with open(index_path, "r") as f:
        index_data = json.load(f)

    results = list(index_data.values())
    print(f"üìä {len(results)} r√©sultats charg√©s depuis {index_path}\n")

    # G√©n√©rer rapport r√©capitulatif
    output_path = Path("backtest_results") / "SUMMARY_REPORT.md"
    report = generate_summary_report(results, output_path=output_path)

    print(f"‚úÖ Rapport g√©n√©r√©: {output_path}")
    print("\n--- Aper√ßu du rapport ---\n")
    print("\n".join(report.split("\n")[:30]))  # Afficher les 30 premi√®res lignes
    print("\n...")
```
<!-- MODULE-END: report_generator.py -->

<!-- MODULE-START: results_organizer.py -->
```json
{
  "name": "results_organizer.py",
  "path": "backtest\\results_organizer.py",
  "ext": ".py",
  "anchor": "results_organizer_py"
}
```
## results_organizer_py
*Chemin* : `backtest\results_organizer.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.results_organizer

Purpose: Organiser automatiquement les r√©sultats de backtest en structure hi√©rarchique claire.

Role in pipeline: organization / archiving

Key components: organize_results, create_category_structure, archive_old_results

Inputs: R√©pertoire backtest_results

Outputs: Structure hi√©rarchique organis√©e par cat√©gorie/strat√©gie/performance

Dependencies: pathlib, shutil, json

Conventions: Organisation: backtest_results/{category}/{strategy}/{symbol_tf}/{run_id}

Read-if: Organisation ou archivage des r√©sultats.

Skip-if: Structure flat convient √† votre usage.
"""

import sys
import json
import shutil
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime, timedelta

# Ajouter le r√©pertoire racine au PYTHONPATH
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from backtest.report_generator import classify_result, rank_results
from utils.log import get_logger

logger = get_logger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

CATEGORIES = {
    "excellent": "üèÜ_Excellent",
    "good": "‚úÖ_Good",
    "mediocre": "üìä_Mediocre",
    "unprofitable": "‚ùå_Unprofitable",
    "failed": "‚ùå_Failed",  # Alias pour unprofitable
    "ruined": "üíÄ_Ruined",
    "insufficient_data": "‚ö†Ô∏è_Insufficient_Data",
}

ARCHIVE_AFTER_DAYS = 90  # Archiver r√©sultats > 90 jours


# =============================================================================
# FONCTIONS D'ORGANISATION
# =============================================================================

def organize_results(
    results_dir: Path = Path("backtest_results"),
    organized_dir: Optional[Path] = None,
    dry_run: bool = False,
) -> Dict[str, int]:
    """
    Organise les r√©sultats de backtest en structure hi√©rarchique.

    Structure cible:
        backtest_results_organized/
        ‚îú‚îÄ‚îÄ üèÜ_Excellent/
        ‚îÇ   ‚îú‚îÄ‚îÄ ema_cross/
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ BTCUSDC_1h/
        ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ run_20260103_abc123/
        ‚îÇ   ‚îî‚îÄ‚îÄ rsi_reversal/
        ‚îú‚îÄ‚îÄ ‚úÖ_Good/
        ‚îú‚îÄ‚îÄ üìä_Mediocre/
        ‚îú‚îÄ‚îÄ ‚ùå_Unprofitable/
        ‚îî‚îÄ‚îÄ üíÄ_Ruined/

    Args:
        results_dir: R√©pertoire source des r√©sultats
        organized_dir: R√©pertoire destination (d√©faut: backtest_results_organized)
        dry_run: Si True, affiche les actions sans les ex√©cuter

    Returns:
        Dict compteur par cat√©gorie

    Example:
        >>> stats = organize_results(dry_run=True)
        >>> print(stats)
        {"excellent": 5, "good": 12, ...}
    """
    if organized_dir is None:
        organized_dir = results_dir.parent / "backtest_results_organized"

    # Charger l'index
    index_path = results_dir / "index.json"
    if not index_path.exists():
        logger.error(f"Index introuvable: {index_path}")
        return {}

    with open(index_path, "r") as f:
        index_data = json.load(f)

    results = list(index_data.values())
    logger.info(f"üìä {len(results)} r√©sultats √† organiser")

    stats = {cat: 0 for cat in CATEGORIES.keys()}

    for result in results:
        run_id = result.get("run_id", "unknown")
        metrics = result.get("metrics", {})
        strategy = result.get("strategy", "unknown")
        symbol = result.get("symbol", "unknown")
        timeframe = result.get("timeframe", "unknown")
        timestamp = result.get("timestamp", "")

        # Classifier
        category, _ = classify_result(metrics)
        stats[category] += 1

        # Construire chemins
        category_name = CATEGORIES.get(category, "Unknown")
        symbol_tf = f"{symbol}_{timeframe}"

        # Extraire date du timestamp
        try:
            ts_dt = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
            date_str = ts_dt.strftime("%Y%m%d_%H%M%S")
        except:
            date_str = "unknown"

        run_folder_name = f"{date_str}_{run_id[:8]}"

        source_path = results_dir / run_id
        target_path = organized_dir / category_name / strategy / symbol_tf / run_folder_name

        # Copier ou afficher
        if dry_run:
            logger.info(f"[DRY-RUN] {source_path.name} ‚Üí {target_path}")
        else:
            if source_path.exists():
                target_path.parent.mkdir(parents=True, exist_ok=True)
                if target_path.exists():
                    shutil.rmtree(target_path)
                shutil.copytree(source_path, target_path)
                logger.debug(f"‚úÖ Copi√©: {run_id} ‚Üí {target_path}")
            else:
                logger.warning(f"‚ö†Ô∏è Source introuvable: {source_path}")

    # Cr√©er README dans chaque cat√©gorie
    if not dry_run:
        create_category_readmes(organized_dir, stats)

    # Afficher statistiques
    logger.info("\n=== Statistiques d'organisation ===")
    for category, count in stats.items():
        emoji_name = CATEGORIES.get(category, category)
        logger.info(f"{emoji_name}: {count} r√©sultats")

    return stats


def create_category_readmes(organized_dir: Path, stats: Dict[str, int]):
    """
    Cr√©e des fichiers README.md dans chaque cat√©gorie.

    Args:
        organized_dir: R√©pertoire organis√©
        stats: Statistiques par cat√©gorie
    """
    descriptions = {
        "excellent": "üèÜ Configurations exceptionnelles (Return > 5% ET Sharpe > 2.0). **Pr√™tes pour production.**",
        "good": "‚úÖ Bonnes configurations (Return > 5% ET Sharpe > 1.0). √Ä valider sur d'autres timeframes/symboles.",
        "mediocre": "üìä Configurations rentables mais m√©diocres. N√©cessitent optimisation.",
        "unprofitable": "‚ùå Configurations non rentables. √Ä analyser pour comprendre les √©checs.",
        "ruined": "üíÄ **DANGER** : Ces configurations ont men√© √† la ruine du compte. √Ä √©viter absolument.",
        "insufficient_data": "‚ö†Ô∏è R√©sultats avec trop peu de trades (< 10). Donn√©es insuffisantes pour juger.",
    }

    for category, category_name in CATEGORIES.items():
        category_path = organized_dir / category_name
        if not category_path.exists():
            continue

        readme_path = category_path / "README.md"
        count = stats.get(category, 0)

        content = [
            f"# {category_name}",
            "",
            descriptions.get(category, "Cat√©gorie de r√©sultats."),
            "",
            f"**Nombre de r√©sultats:** {count}",
            "",
            "## Structure",
            "",
            "Les r√©sultats sont organis√©s par :",
            "1. **Strat√©gie** (ex: ema_cross, rsi_reversal)",
            "2. **Symbole + Timeframe** (ex: BTCUSDC_1h)",
            "3. **Date + Run ID** (ex: 20260103_123456_abc12345)",
            "",
            "## Fichiers dans chaque r√©sultat",
            "",
            "- `metadata.json` : Param√®tres et m√©triques compl√®tes",
            "- `equity.parquet` : Courbe d'√©quit√© (si disponible)",
            "- `trades.parquet` : Liste d√©taill√©e des trades (si disponible)",
            "",
            "---",
            f"*G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
        ]

        readme_path.write_text("\n".join(content), encoding="utf-8")
        logger.debug(f"üìÑ README cr√©√©: {readme_path}")


def archive_old_results(
    results_dir: Path = Path("backtest_results"),
    archive_dir: Optional[Path] = None,
    days_threshold: int = ARCHIVE_AFTER_DAYS,
    dry_run: bool = False,
) -> int:
    """
    Archive les r√©sultats anciens (> days_threshold jours).

    Args:
        results_dir: R√©pertoire des r√©sultats
        archive_dir: R√©pertoire d'archivage (d√©faut: backtest_results_archive)
        days_threshold: Seuil en jours pour archivage
        dry_run: Si True, affiche sans archiver

    Returns:
        Nombre de r√©sultats archiv√©s

    Example:
        >>> count = archive_old_results(days_threshold=90, dry_run=True)
        >>> print(f"{count} r√©sultats √† archiver")
    """
    if archive_dir is None:
        archive_dir = results_dir.parent / "backtest_results_archive"

    # Charger index
    index_path = results_dir / "index.json"
    if not index_path.exists():
        logger.error(f"Index introuvable: {index_path}")
        return 0

    with open(index_path, "r") as f:
        index_data = json.load(f)

    cutoff_date = datetime.now() - timedelta(days=days_threshold)
    archived_count = 0

    for run_id, result in index_data.items():
        timestamp_str = result.get("timestamp", "")
        try:
            ts_dt = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        except:
            logger.warning(f"‚ö†Ô∏è Timestamp invalide pour {run_id}: {timestamp_str}")
            continue

        if ts_dt < cutoff_date:
            source_path = results_dir / run_id
            target_path = archive_dir / run_id

            if dry_run:
                logger.info(f"[DRY-RUN] Archiver: {run_id} ({ts_dt.strftime('%Y-%m-%d')})")
            else:
                if source_path.exists():
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(source_path), str(target_path))
                    logger.debug(f"üì¶ Archiv√©: {run_id}")

            archived_count += 1

    logger.info(f"üì¶ {archived_count} r√©sultats archiv√©s (> {days_threshold} jours)")
    return archived_count


# =============================================================================
# SCRIPT PRINCIPAL
# =============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Organiser et archiver les r√©sultats de backtest"
    )
    parser.add_argument(
        "--organize",
        action="store_true",
        help="Organiser les r√©sultats par cat√©gorie",
    )
    parser.add_argument(
        "--archive",
        action="store_true",
        help="Archiver les r√©sultats anciens",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Mode simulation (ne modifie rien)",
    )
    parser.add_argument(
        "--days",
        type=int,
        default=ARCHIVE_AFTER_DAYS,
        help=f"Seuil en jours pour archivage (d√©faut: {ARCHIVE_AFTER_DAYS})",
    )

    args = parser.parse_args()

    if args.organize:
        print("=== Organisation des r√©sultats ===\n")
        stats = organize_results(dry_run=args.dry_run)
        print(f"\n‚úÖ Organisation {'simul√©e' if args.dry_run else 'termin√©e'}")

    if args.archive:
        print("\n=== Archivage des r√©sultats anciens ===\n")
        count = archive_old_results(days_threshold=args.days, dry_run=args.dry_run)
        print(f"\nüì¶ {count} r√©sultats {'√† archiver' if args.dry_run else 'archiv√©s'}")

    if not args.organize and not args.archive:
        parser.print_help()
```
<!-- MODULE-END: results_organizer.py -->

<!-- MODULE-START: simulator.py -->
```json
{
  "name": "simulator.py",
  "path": "backtest\\simulator.py",
  "ext": ".py",
  "anchor": "simulator_py"
}
```
## simulator_py
*Chemin* : `backtest\simulator.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.simulator

Purpose: Simuler l'ex√©cution des trades et le calcul des courbes d'√©quit√©/rendement.

Role in pipeline: execution

Key components: Trade, simulate_trades, calculate_equity_curve, calculate_returns

Inputs: Signaux (1/-1/0), DataFrame OHLCV, param√®tres d'ex√©cution (spread, slippage, levier)

Outputs: Trade list, equity curve array, returns array

Dependencies: numpy, pandas, utils.log

Conventions: Trade.side = 'LONG'|'SHORT'; pnl en devise de base; return_pct en fractions [0,1] ou pourcentages.

Read-if: Optimisation simulation ou modification de la m√©canique des trades.

Skip-if: Vous ne touchez qu'aux strat√©gies/indicateurs.
"""

from dataclasses import dataclass
from typing import Any, Dict, List, Literal, Optional

import numpy as np
import pandas as pd

from utils.log import get_logger

# Import optionnel de tqdm pour barres de progression
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False

    def tqdm(iterable, **kwargs):
        return iterable

logger = get_logger(__name__)


@dataclass
class Trade:
    """
    Repr√©sentation d'un trade ex√©cut√©.
    """
    entry_ts: pd.Timestamp
    exit_ts: pd.Timestamp
    side: Literal["LONG", "SHORT"]
    entry_price: float
    exit_price: float
    size: float
    pnl: float
    return_pct: float
    exit_reason: str
    leverage: float = 1.0
    fees_paid: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "entry_ts": self.entry_ts,
            "exit_ts": self.exit_ts,
            "side": self.side,
            "price_entry": self.entry_price,
            "price_exit": self.exit_price,
            "size": self.size,
            "pnl": self.pnl,
            "return_pct": self.return_pct,
            "exit_reason": self.exit_reason,
            "leverage_used": self.leverage,
            "fees_paid": self.fees_paid
        }


def simulate_trades(
    df: pd.DataFrame,
    signals: pd.Series,
    params: Dict[str, Any],
    execution_engine: Optional[Any] = None,
    show_progress: bool = False
) -> pd.DataFrame:
    """
    Simule l'ex√©cution des trades bas√©e sur les signaux.

    Features:
    - Gestion des positions (une seule √† la fois)
    - Stop-loss configurable
    - Calcul des frais et slippage (fixe ou dynamique)
    - Ex√©cution r√©aliste optionnelle (spread/slippage dynamique)
    - Sortie en fin de donn√©es si position ouverte

    Args:
        df: DataFrame OHLCV avec index datetime
        signals: S√©rie de signaux (+1, -1, 0)
        params: Param√®tres de trading:
            - leverage: Levier (d√©faut: 3)
            - k_sl: Multiplicateur stop-loss % (d√©faut: 1.5)
            - initial_capital: Capital initial (d√©faut: 10000)
            - fees_bps: Frais en bps (d√©faut: 10)
            - slippage_bps: Slippage en bps (d√©faut: 5)
            - execution_model: Mod√®le d'ex√©cution ('fixed', 'dynamic', 'realistic')
        execution_engine: ExecutionEngine optionnel pour ex√©cution r√©aliste
        show_progress: Afficher une barre de progression (d√©faut: False)

    Returns:
        DataFrame des trades avec colonnes:
        entry_ts, exit_ts, pnl, size, price_entry, price_exit, side, exit_reason, etc.
    """
    logger.debug("D√©but simulation des trades")

    trades: List[Trade] = []

    # √âtat de position
    position = 0  # 0=flat, 1=long, -1=short
    entry_price = 0.0
    entry_time: Optional[pd.Timestamp] = None
    position_size = 0.0
    exit_pending_reason: Optional[str] = None

    # Param√®tres avec d√©fauts
    leverage = params.get("leverage", 3)
    k_sl = params.get("k_sl", 1.5)  # Stop loss en %
    initial_capital = params.get("initial_capital", 10000.0)
    fees_bps = params.get("fees_bps", 10.0)
    slippage_bps = params.get("slippage_bps", 5.0)

    # Mode d'ex√©cution
    use_realistic_execution = execution_engine is not None
    if use_realistic_execution:
        execution_engine.prepare(df)
        logger.debug("Mode ex√©cution r√©aliste activ√©")

    # Convertir en arrays pour performance
    timestamps = df.index.values
    closes = df["close"].values
    lows = df["low"].values if "low" in df.columns else closes.copy()
    highs = df["high"].values if "high" in df.columns else closes.copy()
    signal_values = signals.values if hasattr(signals, "values") else signals

    bb_stop_long = df["bb_stop_long"].values if "bb_stop_long" in df.columns else None
    bb_tp_long = df["bb_tp_long"].values if "bb_tp_long" in df.columns else None
    bb_stop_short = df["bb_stop_short"].values if "bb_stop_short" in df.columns else None
    bb_tp_short = df["bb_tp_short"].values if "bb_tp_short" in df.columns else None
    bb_pos_low = df["bb_pos_low"].values if "bb_pos_low" in df.columns else None
    bb_pos_high = df["bb_pos_high"].values if "bb_pos_high" in df.columns else None
    sl_level_arr = df["sl_level"].values if "sl_level" in df.columns else None
    tp_level_arr = df["tp_level"].values if "tp_level" in df.columns else None
    sl_level_param = params.get("sl_level", np.nan)
    if sl_level_param is None:
        sl_level_param = np.nan
    sl_level_param = float(sl_level_param)
    tp_level_param = params.get("tp_level", np.nan)
    if tp_level_param is None:
        tp_level_param = np.nan
    tp_level_param = float(tp_level_param)

    stop_price = np.nan
    tp_price = np.nan
    stop_level = np.nan
    tp_level = np.nan
    use_bb_pos = False
    has_bb_stop = False
    has_bb_tp = False

    n_bars = len(closes)

    # Tracking des co√ªts d'ex√©cution
    total_spread_cost = 0.0
    total_slippage_cost = 0.0

    # Barre de progression optionnelle
    bar_iterator = tqdm(
        range(n_bars),
        desc="Simulating trades",
        unit="bar",
        disable=not (show_progress and TQDM_AVAILABLE),
        leave=False
    ) if show_progress else range(n_bars)

    def _init_trade_levels(bar_idx: int, pos: int) -> None:
        nonlocal stop_price, tp_price, stop_level, tp_level, use_bb_pos, has_bb_stop, has_bb_tp
        stop_price = np.nan
        tp_price = np.nan
        stop_level = np.nan
        tp_level = np.nan
        use_bb_pos = False
        has_bb_stop = False
        has_bb_tp = False

        if pos == 1:
            if bb_stop_long is not None:
                stop_price = float(bb_stop_long[bar_idx])
                has_bb_stop = not np.isnan(stop_price)
            if bb_tp_long is not None:
                tp_price = float(bb_tp_long[bar_idx])
                has_bb_tp = not np.isnan(tp_price)
        else:
            if bb_stop_short is not None:
                stop_price = float(bb_stop_short[bar_idx])
                has_bb_stop = not np.isnan(stop_price)
            if bb_tp_short is not None:
                tp_price = float(bb_tp_short[bar_idx])
                has_bb_tp = not np.isnan(tp_price)

        if not (has_bb_stop or has_bb_tp) and bb_pos_low is not None and bb_pos_high is not None:
            use_bb_pos = True
            stop_level = float(sl_level_arr[bar_idx]) if sl_level_arr is not None else sl_level_param
            tp_level = float(tp_level_arr[bar_idx]) if tp_level_arr is not None else tp_level_param
            has_bb_stop = not np.isnan(stop_level)
            has_bb_tp = not np.isnan(tp_level)

    for i in bar_iterator:
        timestamp = pd.Timestamp(timestamps[i])
        close_price = closes[i]
        signal = signal_values[i]

        # === Entr√©e en position ===
        if position == 0 and signal != 0:
            position = int(signal)
            requested_size = leverage * initial_capital / close_price

            # Calcul du prix d'entr√©e
            if use_realistic_execution:
                exec_result = execution_engine.execute_order(
                    price=close_price,
                    side=position,
                    bar_idx=i,
                    size=requested_size
                )
                entry_price = exec_result.executed_price
                filled_size = getattr(exec_result, "filled_size", requested_size)
                if filled_size <= 0:
                    position = 0
                    continue
                position_size = filled_size
                total_spread_cost += exec_result.spread_cost
                total_slippage_cost += exec_result.slippage_cost
            else:
                # Mode simple: slippage fixe
                slip_factor = 1 + (slippage_bps * 0.0001 * position)
                entry_price = close_price * slip_factor
                position_size = leverage * initial_capital / entry_price

            entry_time = timestamp
            exit_pending_reason = None
            _init_trade_levels(i, position)

            logger.debug(f"Entr√©e {'LONG' if position == 1 else 'SHORT'} @ {entry_price:.2f}")

        # === En position: v√©rifier sortie ===
        elif position != 0:
            exit_condition = False
            exit_reason = ""

            # 1. Exit pending (partial fill)
            if exit_pending_reason is not None:
                exit_condition = True
                exit_reason = exit_pending_reason
            else:
                use_bb_levels = use_bb_pos or has_bb_stop or has_bb_tp

                if use_bb_levels:
                    sl_hit = False
                    tp_hit = False

                    if use_bb_pos:
                        if position == 1:
                            if has_bb_stop and bb_pos_low[i] <= stop_level:
                                sl_hit = True
                            if has_bb_tp and bb_pos_high[i] >= tp_level:
                                tp_hit = True
                        else:
                            if has_bb_stop and bb_pos_high[i] >= stop_level:
                                sl_hit = True
                            if has_bb_tp and bb_pos_low[i] <= tp_level:
                                tp_hit = True
                    else:
                        if has_bb_stop:
                            if position == 1 and lows[i] <= stop_price:
                                sl_hit = True
                            elif position == -1 and highs[i] >= stop_price:
                                sl_hit = True
                        if has_bb_tp:
                            if position == 1 and highs[i] >= tp_price:
                                tp_hit = True
                            elif position == -1 and lows[i] <= tp_price:
                                tp_hit = True

                    if not sl_hit and not has_bb_stop:
                        if position == 1 and lows[i] <= entry_price * (1 - k_sl * 0.01):
                            sl_hit = True
                        elif position == -1 and highs[i] >= entry_price * (1 + k_sl * 0.01):
                            sl_hit = True

                    if sl_hit:
                        exit_condition = True
                        exit_reason = "stop_loss"
                    elif tp_hit:
                        exit_condition = True
                        exit_reason = "take_profit"
                    elif signal != 0 and signal != position:
                        exit_condition = True
                        exit_reason = "signal_reverse"
                else:
                    if signal != 0 and signal != position:
                        exit_condition = True
                        exit_reason = "signal_reverse"

                    if position == 1:
                        sl_price = entry_price * (1 - k_sl * 0.01)
                        if lows[i] <= sl_price:
                            exit_condition = True
                            exit_reason = "stop_loss"
                    elif position == -1:
                        sl_price = entry_price * (1 + k_sl * 0.01)
                        if highs[i] >= sl_price:
                            exit_condition = True
                            exit_reason = "stop_loss"

            # === Ex√©cuter sortie ===
            if exit_condition:
                # Calcul du prix de sortie
                if use_realistic_execution:
                    exec_result = execution_engine.execute_order(
                        price=close_price,
                        side=-position,  # Direction oppos√©e pour la sortie
                        bar_idx=i,
                        size=position_size
                    )
                    exit_price = exec_result.executed_price
                    filled_size = getattr(exec_result, "filled_size", position_size)
                    total_spread_cost += exec_result.spread_cost
                    total_slippage_cost += exec_result.slippage_cost
                else:
                    # Mode simple: slippage fixe
                    slip_factor = 1 - (slippage_bps * 0.0001 * position)
                    exit_price = close_price * slip_factor
                    filled_size = position_size

                if filled_size <= 0:
                    exit_pending_reason = exit_reason or "exit_pending"
                    continue

                trade_size = min(filled_size, position_size)

                # Calcul PnL
                if position == 1:
                    raw_return = (exit_price - entry_price) / entry_price
                else:
                    raw_return = (entry_price - exit_price) / entry_price

                # Frais (aller-retour)
                total_fees_pct = fees_bps * 2 * 0.0001
                net_return = raw_return - total_fees_pct

                # PnL avec taille de position
                trade_notional = trade_size * entry_price
                pnl = net_return * trade_notional

                # Frais pay√©s
                fees_paid = trade_size * entry_price * total_fees_pct

                exit_reason_used = exit_reason
                if trade_size < position_size:
                    exit_reason_used = f"{exit_reason}_partial"

                trade = Trade(
                    entry_ts=entry_time,
                    exit_ts=timestamp,
                    side="LONG" if position == 1 else "SHORT",
                    entry_price=entry_price,
                    exit_price=exit_price,
                    size=trade_size,
                    pnl=pnl,
                    return_pct=net_return * 100,
                    exit_reason=exit_reason_used,
                    leverage=leverage,
                    fees_paid=fees_paid
                )
                trades.append(trade)

                logger.debug(f"Sortie {trade.side} @ {exit_price:.2f}, PnL: ${pnl:.2f}")

                position_size -= trade_size
                if position_size <= 0:
                    # Reset position
                    position = 0
                    entry_price = 0.0
                    entry_time = None
                    exit_pending_reason = None
                    stop_price = np.nan
                    tp_price = np.nan
                    stop_level = np.nan
                    tp_level = np.nan
                    use_bb_pos = False
                    has_bb_stop = False
                    has_bb_tp = False

                    # Nouvelle position si signal pr√©sent
                    if signal != 0:
                        position = int(signal)
                        requested_size = leverage * initial_capital / close_price
                        if use_realistic_execution:
                            exec_result = execution_engine.execute_order(
                                price=close_price,
                                side=position,
                                bar_idx=i,
                                size=requested_size
                            )
                            entry_price = exec_result.executed_price
                            filled_size = getattr(exec_result, "filled_size", requested_size)
                            if filled_size <= 0:
                                position = 0
                                continue
                            position_size = filled_size
                            total_spread_cost += exec_result.spread_cost
                            total_slippage_cost += exec_result.slippage_cost
                        else:
                            entry_price = close_price * (1 + slippage_bps * 0.0001 * position)
                            position_size = leverage * initial_capital / entry_price
                        entry_time = timestamp
                        _init_trade_levels(i, position)
                else:
                    exit_pending_reason = exit_reason

    # === Trade final si position ouverte ===
    if position != 0 and entry_time is not None:
        if use_realistic_execution:
            exec_result = execution_engine.execute_order(
                price=closes[-1],
                side=-position,
                bar_idx=n_bars - 1,
                size=position_size
            )
            final_price = exec_result.executed_price
            total_spread_cost += exec_result.spread_cost
            total_slippage_cost += exec_result.slippage_cost
        else:
            final_price = closes[-1] * (1 - slippage_bps * 0.0001 * position)

        final_time = pd.Timestamp(timestamps[-1])

        if position == 1:
            raw_return = (final_price - entry_price) / entry_price
        else:
            raw_return = (entry_price - final_price) / entry_price

        total_fees_pct = fees_bps * 2 * 0.0001
        net_return = raw_return - total_fees_pct
        trade_notional = position_size * entry_price
        pnl = net_return * trade_notional

        trade = Trade(
            entry_ts=entry_time,
            exit_ts=final_time,
            side="LONG" if position == 1 else "SHORT",
            entry_price=entry_price,
            exit_price=final_price,
            size=position_size,
            pnl=pnl,
            return_pct=net_return * 100,
            exit_reason="end_of_data",
            leverage=leverage,
            fees_paid=position_size * entry_price * total_fees_pct
        )
        trades.append(trade)

    # Construire DataFrame
    if trades:
        trades_df = pd.DataFrame([t.to_dict() for t in trades])
    else:
        # DataFrame vide avec colonnes requises
        trades_df = pd.DataFrame(columns=[
            "entry_ts", "exit_ts", "pnl", "size", "price_entry", "price_exit",
            "side", "exit_reason", "return_pct", "leverage_used", "fees_paid"
        ])

    logger.info(f"Simulation termin√©e: {len(trades)} trades")

    return trades_df


def calculate_equity_curve(
    df: pd.DataFrame,
    trades_df: pd.DataFrame,
    initial_capital: float = 10000.0,
    run_id: Optional[str] = None  # Pour logging structur√©
) -> pd.Series:
    """
    Calcule la courbe d'√©quit√© avec mark-to-market.

    IMPORTANT: Inclut le P&L non r√©alis√© des positions ouvertes.

    Args:
        df: DataFrame OHLCV (pour l'index temporel)
        trades_df: DataFrame des trades
        initial_capital: Capital initial

    Returns:
        pd.Series de l'√©quit√© avec mark-to-market
    """
    # EQUITY_SERIES_META - Log m√©tadonn√©es courbe equity
    if run_id:
        freq_str = "unknown"
        if hasattr(df.index, 'freq') and df.index.freq is not None:
            freq_str = str(df.index.freq)
        elif isinstance(df.index, pd.DatetimeIndex) and len(df.index) > 1:
            freq_str = pd.infer_freq(df.index) or "unknown"

        logger.info(
            f"EQUITY_SERIES_META run_id={run_id} "
            f"index_type={type(df.index).__name__} freq={freq_str} "
            f"n_points={len(df)} initial_capital={initial_capital} currency=USD"
        )

    equity = pd.Series(initial_capital, index=df.index, dtype=np.float64)

    if trades_df.empty:
        if run_id:
            logger.info(
                f"EQUITY_COMPLETE run_id={run_id} len={len(equity)} "
                f"min={equity.min():.2f} max={equity.max():.2f} "
                f"final={equity.iloc[-1]:.2f} pnl=0.00 note=no_trades"
            )
        return equity

    # Harmoniser les timezones
    entry_ts_series = pd.to_datetime(trades_df["entry_ts"])
    exit_ts_series = pd.to_datetime(trades_df["exit_ts"])

    if hasattr(df.index, 'tz') and df.index.tz is not None:
        if entry_ts_series.dt.tz is None:
            entry_ts_series = entry_ts_series.dt.tz_localize(df.index.tz)
        elif entry_ts_series.dt.tz != df.index.tz:
            entry_ts_series = entry_ts_series.dt.tz_convert(df.index.tz)

        if exit_ts_series.dt.tz is None:
            exit_ts_series = exit_ts_series.dt.tz_localize(df.index.tz)
        elif exit_ts_series.dt.tz != df.index.tz:
            exit_ts_series = exit_ts_series.dt.tz_convert(df.index.tz)

    # Capital r√©alis√©
    realized_capital = initial_capital

    # Parcourir chaque barre pour calculer equity avec mark-to-market
    for bar_idx, bar_time in enumerate(df.index):
        current_price = df['close'].iloc[bar_idx]

        # Trades ferm√©s √† cette barre
        closed_trades = trades_df[exit_ts_series <= bar_time]
        if not closed_trades.empty:
            realized_capital = initial_capital + closed_trades['pnl'].sum()

        # Positions ouvertes
        open_trades = trades_df[
            (entry_ts_series <= bar_time) & (exit_ts_series > bar_time)
        ]

        unrealized_pnl = 0.0
        if not open_trades.empty:
            for _, trade in open_trades.iterrows():
                entry_price = trade['price_entry']
                size = trade['size']
                side = trade.get('side', 'LONG')

                if side == 'LONG':
                    unrealized_pnl += (current_price - entry_price) * size
                else:  # SHORT
                    unrealized_pnl += (entry_price - current_price) * size

        equity.iloc[bar_idx] = realized_capital + unrealized_pnl

    # Logs d√©taill√©s avant return
    if run_id:
        # D√©tection jumps anormaux
        jumps = equity.pct_change().abs()
        if len(jumps) > 1:
            threshold = jumps.mean() + 3 * jumps.std()
            abnormal_jumps = jumps[jumps > threshold].dropna()

            if not abnormal_jumps.empty:
                logger.warning(
                    f"EQUITY_JUMPS run_id={run_id} n_jumps={len(abnormal_jumps)} "
                    f"max_jump={abnormal_jumps.max():.4f} "
                    f"jump_steps={abnormal_jumps.index.tolist()[:10]}"
                )

        # Drawdown analysis
        from backtest.performance import drawdown_series, max_drawdown
        dd_series = drawdown_series(equity)
        max_dd = max_drawdown(equity)

        dd_start = None
        if not dd_series.empty and dd_series.min() < 0:
            dd_start = str(dd_series.idxmin())

        logger.info(
            f"EQUITY_DD run_id={run_id} max_dd_pct={max_dd * 100:.2f} "
            f"dd_start={dd_start}"
        )

        # R√©conciliation ledger
        if not trades_df.empty:
            equity_final = equity.iloc[-1]
            pnl_total = trades_df['pnl'].sum()
            equity_expected = initial_capital + pnl_total
            delta = abs(equity_final - equity_expected)

            if delta > 0.01:  # epsilon = 1 cent
                fees_total = trades_df.get('fees', pd.Series([0])).sum()
                logger.error(
                    f"EQUITY_RECONCILE_FAIL run_id={run_id} "
                    f"equity_final={equity_final:.2f} equity_expected={equity_expected:.2f} "
                    f"delta={delta:.2f} initial_capital={initial_capital:.2f} "
                    f"pnl_total={pnl_total:.2f} fees_total={fees_total:.2f}"
                )

        # Log final
        logger.info(
            f"EQUITY_COMPLETE run_id={run_id} len={len(equity)} "
            f"min={equity.min():.2f} max={equity.max():.2f} "
            f"final={equity.iloc[-1]:.2f} pnl={equity.iloc[-1] - initial_capital:.2f}"
        )

    return equity


def calculate_returns(equity: pd.Series) -> pd.Series:
    """
    Calcule les rendements p√©riodiques √† partir de la courbe d'√©quit√©.
    """
    returns = equity.pct_change().fillna(0)
    return returns


__all__ = ["simulate_trades", "Trade", "calculate_equity_curve", "calculate_returns"]


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur l'ex√©cution/simulation
# - Conventions Trade.side et return_pct explicit√©es pour √©viter ambigu√Øt√©s
# - Read-if/Skip-if ajout√©s pour guider la lecture
```
<!-- MODULE-END: simulator.py -->

<!-- MODULE-START: simulator_fast.py -->
```json
{
  "name": "simulator_fast.py",
  "path": "backtest\\simulator_fast.py",
  "ext": ".py",
  "anchor": "simulator_fast_py"
}
```
## simulator_fast_py
*Chemin* : `backtest\simulator_fast.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Fast Trade Simulator (Numba-accelerated)
=======================================================

Version haute performance du simulateur de trades utilisant Numba JIT.
Jusqu'√† 100x plus rapide que la version Python pure.

Usage:
    from backtest.simulator_fast import simulate_trades_fast

    trades_df = simulate_trades_fast(df, signals, params)
"""

from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# Numba pour JIT compilation
try:
    from numba import njit, prange
    HAS_NUMBA = True
except ImportError:
    HAS_NUMBA = False

from utils.log import get_logger

logger = get_logger(__name__)


# =============================================================================
# NUMBA-OPTIMIZED CORE (JIT-compiled)
# =============================================================================

if HAS_NUMBA:
    @njit(cache=True, fastmath=True)
    def _simulate_trades_numba(
        closes: np.ndarray,
        highs: np.ndarray,
        lows: np.ndarray,
        signals: np.ndarray,
        leverage: float,
        k_sl: float,
        initial_capital: float,
        fees_bps: float,
        slippage_bps: float,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray,
               np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:
        """
        C≈ìur de simulation JIT-compil√©.

        Retourne les arrays numpy des trades pour reconstruction DataFrame.
        """
        n_bars = len(closes)

        # Pr√©-allouer les arrays de sortie (max = n_bars/2 trades)
        max_trades = n_bars // 2 + 1
        entry_indices = np.zeros(max_trades, dtype=np.int64)
        exit_indices = np.zeros(max_trades, dtype=np.int64)
        sides = np.zeros(max_trades, dtype=np.int64)  # 1=long, -1=short
        entry_prices = np.zeros(max_trades, dtype=np.float64)
        exit_prices = np.zeros(max_trades, dtype=np.float64)
        pnls = np.zeros(max_trades, dtype=np.float64)
        returns_pct = np.zeros(max_trades, dtype=np.float64)
        exit_reasons = np.zeros(max_trades, dtype=np.int64)  # 0=signal, 1=sl, 2=end
        sizes = np.zeros(max_trades, dtype=np.float64)

        # √âtat position
        position = 0
        entry_price = 0.0
        entry_idx = 0
        trade_count = 0

        # Constantes pr√©calcul√©es
        slippage_factor = slippage_bps * 0.0001
        fees_factor = fees_bps * 2 * 0.0001
        sl_pct = k_sl * 0.01

        for i in range(n_bars):
            close_price = closes[i]
            signal = signals[i]

            # === Entr√©e en position ===
            if position == 0 and signal != 0:
                position = int(signal)
                entry_price = close_price * (1.0 + slippage_factor * position)
                entry_idx = i

            # === En position: v√©rifier sortie ===
            elif position != 0:
                exit_condition = False
                exit_reason = 0

                # 1. Signal oppos√©
                if signal != 0 and signal != position:
                    exit_condition = True
                    exit_reason = 0  # signal_reverse

                # 2. Stop-loss (intrabar check avec high/low)
                elif position == 1:
                    sl_price = entry_price * (1.0 - sl_pct)
                    if lows[i] <= sl_price:
                        exit_condition = True
                        exit_reason = 1  # stop_loss
                elif position == -1:
                    sl_price = entry_price * (1.0 + sl_pct)
                    if highs[i] >= sl_price:
                        exit_condition = True
                        exit_reason = 1  # stop_loss

                # === Ex√©cuter sortie ===
                if exit_condition:
                    exit_price = close_price * (1.0 - slippage_factor * position)

                    # PnL
                    if position == 1:
                        raw_return = (exit_price - entry_price) / entry_price
                    else:
                        raw_return = (entry_price - exit_price) / entry_price

                    net_return = raw_return - fees_factor
                    pnl = net_return * leverage * initial_capital
                    position_size = leverage * initial_capital / entry_price

                    # Enregistrer trade
                    entry_indices[trade_count] = entry_idx
                    exit_indices[trade_count] = i
                    sides[trade_count] = position
                    entry_prices[trade_count] = entry_price
                    exit_prices[trade_count] = exit_price
                    pnls[trade_count] = pnl
                    returns_pct[trade_count] = net_return * 100.0
                    exit_reasons[trade_count] = exit_reason
                    sizes[trade_count] = position_size
                    trade_count += 1

                    # Reset
                    position = 0
                    entry_price = 0.0

                    # Nouvelle position si signal pr√©sent
                    if signal != 0:
                        position = int(signal)
                        entry_price = close_price * (1.0 + slippage_factor * position)
                        entry_idx = i

        # === Trade final si position ouverte ===
        if position != 0:
            final_price = closes[-1] * (1.0 - slippage_factor * position)

            if position == 1:
                raw_return = (final_price - entry_price) / entry_price
            else:
                raw_return = (entry_price - final_price) / entry_price

            net_return = raw_return - fees_factor
            pnl = net_return * leverage * initial_capital
            position_size = leverage * initial_capital / entry_price

            entry_indices[trade_count] = entry_idx
            exit_indices[trade_count] = n_bars - 1
            sides[trade_count] = position
            entry_prices[trade_count] = entry_price
            exit_prices[trade_count] = final_price
            pnls[trade_count] = pnl
            returns_pct[trade_count] = net_return * 100.0
            exit_reasons[trade_count] = 2  # end_of_data
            sizes[trade_count] = position_size
            trade_count += 1

        return (
            entry_indices[:trade_count],
            exit_indices[:trade_count],
            sides[:trade_count],
            entry_prices[:trade_count],
            exit_prices[:trade_count],
            pnls[:trade_count],
            returns_pct[:trade_count],
            exit_reasons[:trade_count],
            sizes[:trade_count],
            trade_count
        )

    @njit(cache=True, fastmath=True)
    def _calculate_equity_numba(
        n_bars: int,
        exit_indices: np.ndarray,
        pnls: np.ndarray,
        initial_capital: float
    ) -> np.ndarray:
        """
        Calcul vectoris√© ULTRA-RAPIDE de l'equity (100√ó speedup vs boucle manuelle).

        Utilise np.cumsum natif au lieu d'une boucle Python pour performance maximale.
        Complexit√©: O(n_trades + n_bars) avec op√©rations vectoris√©es.

        Note: parallel=False car cumsum est s√©quentiel par nature.
        """
        # Cr√©er array des changements de capital aux indices de sortie des trades
        capital_changes = np.zeros(n_bars, dtype=np.float64)

        # Placer les P&L aux indices de sortie (O(n_trades))
        for i in range(len(exit_indices)):
            idx = exit_indices[i]
            if 0 <= idx < n_bars:  # S√©curit√© bounds checking
                capital_changes[idx] += pnls[i]

        # Cumulative sum vectoris√© (100√ó plus rapide que boucle manuelle!)
        # NumPy cumsum est optimis√© en C avec SIMD sur CPU moderne
        equity = initial_capital + np.cumsum(capital_changes)

        return equity


# =============================================================================
# NUMPY VECTORIZED FALLBACK (si Numba non disponible)
# =============================================================================

def _simulate_trades_numpy(
    closes: np.ndarray,
    highs: np.ndarray,
    lows: np.ndarray,
    signals: np.ndarray,
    leverage: float,
    k_sl: float,
    initial_capital: float,
    fees_bps: float,
    slippage_bps: float,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray,
           np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:
    """Version numpy pure (fallback si pas de Numba)."""
    n_bars = len(closes)

    # Pr√©-allouer
    max_trades = n_bars // 2 + 1
    entry_indices = np.zeros(max_trades, dtype=np.int64)
    exit_indices = np.zeros(max_trades, dtype=np.int64)
    sides = np.zeros(max_trades, dtype=np.int64)
    entry_prices = np.zeros(max_trades, dtype=np.float64)
    exit_prices = np.zeros(max_trades, dtype=np.float64)
    pnls = np.zeros(max_trades, dtype=np.float64)
    returns_pct = np.zeros(max_trades, dtype=np.float64)
    exit_reasons = np.zeros(max_trades, dtype=np.int64)
    sizes = np.zeros(max_trades, dtype=np.float64)

    position = 0
    entry_price = 0.0
    entry_idx = 0
    trade_count = 0

    slippage_factor = slippage_bps * 0.0001
    fees_factor = fees_bps * 2 * 0.0001
    sl_pct = k_sl * 0.01

    for i in range(n_bars):
        close_price = closes[i]
        signal = signals[i]

        if position == 0 and signal != 0:
            position = int(signal)
            entry_price = close_price * (1.0 + slippage_factor * position)
            entry_idx = i

        elif position != 0:
            exit_condition = False
            exit_reason = 0

            if signal != 0 and signal != position:
                exit_condition = True
                exit_reason = 0
            elif position == 1 and lows[i] <= entry_price * (1.0 - sl_pct):
                exit_condition = True
                exit_reason = 1
            elif position == -1 and highs[i] >= entry_price * (1.0 + sl_pct):
                exit_condition = True
                exit_reason = 1

            if exit_condition:
                exit_price = close_price * (1.0 - slippage_factor * position)

                if position == 1:
                    raw_return = (exit_price - entry_price) / entry_price
                else:
                    raw_return = (entry_price - exit_price) / entry_price

                net_return = raw_return - fees_factor
                pnl = net_return * leverage * initial_capital
                position_size = leverage * initial_capital / entry_price

                entry_indices[trade_count] = entry_idx
                exit_indices[trade_count] = i
                sides[trade_count] = position
                entry_prices[trade_count] = entry_price
                exit_prices[trade_count] = exit_price
                pnls[trade_count] = pnl
                returns_pct[trade_count] = net_return * 100.0
                exit_reasons[trade_count] = exit_reason
                sizes[trade_count] = position_size
                trade_count += 1

                position = 0
                entry_price = 0.0

                if signal != 0:
                    position = int(signal)
                    entry_price = close_price * (1.0 + slippage_factor * position)
                    entry_idx = i

    # Trade final
    if position != 0:
        final_price = closes[-1] * (1.0 - slippage_factor * position)

        if position == 1:
            raw_return = (final_price - entry_price) / entry_price
        else:
            raw_return = (entry_price - final_price) / entry_price

        net_return = raw_return - fees_factor
        pnl = net_return * leverage * initial_capital
        position_size = leverage * initial_capital / entry_price

        entry_indices[trade_count] = entry_idx
        exit_indices[trade_count] = n_bars - 1
        sides[trade_count] = position
        entry_prices[trade_count] = entry_price
        exit_prices[trade_count] = final_price
        pnls[trade_count] = pnl
        returns_pct[trade_count] = net_return * 100.0
        exit_reasons[trade_count] = 2
        sizes[trade_count] = position_size
        trade_count += 1

    return (
        entry_indices[:trade_count],
        exit_indices[:trade_count],
        sides[:trade_count],
        entry_prices[:trade_count],
        exit_prices[:trade_count],
        pnls[:trade_count],
        returns_pct[:trade_count],
        exit_reasons[:trade_count],
        sizes[:trade_count],
        trade_count
    )


# =============================================================================
# PUBLIC API
# =============================================================================

EXIT_REASON_MAP = {0: "signal_reverse", 1: "stop_loss", 2: "end_of_data", 3: "take_profit"}


def _simulate_trades_numpy_bb_levels(
    closes: np.ndarray,
    highs: np.ndarray,
    lows: np.ndarray,
    signals: np.ndarray,
    leverage: float,
    k_sl: float,
    initial_capital: float,
    fees_bps: float,
    slippage_bps: float,
    bb_stop_long: Optional[np.ndarray],
    bb_tp_long: Optional[np.ndarray],
    bb_stop_short: Optional[np.ndarray],
    bb_tp_short: Optional[np.ndarray],
    bb_pos_low: Optional[np.ndarray],
    bb_pos_high: Optional[np.ndarray],
    sl_level_arr: Optional[np.ndarray],
    tp_level_arr: Optional[np.ndarray],
    sl_level_param: float,
    tp_level_param: float,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray,
           np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:
    """Fallback numpy loop with BB-level stop-loss/take-profit support."""
    n_bars = len(closes)

    max_trades = n_bars // 2 + 1
    entry_indices = np.zeros(max_trades, dtype=np.int64)
    exit_indices = np.zeros(max_trades, dtype=np.int64)
    sides = np.zeros(max_trades, dtype=np.int64)
    entry_prices = np.zeros(max_trades, dtype=np.float64)
    exit_prices = np.zeros(max_trades, dtype=np.float64)
    pnls = np.zeros(max_trades, dtype=np.float64)
    returns_pct = np.zeros(max_trades, dtype=np.float64)
    exit_reasons = np.zeros(max_trades, dtype=np.int64)
    sizes = np.zeros(max_trades, dtype=np.float64)

    position = 0
    entry_price = 0.0
    entry_idx = 0
    trade_count = 0

    stop_price = np.nan
    tp_price = np.nan
    stop_level = np.nan
    tp_level = np.nan
    use_bb_pos = False
    has_bb_stop = False
    has_bb_tp = False

    slippage_factor = slippage_bps * 0.0001
    fees_factor = fees_bps * 2 * 0.0001
    sl_pct = k_sl * 0.01

    def _init_trade_levels(bar_idx: int, pos: int) -> Tuple[float, float, float, float, bool, bool, bool]:
        stop_p = np.nan
        tp_p = np.nan
        stop_l = np.nan
        tp_l = np.nan
        use_pos = False
        has_stop = False
        has_tp = False

        if pos == 1:
            if bb_stop_long is not None:
                stop_p = bb_stop_long[bar_idx]
                has_stop = not np.isnan(stop_p)
            if bb_tp_long is not None:
                tp_p = bb_tp_long[bar_idx]
                has_tp = not np.isnan(tp_p)
        else:
            if bb_stop_short is not None:
                stop_p = bb_stop_short[bar_idx]
                has_stop = not np.isnan(stop_p)
            if bb_tp_short is not None:
                tp_p = bb_tp_short[bar_idx]
                has_tp = not np.isnan(tp_p)

        if not (has_stop or has_tp) and bb_pos_low is not None and bb_pos_high is not None:
            use_pos = True
            stop_l = sl_level_arr[bar_idx] if sl_level_arr is not None else sl_level_param
            tp_l = tp_level_arr[bar_idx] if tp_level_arr is not None else tp_level_param
            has_stop = not np.isnan(stop_l)
            has_tp = not np.isnan(tp_l)

        return stop_p, tp_p, stop_l, tp_l, use_pos, has_stop, has_tp

    for i in range(n_bars):
        close_price = closes[i]
        signal = signals[i]

        if position == 0 and signal != 0:
            position = int(signal)
            entry_price = close_price * (1.0 + slippage_factor * position)
            entry_idx = i
            stop_price, tp_price, stop_level, tp_level, use_bb_pos, has_bb_stop, has_bb_tp = _init_trade_levels(i, position)

        elif position != 0:
            exit_condition = False
            exit_reason = 0

            sl_hit = False
            tp_hit = False

            if use_bb_pos:
                if position == 1:
                    if has_bb_stop and bb_pos_low[i] <= stop_level:
                        sl_hit = True
                    if has_bb_tp and bb_pos_high[i] >= tp_level:
                        tp_hit = True
                else:
                    if has_bb_stop and bb_pos_high[i] >= stop_level:
                        sl_hit = True
                    if has_bb_tp and bb_pos_low[i] <= tp_level:
                        tp_hit = True
            else:
                if has_bb_stop:
                    if position == 1 and lows[i] <= stop_price:
                        sl_hit = True
                    elif position == -1 and highs[i] >= stop_price:
                        sl_hit = True
                if has_bb_tp:
                    if position == 1 and highs[i] >= tp_price:
                        tp_hit = True
                    elif position == -1 and lows[i] <= tp_price:
                        tp_hit = True

            if not sl_hit and not has_bb_stop:
                if position == 1 and lows[i] <= entry_price * (1.0 - sl_pct):
                    sl_hit = True
                elif position == -1 and highs[i] >= entry_price * (1.0 + sl_pct):
                    sl_hit = True

            if sl_hit:
                exit_condition = True
                exit_reason = 1
            elif tp_hit:
                exit_condition = True
                exit_reason = 3
            elif signal != 0 and signal != position:
                exit_condition = True
                exit_reason = 0

            if exit_condition:
                exit_price = close_price * (1.0 - slippage_factor * position)

                if position == 1:
                    raw_return = (exit_price - entry_price) / entry_price
                else:
                    raw_return = (entry_price - exit_price) / entry_price

                net_return = raw_return - fees_factor
                pnl = net_return * leverage * initial_capital
                position_size = leverage * initial_capital / entry_price

                entry_indices[trade_count] = entry_idx
                exit_indices[trade_count] = i
                sides[trade_count] = position
                entry_prices[trade_count] = entry_price
                exit_prices[trade_count] = exit_price
                pnls[trade_count] = pnl
                returns_pct[trade_count] = net_return * 100.0
                exit_reasons[trade_count] = exit_reason
                sizes[trade_count] = position_size
                trade_count += 1

                position = 0
                entry_price = 0.0
                stop_price = np.nan
                tp_price = np.nan
                stop_level = np.nan
                tp_level = np.nan
                use_bb_pos = False
                has_bb_stop = False
                has_bb_tp = False

                if signal != 0:
                    position = int(signal)
                    entry_price = close_price * (1.0 + slippage_factor * position)
                    entry_idx = i
                    stop_price, tp_price, stop_level, tp_level, use_bb_pos, has_bb_stop, has_bb_tp = _init_trade_levels(i, position)

    if position != 0:
        final_price = closes[-1] * (1.0 - slippage_factor * position)

        if position == 1:
            raw_return = (final_price - entry_price) / entry_price
        else:
            raw_return = (entry_price - final_price) / entry_price

        net_return = raw_return - fees_factor
        pnl = net_return * leverage * initial_capital
        position_size = leverage * initial_capital / entry_price

        entry_indices[trade_count] = entry_idx
        exit_indices[trade_count] = n_bars - 1
        sides[trade_count] = position
        entry_prices[trade_count] = entry_price
        exit_prices[trade_count] = final_price
        pnls[trade_count] = pnl
        returns_pct[trade_count] = net_return * 100.0
        exit_reasons[trade_count] = 2
        sizes[trade_count] = position_size
        trade_count += 1

    return (
        entry_indices[:trade_count],
        exit_indices[:trade_count],
        sides[:trade_count],
        entry_prices[:trade_count],
        exit_prices[:trade_count],
        pnls[:trade_count],
        returns_pct[:trade_count],
        exit_reasons[:trade_count],
        sizes[:trade_count],
        trade_count
    )


def simulate_trades_fast(
    df: pd.DataFrame,
    signals: pd.Series,
    params: Dict[str, Any],
) -> pd.DataFrame:
    """
    Simule l'ex√©cution des trades avec optimisation Numba.

    10-100x plus rapide que simulate_trades() standard.

    Args:
        df: DataFrame OHLCV avec index datetime
        signals: S√©rie de signaux (+1, -1, 0)
        params: Param√®tres de trading

    Returns:
        DataFrame des trades
    """
    # Extraire param√®tres
    leverage = float(params.get("leverage", 3))
    k_sl = float(params.get("k_sl", 1.5))
    initial_capital = float(params.get("initial_capital", 10000.0))
    fees_bps = float(params.get("fees_bps", 10.0))
    slippage_bps = float(params.get("slippage_bps", 5.0))

    # Convertir en arrays numpy (contiguous pour performance)
    closes = np.ascontiguousarray(df["close"].values, dtype=np.float64)
    highs = np.ascontiguousarray(df["high"].values, dtype=np.float64)
    lows = np.ascontiguousarray(df["low"].values, dtype=np.float64)
    signal_arr = np.ascontiguousarray(
        signals.values if hasattr(signals, "values") else signals,
        dtype=np.float64
    )

    bb_stop_long = (
        np.ascontiguousarray(df["bb_stop_long"].values, dtype=np.float64)
        if "bb_stop_long" in df.columns else None
    )
    bb_tp_long = (
        np.ascontiguousarray(df["bb_tp_long"].values, dtype=np.float64)
        if "bb_tp_long" in df.columns else None
    )
    bb_stop_short = (
        np.ascontiguousarray(df["bb_stop_short"].values, dtype=np.float64)
        if "bb_stop_short" in df.columns else None
    )
    bb_tp_short = (
        np.ascontiguousarray(df["bb_tp_short"].values, dtype=np.float64)
        if "bb_tp_short" in df.columns else None
    )
    bb_pos_low = (
        np.ascontiguousarray(df["bb_pos_low"].values, dtype=np.float64)
        if "bb_pos_low" in df.columns else None
    )
    bb_pos_high = (
        np.ascontiguousarray(df["bb_pos_high"].values, dtype=np.float64)
        if "bb_pos_high" in df.columns else None
    )
    sl_level_arr = (
        np.ascontiguousarray(df["sl_level"].values, dtype=np.float64)
        if "sl_level" in df.columns else None
    )
    tp_level_arr = (
        np.ascontiguousarray(df["tp_level"].values, dtype=np.float64)
        if "tp_level" in df.columns else None
    )
    sl_level_param = params.get("sl_level", np.nan)
    if sl_level_param is None:
        sl_level_param = np.nan
    sl_level_param = float(sl_level_param)
    tp_level_param = params.get("tp_level", np.nan)
    if tp_level_param is None:
        tp_level_param = np.nan
    tp_level_param = float(tp_level_param)

    use_bb_levels = any(
        arr is not None for arr in (
            bb_stop_long,
            bb_tp_long,
            bb_stop_short,
            bb_tp_short,
            bb_pos_low,
            bb_pos_high,
        )
    )

    # Choisir l'impl√©mentation
    if use_bb_levels:
        result = _simulate_trades_numpy_bb_levels(
            closes, highs, lows, signal_arr,
            leverage, k_sl, initial_capital, fees_bps, slippage_bps,
            bb_stop_long, bb_tp_long, bb_stop_short, bb_tp_short,
            bb_pos_low, bb_pos_high, sl_level_arr, tp_level_arr,
            sl_level_param, tp_level_param,
        )
    elif HAS_NUMBA:
        result = _simulate_trades_numba(
            closes, highs, lows, signal_arr,
            leverage, k_sl, initial_capital, fees_bps, slippage_bps
        )
    else:
        logger.debug("Numba non disponible, utilisation de NumPy pur")
        result = _simulate_trades_numpy(
            closes, highs, lows, signal_arr,
            leverage, k_sl, initial_capital, fees_bps, slippage_bps
        )

    (entry_indices, exit_indices, sides, entry_prices, exit_prices,
     pnls, returns_pct, exit_reasons, sizes, trade_count) = result

    if trade_count == 0:
        return pd.DataFrame(columns=[
            "entry_ts", "exit_ts", "pnl", "size", "price_entry", "price_exit",
            "side", "exit_reason", "return_pct", "leverage_used", "fees_paid"
        ])

    # Convertir timestamps
    timestamps = df.index.values
    fees_factor = fees_bps * 2 * 0.0001

    trades_df = pd.DataFrame({
        "entry_ts": pd.to_datetime(timestamps[entry_indices]),
        "exit_ts": pd.to_datetime(timestamps[exit_indices]),
        "pnl": pnls,
        "size": sizes,
        "price_entry": entry_prices,
        "price_exit": exit_prices,
        "side": np.where(sides == 1, "LONG", "SHORT"),
        "exit_reason": [EXIT_REASON_MAP.get(r, "unknown") for r in exit_reasons],
        "return_pct": returns_pct,
        "leverage_used": leverage,
        "fees_paid": sizes * entry_prices * fees_factor
    })

    logger.debug(f"Simulation fast termin√©e: {trade_count} trades")

    return trades_df


def calculate_equity_fast(
    df: pd.DataFrame,
    trades_df: pd.DataFrame,
    initial_capital: float = 10000.0
) -> pd.Series:
    """
    Calcule la courbe d'√©quit√© avec mark-to-market.

    IMPORTANT: Inclut le P&L non r√©alis√© des positions ouvertes.

    Args:
        df: DataFrame OHLCV (pour l'index)
        trades_df: DataFrame des trades
        initial_capital: Capital initial

    Returns:
        pd.Series de l'√©quit√© avec mark-to-market
    """
    n_bars = len(df)

    if trades_df.empty:
        return pd.Series(initial_capital, index=df.index, dtype=np.float64)

    # Pr√©parer les timestamps et harmoniser les timezones
    entry_ts = pd.to_datetime(trades_df["entry_ts"])
    exit_ts = pd.to_datetime(trades_df["exit_ts"])

    # Harmoniser les timezones avec df.index
    if hasattr(df.index, 'tz') and df.index.tz is not None:
        if entry_ts.dt.tz is None:
            entry_ts = entry_ts.dt.tz_localize(df.index.tz)
        elif entry_ts.dt.tz != df.index.tz:
            entry_ts = entry_ts.dt.tz_convert(df.index.tz)

        if exit_ts.dt.tz is None:
            exit_ts = exit_ts.dt.tz_localize(df.index.tz)
        elif exit_ts.dt.tz != df.index.tz:
            exit_ts = exit_ts.dt.tz_convert(df.index.tz)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # OPTIMISATION CRITIQUE: Utiliser get_indexer au lieu de dict comprehension
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # AVANT: ts_to_idx = {ts: i for i, ts in enumerate(df.index)}  # 116k it√©rations!
    # APR√àS: get_indexer natif pandas (100√ó plus rapide avec binary search)

    # Convertir en indices avec get_indexer (vectoris√©, O(n log n))
    entry_indices = df.index.get_indexer(entry_ts, method=None)
    exit_indices = df.index.get_indexer(exit_ts, method=None)

    # Remplacer -1 (not found) par bornes valides
    entry_indices = np.where(entry_indices == -1, 0, entry_indices).astype(np.int64)
    exit_indices = np.where(exit_indices == -1, n_bars - 1, exit_indices).astype(np.int64)

    # Extraire donn√©es des trades
    pnls = trades_df["pnl"].values.astype(np.float64)
    entry_prices = trades_df["price_entry"].values.astype(np.float64)
    sizes = trades_df["size"].values.astype(np.float64)
    sides = trades_df.get("side", pd.Series(["LONG"] * len(trades_df))).values

    # Prix close pour mark-to-market
    close_prices = df['close'].values.astype(np.float64)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # UTILISER VERSION NUMBA (Simplifi√©e: P&L r√©alis√©s uniquement, sans mark-to-market)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # IMPORTANT: La version Numba utilise P&L r√©alis√©s cumul√©s (sans mark-to-market)
    # pour performance maximale. Le mark-to-market est co√ªteux (O(n_bars √ó n_trades))
    # et apporte peu de valeur quand les trades sont courts.
    if HAS_NUMBA:
        # Appel Numba JIT avec signature simplifi√©e
        equity_arr = _calculate_equity_numba(
            n_bars,
            exit_indices,
            pnls,
            initial_capital
        )
    else:
        # Fallback Python pur (lent mais fonctionne sans Numba)
        equity_arr = np.full(n_bars, initial_capital, dtype=np.float64)

        for bar_idx in range(n_bars):
            # Capital r√©alis√© (somme des P&L des trades cl√¥tur√©s)
            closed_mask = exit_indices <= bar_idx
            realized_pnl = pnls[closed_mask].sum() if np.any(closed_mask) else 0.0

            # P&L non r√©alis√© des positions ouvertes
            open_mask = (entry_indices <= bar_idx) & (exit_indices > bar_idx)
            unrealized_pnl = 0.0

            if np.any(open_mask):
                current_price = close_prices[bar_idx]
                for i in np.where(open_mask)[0]:
                    if sides[i] == 'LONG':
                        unrealized_pnl += (current_price - entry_prices[i]) * sizes[i]
                    else:  # SHORT
                        unrealized_pnl += (entry_prices[i] - current_price) * sizes[i]

            equity_arr[bar_idx] = initial_capital + realized_pnl + unrealized_pnl

    return pd.Series(equity_arr, index=df.index, dtype=np.float64)


def calculate_returns_fast(equity: pd.Series) -> pd.Series:
    """Calcul vectoris√© des rendements."""
    equity_arr = equity.values
    returns = np.zeros_like(equity_arr)
    returns[1:] = (equity_arr[1:] - equity_arr[:-1]) / equity_arr[:-1]
    returns = np.nan_to_num(returns, 0.0)
    return pd.Series(returns, index=equity.index, dtype=np.float64)


# =============================================================================
# BATCH PROCESSING
# =============================================================================

def simulate_batch(
    df: pd.DataFrame,
    signals_batch: List[pd.Series],
    params_batch: List[Dict[str, Any]],
    n_jobs: int = -1
) -> List[pd.DataFrame]:
    """
    Simule plusieurs backtests en parall√®le.

    Args:
        df: DataFrame OHLCV partag√©
        signals_batch: Liste de s√©ries de signaux
        params_batch: Liste de param√®tres
        n_jobs: Nombre de workers (-1 = tous les CPUs)

    Returns:
        Liste de DataFrames de trades
    """
    import os
    from concurrent.futures import ThreadPoolExecutor, as_completed

    if n_jobs == -1:
        n_jobs = os.cpu_count() or 4

    results = [None] * len(signals_batch)

    def run_single(idx: int) -> Tuple[int, pd.DataFrame]:
        trades = simulate_trades_fast(df, signals_batch[idx], params_batch[idx])
        return idx, trades

    with ThreadPoolExecutor(max_workers=n_jobs) as executor:
        futures = [executor.submit(run_single, i) for i in range(len(signals_batch))]
        for future in as_completed(futures):
            idx, trades = future.result()
            results[idx] = trades

    return results


__all__ = [
    "simulate_trades_fast",
    "calculate_equity_fast",
    "calculate_returns_fast",
    "simulate_batch",
    "HAS_NUMBA"
]
```
<!-- MODULE-END: simulator_fast.py -->

<!-- MODULE-START: storage.py -->
```json
{
  "name": "storage.py",
  "path": "backtest\\storage.py",
  "ext": ".py",
  "anchor": "storage_py"
}
```
## storage_py
*Chemin* : `backtest\storage.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.storage

Purpose: Persister et indexer les r√©sultats de backtests pour rechargement/recherche rapide.

Role in pipeline: persistence / reporting

Key components: ResultStorage, StoredResultMetadata, get_storage

Inputs: RunResult, run_id, auto_cleanup flag

Outputs: Fichiers JSON/Parquet dans backtest_results/{run_id}/, index.json

Dependencies: pandas, pathlib, json, optionnel: pyarrow (Parquet)

Conventions: Structure run_id/metadata.json + equity.parquet + trades.parquet; index.json catalogue; auto_cleanup garde N derniers runs.

Read-if: Persistance r√©sultats, recherche historique, ou gestion stockage.

Skip-if: Backtests ponctuels sans sauvegarde.
"""

from __future__ import annotations

import json
import shutil
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import pandas as pd

from backtest.engine import RunResult
from backtest.sweep import SweepResults
from metrics_types import PerformanceMetricsPct, normalize_metrics
from utils.log import get_logger

logger = get_logger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

DEFAULT_STORAGE_DIR = Path("backtest_results")
MAX_RESULTS_TO_KEEP = 1000  # Nombre maximum de r√©sultats √† garder


# =============================================================================
# DATACLASSES
# =============================================================================

@dataclass
class StoredResultMetadata:
    """M√©tadonn√©es d'un r√©sultat sauvegard√©."""
    run_id: str
    timestamp: str
    strategy: str
    symbol: str
    timeframe: str
    params: Dict[str, Any]
    metrics: PerformanceMetricsPct
    n_bars: int
    n_trades: int
    period_start: str
    period_end: str
    duration_sec: float

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dict pour s√©rialisation."""
        payload = asdict(self)
        payload["metrics"] = normalize_metrics(self.metrics, "pct")
        return payload

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "StoredResultMetadata":
        """Cr√©e depuis un dict."""
        metrics = normalize_metrics(data.get("metrics", {}), "pct")
        return cls(
            run_id=data["run_id"],
            timestamp=data["timestamp"],
            strategy=data["strategy"],
            symbol=data["symbol"],
            timeframe=data["timeframe"],
            params=data.get("params", {}),
            metrics=metrics,
            n_bars=data["n_bars"],
            n_trades=data["n_trades"],
            period_start=data.get("period_start", ""),
            period_end=data.get("period_end", ""),
            duration_sec=data.get("duration_sec", 0.0),
        )


# =============================================================================
# STORAGE ENGINE
# =============================================================================

class ResultStorage:
    """
    Gestionnaire de stockage des r√©sultats de backtests.

    Features:
    - Sauvegarde automatique avec structure organis√©e
    - Index pour recherche rapide
    - Compression optionnelle
    - Nettoyage automatique des anciens r√©sultats

    Example:
        >>> storage = ResultStorage()
        >>>
        >>> # Sauvegarder un r√©sultat
        >>> storage.save_result(run_result)
        >>>
        >>> # Lister tous les r√©sultats
        >>> all_results = storage.list_results()
        >>>
        >>> # Rechercher
        >>> best_runs = storage.search_results(min_sharpe=2.0)
        >>>
        >>> # Charger un r√©sultat sp√©cifique
        >>> result = storage.load_result(run_id)
    """

    def __init__(
        self,
        storage_dir: Optional[Union[str, Path]] = None,
        auto_save: bool = True,
        compress: bool = False,
    ):
        """
        Initialise le gestionnaire de stockage.

        Args:
            storage_dir: R√©pertoire de stockage (d√©faut: backtest_results/)
            auto_save: Activer la sauvegarde automatique
            compress: Compresser les fichiers Parquet
        """
        self.storage_dir = Path(storage_dir) if storage_dir else DEFAULT_STORAGE_DIR
        self.auto_save = auto_save
        self.compress = compress

        # Cr√©er le r√©pertoire si n√©cessaire
        self.storage_dir.mkdir(parents=True, exist_ok=True)

        # Chemin de l'index
        self.index_path = self.storage_dir / "index.json"

        # Charger ou cr√©er l'index
        self._index: Dict[str, StoredResultMetadata] = self._load_index()

        logger.info(f"ResultStorage initialis√©: {self.storage_dir} ({len(self._index)} r√©sultats)")

    # =========================================================================
    # SAUVEGARDE
    # =========================================================================

    def save_result(
        self,
        result: RunResult,
        run_id: Optional[str] = None,
        auto_cleanup: bool = False,
    ) -> str:
        """
        Sauvegarde un r√©sultat de backtest.

        Args:
            result: RunResult √† sauvegarder
            run_id: ID personnalis√© (sinon utilise result.meta['run_id'])
            auto_cleanup: Nettoyer les anciens r√©sultats si trop nombreux

        Returns:
            run_id du r√©sultat sauvegard√©
        """
        # R√©cup√©rer ou g√©n√©rer le run_id
        if run_id is None:
            run_id = result.meta.get("run_id", f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}")

        # Cr√©er le r√©pertoire du run
        run_dir = self.storage_dir / run_id
        run_dir.mkdir(parents=True, exist_ok=True)

        try:
            # 1. Sauvegarder les m√©tadonn√©es
            metrics_pct = normalize_metrics(result.metrics, "pct")
            metadata = StoredResultMetadata(
                run_id=run_id,
                timestamp=datetime.now().isoformat(),
                strategy=result.meta.get("strategy", "unknown"),
                symbol=result.meta.get("symbol", "unknown"),
                timeframe=result.meta.get("timeframe", "unknown"),
                params=result.meta.get("params", {}),
                metrics=metrics_pct,
                n_bars=result.meta.get("n_bars", len(result.equity)),
                n_trades=len(result.trades),
                period_start=result.meta.get("period_start", ""),
                period_end=result.meta.get("period_end", ""),
                duration_sec=result.meta.get("duration_sec", 0.0),
            )

            metadata_path = run_dir / "metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata.to_dict(), f, indent=2, ensure_ascii=False)

            # 2. Sauvegarder la courbe d'√©quit√©
            equity_path = run_dir / "equity.parquet"
            equity_df = result.equity.to_frame(name="equity")
            equity_df.to_parquet(
                equity_path,
                compression="snappy" if self.compress else None,
                index=True,
            )

            # 3. Sauvegarder les trades
            trades_path = run_dir / "trades.parquet"
            result.trades.to_parquet(
                trades_path,
                compression="snappy" if self.compress else None,
                index=False,
            )

            # 4. Sauvegarder les returns
            returns_path = run_dir / "returns.parquet"
            returns_df = result.returns.to_frame(name="returns")
            returns_df.to_parquet(
                returns_path,
                compression="snappy" if self.compress else None,
                index=True,
            )

            # 5. Mettre √† jour l'index
            self._index[run_id] = metadata
            self._save_index()

            logger.info(f"‚úÖ R√©sultat sauvegard√©: {run_id} ({metadata.strategy})")

            # Nettoyage optionnel
            if auto_cleanup:
                self._cleanup_old_results()

            return run_id

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde: {e}")
            # Nettoyer en cas d'erreur
            if run_dir.exists():
                shutil.rmtree(run_dir)
            raise

    def save_sweep_results(
        self,
        sweep_results: SweepResults,
        sweep_id: Optional[str] = None,
    ) -> str:
        """
        Sauvegarde les r√©sultats d'un sweep.

        Args:
            sweep_results: SweepResults √† sauvegarder
            sweep_id: ID personnalis√© du sweep

        Returns:
            sweep_id
        """
        if sweep_id is None:
            sweep_id = f"sweep_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        sweep_dir = self.storage_dir / sweep_id
        sweep_dir.mkdir(parents=True, exist_ok=True)

        try:
            # Sauvegarder le r√©sum√©
            summary = {
                "sweep_id": sweep_id,
                "timestamp": datetime.now().isoformat(),
                "n_completed": sweep_results.n_completed,
                "n_failed": sweep_results.n_failed,
                "total_time": sweep_results.total_time,
                "best_params": sweep_results.best_params,
                "best_metrics": normalize_metrics(sweep_results.best_metrics, "pct"),
                "resource_stats": sweep_results.resource_stats,
            }

            summary_path = sweep_dir / "summary.json"
            with open(summary_path, "w", encoding="utf-8") as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)

            # Sauvegarder tous les r√©sultats en DataFrame
            results_df = sweep_results.to_dataframe()
            results_path = sweep_dir / "all_results.parquet"
            results_df.to_parquet(
                results_path,
                compression="snappy" if self.compress else None,
                index=False,
            )

            logger.info(f"‚úÖ Sweep sauvegard√©: {sweep_id} ({sweep_results.n_completed} r√©sultats)")

            return sweep_id

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde du sweep: {e}")
            if sweep_dir.exists():
                shutil.rmtree(sweep_dir)
            raise

    # =========================================================================
    # CHARGEMENT
    # =========================================================================

    def load_result(self, run_id: str) -> RunResult:
        """
        Charge un r√©sultat de backtest.

        Args:
            run_id: ID du run √† charger

        Returns:
            RunResult reconstruit

        Raises:
            FileNotFoundError: Si le run_id n'existe pas
        """
        run_dir = self.storage_dir / run_id

        if not run_dir.exists():
            raise FileNotFoundError(f"Run inexistant: {run_id}")

        try:
            # 1. Charger les m√©tadonn√©es
            metadata_path = run_dir / "metadata.json"
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata_dict = json.load(f)
            metadata = StoredResultMetadata.from_dict(metadata_dict)

            # 2. Charger l'√©quit√©
            equity_path = run_dir / "equity.parquet"
            equity_df = pd.read_parquet(equity_path)
            equity = equity_df["equity"]

            # 3. Charger les trades
            trades_path = run_dir / "trades.parquet"
            trades = pd.read_parquet(trades_path)

            # 4. Charger les returns
            returns_path = run_dir / "returns.parquet"
            returns_df = pd.read_parquet(returns_path)
            returns = returns_df["returns"]

            # 5. Reconstruire le RunResult
            result = RunResult(
                equity=equity,
                returns=returns,
                trades=trades,
                metrics=metadata.metrics,
                meta={
                    "run_id": metadata.run_id,
                    "strategy": metadata.strategy,
                    "symbol": metadata.symbol,
                    "timeframe": metadata.timeframe,
                    "params": metadata.params,
                    "n_bars": metadata.n_bars,
                    "period_start": metadata.period_start,
                    "period_end": metadata.period_end,
                    "duration_sec": metadata.duration_sec,
                    "loaded_from_storage": True,
                    "loaded_at": datetime.now().isoformat(),
                }
            )

            logger.info(f"‚úÖ R√©sultat charg√©: {run_id}")
            return result

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement de {run_id}: {e}")
            raise

    def load_sweep_results(self, sweep_id: str) -> Dict[str, Any]:
        """
        Charge les r√©sultats d'un sweep.

        Args:
            sweep_id: ID du sweep

        Returns:
            Dict avec summary et results_df
        """
        sweep_dir = self.storage_dir / sweep_id

        if not sweep_dir.exists():
            raise FileNotFoundError(f"Sweep inexistant: {sweep_id}")

        try:
            # Charger le r√©sum√©
            summary_path = sweep_dir / "summary.json"
            with open(summary_path, "r", encoding="utf-8") as f:
                summary = json.load(f)
            summary["best_metrics"] = normalize_metrics(
                summary.get("best_metrics", {}), "pct"
            )

            # Charger les r√©sultats
            results_path = sweep_dir / "all_results.parquet"
            results_df = pd.read_parquet(results_path)

            logger.info(f"‚úÖ Sweep charg√©: {sweep_id}")

            return {
                "summary": summary,
                "results_df": results_df,
                "sweep_id": sweep_id,
            }

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du sweep {sweep_id}: {e}")
            raise

    # =========================================================================
    # RECHERCHE & LISTAGE
    # =========================================================================

    def list_results(
        self,
        limit: Optional[int] = None,
        sort_by: str = "timestamp",
        reverse: bool = True,
    ) -> List[StoredResultMetadata]:
        """
        Liste tous les r√©sultats disponibles.

        Args:
            limit: Limiter le nombre de r√©sultats
            sort_by: Champ de tri (timestamp, sharpe_ratio, etc.)
            reverse: Tri descendant

        Returns:
            Liste de m√©tadonn√©es
        """
        results = list(self._index.values())

        # Tri
        if sort_by == "timestamp":
            results.sort(key=lambda x: x.timestamp, reverse=reverse)
        elif sort_by == "sharpe_ratio":
            results.sort(
                key=lambda x: x.metrics.get("sharpe_ratio", 0),
                reverse=reverse
            )
        elif sort_by == "total_return":
            results.sort(
                key=lambda x: x.metrics.get("total_return_pct", 0),
                reverse=reverse
            )

        # Limite
        if limit:
            results = results[:limit]

        return results

    def search_results(
        self,
        strategy: Optional[str] = None,
        symbol: Optional[str] = None,
        timeframe: Optional[str] = None,
        min_sharpe: Optional[float] = None,
        max_drawdown: Optional[float] = None,
        min_trades: Optional[int] = None,
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
    ) -> List[StoredResultMetadata]:
        """
        Recherche des r√©sultats avec filtres.

        Args:
            strategy: Nom de la strat√©gie
            symbol: Symbole
            timeframe: Timeframe
            min_sharpe: Sharpe ratio minimum
            max_drawdown: Drawdown maximum (%)
            min_trades: Nombre minimum de trades
            date_from: Date minimum (ISO format)
            date_to: Date maximum (ISO format)

        Returns:
            Liste de m√©tadonn√©es filtr√©es
        """
        results = list(self._index.values())

        # Filtres
        if strategy:
            results = [r for r in results if r.strategy == strategy]

        if symbol:
            results = [r for r in results if r.symbol == symbol]

        if timeframe:
            results = [r for r in results if r.timeframe == timeframe]

        if min_sharpe is not None:
            results = [
                r for r in results
                if r.metrics.get("sharpe_ratio", 0) >= min_sharpe
            ]

        if max_drawdown is not None:
            results = [
                r for r in results
                if r.metrics.get("max_drawdown_pct", 100) <= max_drawdown
            ]

        if min_trades is not None:
            results = [r for r in results if r.n_trades >= min_trades]

        if date_from:
            results = [r for r in results if r.timestamp >= date_from]

        if date_to:
            results = [r for r in results if r.timestamp <= date_to]

        return results

    def get_best_results(
        self,
        n: int = 10,
        metric: str = "sharpe_ratio",
    ) -> List[StoredResultMetadata]:
        """
        Retourne les N meilleurs r√©sultats selon une m√©trique.

        Args:
            n: Nombre de r√©sultats
            metric: M√©trique de tri

        Returns:
            Liste des meilleurs r√©sultats
        """
        results = list(self._index.values())
        results.sort(
            key=lambda x: x.metrics.get(metric, float("-inf")),
            reverse=True
        )
        return results[:n]

    # =========================================================================
    # GESTION
    # =========================================================================

    def delete_result(self, run_id: str) -> bool:
        """
        Supprime un r√©sultat.

        Args:
            run_id: ID du run √† supprimer

        Returns:
            True si supprim√©, False sinon
        """
        run_dir = self.storage_dir / run_id

        if not run_dir.exists():
            logger.warning(f"‚ö†Ô∏è Run inexistant: {run_id}")
            return False

        try:
            shutil.rmtree(run_dir)

            if run_id in self._index:
                del self._index[run_id]
                self._save_index()

            logger.info(f"üóëÔ∏è R√©sultat supprim√©: {run_id}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la suppression: {e}")
            return False

    def _cleanup_old_results(self, keep_last: int = MAX_RESULTS_TO_KEEP) -> int:
        """
        Nettoie les anciens r√©sultats pour √©viter l'accumulation.

        Args:
            keep_last: Nombre de r√©sultats √† garder

        Returns:
            Nombre de r√©sultats supprim√©s
        """
        results = list(self._index.values())
        results.sort(key=lambda x: x.timestamp, reverse=True)

        to_delete = results[keep_last:]
        deleted_count = 0

        for result in to_delete:
            if self.delete_result(result.run_id):
                deleted_count += 1

        if deleted_count > 0:
            logger.info(f"üßπ Nettoyage: {deleted_count} anciens r√©sultats supprim√©s")

        return deleted_count

    def clear_all(self) -> bool:
        """
        Supprime TOUS les r√©sultats (attention!).

        Returns:
            True si succ√®s
        """
        try:
            if self.storage_dir.exists():
                shutil.rmtree(self.storage_dir)
                self.storage_dir.mkdir(parents=True, exist_ok=True)

            self._index = {}
            self._save_index()

            logger.warning("üßπ TOUS les r√©sultats ont √©t√© supprim√©s")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du nettoyage: {e}")
            return False

    # =========================================================================
    # INDEX
    # =========================================================================

    def _load_index(self) -> Dict[str, StoredResultMetadata]:
        """Charge l'index depuis le disque."""
        if not self.index_path.exists():
            return {}

        try:
            with open(self.index_path, "r", encoding="utf-8") as f:
                index_data = json.load(f)

            # Reconstruire les objets StoredResultMetadata
            index = {}
            for run_id, meta_dict in index_data.items():
                try:
                    index[run_id] = StoredResultMetadata.from_dict(meta_dict)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è M√©tadonn√©e corrompue pour {run_id}: {e}")

            return index

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement de l'index: {e}")
            return {}

    def _save_index(self) -> None:
        """Sauvegarde l'index sur le disque."""
        try:
            index_data = {
                run_id: meta.to_dict()
                for run_id, meta in self._index.items()
            }

            with open(self.index_path, "w", encoding="utf-8") as f:
                json.dump(index_data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde de l'index: {e}")

    def rebuild_index(self) -> int:
        """
        Reconstruit l'index en scannant tous les r√©pertoires.

        Utile en cas de corruption ou si des fichiers ont √©t√© ajout√©s manuellement.

        Returns:
            Nombre de r√©sultats index√©s
        """
        logger.info("üîÑ Reconstruction de l'index...")

        self._index = {}
        count = 0

        for run_dir in self.storage_dir.iterdir():
            if not run_dir.is_dir():
                continue

            metadata_path = run_dir / "metadata.json"
            if not metadata_path.exists():
                continue

            try:
                with open(metadata_path, "r", encoding="utf-8") as f:
                    meta_dict = json.load(f)

                metadata = StoredResultMetadata.from_dict(meta_dict)
                self._index[metadata.run_id] = metadata
                count += 1

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Impossible de charger {run_dir.name}: {e}")

        self._save_index()
        logger.info(f"‚úÖ Index reconstruit: {count} r√©sultats")

        return count


# =============================================================================
# INSTANCE GLOBALE
# =============================================================================

_storage_instance: Optional[ResultStorage] = None


def get_storage(
    storage_dir: Optional[Union[str, Path]] = None,
    auto_save: bool = True,
    compress: bool = False,
) -> ResultStorage:
    """
    Retourne l'instance globale de ResultStorage (singleton).

    Args:
        storage_dir: R√©pertoire de stockage
        auto_save: Activer la sauvegarde automatique
        compress: Compresser les fichiers

    Returns:
        ResultStorage instance
    """
    global _storage_instance
    if _storage_instance is None:
        _storage_instance = ResultStorage(
            storage_dir=storage_dir,
            auto_save=auto_save,
            compress=compress,
        )
    return _storage_instance


__all__ = [
    "ResultStorage",
    "StoredResultMetadata",
    "get_storage",
]


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur persistance/indexation
# - Conventions structure r√©pertoires et index.json explicit√©es
# - Read-if/Skip-if ajout√©s pour tri rapide
```
<!-- MODULE-END: storage.py -->

<!-- MODULE-START: sweep.py -->
```json
{
  "name": "sweep.py",
  "path": "backtest\\sweep.py",
  "ext": ".py",
  "anchor": "sweep_py"
}
```
## sweep_py
*Chemin* : `backtest\sweep.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.sweep

Purpose: Optimiser les param√®tres via grid search parall√©lis√© avec suivi temps r√©el et filtrage par contraintes.

Role in pipeline: optimization

Key components: SweepEngine, SweepResult, SweepResultItem, run_sweep

Inputs: param_grid (Dict ou liste), strat√©gie, DataFrame OHLCV, max_workers, constraints optionnelles

Outputs: SweepResult (best_result, all_results, stats, timing)

Dependencies: backtest.engine, performance.parallel, performance.monitor, utils.parameters

Conventions: Combinaisons g√©n√©r√©es via product(); contraintes appliqu√©es; r√©sultats tri√©s par m√©trique cible; nb combinaisons plafonn√©.

Read-if: Param√©tragedu sweep, parallelisation, monitoring ou ajout de contraintes.

Skip-if: Vous utilisez optuna/pareto au lieu de sweep classique.
"""

from __future__ import annotations

import logging
import time
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union

import pandas as pd

if TYPE_CHECKING:
    from strategies.base import StrategyBase

from backtest.engine import BacktestEngine
from metrics_types import PerformanceMetricsPct, normalize_metrics
from performance.monitor import (
    ProgressBar,
    ResourceTracker,
)
from performance.parallel import (
    ParallelRunner,
    generate_param_grid,
)
from performance.profiler import Profiler
from utils.parameters import compute_search_space_stats

logger = logging.getLogger(__name__)


def _normalize_metrics_pct(metrics: Dict[str, Any]) -> PerformanceMetricsPct:
    if not metrics:
        return {}
    return normalize_metrics(metrics, "pct")


@dataclass
class SweepResultItem:
    """R√©sultat d'une combinaison de param√®tres."""
    params: Dict[str, Any]
    metrics: PerformanceMetricsPct
    success: bool
    error: Optional[str] = None


@dataclass
class SweepResults:
    """R√©sultats complets d'un sweep param√©trique."""
    items: List[SweepResultItem]
    best_params: Dict[str, Any]
    best_metrics: PerformanceMetricsPct
    total_time: float
    n_completed: int
    n_failed: int
    resource_stats: Optional[Dict[str, Any]] = None

    def __post_init__(self) -> None:
        self.best_metrics = _normalize_metrics_pct(self.best_metrics)
        for item in self.items:
            item.metrics = _normalize_metrics_pct(item.metrics)

    def to_dataframe(self) -> pd.DataFrame:
        """Convertit les r√©sultats en DataFrame."""
        rows = []
        for item in self.items:
            row = {**item.params, **item.metrics, "success": item.success}
            if item.error:
                row["error"] = item.error
            rows.append(row)
        return pd.DataFrame(rows)

    def get_top_n(self, n: int = 10, metric: str = "sharpe_ratio") -> pd.DataFrame:
        """Retourne les N meilleures combinaisons."""
        df = self.to_dataframe()
        if metric in df.columns:
            return df.nlargest(n, metric)
        return df.head(n)

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel."""
        sharpe = self.best_metrics.get('sharpe_ratio', 0)
        total_pnl = self.best_metrics.get('total_pnl', 0)
        win_rate = self.best_metrics.get('win_rate_pct', 0)

        # G√©rer le cas o√π les valeurs sont des strings (N/A)
        sharpe_str = f"{sharpe:.2f}" if isinstance(sharpe, (int, float)) else str(sharpe)
        pnl_str = f"${total_pnl:,.2f}" if isinstance(total_pnl, (int, float)) else str(total_pnl)
        wr_str = f"{win_rate:.1f}%" if isinstance(win_rate, (int, float)) else str(win_rate)

        return f"""
Sweep Results Summary
=====================
Completed: {self.n_completed}/{self.n_completed + self.n_failed}
Failed: {self.n_failed}
Total time: {self.total_time:.1f}s
Avg time/combo: {self.total_time / max(1, self.n_completed):.2f}s

Best Parameters:
{self.best_params}

Best Metrics:
  Sharpe: {sharpe_str}
  Total P&L: {pnl_str}
  Win Rate: {wr_str}
"""


def _run_single_backtest_wrapper(
    params: Dict[str, Any],
    df: pd.DataFrame,
    strategy: "StrategyBase",
    initial_capital: float,
    silent_mode: bool = True,
    fast_metrics: bool = True,
) -> Dict[str, Any]:
    """
    Wrapper function pour ex√©cuter un backtest en parall√®le (picklable).

    Cette fonction est con√ßue pour √™tre utilis√©e avec concurrent.futures:
    - Accepte tous les arguments n√©cessaires explicitement
    - Retourne un dict avec params, metrics, success, error
    - G√®re les exceptions de mani√®re robuste

    Args:
        params: Param√®tres de la strat√©gie
        df: DataFrame OHLCV
        strategy: Instance de strat√©gie
        initial_capital: Capital initial
        silent_mode: D√©sactive les logs pour acc√©l√©rer les sweeps
        fast_metrics: Utilise la version rapide des m√©triques

    Returns:
        Dict avec cl√©s: params, metrics, success, error (optionnel)
    """
    try:
        engine = BacktestEngine(initial_capital=initial_capital)
        result = engine.run(
            df=df,
            strategy=strategy,
            params=params,
            silent_mode=silent_mode,
            fast_metrics=fast_metrics,
        )

        return {
            "params": params,
            "metrics": _normalize_metrics_pct(result.metrics),
            "success": True,
        }
    except Exception as e:
        logger.error(f"Backtest failed for params {params}: {e}")
        return {
            "params": params,
            "metrics": {},
            "success": False,
            "error": str(e),
        }


class SweepEngine:
    """
    Moteur de sweep param√©trique avec parall√©lisation et monitoring.

    Features:
    - Ex√©cution parall√®le sur tous les CPU
    - Monitoring temps r√©el (CPU, RAM)
    - Barre de progression
    - Arr√™t anticip√© optionnel
    - Profiling optionnel

    Example:
        >>> engine = SweepEngine(max_workers=8)
        >>>
        >>> results = engine.run_sweep(
        ...     df=data,
        ...     strategy=my_strategy,
        ...     param_grid={
        ...         "period": range(10, 30, 5),
        ...         "threshold": [0.5, 1.0, 1.5]
        ...     },
        ...     optimize_for="sharpe_ratio"
        ... )
        >>>
        >>> print(results.best_params)
    """

    def __init__(
        self,
        max_workers: Optional[int] = None,
        use_processes: bool = True,
        initial_capital: float = 10000.0,
        enable_profiling: bool = False,
        auto_save: bool = True,
        silent_mode: bool = True,
        fast_metrics: bool = True,
    ):
        """
        Initialise le moteur de sweep.

        Args:
            max_workers: Nombre de workers parall√®les (None = auto)
            use_processes: Utiliser multiprocessing (True) ou threading (False)
            initial_capital: Capital de d√©part
            enable_profiling: Activer le profiling des performances
            auto_save: Sauvegarder automatiquement les r√©sultats
            silent_mode: D√©sactiver les logs internes pendant le sweep
            fast_metrics: Utiliser les m√©triques rapides (Sharpe/Sortino)
        """
        self.max_workers = max_workers
        self.use_processes = use_processes
        self.initial_capital = initial_capital
        self.enable_profiling = enable_profiling
        self.auto_save = auto_save
        self.silent_mode = silent_mode
        self.fast_metrics = fast_metrics

        self._runner = ParallelRunner(
            max_workers=max_workers,
            use_processes=use_processes,
            backend="loky",  # Optimal: √©vite pickling r√©p√©titif du DataFrame
        )

        self._stop_requested = False

        logger.info(
            f"SweepEngine initialis√©: {self._runner.max_workers} workers, "
            f"capital=${initial_capital:,.0f}, auto_save={auto_save}"
        )

    def run_sweep(
        self,
        df: pd.DataFrame,
        strategy: Union["StrategyBase", str],
        param_grid: Dict[str, Any],
        *,
        optimize_for: str = "sharpe_ratio",
        minimize: bool = False,
        show_progress: bool = True,
        early_stop_threshold: Optional[float] = None,
        silent_mode: Optional[bool] = None,
        fast_metrics: Optional[bool] = None,
    ) -> SweepResults:
        """
        Ex√©cute un sweep param√©trique complet.

        Args:
            df: DataFrame OHLCV
            strategy: Strat√©gie √† tester
            param_grid: Dict des plages de param√®tres
            optimize_for: M√©trique √† optimiser
            minimize: True pour minimiser (ex: drawdown)
            show_progress: Afficher la progression
            early_stop_threshold: Arr√™ter si m√©trique atteint ce seuil
            silent_mode: D√©sactiver logs internes (None = valeur engine)
            fast_metrics: Utiliser m√©triques rapides (None = valeur engine)

        Returns:
            SweepResults avec tous les r√©sultats et le meilleur
        """
        self._stop_requested = False
        start_time = time.time()
        silent_mode = self.silent_mode if silent_mode is None else silent_mode
        fast_metrics = self.fast_metrics if fast_metrics is None else fast_metrics

        # Calculer les statistiques d'espace de recherche
        try:
            stats = compute_search_space_stats(param_grid, max_combinations=100000)
            logger.info(f"Search space: {stats.summary()}")

            if stats.warnings:
                for warning in stats.warnings:
                    logger.warning(f"‚ö†Ô∏è {warning}")

            # Log d√©taill√© par param√®tre
            for param_name, count in stats.per_param_counts.items():
                if count > 0:
                    logger.debug(f"  {param_name}: {count} valeurs")
        except Exception as e:
            logger.warning(f"Failed to compute search space stats: {e}")

        # G√©n√©rer toutes les combinaisons
        combinations = generate_param_grid(param_grid)
        n_combos = len(combinations)

        logger.info(f"D√©marrage sweep: {n_combos} combinaisons")

        # R√©soudre la strat√©gie si c'est un nom
        if isinstance(strategy, str):
            strategy = self._get_strategy_by_name(strategy)

        # Tracker de ressources
        tracker = ResourceTracker(interval=1.0)
        tracker.start()

        results: List[SweepResultItem] = []
        best_value = float("-inf") if not minimize else float("inf")
        best_params: Dict[str, Any] = {}
        best_metrics: PerformanceMetricsPct = {}

        # Profiler optionnel
        profiler = Profiler("sweep") if self.enable_profiling else None
        if profiler:
            profiler.start()

        try:
            # Callback de progression pour int√©gration avec ProgressBar
            pbar = None
            if show_progress:
                pbar = ProgressBar(total=n_combos, description="Sweep")
                pbar.__enter__()

            def progress_callback(current: int, total: int):
                """Callback appel√© par ParallelRunner pour mettre √† jour la progress bar."""
                if pbar:
                    pbar.update(current)

            # Ex√©cution parall√®le via ParallelRunner
            parallel_result = self._runner.run_sweep(
                run_func=_run_single_backtest_wrapper,
                param_grid=combinations,
                progress_callback=progress_callback if show_progress else None,
                # Fixed kwargs pass√©s √† chaque appel de _run_single_backtest_wrapper
                df=df,
                strategy=strategy,
                initial_capital=self.initial_capital,
                silent_mode=silent_mode,
                fast_metrics=fast_metrics,
            )

            if pbar:
                pbar.__exit__(None, None, None)

            # Traiter les r√©sultats du ParallelRunner
            for item_data in parallel_result.results:
                # V√©rifier si un arr√™t d'urgence a √©t√© demand√©
                if self._stop_requested:
                    logger.warning("üõë Arr√™t d'urgence d√©tect√© - Interruption du sweep")
                    break

                if item_data.get("success"):
                    result = item_data["result"]
                    metrics = _normalize_metrics_pct(result.get("metrics", {}))
                    item = SweepResultItem(
                        params=result["params"],
                        metrics=metrics,
                        success=result["success"],
                        error=result.get("error"),
                    )
                else:
                    # Cas d'erreur
                    item = SweepResultItem(
                        params=item_data["params"],
                        metrics={},
                        success=False,
                        error=item_data.get("error", "Unknown error"),
                    )

                results.append(item)

                # Mise √† jour du meilleur
                if item.success and optimize_for in item.metrics:
                    value = item.metrics[optimize_for]
                    is_better = (
                        (not minimize and value > best_value) or
                        (minimize and value < best_value)
                    )
                    if is_better:
                        best_value = value
                        best_params = item.params.copy()
                        best_metrics = item.metrics.copy()

                        # Early stopping (post-traitement)
                        if early_stop_threshold is not None:
                            if (not minimize and best_value >= early_stop_threshold) or \
                               (minimize and best_value <= early_stop_threshold):
                                logger.info(f"Early stop: {optimize_for}={best_value:.4f}")
                                # Note: avec ParallelRunner, les t√¢ches restantes sont d√©j√† lanc√©es
                                # mais on arr√™te le traitement des r√©sultats
                                break

        finally:
            # Arr√™ter le tracking
            resource_stats = tracker.stop()

            if profiler:
                profiler.stop()
                if self.enable_profiling:
                    profiler.print_stats(top_n=10)

        total_time = time.time() - start_time
        n_completed = sum(1 for r in results if r.success)
        n_failed = sum(1 for r in results if not r.success)

        logger.info(f"Sweep termin√©: {n_completed}/{n_combos} en {total_time:.1f}s")
        logger.info(f"Meilleur {optimize_for}: {best_value:.4f}")

        sweep_results = SweepResults(
            items=results,
            best_params=best_params,
            best_metrics=best_metrics,
            total_time=total_time,
            n_completed=n_completed,
            n_failed=n_failed,
            resource_stats={
                "cpu_avg": resource_stats.cpu_avg,
                "cpu_max": resource_stats.cpu_max,
                "memory_max_gb": resource_stats.memory_max_gb,
                "duration": resource_stats.duration_seconds,
            }
        )

        # Sauvegarde automatique si activ√©e
        if self.auto_save:
            try:
                from backtest.storage import get_storage
                storage = get_storage()
                sweep_id = storage.save_sweep_results(sweep_results)
                logger.info(f"‚úÖ Sweep sauvegard√©: {sweep_id}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Sauvegarde automatique √©chou√©e: {e}")

        return sweep_results

    def run_sweep_parallel(
        self,
        df: pd.DataFrame,
        strategy: Union["StrategyBase", str],
        param_grid: Dict[str, Any],
        *,
        optimize_for: str = "sharpe_ratio",
        minimize: bool = False,
        silent_mode: Optional[bool] = None,
        fast_metrics: Optional[bool] = None,
    ) -> SweepResults:
        """
        Ex√©cute un sweep param√©trique en parall√®le (multiprocessing).

        Note: Le multiprocessing n√©cessite que strategy soit picklable.
        Pour des strat√©gies complexes, utilisez run_sweep().

        Args:
            df: DataFrame OHLCV
            strategy: Strat√©gie √† tester
            param_grid: Dict des plages de param√®tres
            optimize_for: M√©trique √† optimiser
            minimize: True pour minimiser
            silent_mode: D√©sactiver logs internes (None = valeur engine)
            fast_metrics: Utiliser m√©triques rapides (None = valeur engine)

        Returns:
            SweepResults
        """
        start_time = time.time()
        silent_mode = self.silent_mode if silent_mode is None else silent_mode
        fast_metrics = self.fast_metrics if fast_metrics is None else fast_metrics

        combinations = generate_param_grid(param_grid)
        n_combos = len(combinations)

        logger.info(f"D√©marrage sweep parall√®le: {n_combos} combinaisons, {self._runner.max_workers} workers")

        if isinstance(strategy, str):
            strategy = self._get_strategy_by_name(strategy)

        # Utiliser le runner parall√®le
        parallel_result = self._runner.run_sweep(
            run_func=_run_single_backtest_wrapper,
            param_grid=combinations,
            df=df,
            strategy=strategy,
            initial_capital=self.initial_capital,
            silent_mode=silent_mode,
            fast_metrics=fast_metrics,
        )

        # Convertir les r√©sultats
        results: List[SweepResultItem] = []
        best_value = float("-inf") if not minimize else float("inf")
        best_params: Dict[str, Any] = {}
        best_metrics: PerformanceMetricsPct = {}

        for item in parallel_result.results:
            if item.get("success"):
                metrics = _normalize_metrics_pct(item["result"].get("metrics", {}))
                result_item = SweepResultItem(
                    params=item["result"]["params"],
                    metrics=metrics,
                    success=True,
                )
            else:
                result_item = SweepResultItem(
                    params=item["params"],
                    metrics={},
                    success=False,
                    error=item.get("error"),
                )

            results.append(result_item)

            if result_item.success and optimize_for in result_item.metrics:
                value = result_item.metrics[optimize_for]
                is_better = (
                    (not minimize and value > best_value) or
                    (minimize and value < best_value)
                )
                if is_better:
                    best_value = value
                    best_params = result_item.params.copy()
                    best_metrics = result_item.metrics.copy()

        total_time = time.time() - start_time

        sweep_results = SweepResults(
            items=results,
            best_params=best_params,
            best_metrics=best_metrics,
            total_time=total_time,
            n_completed=parallel_result.n_completed,
            n_failed=parallel_result.n_failed,
            resource_stats={
                "memory_peak_gb": parallel_result.memory_peak_gb,
                "avg_time_per_task": parallel_result.avg_time_per_task,
            }
        )

        # Sauvegarde automatique si activ√©e
        if self.auto_save:
            try:
                from backtest.storage import get_storage
                storage = get_storage()
                sweep_id = storage.save_sweep_results(sweep_results)
                logger.info(f"‚úÖ Sweep parall√®le sauvegard√©: {sweep_id}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Sauvegarde automatique √©chou√©e: {e}")

        return sweep_results

    def request_stop(self):
        """Demande l'arr√™t du sweep en cours."""
        self._stop_requested = True
        self._runner.request_stop()
        logger.info("Arr√™t du sweep demand√©")

    def is_stopped(self) -> bool:
        """V√©rifie si un arr√™t a √©t√© demand√©."""
        return self._stop_requested

    def _get_strategy_by_name(self, name: str) -> "StrategyBase":
        """R√©cup√®re une strat√©gie par son nom."""
        from strategies import get_strategy, list_strategies

        available = list_strategies()
        name_lower = name.lower().replace("-", "_").replace(" ", "_")

        if name_lower not in available:
            raise ValueError(f"Strat√©gie inconnue: {name}. Disponibles: {available}")

        return get_strategy(name_lower)()


# ======================== Fonctions utilitaires ========================

def quick_sweep(
    df: pd.DataFrame,
    strategy: Union["StrategyBase", str],
    param_grid: Dict[str, Any],
    optimize_for: str = "sharpe_ratio",
    max_workers: int = 4,
) -> SweepResults:
    """
    Fonction raccourcie pour un sweep rapide.

    Args:
        df: DataFrame OHLCV
        strategy: Strat√©gie √† tester
        param_grid: Grille de param√®tres
        optimize_for: M√©trique cible
        max_workers: Nombre de workers

    Returns:
        SweepResults

    Example:
        >>> results = quick_sweep(
        ...     df=data,
        ...     strategy="bollinger_atr",
        ...     param_grid={"entry_z": [1.5, 2.0, 2.5]},
        ... )
    """
    engine = SweepEngine(max_workers=max_workers)
    return engine.run_sweep(
        df=df,
        strategy=strategy,
        param_grid=param_grid,
        optimize_for=optimize_for,
        show_progress=True,
    )


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur grid search parall√©lis√©
# - Conventions g√©n√©ration/contraintes/tri explicit√©es
# - Read-if/Skip-if ajout√©s pour orienter le tri
```
<!-- MODULE-END: sweep.py -->

<!-- MODULE-START: validation.py -->
```json
{
  "name": "validation.py",
  "path": "backtest\\validation.py",
  "ext": ".py",
  "anchor": "validation_py"
}
```
## validation_py
*Chemin* : `backtest\validation.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest.validation

Purpose: Valider l'absence d'overfitting via walk-forward analysis avec fen√™tres glissantes train/test.

Role in pipeline: validation

Key components: ValidationFold, WalkForwardValidator, validate_combinatorial

Inputs: DataFrame OHLCV, n_folds (d√©faut 5), train_ratio (d√©faut 0.7)

Outputs: ValidationFold list, overfitting_ratio estim√©, m√©triques train vs test

Dependencies: numpy, pandas, utils.log

Conventions: Embargo temporel respect√©; fold_id 0-based; overfitting_ratio > 1.0 signale overfitting; fen√™tres non-chevauchantes.

Read-if: Int√©gration validation au pipeline, d√©tection overfitting, ou param√®tres de folds.

Skip-if: Vous n'utilisez pas la validation walk-forward.
"""

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class ValidationFold:
    """Repr√©sente un pli de validation."""

    fold_id: int
    train_start: int
    train_end: int
    test_start: int
    test_end: int

    # M√©triques calcul√©es apr√®s backtest
    train_metrics: Optional[Dict[str, Any]] = None
    test_metrics: Optional[Dict[str, Any]] = None

    @property
    def train_size(self) -> int:
        return self.train_end - self.train_start

    @property
    def test_size(self) -> int:
        return self.test_end - self.test_start

    @property
    def overfitting_ratio(self) -> Optional[float]:
        """
        Ratio d'overfitting: performance train vs test.
        > 1.0 = overfitting probable
        """
        if self.train_metrics is None or self.test_metrics is None:
            return None

        train_sharpe = self.train_metrics.get("sharpe_ratio", 0)
        test_sharpe = self.test_metrics.get("sharpe_ratio", 0)

        if test_sharpe == 0:
            return float('inf') if train_sharpe > 0 else 1.0

        return train_sharpe / test_sharpe


@dataclass
class WalkForwardResult:
    """R√©sultat complet d'une validation walk-forward."""

    folds: List[ValidationFold]
    total_train_samples: int
    total_test_samples: int
    embargo_samples: int

    # M√©triques agr√©g√©es
    avg_train_sharpe: float = 0.0
    avg_test_sharpe: float = 0.0
    avg_train_return: float = 0.0
    avg_test_return: float = 0.0
    avg_overfitting_ratio: float = 0.0

    # M√©triques robustes (nouvelles)
    robust_overfitting_ratio: float = 0.0
    degradation_pct: float = 0.0
    test_stability_std: float = 0.0
    n_valid_folds: int = 0

    # Stabilit√©
    sharpe_std: float = 0.0
    return_std: float = 0.0

    # Verdict
    is_robust: bool = False
    confidence_score: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "n_folds": len(self.folds),
            "total_train_samples": self.total_train_samples,
            "total_test_samples": self.total_test_samples,
            "embargo_samples": self.embargo_samples,
            "avg_train_sharpe": self.avg_train_sharpe,
            "avg_test_sharpe": self.avg_test_sharpe,
            "avg_train_return": self.avg_train_return,
            "avg_test_return": self.avg_test_return,
            "avg_overfitting_ratio": self.avg_overfitting_ratio,
            "robust_overfitting_ratio": self.robust_overfitting_ratio,
            "degradation_pct": self.degradation_pct,
            "test_stability_std": self.test_stability_std,
            "n_valid_folds": self.n_valid_folds,
            "sharpe_std": self.sharpe_std,
            "return_std": self.return_std,
            "is_robust": self.is_robust,
            "confidence_score": self.confidence_score,
            "folds": [
                {
                    "fold_id": f.fold_id,
                    "train_range": f"{f.train_start}-{f.train_end}",
                    "test_range": f"{f.test_start}-{f.test_end}",
                    "overfitting_ratio": f.overfitting_ratio,
                }
                for f in self.folds
            ],
        }


class WalkForwardValidator:
    """
    Validateur Walk-Forward pour d√©tecter l'overfitting.

    Divise les donn√©es en fen√™tres train/test glissantes avec:
    - Embargo temporel entre train et test (√©vite le leakage)
    - Purge des donn√©es trop proches du test

    Usage:
        validator = WalkForwardValidator(n_folds=5, test_pct=0.2)
        folds = validator.split(df)
        for fold in folds:
            # Optimiser sur train_data
            # Valider sur test_data
    """

    def __init__(
        self,
        n_folds: int = 5,
        test_pct: float = 0.2,
        embargo_pct: float = 0.01,
        purge_pct: float = 0.0,
        min_train_samples: int = 100,
        min_test_samples: int = 50,
        expanding: bool = False
    ):
        """
        Args:
            n_folds: Nombre de fen√™tres de validation
            test_pct: Pourcentage de donn√©es pour le test (par fold)
            embargo_pct: Embargo entre train et test (% du total)
            purge_pct: Purge avant le test (donn√©es exclues)
            min_train_samples: Minimum de samples pour le train
            min_test_samples: Minimum de samples pour le test (√©vite les indicateurs invalides)
            expanding: Si True, fen√™tre d'entra√Ænement qui grandit
        """
        self.n_folds = n_folds
        self.test_pct = test_pct
        self.embargo_pct = embargo_pct
        self.purge_pct = purge_pct
        self.min_train_samples = min_train_samples
        self.min_test_samples = min_test_samples
        self.expanding = expanding

        logger.info(
            f"WalkForwardValidator: {n_folds} folds, "
            f"test={test_pct:.0%}, embargo={embargo_pct:.1%}"
        )

    def split(self, data: pd.DataFrame) -> List[ValidationFold]:
        """
        G√©n√®re les indices des fen√™tres walk-forward.

        Args:
            data: DataFrame avec les donn√©es OHLCV

        Returns:
            Liste de ValidationFold avec les indices
        """
        n_samples = len(data)

        # Calculer les tailles
        embargo_size = max(1, int(n_samples * self.embargo_pct))
        purge_size = max(0, int(n_samples * self.purge_pct))
        test_size = max(10, int(n_samples * self.test_pct))

        # Espace disponible pour train + test par fold
        # Dans walk-forward, on avance progressivement
        fold_size = (n_samples - embargo_size) // self.n_folds

        folds = []

        for i in range(self.n_folds):
            if self.expanding:
                # Fen√™tre expandante: train grandit √† chaque fold
                train_start = 0
            else:
                # Fen√™tre roulante: train de taille fixe
                train_start = i * fold_size

            # Fin du train (avant embargo)
            train_end = (i + 1) * fold_size - embargo_size - purge_size

            # D√©but du test (apr√®s embargo)
            test_start = train_end + embargo_size + purge_size

            # Fin du test
            test_end = min(test_start + test_size, n_samples)

            # V√©rifications
            if train_end - train_start < self.min_train_samples:
                logger.warning(f"Fold {i}: train trop petit ({train_end - train_start} < {self.min_train_samples}), skip")
                continue

            if test_end - test_start < self.min_test_samples:
                logger.warning(f"Fold {i}: test trop petit ({test_end - test_start} < {self.min_test_samples}), skip")
                continue

            fold = ValidationFold(
                fold_id=i,
                train_start=train_start,
                train_end=train_end,
                test_start=test_start,
                test_end=test_end,
            )
            folds.append(fold)

        logger.info(f"Walk-forward: {len(folds)} folds g√©n√©r√©s")
        return folds

    def get_data_splits(
        self,
        data: pd.DataFrame,
        fold: ValidationFold
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Retourne les DataFrames train et test pour un fold.

        Args:
            data: DataFrame complet
            fold: ValidationFold avec les indices

        Returns:
            Tuple (train_df, test_df)
        """
        train_df = data.iloc[fold.train_start:fold.train_end].copy()
        test_df = data.iloc[fold.test_start:fold.test_end].copy()

        return train_df, test_df


class OverfittingDetector:
    """
    D√©tecte l'overfitting en comparant les performances train/test.

    M√©thodes:
    - Ratio Sharpe train/test
    - D√©gradation du return
    - Instabilit√© des param√®tres optimaux
    """

    def __init__(
        self,
        max_overfitting_ratio: float = 2.0,
        min_test_sharpe: float = 0.5,
        min_confidence: float = 0.6
    ):
        """
        Args:
            max_overfitting_ratio: Ratio max train/test accept√©
            min_test_sharpe: Sharpe minimum sur test
            min_confidence: Score de confiance minimum
        """
        self.max_overfitting_ratio = max_overfitting_ratio
        self.min_test_sharpe = min_test_sharpe
        self.min_confidence = min_confidence

    def analyze(self, result: WalkForwardResult) -> Dict[str, Any]:
        """
        Analyse compl√®te des r√©sultats walk-forward.

        Args:
            result: R√©sultats de validation walk-forward

        Returns:
            Dict avec diagnostic d'overfitting
        """
        diagnosis = {
            "overfitting_detected": False,
            "severity": "none",
            "reasons": [],
            "recommendations": [],
        }

        # V√©rifier ratio d'overfitting
        if result.avg_overfitting_ratio > self.max_overfitting_ratio:
            diagnosis["overfitting_detected"] = True
            diagnosis["reasons"].append(
                f"Ratio overfitting trop √©lev√©: {result.avg_overfitting_ratio:.2f} "
                f"(max: {self.max_overfitting_ratio})"
            )

        # V√©rifier performance sur test
        if result.avg_test_sharpe < self.min_test_sharpe:
            diagnosis["overfitting_detected"] = True
            diagnosis["reasons"].append(
                f"Sharpe test trop bas: {result.avg_test_sharpe:.2f} "
                f"(min: {self.min_test_sharpe})"
            )

        # V√©rifier stabilit√©
        if result.sharpe_std > abs(result.avg_test_sharpe):
            diagnosis["reasons"].append(
                f"Performance instable: std={result.sharpe_std:.2f} > mean={result.avg_test_sharpe:.2f}"
            )

        # V√©rifier confidence
        if result.confidence_score < self.min_confidence:
            diagnosis["overfitting_detected"] = True
            diagnosis["reasons"].append(
                f"Confiance insuffisante: {result.confidence_score:.1%} "
                f"(min: {self.min_confidence:.0%})"
            )

        # D√©terminer la s√©v√©rit√©
        if not diagnosis["overfitting_detected"]:
            diagnosis["severity"] = "none"
        elif result.avg_overfitting_ratio > 3.0 or result.avg_test_sharpe < 0:
            diagnosis["severity"] = "critical"
        elif result.avg_overfitting_ratio > 2.0:
            diagnosis["severity"] = "high"
        else:
            diagnosis["severity"] = "moderate"

        # Recommandations
        if diagnosis["overfitting_detected"]:
            diagnosis["recommendations"] = [
                "R√©duire le nombre de param√®tres optimis√©s",
                "Augmenter la p√©riode de test",
                "Utiliser des contraintes sur les param√®tres",
                "Essayer une granularit√© plus grossi√®re",
                "Ajouter de la r√©gularisation",
            ]

        return diagnosis


def compute_robust_overfitting_metrics(folds: List[ValidationFold]) -> Dict[str, float]:
    """
    Calcule des m√©triques robustes d'overfitting avec p√©nalit√© de stabilit√©.

    Am√©lioration par rapport au simple ratio train/test :
    - Prend en compte la variabilit√© des performances out-of-sample
    - Calcule la d√©gradation en pourcentage
    - P√©nalise l'instabilit√© des r√©sultats

    Args:
        folds: Liste des folds avec m√©triques train/test

    Returns:
        Dict avec m√©triques robustes
    """
    # Filtrer les folds valides
    valid_folds = [f for f in folds if f.train_metrics and f.test_metrics]

    if not valid_folds:
        return {
            "overfitting_ratio": 999.0,
            "robust_ratio": 999.0,
            "degradation_pct": 100.0,
            "test_stability_std": 0.0,
            "n_valid_folds": 0,
        }

    # Extraire les Sharpe ratios
    train_sharpes = [f.train_metrics.get("sharpe_ratio", 0) for f in valid_folds]
    test_sharpes = [f.test_metrics.get("sharpe_ratio", 0) for f in valid_folds]

    # Moyennes
    avg_train = np.mean(train_sharpes)
    avg_test = np.mean(test_sharpes)
    std_test = np.std(test_sharpes)

    # Ratio classique train/test
    if avg_test > 0:
        base_ratio = avg_train / avg_test
    else:
        base_ratio = 999.0

    # D√©gradation en pourcentage
    if avg_train > 0:
        degradation_pct = ((avg_train - avg_test) / avg_train) * 100
    else:
        degradation_pct = 100.0

    # P√©nalit√© pour instabilit√© (coefficient ajustable)
    # Plus l'√©cart-type est grand, plus le mod√®le est instable out-of-sample
    stability_penalty = std_test * 2.0

    # Ratio robuste = ratio classique + p√©nalit√© de stabilit√©
    robust_ratio = base_ratio + stability_penalty

    return {
        "overfitting_ratio": base_ratio,
        "robust_ratio": robust_ratio,
        "degradation_pct": max(0, degradation_pct),  # Pas de d√©gradation n√©gative
        "test_stability_std": std_test,
        "n_valid_folds": len(valid_folds),
    }


def calculate_walk_forward_metrics(folds: List[ValidationFold]) -> WalkForwardResult:
    """
    Calcule les m√©triques agr√©g√©es de la validation walk-forward.

    Args:
        folds: Liste des folds avec leurs m√©triques

    Returns:
        WalkForwardResult avec les m√©triques agr√©g√©es
    """
    valid_folds = [f for f in folds if f.train_metrics and f.test_metrics]

    if not valid_folds:
        return WalkForwardResult(
            folds=folds,
            total_train_samples=0,
            total_test_samples=0,
            embargo_samples=0,
        )

    # Extraire les m√©triques
    train_sharpes = [f.train_metrics.get("sharpe_ratio", 0) for f in valid_folds]
    test_sharpes = [f.test_metrics.get("sharpe_ratio", 0) for f in valid_folds]
    train_returns = [f.train_metrics.get("total_return_pct", 0) for f in valid_folds]
    test_returns = [f.test_metrics.get("total_return_pct", 0) for f in valid_folds]
    overfitting_ratios = [f.overfitting_ratio for f in valid_folds if f.overfitting_ratio]

    # Calculer les moyennes
    avg_train_sharpe = np.mean(train_sharpes)
    avg_test_sharpe = np.mean(test_sharpes)
    avg_train_return = np.mean(train_returns)
    avg_test_return = np.mean(test_returns)
    avg_overfitting = np.mean(overfitting_ratios) if overfitting_ratios else 1.0

    # Stabilit√©
    sharpe_std = np.std(test_sharpes)
    return_std = np.std(test_returns)

    # Score de confiance (0-1)
    # Bas√© sur: performance, stabilit√©, coh√©rence train/test
    confidence_factors = []

    # Performance test positive
    if avg_test_sharpe > 0:
        confidence_factors.append(min(avg_test_sharpe / 2, 1.0))
    else:
        confidence_factors.append(0)

    # Stabilit√©
    if sharpe_std > 0:
        stability = 1 / (1 + sharpe_std)
        confidence_factors.append(stability)

    # Coh√©rence train/test
    if avg_overfitting < 3:
        coherence = 1 - (avg_overfitting - 1) / 2
        confidence_factors.append(max(0, coherence))
    else:
        confidence_factors.append(0)

    confidence_score = np.mean(confidence_factors) if confidence_factors else 0

    # Verdict de robustesse
    is_robust = (
        avg_test_sharpe > 0.5 and
        avg_overfitting < 2.0 and
        confidence_score > 0.5
    )

    # Totaux
    total_train = sum(f.train_size for f in valid_folds)
    total_test = sum(f.test_size for f in valid_folds)
    embargo = valid_folds[0].test_start - valid_folds[0].train_end if valid_folds else 0

    # Calculer les m√©triques robustes d'overfitting
    robust_metrics = compute_robust_overfitting_metrics(folds)

    return WalkForwardResult(
        folds=folds,
        total_train_samples=total_train,
        total_test_samples=total_test,
        embargo_samples=embargo,
        avg_train_sharpe=avg_train_sharpe,
        avg_test_sharpe=avg_test_sharpe,
        avg_train_return=avg_train_return,
        avg_test_return=avg_test_return,
        avg_overfitting_ratio=avg_overfitting,
        robust_overfitting_ratio=robust_metrics["robust_ratio"],
        degradation_pct=robust_metrics["degradation_pct"],
        test_stability_std=robust_metrics["test_stability_std"],
        n_valid_folds=robust_metrics["n_valid_folds"],
        sharpe_std=sharpe_std,
        return_std=return_std,
        is_robust=is_robust,
        confidence_score=confidence_score,
    )


def train_test_split(
    data: pd.DataFrame,
    test_pct: float = 0.2,
    embargo_pct: float = 0.01
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Split simple train/test avec embargo temporel.

    L'embargo √©vite le data leakage entre train et test
    (important pour les donn√©es temporelles).

    Args:
        data: DataFrame complet
        test_pct: Pourcentage pour le test
        embargo_pct: Embargo entre train et test

    Returns:
        Tuple (train_df, test_df)
    """
    n = len(data)
    embargo_size = max(1, int(n * embargo_pct))
    test_size = max(10, int(n * test_pct))

    train_end = n - test_size - embargo_size
    test_start = train_end + embargo_size

    train_df = data.iloc[:train_end].copy()
    test_df = data.iloc[test_start:].copy()

    logger.info(
        f"Train/Test split: train={len(train_df)}, "
        f"embargo={embargo_size}, test={len(test_df)}"
    )

    return train_df, test_df


def format_validation_report(result: WalkForwardResult) -> str:
    """
    Formate un rapport de validation walk-forward.
    """
    verdict_emoji = "‚úÖ" if result.is_robust else "‚ùå"

    report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë            VALIDATION WALK-FORWARD                        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë VERDICT: {verdict_emoji} {"ROBUST" if result.is_robust else "OVERFITTING D√âTECT√â"}
‚ïë Confiance: {result.confidence_score:.1%}
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë CONFIGURATION                                             ‚ïë
‚ïë   Nombre de folds:     {len(result.folds):>10d}                      ‚ïë
‚ïë   Samples train:       {result.total_train_samples:>10d}                      ‚ïë
‚ïë   Samples test:        {result.total_test_samples:>10d}                      ‚ïë
‚ïë   Embargo:             {result.embargo_samples:>10d}                      ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë PERFORMANCES MOYENNES                                     ‚ïë
‚ïë   Sharpe Train:        {result.avg_train_sharpe:>10.3f}                      ‚ïë
‚ïë   Sharpe Test:         {result.avg_test_sharpe:>10.3f}                      ‚ïë
‚ïë   Return Train:        {result.avg_train_return:>10.2f}%                     ‚ïë
‚ïë   Return Test:         {result.avg_test_return:>10.2f}%                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë STABILIT√â & OVERFITTING                                   ‚ïë
‚ïë   Ratio Classique:     {result.avg_overfitting_ratio:>10.2f}x                     ‚ïë
‚ïë   Ratio Robuste:       {result.robust_overfitting_ratio:>10.2f}x (avec p√©nalit√©) ‚ïë
‚ïë   D√©gradation:         {result.degradation_pct:>10.1f}%                     ‚ïë
‚ïë   Std Test (stabilit√©):{result.test_stability_std:>10.3f}                      ‚ïë
‚ïë   Folds valides:       {result.n_valid_folds:>10d}                      ‚ïë
‚ïë   Std Sharpe:          {result.sharpe_std:>10.3f}                      ‚ïë
‚ïë   Std Return:          {result.return_std:>10.2f}%                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë CRIT√àRES RECOMMAND√âS                                      ‚ïë
‚ïë   ‚úì Ratio robuste < 1.8                                  ‚ïë
‚ïë   ‚úì D√©gradation < 40%                                    ‚ïë
‚ïë   ‚úì Std stabilit√© < 0.5                                  ‚ïë
‚ïë   ‚úì Folds valides >= 4                                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

    # D√©tail par fold
    if result.folds:
        report += "\nüìä D√âTAIL PAR FOLD:\n"
        for fold in result.folds:
            if fold.train_metrics and fold.test_metrics:
                train_s = fold.train_metrics.get("sharpe_ratio", 0)
                test_s = fold.test_metrics.get("sharpe_ratio", 0)
                ratio = fold.overfitting_ratio or 0
                status = "üü¢" if ratio < 2 else "üü°" if ratio < 3 else "üî¥"
                report += (
                    f"  {status} Fold {fold.fold_id}: "
                    f"Train={train_s:.2f} ‚Üí Test={test_s:.2f} "
                    f"(ratio: {ratio:.2f}x)\n"
                )

    return report


__all__ = [
    "ValidationFold",
    "WalkForwardResult",
    "WalkForwardValidator",
    "OverfittingDetector",
    "calculate_walk_forward_metrics",
    "train_test_split",
    "format_validation_report",
]


# Docstring update summary
# - Docstring de module normalis√©e (LLM-friendly) centr√©e sur validation/walk-forward
# - Conventions embargo/overfitting_ratio explicit√©es (ratio > 1.0 = risk)
# - Read-if/Skip-if ajout√©s pour tri rapide
```
<!-- MODULE-END: validation.py -->

<!-- MODULE-START: warmup.py -->
```json
{
  "name": "warmup.py",
  "path": "backtest\\warmup.py",
  "ext": ".py",
  "anchor": "warmup_py"
}
```
## warmup_py
*Chemin* : `backtest\warmup.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest/warmup

Purpose: Pr√©-compilation JIT Numba au d√©marrage pour √©liminer le co√ªt de compilation (170ms ‚Üí 8ms).

Role in pipeline: initialisation / performance

Key components: warmup_numba(), _warmup_complete flag

Inputs: Aucun (g√©n√®re des donn√©es synth√©tiques)

Outputs: Cache Numba pr√©-compil√© (~22x acc√©l√©ration des premiers backtests)

Dependencies: numpy, pandas, backtest.simulator_fast

Conventions: Appel√© une fois au d√©marrage de l'application (app.py ou __main__.py)

Read-if: Vous optimisez le temps de d√©marrage ou les performances de backtest.

Skip-if: Vous travaillez sur la logique m√©tier.

Performance:
- Sans warmup: Premier backtest = 170ms (compilation JIT)
- Avec warmup: Premier backtest = 8ms (cache utilis√©)
- Overhead warmup: ~200ms au d√©marrage (co√ªt unique)
- R√©sultat: 133 backtests/seconde apr√®s warmup
"""

import logging
import time
from typing import Tuple

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

# Flag pour √©viter double warmup
_warmup_complete = False
_warmup_time_ms = 0.0


def warmup_numba(silent: bool = True) -> Tuple[bool, float]:
    """
    Pr√©-compile les fonctions Numba JIT pour acc√©l√©rer les premiers backtests.

    Cette fonction ex√©cute un mini-backtest avec des donn√©es synth√©tiques
    pour forcer la compilation JIT de toutes les fonctions Numba critiques.

    Args:
        silent: Si True, supprime les logs (d√©faut). Si False, affiche les logs de timing.

    Returns:
        Tuple[bool, float]: (success, warmup_time_ms)
            - success: True si le warmup a r√©ussi
            - warmup_time_ms: Temps de warmup en millisecondes

    Notes:
        - Appel√© automatiquement au premier import si NUMBA_WARMUP_ON_IMPORT=1
        - Co√ªt unique d'environ 200ms au d√©marrage
        - Acc√©l√®re les backtests suivants de 22x (170ms ‚Üí 8ms)

    Example:
        >>> from backtest.warmup import warmup_numba
        >>> success, time_ms = warmup_numba()
        >>> print(f"Warmup en {time_ms:.0f}ms")
    """
    global _warmup_complete, _warmup_time_ms

    # √âviter double warmup
    if _warmup_complete:
        if not silent:
            logger.info(f"‚ö° Numba d√©j√† pr√©-compil√© ({_warmup_time_ms:.0f}ms)")
        return True, _warmup_time_ms

    start = time.perf_counter()

    try:
        # Import du simulateur fast (d√©clenche import Numba)
        from backtest.simulator_fast import simulate_trades_fast

        # G√©n√©rer des donn√©es synth√©tiques minimales (50 barres = rapide mais suffisant)
        n = 50
        np.random.seed(42)

        # Prix synth√©tique avec tendance
        prices = 100 + np.cumsum(np.random.randn(n) * 0.5)

        # DataFrame OHLCV minimal
        df = pd.DataFrame({
            'open': prices,
            'high': prices + np.abs(np.random.randn(n) * 0.3),
            'low': prices - np.abs(np.random.randn(n) * 0.3),
            'close': prices + np.random.randn(n) * 0.2,
            'volume': np.random.randint(1000, 10000, n),
        }, index=pd.date_range('2024-01-01', periods=n, freq='1h'))

        # Signaux synth√©tiques (quelques entr√©es/sorties)
        signals = pd.Series(0, index=df.index)
        signals.iloc[5] = 1   # Entr√©e long
        signals.iloc[15] = 0  # Sortie
        signals.iloc[25] = 1  # Entr√©e
        signals.iloc[40] = 0  # Sortie

        # Param√®tres minimaux
        params = {
            'initial_capital': 10000.0,
            'fees_bps': 10,
            'slippage_bps': 5,
            'k_sl': 2.0,
        }

        # Ex√©cuter un backtest rapide pour compiler Numba
        # Mode classique
        _ = simulate_trades_fast(
            df=df,
            signals=signals,
            params=params
        )

        # Mode bb_pos si disponible (colonnes optionnelles)
        try:
            df_bbpos = df.copy()
            df_bbpos['bb_pos_low'] = np.random.uniform(0, 1, n)
            df_bbpos['bb_pos_high'] = np.random.uniform(0, 1, n)
            df_bbpos['bb_lower'] = prices - 2
            df_bbpos['bb_upper'] = prices + 2

            params_bbpos = params.copy()
            params_bbpos['entry_level'] = 0.0
            params_bbpos['sl_level'] = -0.5
            params_bbpos['tp_level'] = 1.0

            _ = simulate_trades_fast(
                df=df_bbpos,
                signals=signals,
                params=params_bbpos
            )
        except Exception:
            pass  # Mode bb_pos optionnel

        elapsed_ms = (time.perf_counter() - start) * 1000
        _warmup_complete = True
        _warmup_time_ms = elapsed_ms

        if not silent:
            logger.info(f"‚ö° Numba JIT pr√©-compil√© en {elapsed_ms:.0f}ms (133 bt/s disponible)")

        return True, elapsed_ms

    except Exception as e:
        elapsed_ms = (time.perf_counter() - start) * 1000
        if not silent:
            logger.warning(f"‚ö†Ô∏è Warmup Numba √©chou√© apr√®s {elapsed_ms:.0f}ms: {e}")
        return False, elapsed_ms


def is_warmed_up() -> bool:
    """V√©rifie si Numba est d√©j√† pr√©-compil√©."""
    return _warmup_complete


def get_warmup_time() -> float:
    """Retourne le temps de warmup en ms (0 si pas encore fait)."""
    return _warmup_time_ms


def reset_warmup_flag():
    """Reset le flag de warmup (pour tests uniquement)."""
    global _warmup_complete, _warmup_time_ms
    _warmup_complete = False
    _warmup_time_ms = 0.0


# Auto-warmup au premier import si variable d'environnement d√©finie
# D√©sactiv√© par d√©faut pour √©viter surprises
import os
if os.environ.get('NUMBA_WARMUP_ON_IMPORT', '').lower() in ('1', 'true', 'yes'):
    warmup_numba(silent=True)
```
<!-- MODULE-END: warmup.py -->

<!-- MODULE-START: worker.py -->
```json
{
  "name": "worker.py",
  "path": "backtest\\worker.py",
  "ext": ".py",
  "anchor": "worker_py"
}
```
## worker_py
*Chemin* : `backtest\worker.py`  
*Type* : `.py`  

```python
"""
Module worker isol√© pour les backtests parall√®les.

Ce module est s√©par√© de l'UI Streamlit pour √©viter les probl√®mes de pickling
quand Streamlit recharge ses modules (hot-reload).

La fonction `run_backtest_worker` est stable et ne change pas de r√©f√©rence
pendant l'ex√©cution d'un sweep.
"""
from __future__ import annotations

import os
import traceback
from typing import Any, Dict, Tuple

# Ces imports sont faits au niveau du module pour √™tre disponibles dans les workers
try:
    from backtest.engine import BacktestEngine
except ImportError:
    BacktestEngine = None

# Variable globale pour le DataFrame (partag√©e entre tous les backtests d'un worker)
# Initialis√©e une seule fois par worker via init_worker_with_dataframe()
_worker_dataframe = None
_worker_strategy_key = None
_worker_symbol = None
_worker_timeframe = None
_worker_initial_capital = None
_worker_debug_enabled = False
_worker_fast_metrics = False
_worker_period_days = None
_worker_engine = None
_worker_indicator_cache = None  # Cache des indicateurs calcul√©s


def init_worker_with_dataframe(
    df_or_path,
    strategy_key: str,
    symbol: str,
    timeframe: str,
    initial_capital: float,
    debug_enabled: bool,
    thread_limit: int,
    fast_metrics: bool = False,
    is_path: bool = False,
):
    """
    Initializer pour ProcessPoolExecutor - charge le DataFrame une seule fois.

    Cette fonction est appel√©e une fois par worker au d√©marrage du pool.
    Le DataFrame est stock√© en variable globale pour √©viter la s√©rialisation pickle
    r√©p√©t√©e √† chaque soumission de t√¢che.

    IMPORTANT: Application ROBUSTE des limites de threads BLAS pour √©viter
    nested parallelism (8 workers √ó 16 threads BLAS = 128 threads ‚Üí surcharge CPU).
    La limitation est appliqu√©e PROGRAMMATIQUEMENT, pas seulement via env vars.

    Args:
        df_or_path: DataFrame OHLCV complet OU chemin vers fichier parquet (si is_path=True)
        strategy_key: Nom de la strat√©gie
        symbol: Symbole (ex: BTCUSDC)
        timeframe: Timeframe (ex: 1h)
        initial_capital: Capital initial
        debug_enabled: Activer logs de debug
        thread_limit: Limite de threads CPU (0 = auto-detect, recommand√©: 1)
        fast_metrics: Utiliser les m√©triques rapides pour les sweeps
        is_path: Si True, df_or_path est un chemin de fichier √† charger
    """
    global _worker_dataframe, _worker_strategy_key, _worker_symbol
    global _worker_timeframe, _worker_initial_capital, _worker_debug_enabled
    global _worker_fast_metrics, _worker_period_days, _worker_engine

    # Charger le DataFrame depuis le fichier ou utiliser celui fourni
    if is_path:
        import pandas as pd
        _worker_dataframe = pd.read_parquet(df_or_path)
    else:
        _worker_dataframe = df_or_path
    _worker_strategy_key = strategy_key
    _worker_symbol = symbol
    _worker_timeframe = timeframe
    _worker_initial_capital = initial_capital
    _worker_debug_enabled = debug_enabled
    _worker_fast_metrics = fast_metrics
    _worker_engine = None

    # R√©initialiser le cache d'indicateurs pour ce worker
    global _worker_indicator_cache
    _worker_indicator_cache = {}

    # Pr√©-calcul du nombre de jours (√©vite co√ªt r√©p√©t√©)
    _worker_period_days = None
    try:
        import pandas as pd
        start_day = pd.to_datetime(_worker_dataframe.index[0]).date()
        end_day = pd.to_datetime(_worker_dataframe.index[-1]).date()
        days = (end_day - start_day).days
        _worker_period_days = days if days > 0 else None
    except Exception:
        _worker_period_days = None

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # LIMITATION THREADS BLAS - APPLICATION PROGRAMMATIQUE ROBUSTE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # PROBL√àME: Sans limitation, NumPy/SciPy utilise tous les c≈ìurs par worker
    #   ‚Üí 8 workers √ó 16 threads BLAS = 128 threads ‚Üí surcharge CPU massive
    # SOLUTION: Forcer 1 thread BLAS par worker de mani√®re programmatique
    #   ‚Üí 8 workers √ó 1 thread BLAS = 8 threads ‚Üí charge CPU optimale
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # D√©terminer la limite effective (d√©faut: 1 thread si non sp√©cifi√©)
    effective_limit = thread_limit if thread_limit > 0 else 1

    # 1Ô∏è‚É£ Variables d'environnement (fallback pour biblioth√®ques qui ne supportent pas threadpoolctl)
    os.environ["BACKTEST_WORKER_THREADS"] = str(effective_limit)
    for var in (
        "OMP_NUM_THREADS",
        "MKL_NUM_THREADS",
        "OPENBLAS_NUM_THREADS",
        "NUMEXPR_NUM_THREADS",
        "VECLIB_MAXIMUM_THREADS",
        "BLIS_NUM_THREADS",
    ):
        os.environ[var] = str(effective_limit)

    # 2Ô∏è‚É£ threadpoolctl - APPLICATION PROGRAMMATIQUE (priorit√© haute)
    # C'est LA m√©thode robuste pour contr√¥ler BLAS m√™me sans env vars
    threadpoolctl_applied = False
    try:
        import threadpoolctl

        # Appliquer limite sur TOUS les thread pools (BLAS, OpenMP, TBB, etc.)
        threadpoolctl.threadpool_limits(limits=effective_limit)
        threadpoolctl_applied = True

        # V√©rification (optionnel en debug)
        if debug_enabled:
            info = threadpoolctl.threadpool_info()
            total_threads = sum(pool.get("num_threads", 0) for pool in info)
            import logging
            logger = logging.getLogger(__name__)
            logger.debug(
                "Worker thread limit applied: %d thread(s) across %d pool(s)",
                total_threads,
                len(info),
            )
    except ImportError:
        # threadpoolctl non install√© - fallback env vars uniquement
        if debug_enabled:
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(
                "threadpoolctl not available - using env vars only (less reliable)"
            )
    except Exception as e:
        if debug_enabled:
            import logging
            logger = logging.getLogger(__name__)
            logger.warning("threadpoolctl configuration failed: %s", e)

    # 3Ô∏è‚É£ PyTorch (si disponible)
    try:
        import torch
        torch.set_num_threads(effective_limit)
        torch.set_num_interop_threads(max(1, effective_limit // 2))
    except Exception:
        pass  # Torch non utilis√© ou indisponible

    # 4Ô∏è‚É£ V√©rification finale (optionnel - seulement en debug)
    if debug_enabled and not threadpoolctl_applied:
        import logging
        logger = logging.getLogger(__name__)
        logger.warning(
            "‚ö†Ô∏è Thread limiting applied via env vars only - "
            "consider installing threadpoolctl for robust control: "
            "pip install threadpoolctl"
        )


def run_backtest_worker(param_combo: Dict[str, Any]) -> Dict[str, Any]:
    """
    Worker function pour ProcessPoolExecutor - isol√© du hot-reload Streamlit.

    Cette fonction est d√©finie dans un module s√©par√© (backtest/worker.py) pour
    √©viter les erreurs de pickling quand Streamlit recharge ui/main.py.

    IMPORTANT: Le DataFrame et la configuration sont charg√©s depuis les variables
    globales initialis√©es par init_worker_with_dataframe(). Seul param_combo
    est pass√© en argument, ce qui √©vite la s√©rialisation pickle r√©p√©t√©e du DataFrame.

    Args:
        param_combo: Dictionnaire des param√®tres de la strat√©gie √† tester

    Returns:
        Dict avec r√©sultats du backtest ou erreur
    """
    # R√©cup√©rer les donn√©es depuis les variables globales du worker
    global _worker_engine

    df = _worker_dataframe
    strategy_key = _worker_strategy_key
    symbol = _worker_symbol
    timeframe = _worker_timeframe
    initial_capital = _worker_initial_capital
    debug_enabled = _worker_debug_enabled
    fast_metrics = _worker_fast_metrics

    # Validation
    if df is None:
        return {
            "params_dict": param_combo,
            "error": "Worker not initialized - DataFrame is None",
        }

    period_days = _worker_period_days

    try:
        if BacktestEngine is None:
            return {
                "params_dict": param_combo,
                "error": "BacktestEngine not available in worker",
            }

        # Cr√©er l'engine localement (pas picklable donc recr√©√© dans chaque process)
        # Note: Les limites de threads sont d√©j√† appliqu√©es par init_worker_with_dataframe()
        if _worker_engine is None:
            _worker_engine = BacktestEngine(initial_capital=initial_capital)
        engine = _worker_engine

        # Import local pour √©viter les d√©pendances circulaires
        from ui.helpers import safe_run_backtest

        # IMPORTANT: ordre des arguments = (engine, df, strategy, params, symbol, timeframe)
        result_i, msg_i = safe_run_backtest(
            engine,
            df,
            strategy_key,
            param_combo,
            symbol=symbol,
            timeframe=timeframe,
            silent_mode=True,
            fast_metrics=fast_metrics,
        )

        if result_i is None:
            return {
                "params_dict": param_combo,
                "error": msg_i or "Backtest failed",
            }

        # Extraire les m√©triques avec fallback robuste
        m = {}
        if hasattr(result_i, "metrics") and result_i.metrics:
            m = result_i.metrics
        elif isinstance(result_i, dict):
            m = result_i.get("metrics", result_i)

        total_trades = m.get("total_trades", 0)
        return {
            "params_dict": param_combo,
            "total_pnl": m.get("total_pnl", 0.0),
            "sharpe": m.get("sharpe_ratio", 0.0),
            "win_rate": m.get("win_rate_pct", m.get("win_rate", 0.0)),
            "max_dd": m.get("max_drawdown_pct", m.get("max_drawdown", 0.0)),
            "account_ruined": m.get("account_ruined", False),
            "min_equity": m.get("min_equity", 0.0),
            "total_trades": total_trades,
            "trades": total_trades,
            "profit_factor": m.get("profit_factor", 0.0),
            "liquidation_total_pnl": m.get("liquidation_total_pnl", m.get("total_pnl", 0.0)),
            "liquidation_total_return_pct": m.get("liquidation_total_return_pct", m.get("total_return_pct", 0.0)),
            "liquidation_sharpe_ratio": m.get("liquidation_sharpe_ratio", m.get("sharpe_ratio", 0.0)),
            "liquidation_max_drawdown_pct": m.get("liquidation_max_drawdown_pct", m.get("max_drawdown_pct", 0.0)),
            "liquidation_triggered": m.get("liquidation_triggered", False),
            "liquidation_time": m.get("liquidation_time"),
            "consecutive_losses_max": m.get("consecutive_losses_max", 0),
            "avg_win_loss_ratio": m.get("avg_win_loss_ratio", 0.0),
            "robustness_score": m.get("robustness_score", 0.0),
            "data_coverage_pct": m.get("data_coverage_pct"),
            "period_days": period_days,
        }

    except Exception as e:
        # Capturer toute erreur d'ex√©cution
        error_msg = str(e)
        if debug_enabled:
            import traceback
            error_msg = traceback.format_exc()
        return {
            "params_dict": param_combo,
            "error": error_msg,
        }
```
<!-- MODULE-END: worker.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "backtest\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `backtest\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: backtest

Purpose: Moteur de backtesting (pipeline complet + optimisation + validation) avec API stable pour UI/agents.

Role in pipeline: core / orchestration

Key components: BacktestEngine, RunResult, OptunaOptimizer, SweepEngine, WalkForwardValidator, BackendFacade

Inputs: Donn√©es OHLCV, strat√©gies, param√®tres, configurations

Outputs: R√©sultats de backtest structur√©s (trades, m√©triques, rapports)

Dependencies: Tous les modules backtest/*, strategies, indicators, data, utils, optionnel: optuna, tabulate

Conventions: Pipeline donn√©es‚Üíindicateurs‚Üísignaux‚Üítrades‚Üím√©triques; erreurs structur√©es; r√©ponses typ√©es.

Read-if: Vous importez le moteur depuis UI/agents ou modifiez l'architecture.

Skip-if: Vous travaillez sur une seule strat/indicateur.
"""

from .engine import BacktestEngine, RunResult
from .errors import (
    BackendInternalError,
    BacktestError,
    DataError,
    LLMUnavailableError,
    ParameterValidationError,
    StrategyNotFoundError,
    UserInputError,
)
from .facade import (
    BackendFacade,
    BackendResponse,
    BacktestRequest,
    ErrorCode,
    ErrorInfo,
    GridOptimizationRequest,
    GridOptimizationResponse,
    LLMOptimizationRequest,
    LLMOptimizationResponse,
    ResponseStatus,
    UIMetrics,
    UIPayload,
    get_facade,
    to_ui_payload,
)
from .performance import PerformanceCalculator, calculate_metrics
from .simulator import Trade, simulate_trades
from .storage import (
    ResultStorage,
    StoredResultMetadata,
    get_storage,
)

# Import conditionnel Optuna (peut ne pas √™tre install√©)
try:
    from .optuna_optimizer import (
        OPTUNA_AVAILABLE,
        MultiObjectiveResult,
        OptimizationResult,
        OptunaOptimizer,
        ParamSpec,
        quick_optimize,
        suggest_param_space,
    )
except ImportError:
    OPTUNA_AVAILABLE = False
    OptunaOptimizer = None
    ParamSpec = None
    OptimizationResult = None
    MultiObjectiveResult = None
    quick_optimize = None
    suggest_param_space = None

__all__ = [
    # Engine
    "BacktestEngine",
    "RunResult",
    # Performance
    "PerformanceCalculator",
    "calculate_metrics",
    # Simulator
    "simulate_trades",
    "Trade",
    # Errors
    "BacktestError",
    "UserInputError",
    "DataError",
    "BackendInternalError",
    "LLMUnavailableError",
    "StrategyNotFoundError",
    "ParameterValidationError",
    # Facade
    "BackendFacade",
    "BacktestRequest",
    "GridOptimizationRequest",
    "LLMOptimizationRequest",
    "BackendResponse",
    "GridOptimizationResponse",
    "LLMOptimizationResponse",
    "ResponseStatus",
    "ErrorCode",
    "UIMetrics",
    "UIPayload",
    "ErrorInfo",
    "get_facade",
    "to_ui_payload",
    # Storage
    "ResultStorage",
    "StoredResultMetadata",
    "get_storage",
    # Optuna (conditional)
    "OPTUNA_AVAILABLE",
    "OptunaOptimizer",
    "ParamSpec",
    "OptimizationResult",
    "MultiObjectiveResult",
    "quick_optimize",
    "suggest_param_space",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: commands.py -->
```json
{
  "name": "commands.py",
  "path": "cli\\commands.py",
  "ext": ".py",
  "anchor": "commands_py"
}
```
## commands_py
*Chemin* : `cli\commands.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.commands

Purpose: Impl√©mentation CLI commands - backtest, sweep, optuna, validate, export, visualize.

Role in pipeline: CLI interface

Key components: cmd_backtest(), cmd_sweep(), cmd_optuna(), Colors, normalize_metric_name(), METRIC_ALIASES

Inputs: argparse parsed args (strategy, data, params, etc.)

Outputs: Console output, JSON results, HTML/CSV exports, visualization

Dependencies: argparse, json, pathlib, pandas, numpy

Conventions: Metric aliases (sharpe ‚Üí sharpe_ratio); couleurs ANSI (d√©sactivable --no-color); progress bars.

Read-if: Ajout commande CLI ou modification format output.

Skip-if: Vous appelez cmd_backtest(args) depuis main.
"""

import json
import os
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd

# =============================================================================
# UTILITAIRES
# =============================================================================

# Syst√®me d'alias pour m√©triques CLI
METRIC_ALIASES = {
    "sharpe": "sharpe_ratio",
    "sortino": "sortino_ratio",
    "total_return": "total_return_pct",
    # Accepter aussi les formes compl√®tes
    "sharpe_ratio": "sharpe_ratio",
    "sortino_ratio": "sortino_ratio",
    "total_return_pct": "total_return_pct",
}


def normalize_metric_name(metric: str) -> str:
    """Normalise le nom d'une m√©trique CLI en nom interne."""
    return METRIC_ALIASES.get(metric, metric)


class Colors:
    """Codes couleurs ANSI pour le terminal."""
    RESET = "\033[0m"
    BOLD = "\033[1m"
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN = "\033[96m"

    @classmethod
    def disable(cls):
        """D√©sactive les couleurs."""
        cls.RESET = cls.BOLD = cls.RED = cls.GREEN = ""
        cls.YELLOW = cls.BLUE = cls.MAGENTA = cls.CYAN = ""


def print_header(text: str, char: str = "="):
    """Affiche un en-t√™te format√©."""
    print(f"\n{Colors.BOLD}{Colors.CYAN}{text}{Colors.RESET}")
    print(Colors.CYAN + char * len(text) + Colors.RESET)


def print_success(text: str):
    """Affiche un message de succ√®s."""
    print(f"{Colors.GREEN}‚úì{Colors.RESET} {text}")


def print_error(text: str):
    """Affiche un message d'erreur."""
    print(f"{Colors.RED}‚úó{Colors.RESET} {text}")


def print_warning(text: str):
    """Affiche un avertissement."""
    print(f"{Colors.YELLOW}‚ö†{Colors.RESET} {text}")


def print_info(text: str):
    """Affiche une information."""
    print(f"{Colors.BLUE}‚Ñπ{Colors.RESET} {text}")


def format_table(headers: List[str], rows: List[List[str]], padding: int = 2) -> str:
    """Formate une table en texte."""
    if not rows:
        return "  (aucune donn√©e)"

    # Calculer largeurs
    widths = [len(h) for h in headers]
    for row in rows:
        for i, cell in enumerate(row):
            if i < len(widths):
                widths[i] = max(widths[i], len(str(cell)))

    # Header
    lines = []
    header_line = "  ".join(h.ljust(widths[i]) for i, h in enumerate(headers))
    lines.append(f"  {Colors.BOLD}{header_line}{Colors.RESET}")
    lines.append("  " + "  ".join("-" * w for w in widths))

    # Rows
    for row in rows:
        row_line = "  ".join(str(cell).ljust(widths[i]) for i, cell in enumerate(row))
        lines.append(f"  {row_line}")

    return "\n".join(lines)


def format_bytes(bytes_count: float) -> str:
    """Formate un nombre de bytes en unit√© lisible."""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_count < 1024.0:
            return f"{bytes_count:.2f} {unit}"
        bytes_count /= 1024.0
    return f"{bytes_count:.2f} PB"


def _apply_date_filter(df: pd.DataFrame, start: str | None, end: str | None) -> pd.DataFrame:
    """Filtre un DataFrame OHLCV par date (UTC)."""
    if not start and not end:
        return df

    if start is not None:
        start_ts = pd.Timestamp(start, tz="UTC")
        df = df[df.index >= start_ts]
    if end is not None:
        end_ts = pd.Timestamp(end, tz="UTC")
        df = df[df.index <= end_ts]

    if df.empty:
        raise ValueError(f"Aucune donn√©e dans la p√©riode {start} - {end}")

    return df


# =============================================================================
# COMMANDE: LIST
# =============================================================================

def cmd_list(args) -> int:
    """Liste les ressources disponibles."""
    if args.no_color:
        Colors.disable()

    resource = args.resource

    if resource == "strategies":
        return _list_strategies(args)
    elif resource == "indicators":
        return _list_indicators(args)
    elif resource == "data":
        return _list_data(args)
    elif resource == "presets":
        return _list_presets(args)

    return 0


def cmd_indicators(args) -> int:
    """Alias: list indicators."""
    args.resource = "indicators"
    return cmd_list(args)


def _list_strategies(args) -> int:
    """Liste les strat√©gies."""
    from strategies import get_strategy, list_strategies

    strategies = list_strategies()

    if args.json:
        data = []
        for name in strategies:
            strat = get_strategy(name)
            if strat:
                instance = strat()
                data.append({
                    "name": name,
                    "description": getattr(instance, "description", ""),
                    "indicators": getattr(instance, "required_indicators", []),
                })
        print(json.dumps(data, indent=2))
        return 0

    print_header(f"Strat√©gies disponibles ({len(strategies)})")

    rows = []
    for name in sorted(strategies):
        strat = get_strategy(name)
        if strat:
            instance = strat()
            desc = getattr(instance, "description", "")[:50]
            indicators = ", ".join(instance.required_indicators[:3])
            if len(instance.required_indicators) > 3:
                indicators += "..."
            rows.append([name, desc, indicators])

    print(format_table(["Nom", "Description", "Indicateurs"], rows))
    return 0


def _list_indicators(args) -> int:
    """Liste les indicateurs."""
    from indicators.registry import get_indicator, list_indicators

    indicators = list_indicators()

    if args.json:
        data = []
        for name in indicators:
            info = get_indicator(name)
            if info:
                data.append({
                    "name": name,
                    "description": info.description,
                    "required_columns": list(info.required_columns),
                })
        print(json.dumps(data, indent=2))
        return 0

    print_header(f"Indicateurs disponibles ({len(indicators)})")

    rows = []
    for name in sorted(indicators):
        info = get_indicator(name)
        if info:
            cols = ", ".join(info.required_columns)
            desc = info.description[:40] if info.description else ""
            rows.append([name, cols, desc])

    print(format_table(["Nom", "Colonnes", "Description"], rows))
    return 0


def _list_data(args) -> int:
    """Liste les fichiers de donn√©es."""
    import os

    from data.loader import discover_available_data

    # R√©cup√©rer tokens et timeframes
    tokens, timeframes = discover_available_data()

    # Chercher les fichiers via variable d'environnement ou r√©pertoire par d√©faut
    env_data_dir = os.environ.get("BACKTEST_DATA_DIR")
    if env_data_dir:
        data_dir = Path(env_data_dir)
    else:
        data_dir = Path(__file__).parent.parent / "data" / "sample_data"

    data_files = []
    if data_dir.exists():
        # Format parquet uniquement (selon variable d'environnement)
        data_files.extend(data_dir.glob("*.parquet"))
        # Aussi chercher CSV et Feather comme fallback
        data_files.extend(data_dir.glob("*.csv"))
        data_files.extend(data_dir.glob("*.feather"))

    if args.json:
        print(json.dumps({
            "data_dir": str(data_dir),
            "tokens": tokens,
            "timeframes": timeframes,
            "files": [str(f) for f in data_files]
        }, indent=2))
        return 0

    print_header(f"Fichiers de donn√©es ({len(data_files)})")

    if env_data_dir:
        print_info(f"R√©pertoire: {data_dir} (via $BACKTEST_DATA_DIR)")
    else:
        print_info(f"R√©pertoire: {data_dir}")

    if not data_files:
        print_warning("Aucun fichier de donn√©es trouv√©")
        if not env_data_dir:
            print_info("D√©finissez $env:BACKTEST_DATA_DIR ou placez des fichiers .parquet dans data/sample_data/")
        return 0

    rows = []
    for f in sorted(data_files):
        path = Path(f)
        size = path.stat().st_size / 1024 if path.exists() else 0
        rows.append([path.name, f"{size:.1f} KB", path.suffix])

    print(format_table(["Fichier", "Taille", "Format"], rows))

    # Afficher aussi les tokens et timeframes
    if tokens:
        print(f"\n{Colors.BOLD}Tokens:{Colors.RESET} {', '.join(tokens)}")
    if timeframes:
        print(f"{Colors.BOLD}Timeframes:{Colors.RESET} {', '.join(timeframes)}")

    return 0


def _list_presets(args) -> int:
    """Liste les presets."""
    from utils.parameters import EMA_CROSS_PRESET, MINIMAL_PRESET, SAFE_RANGES_PRESET

    presets = [SAFE_RANGES_PRESET, MINIMAL_PRESET, EMA_CROSS_PRESET]

    if args.json:
        data = [p.to_dict() for p in presets]
        print(json.dumps(data, indent=2))
        return 0

    print_header(f"Presets disponibles ({len(presets)})")

    rows = []
    for p in presets:
        n_params = len(p.parameters)
        combos = p.estimate_combinations()
        rows.append([p.name, p.description[:40], str(n_params), f"~{combos:,}"])

    print(format_table(["Nom", "Description", "Params", "Combinaisons"], rows))
    return 0


# =============================================================================
# COMMANDE: INFO
# =============================================================================

def cmd_info(args) -> int:
    """Affiche les informations d√©taill√©es d'une ressource."""
    if args.no_color:
        Colors.disable()

    if args.resource_type == "strategy":
        return _info_strategy(args)
    elif args.resource_type == "indicator":
        return _info_indicator(args)

    return 0


def _info_strategy(args) -> int:
    """Affiche les infos d'une strat√©gie."""
    from strategies import get_strategy, list_strategies

    name = args.name.lower()
    strat_class = get_strategy(name)

    if not strat_class:
        print_error(f"Strat√©gie '{name}' non trouv√©e")
        print_info(f"Disponibles: {', '.join(list_strategies())}")
        return 1

    strat = strat_class()

    if getattr(args, "include_optional_params", False):
        strat._include_optional_params = True

    optional_skipped: List[str] = []
    if hasattr(strat, "parameter_specs") and strat.parameter_specs:
        optional_skipped = [
            name
            for name, spec in strat.parameter_specs.items()
            if not getattr(spec, "optimize", True)
        ]

    if optional_skipped and not getattr(strat, "_include_optional_params", False):
        if not args.quiet:
            skipped = ", ".join(optional_skipped)
            print_info(
                f"Param√®tres optionnels ignor√©s: {skipped} (ajoutez --include-optional-params ou BACKTEST_INCLUDE_OPTIONAL_PARAMS=1)"
            )

    if args.json:
        data = {
            "name": name,
            "description": getattr(strat, "description", ""),
            "required_indicators": strat.required_indicators,
            "default_params": strat.default_params,
            "param_ranges": strat.param_ranges,
        }
        print(json.dumps(data, indent=2))
        return 0

    print_header(f"Strat√©gie: {name}")
    print(f"  Description: {getattr(strat, 'description', 'N/A')}")
    print(f"  Indicateurs: {', '.join(strat.required_indicators)}")

    print(f"\n{Colors.BOLD}Param√®tres par d√©faut:{Colors.RESET}")
    for k, v in strat.default_params.items():
        print(f"    {k}: {v}")

    print(f"\n{Colors.BOLD}Plages d'optimisation:{Colors.RESET}")
    for k, (min_v, max_v) in strat.param_ranges.items():
        print(f"    {k}: [{min_v}, {max_v}]")

    return 0


def _info_indicator(args) -> int:
    """Affiche les infos d'un indicateur."""
    from indicators.registry import get_indicator, list_indicators

    name = args.name.lower()
    info = get_indicator(name)

    if not info:
        print_error(f"Indicateur '{name}' non trouv√©")
        print_info(f"Disponibles: {', '.join(list_indicators())}")
        return 1

    if args.json:
        data = {
            "name": info.name,
            "description": info.description,
            "required_columns": list(info.required_columns),
            "settings_class": info.settings_class.__name__ if info.settings_class else None,
        }
        print(json.dumps(data, indent=2))
        return 0

    print_header(f"Indicateur: {name}")
    print(f"  Description: {info.description}")
    print(f"  Colonnes requises: {', '.join(info.required_columns)}")

    if info.settings_class:
        print(f"\n{Colors.BOLD}Param√®tres (Settings):{Colors.RESET}")
        import inspect
        sig = inspect.signature(info.settings_class)
        for param_name, param in sig.parameters.items():
            if param_name != "self":
                default = param.default if param.default != inspect.Parameter.empty else "requis"
                print(f"    {param_name}: {default}")

    return 0


# =============================================================================
# COMMANDE: BACKTEST
# =============================================================================

def cmd_backtest(args) -> int:
    """Ex√©cute un backtest."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    import os
    from pathlib import Path

    from backtest.engine import BacktestEngine
    from strategies import get_strategy, list_strategies

    # Validation strat√©gie
    strategy_name = args.strategy.lower()
    strat_class = get_strategy(strategy_name)

    if not strat_class:
        print_error(f"Strat√©gie '{strategy_name}' non trouv√©e")
        print_info(f"Disponibles: {', '.join(list_strategies())}")
        return 1

    # Validation donn√©es - chercher dans BACKTEST_DATA_DIR si chemin relatif
    data_path = Path(args.data)
    if not data_path.exists():
        # Essayer avec le r√©pertoire de donn√©es
        env_data_dir = os.environ.get("BACKTEST_DATA_DIR")
        if env_data_dir:
            data_path = Path(env_data_dir) / args.data
        else:
            data_path = Path(__file__).parent.parent / "data" / "sample_data" / args.data

    if not data_path.exists():
        print_error(f"Fichier non trouv√©: {args.data}")
        print_info(f"R√©pertoire de recherche: {data_path.parent}")
        return 1

    # Parser param√®tres JSON
    try:
        params = json_module.loads(args.params)
    except json_module.JSONDecodeError as e:
        print_error(f"Param√®tres JSON invalides: {e}")
        return 1

    if not args.quiet:
        print_header("Backtest")
        print(f"  Strat√©gie: {strategy_name}")
        print(f"  Donn√©es: {data_path}")
        print(f"  Capital: {args.capital:,.0f}")
        print(f"  Frais: {args.fees_bps} bps ({args.fees_bps/100:.2f}%)")
        if params:
            print(f"  Param√®tres: {params}")
        print()

    # Chargement donn√©es
    if not args.quiet:
        print_info("Chargement des donn√©es...")

    # Utiliser les fonctions internes pour charger directement depuis le fichier
    from data.loader import _normalize_ohlcv, _read_file
    df = _read_file(data_path)
    df = _normalize_ohlcv(df)
    try:
        df = _apply_date_filter(df, args.start, args.end)
    except ValueError as e:
        print_error(str(e))
        return 1

    if not args.quiet:
        print_success(f"Donn√©es charg√©es: {len(df)} barres")

    # Ex√©cution backtest
    if not args.quiet:
        print_info("Ex√©cution du backtest...")

    # Cr√©er la configuration avec les frais
    from utils.config import Config
    config_kwargs = {"fees_bps": args.fees_bps}
    if args.slippage_bps is not None:
        config_kwargs["slippage_bps"] = args.slippage_bps
    config = Config(**config_kwargs)

    engine = BacktestEngine(
        initial_capital=args.capital,
        config=config,
    )

    # Extraire symbol et timeframe du nom de fichier (ex: BTCUSDC_1h.parquet)
    stem = data_path.stem
    parts = stem.split("_")
    symbol = args.symbol or (parts[0] if parts else "UNKNOWN")
    timeframe = args.timeframe or (parts[1] if len(parts) > 1 else "1h")

    result = engine.run(
        df=df,
        strategy=strategy_name,
        params=params,
        symbol=symbol,
        timeframe=timeframe
    )

    # Affichage r√©sultats
    if not args.quiet:
        print()
        print_header("R√©sultats")
        _print_metrics(result.metrics)
        if result.meta.get("period_start") and result.meta.get("period_end"):
            print(f"    Period: {result.meta['period_start']} -> {result.meta['period_end']}")
        print(f"\n  Trades: {len(result.trades)}")

    # Export si demand√©
    if args.output:
        output_path = Path(args.output)

        # G√©rer metrics qui peut √™tre un dict ou un objet avec to_dict()
        if hasattr(result.metrics, 'to_dict'):
            metrics_dict = result.metrics.to_dict()
        elif isinstance(result.metrics, dict):
            metrics_dict = result.metrics
        else:
            metrics_dict = vars(result.metrics)

        # G√©rer trades qui est un DataFrame
        if isinstance(result.trades, pd.DataFrame):
            trades_list = result.trades.to_dict('records')
        elif result.trades and len(result.trades) > 0:
            first_trade = result.trades[0]
            if hasattr(first_trade, 'to_dict'):
                trades_list = [t.to_dict() for t in result.trades]
            elif hasattr(first_trade, '__dict__'):
                trades_list = [vars(t) for t in result.trades]
            else:
                trades_list = list(result.trades)
        else:
            trades_list = []

        output_data = {
            "strategy": strategy_name,
            "params": params,
            "capital": args.capital,
            "fees_bps": args.fees_bps,
            "meta": result.meta,
            "metrics": metrics_dict,
            "n_trades": len(result.trades),
            "trades": trades_list,
        }

        if args.format == "json":
            with open(output_path, "w") as f:
                json_module.dump(output_data, f, indent=2, default=str)
        elif args.format == "csv":
            pd.DataFrame(result.trades).to_csv(output_path, index=False)
        elif args.format == "parquet":
            pd.DataFrame(result.trades).to_parquet(output_path)

        if not args.quiet:
            print_success(f"R√©sultats export√©s: {output_path}")

    return 0


def _print_metrics(metrics):
    """Affiche les m√©triques de performance."""
    m = metrics.to_dict() if hasattr(metrics, "to_dict") else metrics

    total_return_pct = m.get("total_return_pct")
    if total_return_pct is None:
        total_return_pct = m.get("total_return", 0) * 100
    max_drawdown_pct = m.get("max_drawdown", 0)
    win_rate_pct = m.get("win_rate", 0)

    print(f"  {Colors.BOLD}Performance:{Colors.RESET}")
    print(f"    Total Return: {total_return_pct:+.2f}%")
    print(f"    Sharpe Ratio: {m.get('sharpe_ratio', 0):.3f}")
    print(f"    Sortino Ratio: {m.get('sortino_ratio', 0):.3f}")
    print(f"    Max Drawdown: {max_drawdown_pct:.2f}%")
    print(f"    Win Rate: {win_rate_pct:.1f}%")
    print(f"    Profit Factor: {m.get('profit_factor', 0):.2f}")


# =============================================================================
# COMMANDE: SWEEP
# =============================================================================

def cmd_sweep(args) -> int:
    """Ex√©cute une optimisation param√©trique."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from pathlib import Path

    from backtest.engine import BacktestEngine
    from strategies import get_strategy
    from utils.parameters import ParameterSpec, compute_search_space_stats, generate_param_grid

    # Validation strat√©gie
    strategy_name = args.strategy.lower()
    strat_class = get_strategy(strategy_name)

    if not strat_class:
        print_error(f"Strat√©gie '{strategy_name}' non trouv√©e")
        return 1

    # R√©solution du chemin des donn√©es
    data_path = Path(args.data)
    if not data_path.exists():
        env_data_dir = os.environ.get("BACKTEST_DATA_DIR")
        if env_data_dir:
            data_path = Path(env_data_dir) / args.data
        else:
            data_path = Path(__file__).parent.parent / "data" / "sample_data" / args.data

    if not data_path.exists():
        print_error(f"Fichier non trouv√©: {args.data}")
        return 1

    strat = strat_class()

    if not args.quiet:
        print_header("Optimisation Param√©trique (Sweep)")
        print(f"  Strat√©gie: {strategy_name}")
        print(f"  Donn√©es: {data_path}")
        print(f"  Granularit√©: {args.granularity}")
        print(f"  M√©trique: {args.metric}")
        print(f"  Workers: {args.parallel}")
        print()

    # Construire les specs de param√®tres
    param_specs = {}
    for name, (min_v, max_v) in strat.param_ranges.items():
        default = strat.default_params.get(name, (min_v + max_v) / 2)
        param_type = "int" if isinstance(default, int) else "float"
        param_specs[name] = ParameterSpec(
            name=name,
            min_val=min_v,
            max_val=max_v,
            default=default,
            param_type=param_type,
        )

    # G√©n√©rer la grille
    try:
        grid = generate_param_grid(
            param_specs,
            granularity=args.granularity,
            max_total_combinations=args.max_combinations,
        )
    except ValueError as e:
        print_error(str(e))
        print_info("Augmentez --granularity ou --max-combinations")
        return 1

    # Afficher les statistiques d'espace de recherche (unifi√©)
    stats = compute_search_space_stats(param_specs, max_combinations=args.max_combinations, granularity=args.granularity)

    if not args.quiet:
        print_info(f"Espace de recherche: {stats.total_combinations:,} combinaisons")
        for pname, pcount in stats.per_param_counts.items():
            print(f"    {pname}: {pcount} valeurs")

    # Charger donn√©es avec les fonctions internes
    from data.loader import _normalize_ohlcv, _read_file
    df = _read_file(data_path)
    df = _normalize_ohlcv(df)
    try:
        df = _apply_date_filter(df, args.start, args.end)
    except ValueError as e:
        print_error(str(e))
        return 1

    if not args.quiet:
        print_success(f"Donn√©es charg√©es: {len(df)} barres")
        print_info("Lancement de l'optimisation...")
        print()

    # Extraire symbol et timeframe du nom de fichier
    stem = data_path.stem
    parts = stem.split("_")
    symbol = args.symbol or (parts[0] if parts else "UNKNOWN")
    timeframe = args.timeframe or (parts[1] if len(parts) > 1 else "1h")

    # Cr√©er la configuration avec les frais
    from utils.config import Config
    config_kwargs = {"fees_bps": args.fees_bps}
    if args.slippage_bps is not None:
        config_kwargs["slippage_bps"] = args.slippage_bps
    config = Config(**config_kwargs)

    # Ex√©cuter le sweep
    results = []

    for i, params in enumerate(grid):
        engine = BacktestEngine(
            initial_capital=args.capital,
            config=config,
        )

        try:
            result = engine.run(
                df=df,
                strategy=strategy_name,
                params=params,
                symbol=symbol,
                timeframe=timeframe
            )
            # G√©rer les m√©triques qui peuvent √™tre un dict ou un objet avec to_dict()
            if hasattr(result.metrics, 'to_dict'):
                metrics = result.metrics.to_dict()
            else:
                metrics = dict(result.metrics)

            # Normaliser le nom de la m√©trique
            metric_key = normalize_metric_name(args.metric)

            results.append({
                "params": params,
                "metrics": metrics,
                "score": metrics.get(metric_key, 0),
            })
        except Exception as e:
            if args.verbose:
                print_warning(f"Erreur avec {params}: {e}")

        # Progress
        if not args.quiet and (i + 1) % 10 == 0:
            print(f"\r  Progress: {i+1}/{len(grid)} ({100*(i+1)/len(grid):.1f}%)", end="", flush=True)

    if not args.quiet:
        print("\r" + " " * 50 + "\r", end="")

    # Trier par score (m√©trique d√©j√† normalis√©e)
    metric_key = normalize_metric_name(args.metric)
    reverse = args.metric != "max_drawdown"  # Plus bas = mieux pour drawdown

    results.sort(key=lambda x: x.get("score", 0), reverse=reverse)

    # Afficher les meilleurs
    if not args.quiet:
        print_header(f"Top {args.top} R√©sultats (tri par {args.metric})")

        for i, r in enumerate(results[:args.top]):
            print(f"\n  {Colors.BOLD}#{i+1}{Colors.RESET}")
            print(f"    Param√®tres: {r['params']}")
            print(f"    Sharpe: {r['metrics'].get('sharpe_ratio', 0):.3f}")
            print(f"    Return: {r['metrics'].get('total_return_pct', 0):+.2f}%")
            print(f"    Drawdown: {r['metrics'].get('max_drawdown', 0):.2f}%")

    # Export
    if args.output:
        output_path = Path(args.output)

        export_data = {
            "strategy": strategy_name,
            "granularity": args.granularity,
            "metric": args.metric,
            "n_combinations": len(grid),
            "results": results,
        }

        with open(output_path, "w") as f:
            json_module.dump(export_data, f, indent=2, default=str)

        if not args.quiet:
            print()
            print_success(f"R√©sultats export√©s: {output_path}")

    return 0


# =============================================================================
# COMMANDE: VALIDATE
# =============================================================================

def cmd_validate(args) -> int:
    """Valide la configuration."""
    if args.no_color:
        Colors.disable()

    print_header("Validation")

    errors = []
    warnings = []

    # Valider strat√©gies
    if args.all or args.strategy:
        from strategies import get_strategy, list_strategies

        strategies = [args.strategy] if args.strategy else list_strategies()

        print(f"\n{Colors.BOLD}Strat√©gies:{Colors.RESET}")
        for name in strategies:
            strat = get_strategy(name)
            if strat:
                try:
                    instance = strat()
                    # V√©rifier les attributs requis
                    _ = instance.required_indicators
                    _ = instance.default_params
                    _ = instance.param_ranges
                    print_success(f"  {name}")
                except Exception as e:
                    print_error(f"  {name}: {e}")
                    errors.append(f"Strat√©gie {name}: {e}")
            else:
                print_error(f"  {name}: non trouv√©e")
                errors.append(f"Strat√©gie {name} non trouv√©e")

    # Valider indicateurs
    if args.all:
        from indicators.registry import get_indicator, list_indicators

        print(f"\n{Colors.BOLD}Indicateurs:{Colors.RESET}")
        for name in list_indicators():
            info = get_indicator(name)
            if info and info.function:
                print_success(f"  {name}")
            else:
                print_error(f"  {name}: fonction manquante")
                errors.append(f"Indicateur {name}: fonction manquante")

    # Valider donn√©es
    if args.all or args.data:
        from pathlib import Path

        from data.loader import _normalize_ohlcv, _read_file

        print(f"\n{Colors.BOLD}Donn√©es:{Colors.RESET}")

        if args.data:
            data_files = [args.data]
        else:
            data_dir = Path("data/sample_data")
            data_files = list(data_dir.glob("*.parquet")) + list(data_dir.glob("*.csv"))

        for f in data_files:
            try:
                df = _read_file(Path(f))
                df = _normalize_ohlcv(df)
                required = ["open", "high", "low", "close", "volume"]
                missing = [c for c in required if c not in df.columns]
                if missing:
                    print_warning(f"  {f}: colonnes manquantes {missing}")
                    warnings.append(f"{f}: colonnes manquantes {missing}")
                else:
                    print_success(f"  {f} ({len(df)} barres)")
            except Exception as e:
                print_error(f"  {f}: {e}")
                errors.append(f"{f}: {e}")

    # R√©sum√©
    print()
    if errors:
        print_error(f"Validation √©chou√©e: {len(errors)} erreur(s)")
        return 1
    elif warnings:
        print_warning(f"Validation OK avec {len(warnings)} avertissement(s)")
        return 0
    else:
        print_success("Validation r√©ussie!")
        return 0


# =============================================================================
# COMMANDE: EXPORT
# =============================================================================

def cmd_export(args) -> int:
    """Exporte les r√©sultats."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from pathlib import Path

    input_path = Path(args.input)

    if not input_path.exists():
        print_error(f"Fichier non trouv√©: {input_path}")
        return 1

    # Charger les r√©sultats
    with open(input_path) as f:
        data = json_module.load(f)

    # D√©terminer le fichier de sortie
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = input_path.with_suffix(f".{args.format}")

    if args.format == "html":
        _export_html(data, output_path)
    elif args.format == "csv":
        _export_csv(data, output_path)
    elif args.format == "excel":
        _export_excel(data, output_path)
    else:
        print_error(f"Format non support√©: {args.format}")
        return 1

    print_success(f"Export r√©ussi: {output_path}")
    return 0


def _export_html(data: dict, output_path: Path):
    """Export en HTML."""
    html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Backtest Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1 {{ color: #333; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #4CAF50; color: white; }}
        tr:nth-child(even) {{ background-color: #f2f2f2; }}
        .metric {{ font-size: 1.2em; margin: 10px 0; }}
        .positive {{ color: green; }}
        .negative {{ color: red; }}
    </style>
</head>
<body>
    <h1>Rapport de Backtest</h1>
    <p>Strat√©gie: <strong>{data.get('strategy', 'N/A')}</strong></p>

    <h2>M√©triques</h2>
    <div class="metrics">
"""

    metrics = data.get("metrics", {})
    for key, value in metrics.items():
        if isinstance(value, float):
            css_class = "positive" if value > 0 else "negative"
            html += f'        <p class="metric">{key}: <span class="{css_class}">{value:.4f}</span></p>\n'

    html += """    </div>
</body>
</html>"""

    with open(output_path, "w") as f:
        f.write(html)


def _export_csv(data: dict, output_path: Path):
    """Export en CSV."""
    results = data.get("results", [])
    if results:
        rows = []
        for r in results:
            row = {**r.get("params", {}), **r.get("metrics", {})}
            rows.append(row)
        pd.DataFrame(rows).to_csv(output_path, index=False)
    else:
        # Single backtest
        metrics = data.get("metrics", {})
        pd.DataFrame([metrics]).to_csv(output_path, index=False)


def _export_excel(data: dict, output_path: Path):
    """Export en Excel."""
    try:
        import openpyxl  # noqa: F401
    except ImportError:
        raise ImportError("openpyxl requis pour export Excel: pip install openpyxl")

    results = data.get("results", [])
    if results:
        rows = []
        for r in results:
            row = {**r.get("params", {}), **r.get("metrics", {})}
            rows.append(row)
        pd.DataFrame(rows).to_excel(output_path, index=False)
    else:
        metrics = data.get("metrics", {})
        pd.DataFrame([metrics]).to_excel(output_path, index=False)


__all__ = [
    "cmd_list",
    "cmd_info",
    "cmd_backtest",
    "cmd_sweep",
    "cmd_validate",
    "cmd_export",
    "cmd_optuna",
    "cmd_visualize",
    "cmd_check_gpu",
    "cmd_llm_optimize",
    "cmd_grid_backtest",
    "cmd_analyze",
    "cmd_indicators",
]


# =============================================================================
# COMMANDE: OPTUNA
# =============================================================================

def cmd_optuna(args) -> int:
    """Ex√©cute une optimisation bay√©sienne via Optuna."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from pathlib import Path

    # V√©rifier que Optuna est disponible
    try:
        from backtest.optuna_optimizer import (
            OPTUNA_AVAILABLE,
            OptunaOptimizer,
            suggest_param_space,
        )
    except ImportError:
        print_error("Module optuna_optimizer non trouv√©")
        return 1

    if not OPTUNA_AVAILABLE:
        print_error("Optuna n'est pas install√©: pip install optuna")
        return 1

    from strategies import get_strategy, list_strategies

    # Validation strat√©gie
    strategy_name = args.strategy.lower()
    strat_class = get_strategy(strategy_name)

    if not strat_class:
        print_error(f"Strat√©gie '{strategy_name}' non trouv√©e")
        print_info(f"Strat√©gies disponibles: {', '.join(list_strategies())}")
        return 1

    # R√©solution du chemin des donn√©es
    data_path = Path(args.data)
    if not data_path.exists():
        env_data_dir = os.environ.get("BACKTEST_DATA_DIR")
        if env_data_dir:
            data_path = Path(env_data_dir) / args.data
        else:
            data_path = Path(__file__).parent.parent / "data" / "sample_data" / args.data

    if not data_path.exists():
        print_error(f"Fichier non trouv√©: {args.data}")
        return 1

    if not args.quiet:
        print_header("Optimisation Bay√©sienne (Optuna)")
        print(f"  Strat√©gie: {strategy_name}")
        print(f"  Donn√©es: {data_path}")
        print(f"  Trials: {args.n_trials}")
        print(f"  M√©trique: {args.metric}")
        print(f"  Sampler: {args.sampler}")
        if args.pruning:
            print(f"  Pruning: activ√© ({args.pruner})")
        if args.multi_objective:
            print("  Mode: Multi-objectif (Pareto)")
        print()

    # Charger donn√©es
    from data.loader import _normalize_ohlcv, _read_file
    df = _read_file(data_path)
    df = _normalize_ohlcv(df)
    try:
        df = _apply_date_filter(df, args.start, args.end)
    except ValueError as e:
        print_error(str(e))
        return 1

    if not args.quiet:
        print_success(f"Donn√©es charg√©es: {len(df)} barres")

    # Construire le param_space
    strat = strat_class()

    if args.param_space:
        # Param space personnalis√© via JSON
        try:
            param_space = json_module.loads(args.param_space)
        except json_module.JSONDecodeError as e:
            print_error(f"Erreur JSON param_space: {e}")
            return 1
    else:
        # Param space automatique depuis la strat√©gie
        param_space = suggest_param_space(strategy_name)

        # Enrichir avec les param_ranges de la strat√©gie si non couvert
        for name, (min_v, max_v) in strat.param_ranges.items():
            if name not in param_space:

                default = strat.default_params.get(name, (min_v + max_v) / 2)
                param_type = "int" if isinstance(default, int) else "float"
                param_space[name] = {
                    "type": param_type,
                    "low": min_v,
                    "high": max_v,
                }

    if not param_space:
        print_error(f"Aucun param_space d√©fini pour {strategy_name}")
        return 1

    # Contraintes
    constraints = []
    if args.constraints:
        for c in args.constraints:
            parts = c.split(",")
            if len(parts) == 3:
                constraints.append((parts[0], parts[1], parts[2]))

    # Extraire symbol et timeframe
    stem = data_path.stem
    parts = stem.split("_")
    symbol = args.symbol or (parts[0] if parts else "UNKNOWN")
    timeframe = args.timeframe or (parts[1] if len(parts) > 1 else "1h")

    # Cr√©er l'optimiseur
    from utils.config import Config
    config_kwargs = {"fees_bps": args.fees_bps}
    if args.slippage_bps is not None:
        config_kwargs["slippage_bps"] = args.slippage_bps
    config = Config(**config_kwargs)

    optimizer = OptunaOptimizer(
        strategy_name=strategy_name,
        data=df,
        param_space=param_space,
        constraints=constraints,
        initial_capital=args.capital,
        early_stop_patience=args.early_stop_patience,
        config=config,
        symbol=symbol,
        timeframe=timeframe,
        seed=args.seed,
    )

    if not args.quiet:
        print_info(f"Lancement optimisation ({args.n_trials} trials)...")
        if args.early_stop_patience:
            print_info(f"Early stopping activ√©: patience={args.early_stop_patience}")
        print()

    # Lancer l'optimisation
    try:
        if args.multi_objective:
            # Multi-objectif (Pareto)
            metrics = [normalize_metric_name(m.strip()) for m in args.metric.split(",")]
            directions = []
            for m in metrics:
                if m in ["max_drawdown"]:
                    directions.append("minimize")
                else:
                    directions.append("maximize")

            result = optimizer.optimize_multi_objective(
                n_trials=args.n_trials,
                metrics=metrics,
                directions=directions,
                timeout=args.timeout,
            )

            if not args.quiet:
                print_header("R√©sultats Multi-Objectif (Front de Pareto)")
                print(f"  Solutions Pareto: {len(result.pareto_front)}")
                print()

                for i, sol in enumerate(result.pareto_front[:args.top]):
                    print(f"  {Colors.BOLD}Solution #{i+1}{Colors.RESET}")
                    print(f"    Param√®tres: {sol['params']}")
                    print(f"    Valeurs: {sol['values']}")
                    print()
        else:
            # Mono-objectif (normaliser la m√©trique)
            metric_key = normalize_metric_name(args.metric)
            direction = "minimize" if args.metric == "max_drawdown" else "maximize"

            result = optimizer.optimize(
                n_trials=args.n_trials,
                metric=metric_key,
                direction=direction,
                sampler=args.sampler,
                pruner=args.pruner if args.pruning else "none",
                timeout=args.timeout,
                show_progress=not args.quiet,
            )

            if not args.quiet:
                print_header(f"R√©sultats Optuna (Top {args.top})")
                print(f"  Trials: {result.n_completed}/{args.n_trials} compl√©t√©s")
                print(f"  Pruned: {result.n_pruned}")
                print(f"  Temps total: {result.total_time:.1f}s")
                print()

                print(f"  {Colors.GREEN}Meilleur r√©sultat:{Colors.RESET}")
                print(f"    Param√®tres: {result.best_params}")
                print(f"    {args.metric}: {result.best_value:.4f}")
                if result.best_metrics:
                    print(f"    Sharpe: {result.best_metrics.get('sharpe_ratio', 'N/A'):.3f}")
                    print(f"    Return: {result.best_metrics.get('total_return_pct', 0):+.2f}%")
                    print(f"    Drawdown: {result.best_metrics.get('max_drawdown', 0)*100:.2f}%")
                print()

                # Top N
                top_df = result.get_top_n(args.top)
                if not top_df.empty and len(top_df) > 0:
                    print(f"  {Colors.BOLD}Top {min(args.top, len(top_df))} configurations:{Colors.RESET}")
                    # R√©cup√©rer les noms des param√®tres (excluant 'trial' et 'value')
                    param_cols = [c for c in top_df.columns if c not in ['trial', 'value']]
                    for idx, (_, row) in enumerate(top_df.head(args.top).iterrows()):
                        params = {col: row[col] for col in param_cols if col in row}
                        val = row.get('value', float('nan'))
                        val_str = f"{val:.4f}" if np.isfinite(val) else "N/A"
                        print(f"    #{idx+1}: {params} ‚Üí {val_str}")

    except Exception as e:
        print_error(f"Erreur lors de l'optimisation: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1

    # Export
    if args.output:
        output_path = Path(args.output)

        if args.multi_objective:
            export_data = {
                "strategy": strategy_name,
                "type": "multi_objective",
                "metrics": metrics,
                "n_trials": args.n_trials,
                "pareto_front": result.pareto_front,
            }
        else:
            export_data = {
                "strategy": strategy_name,
                "type": "single_objective",
                "metric": args.metric,
                "n_trials": args.n_trials,
                "n_completed": result.n_completed,
                "n_pruned": result.n_pruned,
                "total_time": result.total_time,
                "best_params": result.best_params,
                "best_value": result.best_value,
                "best_metrics": result.best_metrics,
                "history": result.history,
            }

        with open(output_path, "w") as f:
            json_module.dump(export_data, f, indent=2, default=str)

        if not args.quiet:
            print_success(f"R√©sultats export√©s: {output_path}")

    return 0


# =============================================================================
# COMMANDE: VISUALIZE
# =============================================================================

def cmd_visualize(args) -> int:
    """Visualise les r√©sultats d'un backtest avec graphiques interactifs."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from pathlib import Path

    try:
        from utils.visualization import (
            PLOTLY_AVAILABLE,
            visualize_backtest,
        )
    except ImportError as e:
        print_error(f"Module visualization non disponible: {e}")
        return 1

    if not PLOTLY_AVAILABLE:
        print_error("Plotly requis pour la visualisation: pip install plotly")
        return 1

    # Charger les r√©sultats
    input_path = Path(args.input)
    if not input_path.exists():
        print_error(f"Fichier non trouv√©: {input_path}")
        return 1

    if not args.quiet:
        print_header("Visualisation des R√©sultats")
        print_info(f"Fichier: {input_path}")

    # Charger les donn√©es OHLCV si fournies
    df = None
    data_path = None

    if args.data:
        data_path = Path(args.data)
        if not data_path.exists():
            # Chercher dans BACKTEST_DATA_DIR
            import os
            data_dir = os.environ.get("BACKTEST_DATA_DIR", "data/sample_data")
            alt_path = Path(data_dir) / args.data
            if alt_path.exists():
                data_path = alt_path
            else:
                print_warning(f"Fichier de donn√©es non trouv√©: {args.data}")
                data_path = None

    # Output path
    output_path = None
    if args.output:
        output_path = Path(args.output)
    elif args.html:
        output_path = input_path.with_suffix('.html')

    try:
        # Charger le fichier de r√©sultats
        with open(input_path) as f:
            results_data = json_module.load(f)

        # D√©terminer le type de r√©sultat
        result_type = results_data.get('type', 'backtest')

        if result_type == 'sweep':
            # R√©sultats de sweep - prendre le meilleur
            all_results = results_data.get('results', [])
            if not all_results:
                print_error("Aucun r√©sultat dans le sweep")
                return 1

            # Trier par m√©trique (sharpe par d√©faut)
            metric_key = args.metric or 'sharpe_ratio'
            sorted_results = sorted(
                all_results,
                key=lambda x: x.get('metrics', {}).get(metric_key, float('-inf')),
                reverse=True
            )
            best = sorted_results[0]

            trades = best.get('trades', [])
            metrics = best.get('metrics', {})
            params = best.get('params', {})
            equity_curve = best.get('equity_curve')
            strategy = results_data.get('strategy', 'Unknown')

            if not args.quiet:
                print_info(f"Meilleur r√©sultat (sur {len(all_results)}): {params}")
                print_info(f"{metric_key}: {metrics.get(metric_key, 'N/A'):.4f}")

        elif result_type in ('single_objective', 'multi_objective'):
            # R√©sultats Optuna
            trades = results_data.get('trades', [])
            metrics = results_data.get('best_metrics', {})
            params = results_data.get('best_params', {})
            equity_curve = results_data.get('equity_curve')
            strategy = results_data.get('strategy', 'Unknown')

            if not trades:
                print_warning("Pas de trades dans les r√©sultats Optuna")
                print_info(f"Meilleurs params: {params}")
                print_info(f"Meilleure valeur: {results_data.get('best_value', 'N/A')}")

                # Relancer un backtest avec les meilleurs params pour avoir les trades
                if args.data and data_path:
                    if not args.quiet:
                        print_info("Ex√©cution du backtest avec les meilleurs param√®tres...")

                    from backtest import BacktestEngine
                    from data.loader import _normalize_ohlcv, _read_file
                    from utils.config import Config

                    df = _read_file(data_path)
                    df = _normalize_ohlcv(df)

                    config = Config(fees_bps=args.fees_bps)
                    engine = BacktestEngine(
                        initial_capital=args.capital or 10000,
                        config=config,
                    )

                    stem = data_path.stem
                    parts = stem.split("_")
                    symbol = parts[0] if parts else "UNKNOWN"
                    timeframe = parts[1] if len(parts) > 1 else "1m"

                    result = engine.run(
                        df=df,
                        strategy=strategy,
                        params=params,
                        symbol=symbol,
                        timeframe=timeframe,
                    )
                    if isinstance(result.trades, pd.DataFrame):
                        trades = result.trades.to_dict("records")
                    else:
                        trades = (
                            [t.__dict__ for t in result.trades]
                            if hasattr(result, "trades")
                            else []
                        )
                    if hasattr(result.metrics, "to_dict"):
                        metrics = result.metrics.to_dict()
                    elif isinstance(result.metrics, dict):
                        metrics = result.metrics
                    else:
                        metrics = vars(result.metrics)
                    equity_curve = result.equity.tolist() if hasattr(result, "equity") else None

        else:
            # Backtest simple
            trades = results_data.get('trades', [])
            metrics = results_data.get('metrics', {})
            params = results_data.get('params', {})
            equity_curve = results_data.get('equity_curve')
            strategy = results_data.get('strategy', 'Unknown')

        if not trades and not equity_curve:
            print_error("Aucun trade ou equity curve √† visualiser")
            print_info("Assurez-vous que le fichier contient des donn√©es de trades")
            return 1

        # Charger les donn√©es OHLCV
        if data_path and data_path.exists():
            # Charger directement depuis le fichier
            if data_path.suffix == '.parquet':
                df = pd.read_parquet(data_path)
            elif data_path.suffix == '.csv':
                df = pd.read_csv(data_path)
            elif data_path.suffix == '.json':
                df = pd.read_json(data_path)
            else:
                print_warning(f"Format non support√©: {data_path.suffix}")
                df = None

            if df is not None:
                # Normaliser les colonnes
                df.columns = df.columns.str.lower()
                if 'timestamp' in df.columns:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                    df.set_index('timestamp', inplace=True)
                elif 'time' in df.columns:
                    df['time'] = pd.to_datetime(df['time'])
                    df.set_index('time', inplace=True)
                elif not isinstance(df.index, pd.DatetimeIndex):
                    df.index = pd.to_datetime(df.index)

                # Supprimer timezone pour √©viter les probl√®mes de comparaison
                if hasattr(df.index, 'tz') and df.index.tz is not None:
                    df.index = df.index.tz_localize(None)

                if not args.quiet:
                    print_info(f"Donn√©es OHLCV charg√©es: {len(df)} barres")

        # Pr√©parer le titre
        title = f"Backtest - {strategy}"
        if params:
            params_str = ", ".join(f"{k}={v}" for k, v in list(params.items())[:4])
            title += f"\n({params_str})"

        # Visualisation
        if df is not None:
            visualize_backtest(
                df=df,
                trades=trades,
                metrics=metrics,
                equity_curve=equity_curve,
                title=title,
                output_path=output_path,
                show=not args.no_show,
            )
        else:
            # Pas de donn√©es OHLCV - afficher seulement equity curve
            if equity_curve:
                from utils.visualization import plot_equity_curve
                fig = plot_equity_curve(
                    equity_curve,
                    initial_capital=metrics.get('initial_capital', 10000),
                    title=title,
                )
                if not args.no_show:
                    fig.show()

                if output_path:
                    fig.write_html(str(output_path))
                    print_success(f"Graphique sauvegard√©: {output_path}")
            else:
                print_error("Pas de donn√©es suffisantes pour visualiser")
                return 1

        # Stats finales
        if not args.quiet:
            print()
            print_header("M√©triques Cl√©s", "-")
            pnl = metrics.get('pnl', metrics.get('total_pnl', 0))
            sharpe = metrics.get('sharpe_ratio', 0)
            max_dd = metrics.get('max_drawdown', 0)
            win_rate = metrics.get('win_rate', 0)

            pnl_color = Colors.GREEN if pnl >= 0 else Colors.RED
            print(f"  PnL:          {pnl_color}{pnl:+,.2f}{Colors.RESET}")
            print(f"  Sharpe:       {sharpe:.2f}")
            print(f"  Max DD:       {Colors.RED}{max_dd:.1f}%{Colors.RESET}")
            print(f"  Win Rate:     {win_rate*100:.1f}%")
            print(f"  Trades:       {len(trades)}")

        if output_path:
            print_success(f"Rapport HTML: {output_path}")

        return 0

    except Exception as e:
        print_error(f"Erreur lors de la visualisation: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


# =============================================================================
# COMMANDE: CHECK-GPU
# =============================================================================

def cmd_check_gpu(args) -> int:
    """Diagnostic GPU : CuPy, CUDA, GPUs disponibles et benchmark."""
    if args.no_color:
        Colors.disable()

    import time

    print_header("Diagnostic GPU", "=")

    # 1. CuPy detection
    try:
        import cupy as cp
        cupy_version = cp.__version__
        print_success(f"CuPy install√©: version {cupy_version}")
    except ImportError:
        print_error("CuPy non install√©")
        print_info("  Installation: pip install cupy-cuda12x")
        return 1
    except Exception as e:
        print_error(f"Erreur import CuPy: {e}")
        return 1

    # 2. CUDA version
    try:
        cuda_version = cp.cuda.runtime.runtimeGetVersion()
        cuda_major = cuda_version // 1000
        cuda_minor = (cuda_version % 1000) // 10
        print_success(f"CUDA Runtime: {cuda_major}.{cuda_minor}")
    except Exception as e:
        print_warning(f"Impossible de r√©cup√©rer version CUDA: {e}")

    # 3. GPUs d√©tect√©s
    try:
        device_count = cp.cuda.runtime.getDeviceCount()
        print_success(f"GPU(s) d√©tect√©(s): {device_count}")
        print()

        if device_count == 0:
            print_warning("Aucun GPU d√©tect√©")
            return 1

        # D√©tails de chaque GPU
        print_header("D√©tails des GPUs", "-")
        for device_id in range(device_count):
            props = cp.cuda.runtime.getDeviceProperties(device_id)

            # Nom du GPU
            name = props["name"]
            if isinstance(name, bytes):
                name = name.decode()

            # M√©moire
            with cp.cuda.Device(device_id):
                mem_info = cp.cuda.runtime.memGetInfo()
                free_mem = mem_info[0]
                total_mem = mem_info[1]
                used_mem = total_mem - free_mem

            # Compute capability
            compute_cap = f"{props['major']}.{props['minor']}"

            # Affichage
            print(f"\n  {Colors.BOLD}GPU {device_id}: {name}{Colors.RESET}")
            print(f"    Compute Capability:  {compute_cap}")
            print(f"    VRAM Totale:         {format_bytes(total_mem)}")
            print(f"    VRAM Libre:          {format_bytes(free_mem)} ({100*free_mem/total_mem:.1f}%)")
            print(f"    VRAM Utilis√©e:       {format_bytes(used_mem)} ({100*used_mem/total_mem:.1f}%)")

            if not args.quiet:
                print(f"    Multiprocesseurs:    {props.get('multiProcessorCount', 'N/A')}")
                print(f"    Max Threads/Block:   {props.get('maxThreadsPerBlock', 'N/A')}")
                print(f"    Warp Size:           {props.get('warpSize', 'N/A')}")

    except Exception as e:
        print_error(f"Erreur d√©tection GPU: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1

    # 4. Benchmark CPU vs GPU (si --benchmark)
    if args.benchmark:
        print()
        print_header("Benchmark CPU vs GPU (EMA 10k points)", "-")

        try:
            # Donn√©es de test
            n_samples = 10000
            np.random.seed(42)
            prices_np = 100 + np.cumsum(np.random.randn(n_samples) * 0.5)

            # Fonction EMA simple (pour test)
            def ema_cpu(prices, period=20):
                """EMA sur CPU (NumPy)."""
                alpha = 2.0 / (period + 1)
                ema = np.zeros(len(prices))
                ema[0] = prices[0]
                for i in range(1, len(prices)):
                    ema[i] = alpha * prices[i] + (1 - alpha) * ema[i-1]
                return ema

            def ema_gpu(prices, period=20):
                """EMA sur GPU (CuPy)."""
                alpha = 2.0 / (period + 1)
                prices_gpu = cp.asarray(prices)
                ema = cp.zeros(len(prices_gpu))
                ema[0] = prices_gpu[0]
                for i in range(1, len(prices_gpu)):
                    ema[i] = alpha * prices_gpu[i] + (1 - alpha) * ema[i-1]
                cp.cuda.Device().synchronize()
                return cp.asnumpy(ema)

            # Benchmark CPU
            n_runs = 5
            cpu_times = []
            for _ in range(n_runs):
                start = time.time()
                _ = ema_cpu(prices_np, period=20)
                cpu_times.append(time.time() - start)

            cpu_avg = np.mean(cpu_times) * 1000  # en ms

            # Benchmark GPU (avec warmup)
            _ = ema_gpu(prices_np[:100], period=20)  # warmup

            gpu_times = []
            for _ in range(n_runs):
                start = time.time()
                _ = ema_gpu(prices_np, period=20)
                gpu_times.append(time.time() - start)

            gpu_avg = np.mean(gpu_times) * 1000  # en ms

            # Speedup
            speedup = cpu_avg / gpu_avg if gpu_avg > 0 else 0

            # Affichage
            print(f"\n  {Colors.BOLD}R√©sultats:{Colors.RESET}")
            print(f"    Dataset:        {n_samples:,} points")
            print(f"    Runs:           {n_runs}")
            print(f"    CPU (NumPy):    {cpu_avg:.2f} ms")
            print(f"    GPU (CuPy):     {gpu_avg:.2f} ms")

            if speedup > 1:
                print(f"    Speedup:        {Colors.GREEN}{speedup:.2f}x{Colors.RESET}")
            elif speedup < 1 and speedup > 0:
                print(f"    Speedup:        {Colors.YELLOW}{speedup:.2f}x{Colors.RESET} (GPU plus lent)")
            else:
                print(f"    Speedup:        {Colors.RED}N/A{Colors.RESET}")

            print()
            if speedup > 1:
                print_success("GPU est plus rapide que CPU !")
            elif speedup < 1 and speedup > 0.5:
                print_warning("GPU l√©g√®rement plus lent (overhead transfert)")
            elif speedup < 0.5:
                print_warning("GPU significativement plus lent (dataset trop petit ?)")

        except Exception as e:
            print_error(f"Erreur benchmark: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()

    # 5. Recommandations
    if not args.quiet:
        print()
        print_header("Recommandations", "-")
        print("  ‚Ä¢ Utiliser GPU pour datasets > 5000 points")
        print("  ‚Ä¢ Activer GPU dans indicateurs: voir RAPPORT_ANALYSE_GPU_CPU.md")
        print("  ‚Ä¢ Variable d'environnement: BACKTEST_GPU_ID=0 (forcer GPU 0)")
        print("  ‚Ä¢ Variable d'environnement: CUDA_VISIBLE_DEVICES=0 (limiter √† GPU 0)")

    print()
    print_success("Diagnostic GPU termin√©")
    return 0


# =============================================================================
# COMMANDE: LLM-OPTIMIZE
# =============================================================================

def cmd_llm_optimize(args) -> int:
    """Lance une optimisation LLM avec orchestrateur multi-agents."""
    if args.no_color:
        Colors.disable()

    from pathlib import Path

    from agents.integration import create_orchestrator_with_backtest
    from agents.llm_client import LLMConfig, LLMProvider
    from data.loader import load_ohlcv
    from strategies import get_strategy

    if not args.quiet:
        print_header("Optimisation LLM Multi-Agents")
        print(f"  Strat√©gie: {args.strategy}")
        print(f"  Symbole: {args.symbol}")
        print(f"  Timeframe: {args.timeframe}")
        print(f"  P√©riode: {args.start} ‚Üí {args.end}")
        print(f"  Capital: {args.capital:,.0f}")
        print(f"  Mod√®le LLM: {args.model}")
        print(f"  Max it√©rations: {args.max_iterations}")
        print()

    # Charger les donn√©es
    if not args.quiet:
        print_info("Chargement des donn√©es...")

    try:
        df = load_ohlcv(
            symbol=args.symbol,
            timeframe=args.timeframe,
            start=args.start,
            end=args.end
        )
    except Exception as e:
        print_error(f"Erreur chargement donn√©es: {e}")
        return 1

    if not args.quiet:
        print_success(f"Donn√©es charg√©es: {len(df)} barres")
        print(f"   P√©riode r√©elle: {df.index[0]} ‚Üí {df.index[-1]}")
        print()

    # Configuration LLM
    llm_config = LLMConfig(
        provider=LLMProvider.OLLAMA,
        model=args.model,
        temperature=args.temperature,
        max_tokens=args.max_tokens,
        timeout_seconds=args.timeout,
    )

    # R√©cup√©rer les param√®tres par d√©faut de la strat√©gie
    if not args.quiet:
        print_info("R√©cup√©ration des param√®tres par d√©faut...")

    strategy_class = get_strategy(args.strategy)
    if not strategy_class:
        print_error(f"Strat√©gie '{args.strategy}' non trouv√©e")
        return 1

    strategy_instance = strategy_class()
    initial_params = strategy_instance.default_params

    if not args.quiet:
        print_success(f"Param√®tres initiaux: {list(initial_params.keys())}")
        print()

    # Cr√©er l'orchestrateur
    if not args.quiet:
        print_info("Cr√©ation de l'orchestrateur multi-agents...")

    try:
        orchestrator = create_orchestrator_with_backtest(
            strategy_name=args.strategy,
            data=df,
            data_symbol=args.symbol,
            data_timeframe=args.timeframe,
            initial_params=initial_params,
            llm_config=llm_config,
            initial_capital=args.capital,
            max_iterations=args.max_iterations,
            min_sharpe=args.min_sharpe,
            max_drawdown_limit=args.max_drawdown,
        )
    except Exception as e:
        print_error(f"Erreur cr√©ation orchestrateur: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1

    if not args.quiet:
        print_success("Orchestrateur cr√©√©")
        print()
        print_header("Lancement de l'optimisation", "-")

    # Lancer l'optimisation
    try:
        result = orchestrator.run()
    except Exception as e:
        print_error(f"Erreur durant l'optimisation: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1

    # Afficher les r√©sultats
    if not args.quiet:
        print()
        print_header("R√©sultats Finaux")

        if result.decision == "APPROVED":
            print_success(f"D√©cision: {result.decision}")
        elif result.decision == "REJECTED":
            print_warning(f"D√©cision: {result.decision}")
        else:
            print_error(f"D√©cision: {result.decision}")

        if result.final_params:
            print(f"\n{Colors.BOLD}Param√®tres finaux:{Colors.RESET}")
            for k, v in result.final_params.items():
                print(f"    {k}: {v}")

        if result.final_metrics:
            print(f"\n{Colors.BOLD}M√©triques finales:{Colors.RESET}")
            _print_metrics(result.final_metrics)

        print(f"\n  It√©rations: {result.iterations}")

        if result.reason:
            print(f"\n  Raison: {result.reason}")

    # Export si demand√©
    if args.output:
        output_path = Path(args.output)

        import json as json_module

        export_data = {
            "strategy": args.strategy,
            "symbol": args.symbol,
            "timeframe": args.timeframe,
            "period": {"start": args.start, "end": args.end},
            "model": args.model,
            "max_iterations": args.max_iterations,
            "decision": result.decision,
            "iterations": result.iterations,
            "final_params": result.final_params,
            "final_metrics": result.final_metrics,
            "reason": result.reason,
            "history": result.history if hasattr(result, 'history') else None,
        }

        with open(output_path, "w") as f:
            json_module.dump(export_data, f, indent=2, default=str)

        if not args.quiet:
            print()
            print_success(f"R√©sultats export√©s: {output_path}")

    return 0


# =============================================================================
# COMMANDE: GRID-BACKTEST
# =============================================================================

def cmd_grid_backtest(args) -> int:
    """Ex√©cute un backtest en mode grille de param√®tres."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from itertools import product
    from pathlib import Path

    from backtest.engine import BacktestEngine
    from data.loader import load_ohlcv
    from strategies import get_strategy
    from utils.config import Config

    if not args.quiet:
        print_header("Backtest Mode Grille")
        print(f"  Strat√©gie: {args.strategy}")
        print(f"  Symbole: {args.symbol}")
        print(f"  Timeframe: {args.timeframe}")
        print(f"  P√©riode: {args.start} ‚Üí {args.end}")
        print(f"  Capital: {args.capital:,.0f}")
        print()

    # Charger les donn√©es
    if not args.quiet:
        print_info("Chargement des donn√©es...")

    try:
        df = load_ohlcv(
            symbol=args.symbol,
            timeframe=args.timeframe,
            start=args.start,
            end=args.end
        )
    except Exception as e:
        print_error(f"Erreur chargement donn√©es: {e}")
        return 1

    if not args.quiet:
        print_success(f"Donn√©es charg√©es: {len(df)} barres")
        print(f"   P√©riode r√©elle: {df.index[0]} ‚Üí {df.index[-1]}")
        print()

    # Parser la grille de param√®tres depuis JSON
    if args.param_grid:
        try:
            param_grid = json_module.loads(args.param_grid)
        except json_module.JSONDecodeError as e:
            print_error(f"Erreur parsing param_grid JSON: {e}")
            return 1
    else:
        # Utiliser une grille par d√©faut bas√©e sur la strat√©gie
        strategy_class = get_strategy(args.strategy)
        if not strategy_class:
            print_error(f"Strat√©gie '{args.strategy}' non trouv√©e")
            return 1

        strategy_instance = strategy_class()

        if getattr(args, "include_optional_params", False):
            strategy_instance._include_optional_params = True

        optional_skipped: List[str] = []
        if hasattr(strategy_instance, "parameter_specs") and strategy_instance.parameter_specs:
            optional_skipped = [
                name
                for name, spec in strategy_instance.parameter_specs.items()
                if not getattr(spec, "optimize", True)
            ]

        if optional_skipped and not getattr(strategy_instance, "_include_optional_params", False):
            if not args.quiet:
                skipped = ", ".join(optional_skipped)
                print_info(
                    f"Param√®tres optionnels ignor√©s: {skipped} (ajoutez --include-optional-params ou BACKTEST_INCLUDE_OPTIONAL_PARAMS=1)"
                )
        param_grid = {}

        # G√©n√©rer une grille simple depuis param_ranges
        for param_name, (min_val, max_val) in strategy_instance.param_ranges.items():
            default = strategy_instance.default_params.get(param_name, (min_val + max_val) / 2)

            if isinstance(default, int):
                # Grille de 3 valeurs pour les entiers
                step = max(1, (max_val - min_val) // 2)
                param_grid[param_name] = [min_val, min_val + step, max_val]
            else:
                # Grille de 3 valeurs pour les floats
                param_grid[param_name] = [
                    min_val,
                    (min_val + max_val) / 2,
                    max_val
                ]

    # G√©n√©rer toutes les combinaisons
    param_names = list(param_grid.keys())
    param_values = list(param_grid.values())
    all_combinations = list(product(*param_values))

    # Limiter le nombre de combinaisons
    if len(all_combinations) > args.max_combinations:
        print_warning(f"Nombre de combinaisons ({len(all_combinations)}) > max ({args.max_combinations})")
        print_info(f"Limitation √† {args.max_combinations} combinaisons")
        import random
        random.seed(42)
        all_combinations = random.sample(all_combinations, args.max_combinations)

    if not args.quiet:
        print_header("Grille de param√®tres", "-")
        for param_name, values in param_grid.items():
            print(f"  {param_name}: {values}")
        print(f"\n  Total combinaisons: {len(all_combinations)}")
        print()

    # Cr√©er la configuration avec les frais
    config_kwargs = {"fees_bps": args.fees_bps}
    if args.slippage_bps is not None:
        config_kwargs["slippage_bps"] = args.slippage_bps
    config = Config(**config_kwargs)

    # Ex√©cuter les backtests
    if not args.quiet:
        print_info("Lancement des backtests...")
        print()

    results = []

    for i, param_combination in enumerate(all_combinations):
        params = dict(zip(param_names, param_combination))

        engine = BacktestEngine(
            initial_capital=args.capital,
            config=config,
        )

        try:
            result = engine.run(
                df=df,
                strategy=args.strategy,
                params=params,
                symbol=args.symbol,
                timeframe=args.timeframe
            )

            # G√©rer les m√©triques
            if hasattr(result.metrics, 'to_dict'):
                metrics = result.metrics.to_dict()
            else:
                metrics = dict(result.metrics)

            results.append({
                "params": params,
                "metrics": metrics,
            })
        except Exception as e:
            if args.verbose:
                print_warning(f"Erreur avec {params}: {e}")

        # Progress
        if not args.quiet and (i + 1) % 10 == 0:
            print(f"\r  Progress: {i+1}/{len(all_combinations)} ({100*(i+1)/len(all_combinations):.1f}%)", end="", flush=True)

    if not args.quiet:
        print("\r" + " " * 50 + "\r", end="")
        print_success(f"Backtests termin√©s: {len(results)} r√©sultats")
        print()

    # Trier par m√©trique
    metric_key = args.metric
    reverse = args.metric != "max_drawdown"  # Plus bas = mieux pour drawdown

    results.sort(key=lambda x: x["metrics"].get(metric_key, 0), reverse=reverse)

    # Afficher les meilleurs
    if not args.quiet:
        print_header(f"Top {args.top} R√©sultats (tri par {args.metric})")

        for i, r in enumerate(results[:args.top]):
            print(f"\n  {Colors.BOLD}#{i+1}{Colors.RESET}")
            print(f"    Param√®tres: {r['params']}")
            print(f"    Sharpe: {r['metrics'].get('sharpe_ratio', 0):.3f}")
            print(f"    Return: {r['metrics'].get('total_return_pct', 0):+.2f}%")
            print(f"    Drawdown: {r['metrics'].get('max_drawdown', 0):.2f}%")
            print(f"    {args.metric}: {r['metrics'].get(metric_key, 0):.4f}")

    # Export
    if args.output:
        output_path = Path(args.output)

        export_data = {
            "strategy": args.strategy,
            "symbol": args.symbol,
            "timeframe": args.timeframe,
            "period": {"start": args.start, "end": args.end},
            "param_grid": param_grid,
            "n_combinations": len(all_combinations),
            "metric": args.metric,
            "results": results,
        }

        with open(output_path, "w") as f:
            json_module.dump(export_data, f, indent=2, default=str)

        if not args.quiet:
            print()
            print_success(f"R√©sultats export√©s: {output_path}")

    return 0


# =============================================================================
# COMMANDE: ANALYZE
# =============================================================================

def cmd_analyze(args) -> int:
    """Analyse les r√©sultats de backtests stock√©s."""
    if args.no_color:
        Colors.disable()

    import json as json_module
    from pathlib import Path

    results_dir = Path(args.results_dir)

    if not results_dir.exists():
        print_error(f"R√©pertoire non trouv√©: {results_dir}")
        return 1

    print_header("Analyse des R√©sultats de Backtests")
    print(f"  R√©pertoire: {results_dir}")
    print()

    # Charger l'index
    index_path = results_dir / "index.json"

    if not index_path.exists():
        print_error(f"Fichier index.json non trouv√© dans {results_dir}")
        return 1

    with open(index_path) as f:
        index = json_module.load(f)

    print_info(f"Nombre total de runs: {len(index)}")
    print()

    # Filtrer les runs profitables
    if args.profitable_only:
        filtered = {
            run_id: data for run_id, data in index.items()
            if data['metrics'].get('total_pnl', 0) > 0
        }
    else:
        filtered = index

    print_header(f"R√©sultats {'profitables' if args.profitable_only else 'tous'} ({len(filtered)})", "-")

    # Trier par m√©trique
    metric_key = args.sort_by
    reverse = args.sort_by != "max_drawdown_pct"  # Plus bas = mieux pour drawdown

    sorted_runs = sorted(
        filtered.items(),
        key=lambda x: x[1]['metrics'].get(metric_key, float('-inf') if reverse else float('inf')),
        reverse=reverse
    )

    # Afficher top N
    for i, (run_id, data) in enumerate(sorted_runs[:args.top], 1):
        print(f"\n{Colors.BOLD}Run #{i} - {run_id}{Colors.RESET}")
        print(f"  Strat√©gie: {data['strategy']}")
        print(f"  P√©riode: {data.get('period_start', 'N/A')} ‚Üí {data.get('period_end', 'N/A')}")
        print(f"  Symbole: {data.get('symbol', 'N/A')} | Timeframe: {data.get('timeframe', 'N/A')}")

        print(f"\n  {Colors.BOLD}Param√®tres:{Colors.RESET}")
        for param, value in data['params'].items():
            print(f"    {param}: {value}")

        m = data['metrics']
        print(f"\n  {Colors.BOLD}M√©triques:{Colors.RESET}")
        print(f"    PnL: ${m.get('total_pnl', 0):.2f} | Return: {m.get('total_return_pct', 0):.2f}%")
        print(f"    Sharpe: {m.get('sharpe_ratio', 0):.2f} | Sortino: {m.get('sortino_ratio', 0):.2f}")
        print(f"    Win Rate: {m.get('win_rate_pct', 0):.2f}% | Profit Factor: {m.get('profit_factor', 0):.2f}")
        print(f"    Max DD: {m.get('max_drawdown_pct', 0):.2f}% | Trades: {m.get('total_trades', 0)}")

    # Statistiques globales
    if args.stats and len(filtered) > 0:
        print()
        print_header("Statistiques Globales", "-")

        import numpy as np

        sharpe_values = [d['metrics'].get('sharpe_ratio', 0) for d in filtered.values()]
        return_values = [d['metrics'].get('total_return_pct', 0) for d in filtered.values()]
        dd_values = [d['metrics'].get('max_drawdown_pct', 0) for d in filtered.values()]

        print(f"  {Colors.BOLD}Sharpe Ratio:{Colors.RESET}")
        print(f"    Moyenne: {np.mean(sharpe_values):.2f}")
        print(f"    M√©diane: {np.median(sharpe_values):.2f}")
        print(f"    Min: {np.min(sharpe_values):.2f} | Max: {np.max(sharpe_values):.2f}")

        print(f"\n  {Colors.BOLD}Return %:{Colors.RESET}")
        print(f"    Moyenne: {np.mean(return_values):.2f}%")
        print(f"    M√©diane: {np.median(return_values):.2f}%")
        print(f"    Min: {np.min(return_values):.2f}% | Max: {np.max(return_values):.2f}%")

        print(f"\n  {Colors.BOLD}Max Drawdown %:{Colors.RESET}")
        print(f"    Moyenne: {np.mean(dd_values):.2f}%")
        print(f"    M√©diane: {np.median(dd_values):.2f}%")
        print(f"    Min: {np.min(dd_values):.2f}% | Max: {np.max(dd_values):.2f}%")

    # Export si demand√©
    if args.output:
        output_path = Path(args.output)

        export_data = {
            "total_runs": len(index),
            "filtered_runs": len(filtered),
            "filter": "profitable_only" if args.profitable_only else "all",
            "sort_by": args.sort_by,
            "top_runs": [
                {"run_id": run_id, **data}
                for run_id, data in sorted_runs[:args.top]
            ],
        }

        with open(output_path, "w") as f:
            json_module.dump(export_data, f, indent=2, default=str)

        print()
        print_success(f"Analyse export√©e: {output_path}")

    return 0
```
<!-- MODULE-END: commands.py -->

<!-- MODULE-START: formatters.py -->
```json
{
  "name": "formatters.py",
  "path": "cli\\formatters.py",
  "ext": ".py",
  "anchor": "formatters_py"
}
```
## formatters_py
*Chemin* : `cli\formatters.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.formatters

Purpose: Formatage et affichage pour CLI - couleurs, tableaux, progress bars, messages.

Role in pipeline: Utilitaires d'affichage pour toutes les commandes CLI.

Key components: Colors, print_header, print_success, print_error, format_table, format_bytes

Dependencies: colorama (optionnel), tqdm (optionnel)

Conventions: Couleurs d√©sactivables via Colors.disable() ou --no-color

Read-if: Modification du style d'affichage CLI.

Skip-if: Utilisation des commandes sans modifier l'affichage.
"""

from typing import List, Optional

# =============================================================================
# GESTION COULEURS (colorama si disponible)
# =============================================================================

try:
    from colorama import Fore, Style, init as colorama_init
    colorama_init(autoreset=True)
    COLORAMA_AVAILABLE = True
except ImportError:
    COLORAMA_AVAILABLE = False

    class Fore:
        GREEN = RED = YELLOW = CYAN = BLUE = MAGENTA = WHITE = BLACK = RESET = ""

    class Style:
        BRIGHT = DIM = NORMAL = RESET_ALL = ""


# =============================================================================
# GESTION PROGRESS BARS (tqdm si disponible)
# =============================================================================

try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    tqdm = lambda x, **kwargs: x


# =============================================================================
# CLASSE COLORS
# =============================================================================

class Colors:
    """
    Codes couleurs pour terminal avec support colorama.
    Compatibilit√© Windows am√©lior√©e.
    """
    # Utiliser colorama si disponible
    RESET = Style.RESET_ALL if COLORAMA_AVAILABLE else "\033[0m"
    BOLD = Style.BRIGHT if COLORAMA_AVAILABLE else "\033[1m"
    DIM = Style.DIM if COLORAMA_AVAILABLE else "\033[2m"

    # Couleurs de texte
    RED = Fore.RED if COLORAMA_AVAILABLE else "\033[91m"
    GREEN = Fore.GREEN if COLORAMA_AVAILABLE else "\033[92m"
    YELLOW = Fore.YELLOW if COLORAMA_AVAILABLE else "\033[93m"
    BLUE = Fore.BLUE if COLORAMA_AVAILABLE else "\033[94m"
    MAGENTA = Fore.MAGENTA if COLORAMA_AVAILABLE else "\033[95m"
    CYAN = Fore.CYAN if COLORAMA_AVAILABLE else "\033[96m"
    WHITE = Fore.WHITE if COLORAMA_AVAILABLE else "\033[97m"

    # Combinaisons utiles
    SUCCESS = f"{GREEN}{BOLD}" if COLORAMA_AVAILABLE else "\033[1;92m"
    ERROR = f"{RED}{BOLD}" if COLORAMA_AVAILABLE else "\033[1;91m"
    WARNING = f"{YELLOW}{BOLD}" if COLORAMA_AVAILABLE else "\033[1;93m"
    INFO = f"{CYAN}" if COLORAMA_AVAILABLE else "\033[96m"

    _disabled = False

    @classmethod
    def disable(cls):
        """D√©sactive les couleurs."""
        cls._disabled = True
        cls.RESET = cls.BOLD = cls.DIM = ""
        cls.RED = cls.GREEN = cls.YELLOW = cls.BLUE = ""
        cls.MAGENTA = cls.CYAN = cls.WHITE = ""
        cls.SUCCESS = cls.ERROR = cls.WARNING = cls.INFO = ""

    @classmethod
    def is_disabled(cls) -> bool:
        """V√©rifie si les couleurs sont d√©sactiv√©es."""
        return cls._disabled


# =============================================================================
# FONCTIONS D'AFFICHAGE MESSAGES
# =============================================================================

def print_header(text: str, char: str = "="):
    """Affiche un en-t√™te format√© avec soulignement."""
    print(f"\n{Colors.BOLD}{Colors.CYAN}{text}{Colors.RESET}")
    print(Colors.CYAN + char * len(text) + Colors.RESET)


def print_success(text: str):
    """Affiche un message de succ√®s avec ‚úì."""
    print(f"{Colors.GREEN}‚úì{Colors.RESET} {text}")


def print_error(text: str):
    """Affiche un message d'erreur avec ‚úó."""
    print(f"{Colors.RED}‚úó{Colors.RESET} {text}")


def print_warning(text: str):
    """Affiche un avertissement avec ‚ö†."""
    print(f"{Colors.YELLOW}‚ö†{Colors.RESET} {text}")


def print_info(text: str):
    """Affiche une information avec ‚Ñπ."""
    print(f"{Colors.BLUE}‚Ñπ{Colors.RESET} {text}")


def print_metric(label: str, value: float, color: Optional[str] = None, suffix: str = ""):
    """Affiche une m√©trique format√©e."""
    color = color or Colors.RESET
    print(f"    {label}:  {color}{value}{Colors.RESET}{suffix}")


# =============================================================================
# FORMATAGE TABLEAUX
# =============================================================================

def format_table(headers: List[str], rows: List[List[str]], indent: int = 2) -> str:
    """
    Formate une table en texte align√©.

    Args:
        headers: Liste des en-t√™tes de colonnes
        rows: Liste des lignes (chaque ligne est une liste de cellules)
        indent: Nombre d'espaces d'indentation

    Returns:
        Table format√©e en string
    """
    if not rows:
        return " " * indent + "(aucune donn√©e)"

    # Calculer largeurs maximales par colonne
    widths = [len(h) for h in headers]
    for row in rows:
        for i, cell in enumerate(row):
            if i < len(widths):
                widths[i] = max(widths[i], len(str(cell)))

    prefix = " " * indent
    lines = []

    # Header
    header_line = "  ".join(h.ljust(widths[i]) for i, h in enumerate(headers))
    lines.append(f"{prefix}{Colors.BOLD}{header_line}{Colors.RESET}")
    lines.append(prefix + "  ".join("-" * w for w in widths))

    # Rows
    for row in rows:
        row_line = "  ".join(str(cell).ljust(widths[i]) for i, cell in enumerate(row))
        lines.append(f"{prefix}{row_line}")

    return "\n".join(lines)


def format_dict_table(data: dict, title: Optional[str] = None, indent: int = 2) -> str:
    """
    Formate un dictionnaire en table cl√©-valeur.

    Args:
        data: Dictionnaire √† formater
        title: Titre optionnel
        indent: Indentation

    Returns:
        Table format√©e
    """
    lines = []
    prefix = " " * indent

    if title:
        lines.append(f"{prefix}{Colors.BOLD}{title}{Colors.RESET}")

    max_key_len = max(len(str(k)) for k in data.keys()) if data else 0

    for key, value in data.items():
        lines.append(f"{prefix}  {str(key).ljust(max_key_len)}: {value}")

    return "\n".join(lines)


# =============================================================================
# FORMATAGE VALEURS
# =============================================================================

def format_bytes(bytes_count: float) -> str:
    """Formate un nombre de bytes en unit√© lisible (KB, MB, GB, etc.)."""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_count < 1024.0:
            return f"{bytes_count:.2f} {unit}"
        bytes_count /= 1024.0
    return f"{bytes_count:.2f} PB"


def format_duration(seconds: float) -> str:
    """Formate une dur√©e en format lisible."""
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}min"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}h"


def format_number(value: float, decimals: int = 2) -> str:
    """Formate un nombre avec s√©parateurs de milliers."""
    if abs(value) >= 1000:
        return f"{value:,.{decimals}f}"
    return f"{value:.{decimals}f}"


def format_pnl(pnl: float, period_days: Optional[int] = None) -> str:
    """
    Formate un PnL avec couleur et optionnellement PnL/jour.

    Args:
        pnl: Profit/Loss en valeur absolue
        period_days: Nombre de jours pour calculer PnL/jour

    Returns:
        String format√© avec couleur
    """
    color = Colors.GREEN if pnl >= 0 else Colors.RED
    sign = "+" if pnl >= 0 else ""

    result = f"{color}{sign}${pnl:,.2f}{Colors.RESET}"

    if period_days and period_days > 0:
        daily_pnl = pnl / period_days
        result += f" ({sign}${daily_pnl:,.2f}/jour)"

    return result


def format_percent(value: float, include_sign: bool = True) -> str:
    """Formate un pourcentage avec couleur."""
    color = Colors.GREEN if value >= 0 else Colors.RED
    sign = "+" if value >= 0 and include_sign else ""
    return f"{color}{sign}{value:.2f}%{Colors.RESET}"


# =============================================================================
# PROGRESS BARS
# =============================================================================

def create_progress_bar(iterable, desc: str = "", total: int = None,
                       disable: bool = False, unit: str = "it"):
    """
    Cr√©e une progress bar √©l√©gante avec tqdm.

    Args:
        iterable: It√©rable √† parcourir
        desc: Description de la t√¢che
        total: Nombre total d'√©l√©ments (auto-d√©tect√© si None)
        disable: D√©sactiver la barre
        unit: Unit√© √† afficher

    Returns:
        It√©rable wrapp√© avec progress bar
    """
    if not TQDM_AVAILABLE or disable:
        return iterable

    return tqdm(
        iterable,
        desc=f"{Colors.CYAN}üîÑ {desc}{Colors.RESET}",
        total=total,
        unit=unit,
        ncols=100,
        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
    )


# =============================================================================
# FORMATAGE R√âSULTATS BACKTEST
# =============================================================================

def format_backtest_summary(metrics: dict, period_days: Optional[int] = None) -> str:
    """
    Formate un r√©sum√© de backtest pour affichage CLI.

    Args:
        metrics: Dictionnaire des m√©triques
        period_days: Dur√©e en jours pour calcul PnL/jour

    Returns:
        R√©sum√© format√© multi-lignes
    """
    lines = []

    total_pnl = metrics.get('total_pnl', 0)
    sharpe = metrics.get('sharpe_ratio', 0)
    max_dd = metrics.get('max_drawdown_pct', 0)
    win_rate = metrics.get('win_rate_pct', 0)
    trades = metrics.get('total_trades', metrics.get('trades', 0))
    profit_factor = metrics.get('profit_factor', 0)

    # Couleurs selon performance
    pnl_color = Colors.GREEN if total_pnl > 0 else Colors.RED
    sharpe_color = Colors.GREEN if sharpe > 1 else Colors.YELLOW if sharpe > 0 else Colors.RED

    lines.append(f"  {Colors.BOLD}üí∞ Performance:{Colors.RESET}")

    # PnL avec daily
    pnl_str = f"${total_pnl:,.2f}"
    if period_days and period_days > 0:
        daily = total_pnl / period_days
        pnl_str += f" (${daily:,.2f}/jour)"
    lines.append(f"    P&L Total:     {pnl_color}{pnl_str}{Colors.RESET}")

    lines.append(f"    Sharpe Ratio:  {sharpe_color}{sharpe:.3f}{Colors.RESET}")
    lines.append(f"    Max Drawdown:  {Colors.RED}{abs(max_dd):.2f}%{Colors.RESET}")
    lines.append(f"    Win Rate:      {win_rate:.1f}%")
    lines.append(f"    Profit Factor: {profit_factor:.2f}")
    lines.append(f"    Trades:        {trades}")

    return "\n".join(lines)


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Classes
    "Colors",
    # Constantes
    "COLORAMA_AVAILABLE",
    "TQDM_AVAILABLE",
    "tqdm",
    # Messages
    "print_header",
    "print_success",
    "print_error",
    "print_warning",
    "print_info",
    "print_metric",
    # Tables
    "format_table",
    "format_dict_table",
    # Valeurs
    "format_bytes",
    "format_duration",
    "format_number",
    "format_pnl",
    "format_percent",
    # Progress
    "create_progress_bar",
    # R√©sultats
    "format_backtest_summary",
]
```
<!-- MODULE-END: formatters.py -->

<!-- MODULE-START: report_generator.py -->
```json
{
  "name": "report_generator.py",
  "path": "cli\\report_generator.py",
  "ext": ".py",
  "anchor": "report_generator_py"
}
```
## report_generator_py
*Chemin* : `cli\report_generator.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.report_generator

Purpose: G√©n√©ration de rapports et exports (HTML, CSV, Excel).

Role in pipeline: Export des r√©sultats de backtest/sweep/optuna.

Key components: export_html, export_csv, export_excel, generate_backtest_report

Dependencies: pandas, pathlib, json

Conventions: Tous les exports retournent le Path du fichier cr√©√©.

Read-if: Modification des formats d'export.

Skip-if: Utilisation des exports existants.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import pandas as pd


# =============================================================================
# TEMPLATES HTML
# =============================================================================

HTML_TEMPLATE_HEADER = """<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        :root {{
            --primary: #4CAF50;
            --danger: #f44336;
            --warning: #ff9800;
            --info: #2196F3;
            --dark: #333;
            --light: #f5f5f5;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            margin: 0;
            padding: 20px;
            background: var(--light);
            color: var(--dark);
        }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        h1 {{ color: var(--dark); border-bottom: 3px solid var(--primary); padding-bottom: 10px; }}
        h2 {{ color: var(--primary); margin-top: 30px; }}
        .card {{
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }}
        .metric {{
            text-align: center;
            padding: 15px;
            border-radius: 6px;
            background: var(--light);
        }}
        .metric-value {{
            font-size: 1.8em;
            font-weight: bold;
        }}
        .metric-label {{ color: #666; font-size: 0.9em; }}
        .positive {{ color: var(--primary); }}
        .negative {{ color: var(--danger); }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }}
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        th {{
            background: var(--primary);
            color: white;
            font-weight: 600;
        }}
        tr:hover {{ background: #f5f5f5; }}
        .timestamp {{ color: #999; font-size: 0.8em; }}
    </style>
</head>
<body>
<div class="container">
"""

HTML_TEMPLATE_FOOTER = """
    <p class="timestamp">G√©n√©r√© le {timestamp}</p>
</div>
</body>
</html>
"""


# =============================================================================
# EXPORT HTML
# =============================================================================

def export_html(data: dict, output_path: Path, title: str = "Rapport de Backtest") -> Path:
    """
    Exporte des r√©sultats en HTML format√©.

    Args:
        data: Dictionnaire des r√©sultats
        output_path: Chemin du fichier de sortie
        title: Titre du rapport

    Returns:
        Path du fichier cr√©√©
    """
    html_parts = [HTML_TEMPLATE_HEADER.format(title=title)]

    # Titre et infos g√©n√©rales
    strategy = data.get("strategy", "N/A")
    result_type = data.get("type", "backtest")

    html_parts.append(f"<h1>üìä {title}</h1>")
    html_parts.append(f'<p><strong>Strat√©gie:</strong> {strategy}</p>')
    html_parts.append(f'<p><strong>Type:</strong> {result_type}</p>')

    # Section m√©triques
    metrics = data.get("metrics", data.get("best_metrics", {}))
    if metrics:
        html_parts.append("<h2>üìà M√©triques</h2>")
        html_parts.append('<div class="card"><div class="metrics-grid">')

        metric_display = {
            "total_pnl": ("üí∞ P&L Total", "${:,.2f}"),
            "total_return_pct": ("üìä Return", "{:+.2f}%"),
            "sharpe_ratio": ("üìê Sharpe", "{:.3f}"),
            "sortino_ratio": ("üìê Sortino", "{:.3f}"),
            "max_drawdown_pct": ("üìâ Max DD", "{:.2f}%"),
            "win_rate_pct": ("üéØ Win Rate", "{:.1f}%"),
            "profit_factor": ("üíπ Profit Factor", "{:.2f}"),
            "total_trades": ("üîÑ Trades", "{}"),
        }

        for key, (label, fmt) in metric_display.items():
            value = metrics.get(key)
            if value is not None:
                formatted = fmt.format(value)
                css_class = ""
                if "pnl" in key.lower() or "return" in key.lower():
                    css_class = "positive" if value >= 0 else "negative"
                elif key == "sharpe_ratio":
                    css_class = "positive" if value >= 1 else "negative" if value < 0 else ""

                html_parts.append(f'''
                    <div class="metric">
                        <div class="metric-value {css_class}">{formatted}</div>
                        <div class="metric-label">{label}</div>
                    </div>
                ''')

        html_parts.append("</div></div>")

    # Section param√®tres
    params = data.get("params", data.get("best_params", {}))
    if params:
        html_parts.append("<h2>‚öôÔ∏è Param√®tres</h2>")
        html_parts.append('<div class="card"><table>')
        html_parts.append("<tr><th>Param√®tre</th><th>Valeur</th></tr>")
        for key, value in params.items():
            html_parts.append(f"<tr><td>{key}</td><td>{value}</td></tr>")
        html_parts.append("</table></div>")

    # Section r√©sultats sweep/optuna
    results = data.get("results", [])
    if results and len(results) > 1:
        html_parts.append(f"<h2>üìã R√©sultats ({len(results)} combinaisons)</h2>")
        html_parts.append('<div class="card"><table>')

        # Headers dynamiques
        first_result = results[0]
        param_keys = list(first_result.get("params", {}).keys())
        metric_keys = ["total_pnl", "sharpe_ratio", "win_rate_pct"]

        html_parts.append("<tr>")
        for pk in param_keys[:5]:  # Limiter √† 5 params
            html_parts.append(f"<th>{pk}</th>")
        for mk in metric_keys:
            html_parts.append(f"<th>{mk}</th>")
        html_parts.append("</tr>")

        # Top 20 r√©sultats
        for r in results[:20]:
            html_parts.append("<tr>")
            for pk in param_keys[:5]:
                html_parts.append(f"<td>{r.get('params', {}).get(pk, '')}</td>")
            for mk in metric_keys:
                val = r.get("metrics", {}).get(mk, 0)
                css = "positive" if val > 0 else "negative" if val < 0 else ""
                html_parts.append(f'<td class="{css}">{val:.4f}</td>')
            html_parts.append("</tr>")

        html_parts.append("</table></div>")

    # Footer
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    html_parts.append(HTML_TEMPLATE_FOOTER.format(timestamp=timestamp))

    # √âcriture fichier
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(html_parts))

    return output_path


# =============================================================================
# EXPORT CSV
# =============================================================================

def export_csv(data: dict, output_path: Path) -> Path:
    """
    Exporte des r√©sultats en CSV.

    Args:
        data: Dictionnaire des r√©sultats
        output_path: Chemin du fichier de sortie

    Returns:
        Path du fichier cr√©√©
    """
    results = data.get("results", [])

    if results:
        # Multiple r√©sultats (sweep/optuna)
        rows = []
        for r in results:
            row = {**r.get("params", {}), **r.get("metrics", {})}
            rows.append(row)
        df = pd.DataFrame(rows)
    else:
        # Single backtest
        metrics = data.get("metrics", {})
        params = data.get("params", {})
        df = pd.DataFrame([{**params, **metrics}])

    df.to_csv(output_path, index=False)
    return output_path


# =============================================================================
# EXPORT EXCEL
# =============================================================================

def export_excel(data: dict, output_path: Path) -> Path:
    """
    Exporte des r√©sultats en Excel avec plusieurs feuilles.

    Args:
        data: Dictionnaire des r√©sultats
        output_path: Chemin du fichier de sortie

    Returns:
        Path du fichier cr√©√©

    Raises:
        ImportError: Si openpyxl n'est pas install√©
    """
    try:
        import openpyxl  # noqa: F401
    except ImportError:
        raise ImportError("openpyxl requis pour export Excel: pip install openpyxl")

    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        results = data.get("results", [])

        if results:
            # Feuille principale : tous les r√©sultats
            rows = []
            for r in results:
                row = {**r.get("params", {}), **r.get("metrics", {})}
                rows.append(row)
            df_results = pd.DataFrame(rows)
            df_results.to_excel(writer, sheet_name="R√©sultats", index=False)

            # Feuille top 10
            if len(rows) > 10:
                df_top = df_results.nlargest(10, "total_pnl") if "total_pnl" in df_results else df_results.head(10)
                df_top.to_excel(writer, sheet_name="Top 10", index=False)
        else:
            # Single backtest
            metrics = data.get("metrics", {})
            params = data.get("params", {})

            # Feuille m√©triques
            df_metrics = pd.DataFrame([metrics])
            df_metrics.to_excel(writer, sheet_name="M√©triques", index=False)

            # Feuille param√®tres
            if params:
                df_params = pd.DataFrame([params])
                df_params.to_excel(writer, sheet_name="Param√®tres", index=False)

        # Feuille info
        info = {
            "Strat√©gie": data.get("strategy", "N/A"),
            "Type": data.get("type", "backtest"),
            "G√©n√©r√© le": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }
        df_info = pd.DataFrame([info])
        df_info.to_excel(writer, sheet_name="Info", index=False)

    return output_path


# =============================================================================
# G√âN√âRATION RAPPORT COMPLET
# =============================================================================

def generate_backtest_report(
    metrics: dict,
    params: dict,
    trades: List[dict] = None,
    equity_curve: List[float] = None,
    strategy: str = "Unknown",
    symbol: str = "Unknown",
    timeframe: str = "Unknown",
    output_dir: Optional[Path] = None
) -> Dict[str, Path]:
    """
    G√©n√®re un rapport complet de backtest (HTML + CSV).

    Args:
        metrics: M√©triques de performance
        params: Param√®tres utilis√©s
        trades: Liste des trades (optionnel)
        equity_curve: Courbe d'√©quit√© (optionnel)
        strategy: Nom de la strat√©gie
        symbol: Symbole trad√©
        timeframe: Timeframe
        output_dir: R√©pertoire de sortie (par d√©faut: backtest_results/)

    Returns:
        Dict avec paths des fichiers g√©n√©r√©s {html, csv, json}
    """
    if output_dir is None:
        output_dir = Path("backtest_results")
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"{strategy}_{symbol}_{timeframe}_{timestamp}"

    # Pr√©parer les donn√©es
    data = {
        "strategy": strategy,
        "symbol": symbol,
        "timeframe": timeframe,
        "type": "backtest",
        "params": params,
        "metrics": metrics,
        "generated_at": datetime.now().isoformat(),
    }

    if trades:
        data["trades"] = trades
        data["trade_count"] = len(trades)

    if equity_curve:
        data["equity_curve"] = equity_curve

    output_files = {}

    # Export JSON
    json_path = output_dir / f"{base_name}.json"
    with open(json_path, "w") as f:
        json.dump(data, f, indent=2, default=str)
    output_files["json"] = json_path

    # Export HTML
    html_path = output_dir / f"{base_name}.html"
    export_html(data, html_path, title=f"Backtest {strategy} - {symbol}")
    output_files["html"] = html_path

    # Export CSV (m√©triques uniquement)
    csv_path = output_dir / f"{base_name}_metrics.csv"
    export_csv(data, csv_path)
    output_files["csv"] = csv_path

    return output_files


def generate_sweep_report(
    results: List[dict],
    best_params: dict,
    best_metrics: dict,
    strategy: str,
    total_combinations: int,
    total_time: float,
    output_dir: Optional[Path] = None
) -> Dict[str, Path]:
    """
    G√©n√®re un rapport complet de sweep/optimisation.

    Args:
        results: Liste des r√©sultats {params, metrics}
        best_params: Meilleurs param√®tres trouv√©s
        best_metrics: M√©triques du meilleur r√©sultat
        strategy: Nom de la strat√©gie
        total_combinations: Nombre total de combinaisons test√©es
        total_time: Temps total d'ex√©cution (secondes)
        output_dir: R√©pertoire de sortie

    Returns:
        Dict avec paths des fichiers g√©n√©r√©s
    """
    if output_dir is None:
        output_dir = Path("backtest_results")
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"sweep_{strategy}_{timestamp}"

    data = {
        "strategy": strategy,
        "type": "sweep",
        "total_combinations": total_combinations,
        "total_time": total_time,
        "best_params": best_params,
        "best_metrics": best_metrics,
        "results": results,
        "generated_at": datetime.now().isoformat(),
    }

    output_files = {}

    # Export JSON complet
    json_path = output_dir / f"{base_name}.json"
    with open(json_path, "w") as f:
        json.dump(data, f, indent=2, default=str)
    output_files["json"] = json_path

    # Export HTML
    html_path = output_dir / f"{base_name}.html"
    export_html(data, html_path, title=f"Sweep {strategy}")
    output_files["html"] = html_path

    # Export CSV (tous les r√©sultats)
    csv_path = output_dir / f"{base_name}.csv"
    export_csv(data, csv_path)
    output_files["csv"] = csv_path

    return output_files


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Exports individuels
    "export_html",
    "export_csv",
    "export_excel",
    # G√©n√©rateurs de rapports
    "generate_backtest_report",
    "generate_sweep_report",
]
```
<!-- MODULE-END: report_generator.py -->

<!-- MODULE-START: sweep_executor.py -->
```json
{
  "name": "sweep_executor.py",
  "path": "cli\\sweep_executor.py",
  "ext": ".py",
  "anchor": "sweep_executor_py"
}
```
## sweep_executor_py
*Chemin* : `cli\sweep_executor.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.sweep_executor

Purpose: Ex√©cution des sweeps, grilles et optimisations Optuna en CLI.

Role in pipeline: Moteur d'ex√©cution pour cmd_sweep, cmd_grid_backtest, cmd_optuna.

Key components: run_sweep, run_grid_backtest, run_optuna_optimization, CheckpointManager

Dependencies: backtest.engine, backtest.sweep, utils.parameters, optuna

Conventions: Progress callbacks, checkpoints automatiques, gestion m√©moire.

Read-if: Modification de la logique d'ex√©cution des optimisations.

Skip-if: Utilisation des commandes sans modifier le comportement.
"""

import gc
import time
from dataclasses import dataclass, field
from datetime import datetime
from itertools import product
from pathlib import Path
from typing import Any, Callable, Dict, Iterator, List, Optional, Tuple

import numpy as np
import pandas as pd


# =============================================================================
# DATACLASSES
# =============================================================================

@dataclass
class SweepConfig:
    """Configuration d'un sweep."""
    strategy_name: str
    data_path: Path
    symbol: str
    timeframe: str

    # Param√®tres financiers
    initial_capital: float = 10000
    fees_bps: int = 10
    slippage_bps: int = 5

    # Param√®tres sweep
    granularity: float = 1.0
    max_combinations: int = 10000
    metric: str = "sharpe_ratio"
    minimize: bool = False

    # P√©riode
    start_date: Optional[str] = None
    end_date: Optional[str] = None

    # Checkpoints
    checkpoint_every: int = 0
    checkpoint_seconds: float = 0


@dataclass
class SweepProgress:
    """√âtat de progression d'un sweep."""
    completed: int = 0
    failed: int = 0
    total: int = 0

    best_score: float = float('-inf')
    best_params: Dict[str, Any] = field(default_factory=dict)
    best_metrics: Dict[str, Any] = field(default_factory=dict)

    start_time: float = field(default_factory=time.time)

    @property
    def elapsed(self) -> float:
        """Temps √©coul√© en secondes."""
        return time.time() - self.start_time

    @property
    def progress_pct(self) -> float:
        """Pourcentage de progression."""
        if self.total == 0:
            return 0
        return 100 * (self.completed + self.failed) / self.total

    @property
    def rate(self) -> float:
        """Combinaisons par seconde."""
        if self.elapsed == 0:
            return 0
        return (self.completed + self.failed) / self.elapsed

    @property
    def eta_seconds(self) -> float:
        """Temps restant estim√© en secondes."""
        if self.rate == 0:
            return float('inf')
        remaining = self.total - (self.completed + self.failed)
        return remaining / self.rate


@dataclass
class SweepResult:
    """R√©sultat d'un sweep complet."""
    results: List[Dict[str, Any]]
    best_params: Dict[str, Any]
    best_metrics: Dict[str, Any]
    best_score: float

    total_combinations: int
    completed: int
    failed: int
    total_time: float

    strategy: str
    symbol: str
    timeframe: str


# =============================================================================
# CHECKPOINT MANAGER
# =============================================================================

class CheckpointManager:
    """G√®re les checkpoints pour les optimisations longues."""

    def __init__(
        self,
        checkpoint_id: str,
        checkpoint_every: int = 0,
        checkpoint_seconds: float = 0,
        storage=None
    ):
        self.checkpoint_id = checkpoint_id
        self.checkpoint_every = checkpoint_every
        self.checkpoint_seconds = checkpoint_seconds
        self.storage = storage

        self.last_checkpoint_time = time.time()
        self.last_checkpoint_count = 0
        self.items: List[Dict] = []

    @property
    def enabled(self) -> bool:
        """V√©rifie si les checkpoints sont activ√©s."""
        return (self.checkpoint_every > 0 or self.checkpoint_seconds > 0) and self.storage is not None

    def add_result(self, result: Dict):
        """Ajoute un r√©sultat au buffer de checkpoint."""
        self.items.append(result)

    def should_checkpoint(self, total_done: int) -> bool:
        """V√©rifie si on doit faire un checkpoint maintenant."""
        if not self.enabled or total_done == 0:
            return False

        now = time.time()

        # Check par nombre
        if self.checkpoint_every > 0:
            if total_done - self.last_checkpoint_count >= self.checkpoint_every:
                return True

        # Check par temps
        if self.checkpoint_seconds > 0:
            if now - self.last_checkpoint_time >= self.checkpoint_seconds:
                return True

        return False

    def save_checkpoint(
        self,
        progress: SweepProgress,
        config: SweepConfig,
        status: str = "in_progress"
    ):
        """Sauvegarde un checkpoint."""
        if not self.enabled:
            return

        from backtest.sweep import SweepResults

        sweep_results = SweepResults(
            items=self.items,
            best_params=progress.best_params,
            best_metrics=progress.best_metrics,
            total_time=progress.elapsed,
            n_completed=progress.completed,
            n_failed=progress.failed,
        )

        extra_metadata = {
            "strategy": config.strategy_name,
            "symbol": config.symbol,
            "timeframe": config.timeframe,
            "total_combinations": config.max_combinations,
            "period_start": config.start_date,
            "period_end": config.end_date,
            "status": status,
        }

        self.storage.save_sweep_results(
            sweep_results,
            sweep_id=self.checkpoint_id,
            mode="sweep",
            extra_metadata=extra_metadata,
        )

        self.last_checkpoint_time = time.time()
        self.last_checkpoint_count = progress.completed + progress.failed


# =============================================================================
# G√âN√âRATION DE GRILLE
# =============================================================================

def build_param_grid_from_strategy(
    strategy_instance,
    granularity: float = 1.0,
    max_combinations: int = 10000,
    include_optional: bool = False
) -> Tuple[Dict[str, List], List[str]]:
    """
    Construit une grille de param√®tres depuis une strat√©gie.

    Args:
        strategy_instance: Instance de la strat√©gie
        granularity: Niveau de granularit√© (1.0 = normal)
        max_combinations: Limite de combinaisons
        include_optional: Inclure les param√®tres optionnels

    Returns:
        Tuple (param_grid, param_names)
    """
    from utils.parameters import ParameterSpec, generate_param_grid

    # Construire les specs
    param_specs = {}
    for name, (min_v, max_v) in strategy_instance.param_ranges.items():
        # V√©rifier si param√®tre optionnel
        if hasattr(strategy_instance, "parameter_specs"):
            spec = strategy_instance.parameter_specs.get(name)
            if spec and not getattr(spec, "optimize", True) and not include_optional:
                continue

        default = strategy_instance.default_params.get(name, (min_v + max_v) / 2)
        param_type = "int" if isinstance(default, int) else "float"

        param_specs[name] = ParameterSpec(
            name=name,
            min_val=min_v,
            max_val=max_v,
            default=default,
            param_type=param_type,
        )

    # G√©n√©rer la grille
    grid = generate_param_grid(
        param_specs,
        granularity=granularity,
        max_total_combinations=max_combinations,
    )

    param_names = list(param_specs.keys())

    return list(grid), param_names


def build_simple_grid(
    param_ranges: Dict[str, Tuple[float, float]],
    defaults: Dict[str, Any],
    n_values: int = 3
) -> Tuple[List[Dict], List[str]]:
    """
    Construit une grille simple avec N valeurs par param√®tre.

    Args:
        param_ranges: {param: (min, max)}
        defaults: Valeurs par d√©faut
        n_values: Nombre de valeurs par param√®tre

    Returns:
        Tuple (list of param dicts, param names)
    """
    param_grid = {}

    for param_name, (min_val, max_val) in param_ranges.items():
        default = defaults.get(param_name, (min_val + max_val) / 2)

        if isinstance(default, int):
            step = max(1, (max_val - min_val) // (n_values - 1))
            values = [min_val + i * step for i in range(n_values)]
            values = [int(v) for v in values if v <= max_val]
        else:
            step = (max_val - min_val) / (n_values - 1)
            values = [min_val + i * step for i in range(n_values)]

        param_grid[param_name] = values

    # G√©n√©rer toutes les combinaisons
    param_names = list(param_grid.keys())
    param_values = list(param_grid.values())

    all_combinations = []
    for combo in product(*param_values):
        all_combinations.append(dict(zip(param_names, combo)))

    return all_combinations, param_names


# =============================================================================
# EX√âCUTION SWEEP
# =============================================================================

def run_sweep(
    config: SweepConfig,
    df: pd.DataFrame,
    param_grid: List[Dict],
    on_progress: Optional[Callable[[SweepProgress], None]] = None,
    on_result: Optional[Callable[[Dict], None]] = None,
) -> SweepResult:
    """
    Ex√©cute un sweep param√©trique.

    Args:
        config: Configuration du sweep
        df: DataFrame OHLCV
        param_grid: Liste des combinaisons de param√®tres
        on_progress: Callback de progression
        on_result: Callback par r√©sultat

    Returns:
        SweepResult avec tous les r√©sultats
    """
    from backtest.engine import BacktestEngine
    from utils.config import Config

    # Configuration
    engine_config = Config(
        fees_bps=config.fees_bps,
        slippage_bps=config.slippage_bps,
    )

    # Initialisation
    progress = SweepProgress(total=len(param_grid))

    # Checkpoint manager
    checkpoint_mgr = None
    if config.checkpoint_every > 0 or config.checkpoint_seconds > 0:
        from backtest.storage import get_storage
        storage = get_storage()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_id = f"sweep_{config.strategy_name}_{config.symbol}_{timestamp}"
        checkpoint_mgr = CheckpointManager(
            checkpoint_id=checkpoint_id,
            checkpoint_every=config.checkpoint_every,
            checkpoint_seconds=config.checkpoint_seconds,
            storage=storage,
        )

    minimize = config.minimize
    if minimize:
        progress.best_score = float('inf')

    results = []

    for params in param_grid:
        engine = BacktestEngine(
            initial_capital=config.initial_capital,
            config=engine_config,
        )

        try:
            result = engine.run(
                df=df,
                strategy=config.strategy_name,
                params=params,
                symbol=config.symbol,
                timeframe=config.timeframe,
            )

            metrics = result.metrics.to_dict() if hasattr(result.metrics, 'to_dict') else result.metrics
            score = metrics.get(config.metric, 0)

            result_item = {
                "params": params,
                "metrics": metrics,
                "score": score,
            }
            results.append(result_item)

            # Mettre √† jour le meilleur
            is_better = (score < progress.best_score) if minimize else (score > progress.best_score)
            if is_better:
                progress.best_score = score
                progress.best_params = params.copy()
                progress.best_metrics = metrics.copy()

            progress.completed += 1

            if checkpoint_mgr:
                checkpoint_mgr.add_result(result_item)

            if on_result:
                on_result(result_item)

        except Exception as e:
            progress.failed += 1
            results.append({
                "params": params,
                "error": str(e),
            })

        # Progress callback
        if on_progress:
            on_progress(progress)

        # Checkpoint si n√©cessaire
        if checkpoint_mgr and checkpoint_mgr.should_checkpoint(progress.completed + progress.failed):
            checkpoint_mgr.save_checkpoint(progress, config)

    # Checkpoint final
    if checkpoint_mgr:
        checkpoint_mgr.save_checkpoint(progress, config, status="completed")

    return SweepResult(
        results=results,
        best_params=progress.best_params,
        best_metrics=progress.best_metrics,
        best_score=progress.best_score,
        total_combinations=len(param_grid),
        completed=progress.completed,
        failed=progress.failed,
        total_time=progress.elapsed,
        strategy=config.strategy_name,
        symbol=config.symbol,
        timeframe=config.timeframe,
    )


# =============================================================================
# EX√âCUTION OPTUNA
# =============================================================================

def run_optuna_optimization(
    strategy_name: str,
    df: pd.DataFrame,
    symbol: str,
    timeframe: str,
    n_trials: int = 100,
    metric: str = "sharpe_ratio",
    direction: str = "maximize",
    sampler: str = "tpe",
    pruner: bool = True,
    n_jobs: int = 1,
    timeout: Optional[float] = None,
    initial_capital: float = 10000,
    fees_bps: int = 10,
    slippage_bps: int = 5,
    on_trial_complete: Optional[Callable] = None,
    quiet: bool = False,
) -> Dict[str, Any]:
    """
    Ex√©cute une optimisation Optuna.

    Args:
        strategy_name: Nom de la strat√©gie
        df: DataFrame OHLCV
        symbol: Symbole
        timeframe: Timeframe
        n_trials: Nombre d'essais
        metric: M√©trique √† optimiser
        direction: "maximize" ou "minimize"
        sampler: Type de sampler ("tpe", "cmaes", "random")
        pruner: Activer le pruning
        n_jobs: Nombre de jobs parall√®les
        timeout: Timeout en secondes
        initial_capital: Capital initial
        fees_bps: Frais en basis points
        slippage_bps: Slippage en basis points
        on_trial_complete: Callback apr√®s chaque trial
        quiet: Mode silencieux

    Returns:
        Dict avec r√©sultats complets
    """
    try:
        from backtest.optuna_optimizer import (
            OPTUNA_AVAILABLE,
            OptunaOptimizer,
            suggest_param_space,
        )
    except ImportError:
        raise ImportError("Module optuna_optimizer non disponible")

    if not OPTUNA_AVAILABLE:
        raise ImportError("Optuna n'est pas install√©: pip install optuna")

    from strategies import get_strategy
    from utils.config import Config

    # R√©cup√©rer la strat√©gie
    strategy_class = get_strategy(strategy_name)
    if not strategy_class:
        raise ValueError(f"Strat√©gie '{strategy_name}' non trouv√©e")

    strategy_instance = strategy_class()

    # Construire l'espace de param√®tres
    param_space = suggest_param_space(strategy_instance)

    # Configuration
    config = Config(fees_bps=fees_bps, slippage_bps=slippage_bps)

    # Cr√©er l'optimiseur
    optimizer = OptunaOptimizer(
        strategy_name=strategy_name,
        param_space=param_space,
        df=df,
        symbol=symbol,
        timeframe=timeframe,
        initial_capital=initial_capital,
        config=config,
        metric=metric,
        direction=direction,
    )

    # Ex√©cuter l'optimisation
    result = optimizer.optimize(
        n_trials=n_trials,
        sampler=sampler,
        pruner=pruner,
        n_jobs=n_jobs,
        timeout=timeout,
        show_progress=not quiet,
        callback=on_trial_complete,
    )

    return {
        "best_params": result.best_params,
        "best_value": result.best_value,
        "best_metrics": result.best_metrics,
        "n_completed": result.n_completed,
        "n_pruned": result.n_pruned,
        "total_time": result.total_time,
        "history": result.history,
        "study": result.study,
    }


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Dataclasses
    "SweepConfig",
    "SweepProgress",
    "SweepResult",
    # Classes
    "CheckpointManager",
    # Fonctions grille
    "build_param_grid_from_strategy",
    "build_simple_grid",
    # Ex√©cution
    "run_sweep",
    "run_optuna_optimization",
]
```
<!-- MODULE-END: sweep_executor.py -->

<!-- MODULE-START: validators.py -->
```json
{
  "name": "validators.py",
  "path": "cli\\validators.py",
  "ext": ".py",
  "anchor": "validators_py"
}
```
## validators_py
*Chemin* : `cli\validators.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.validators

Purpose: Validation des arguments CLI, param√®tres et fichiers.

Role in pipeline: Validation avant ex√©cution des commandes.

Key components: validate_strategy, validate_data_file, validate_params, parse_param_grid

Dependencies: pathlib, json, strategies

Conventions: Retourne (success, value_or_error) tuples pour gestion d'erreur propre.

Read-if: Ajout de nouvelles validations CLI.

Skip-if: Utilisation des commandes existantes.
"""

import json
import os
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import pandas as pd


# =============================================================================
# DATACLASSES R√âSULTATS
# =============================================================================

@dataclass
class ValidationResult:
    """R√©sultat d'une validation."""
    success: bool
    value: Any = None
    error: Optional[str] = None
    warnings: List[str] = None

    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []


# =============================================================================
# VALIDATION STRAT√âGIE
# =============================================================================

def validate_strategy(strategy_name: str) -> ValidationResult:
    """
    Valide qu'une strat√©gie existe dans le registre.

    Args:
        strategy_name: Nom de la strat√©gie (case-insensitive)

    Returns:
        ValidationResult avec la classe de strat√©gie si succ√®s
    """
    from strategies import get_strategy, list_strategies

    strategy_name = strategy_name.lower()
    strategy_class = get_strategy(strategy_name)

    if strategy_class is None:
        available = list_strategies()
        return ValidationResult(
            success=False,
            error=f"Strat√©gie '{strategy_name}' non trouv√©e. "
                  f"Disponibles: {', '.join(available[:5])}..."
        )

    return ValidationResult(success=True, value=strategy_class)


def get_strategy_info(strategy_name: str) -> ValidationResult:
    """
    R√©cup√®re les informations compl√®tes d'une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        ValidationResult avec dict d'infos {class, instance, params, ranges}
    """
    result = validate_strategy(strategy_name)
    if not result.success:
        return result

    try:
        strategy_class = result.value
        strategy_instance = strategy_class()

        info = {
            "class": strategy_class,
            "instance": strategy_instance,
            "default_params": strategy_instance.default_params,
            "param_ranges": strategy_instance.param_ranges,
            "parameter_specs": getattr(strategy_instance, "parameter_specs", {}),
        }

        return ValidationResult(success=True, value=info)
    except Exception as e:
        return ValidationResult(
            success=False,
            error=f"Erreur initialisation strat√©gie: {e}"
        )


# =============================================================================
# VALIDATION FICHIERS DONN√âES
# =============================================================================

def validate_data_file(data_path: Union[str, Path],
                       env_var: str = "BACKTEST_DATA_DIR") -> ValidationResult:
    """
    Valide et r√©sout le chemin d'un fichier de donn√©es.

    Args:
        data_path: Chemin du fichier (absolu ou relatif)
        env_var: Variable d'environnement pour r√©pertoire de donn√©es

    Returns:
        ValidationResult avec Path r√©solu si succ√®s
    """
    from data.loader import resolve_data_file

    path = Path(data_path)

    # Essayer le chemin direct
    if path.exists():
        return ValidationResult(success=True, value=path)

    # Essayer avec BACKTEST_DATA_DIR
    data_dir = os.environ.get(env_var)
    if data_dir:
        alt_path = Path(data_dir) / path.name
        if alt_path.exists():
            return ValidationResult(success=True, value=alt_path)

    # Essayer dans data/sample_data
    sample_path = Path(__file__).parent.parent / "data" / "sample_data" / path.name
    if sample_path.exists():
        return ValidationResult(success=True, value=sample_path)

    # Utiliser resolve_data_file comme dernier recours
    try:
        resolved = resolve_data_file(path)
        if resolved.exists():
            return ValidationResult(success=True, value=resolved)
    except Exception:
        pass

    return ValidationResult(
        success=False,
        error=f"Fichier non trouv√©: {data_path}. "
              f"D√©finissez {env_var} ou placez le fichier dans data/sample_data/"
    )


def extract_symbol_timeframe(data_path: Path,
                             default_symbol: str = "UNKNOWN",
                             default_timeframe: str = "1h") -> Tuple[str, str]:
    """
    Extrait symbol et timeframe du nom de fichier.

    Format attendu: SYMBOL_TIMEFRAME.ext (ex: BTCUSDC_1h.parquet)

    Args:
        data_path: Chemin du fichier
        default_symbol: Symbol par d√©faut si non d√©tectable
        default_timeframe: Timeframe par d√©faut si non d√©tectable

    Returns:
        Tuple (symbol, timeframe)
    """
    stem = data_path.stem
    parts = stem.split("_")

    symbol = parts[0] if parts else default_symbol
    timeframe = parts[1] if len(parts) > 1 else default_timeframe

    return symbol, timeframe


# =============================================================================
# VALIDATION PARAM√àTRES
# =============================================================================

def validate_param_value(name: str, value: Any,
                        min_val: float = None,
                        max_val: float = None,
                        param_type: str = None) -> ValidationResult:
    """
    Valide une valeur de param√®tre.

    Args:
        name: Nom du param√®tre
        value: Valeur √† valider
        min_val: Valeur minimum autoris√©e
        max_val: Valeur maximum autoris√©e
        param_type: Type attendu ("int" ou "float")

    Returns:
        ValidationResult avec valeur convertie si succ√®s
    """
    warnings = []

    # Conversion de type
    try:
        if param_type == "int":
            value = int(value)
        elif param_type == "float":
            value = float(value)
    except (ValueError, TypeError) as e:
        return ValidationResult(
            success=False,
            error=f"Param√®tre '{name}': conversion impossible vers {param_type}: {e}"
        )

    # Validation bornes
    if min_val is not None and value < min_val:
        return ValidationResult(
            success=False,
            error=f"Param√®tre '{name}': valeur {value} < minimum {min_val}"
        )

    if max_val is not None and value > max_val:
        return ValidationResult(
            success=False,
            error=f"Param√®tre '{name}': valeur {value} > maximum {max_val}"
        )

    return ValidationResult(success=True, value=value, warnings=warnings)


def parse_param_grid(json_string: str) -> ValidationResult:
    """
    Parse une grille de param√®tres depuis JSON.

    Format attendu: {"param1": [v1, v2, ...], "param2": [v1, v2, ...]}

    Args:
        json_string: String JSON de la grille

    Returns:
        ValidationResult avec dict de grille si succ√®s
    """
    try:
        grid = json.loads(json_string)

        if not isinstance(grid, dict):
            return ValidationResult(
                success=False,
                error="La grille doit √™tre un objet JSON {param: [valeurs]}"
            )

        # Valider que chaque valeur est une liste
        for param, values in grid.items():
            if not isinstance(values, list):
                return ValidationResult(
                    success=False,
                    error=f"Param√®tre '{param}': doit √™tre une liste de valeurs"
                )
            if len(values) == 0:
                return ValidationResult(
                    success=False,
                    error=f"Param√®tre '{param}': liste vide non autoris√©e"
                )

        return ValidationResult(success=True, value=grid)

    except json.JSONDecodeError as e:
        return ValidationResult(
            success=False,
            error=f"JSON invalide: {e}"
        )


def parse_params_string(params_string: str) -> ValidationResult:
    """
    Parse des param√®tres depuis une string key=value.

    Format: "param1=value1,param2=value2" ou JSON

    Args:
        params_string: String de param√®tres

    Returns:
        ValidationResult avec dict de param√®tres si succ√®s
    """
    if not params_string:
        return ValidationResult(success=True, value={})

    # Essayer d'abord JSON
    try:
        params = json.loads(params_string)
        if isinstance(params, dict):
            return ValidationResult(success=True, value=params)
    except json.JSONDecodeError:
        pass

    # Parser format key=value,key=value
    params = {}
    try:
        for pair in params_string.split(","):
            if "=" not in pair:
                return ValidationResult(
                    success=False,
                    error=f"Format invalide: '{pair}'. Attendu: key=value"
                )

            key, value = pair.split("=", 1)
            key = key.strip()
            value = value.strip()

            # Auto-conversion des types
            if value.lower() == "true":
                params[key] = True
            elif value.lower() == "false":
                params[key] = False
            else:
                try:
                    # Essayer int
                    params[key] = int(value)
                except ValueError:
                    try:
                        # Essayer float
                        params[key] = float(value)
                    except ValueError:
                        # Garder string
                        params[key] = value

        return ValidationResult(success=True, value=params)

    except Exception as e:
        return ValidationResult(
            success=False,
            error=f"Erreur parsing param√®tres: {e}"
        )


# =============================================================================
# VALIDATION DATES
# =============================================================================

def validate_date_range(start: Optional[str], end: Optional[str]) -> ValidationResult:
    """
    Valide une plage de dates.

    Args:
        start: Date de d√©but (format YYYY-MM-DD ou None)
        end: Date de fin (format YYYY-MM-DD ou None)

    Returns:
        ValidationResult avec tuple (start_ts, end_ts) si succ√®s
    """
    start_ts = None
    end_ts = None

    if start:
        try:
            start_ts = pd.Timestamp(start, tz="UTC")
        except Exception as e:
            return ValidationResult(
                success=False,
                error=f"Date de d√©but invalide: {start}. Format attendu: YYYY-MM-DD"
            )

    if end:
        try:
            end_ts = pd.Timestamp(end, tz="UTC")
        except Exception as e:
            return ValidationResult(
                success=False,
                error=f"Date de fin invalide: {end}. Format attendu: YYYY-MM-DD"
            )

    if start_ts and end_ts and start_ts >= end_ts:
        return ValidationResult(
            success=False,
            error=f"Date de d√©but ({start}) >= date de fin ({end})"
        )

    return ValidationResult(success=True, value=(start_ts, end_ts))


def apply_date_filter(df: pd.DataFrame,
                     start: Optional[str],
                     end: Optional[str]) -> ValidationResult:
    """
    Applique un filtre de dates √† un DataFrame OHLCV.

    Args:
        df: DataFrame avec index DatetimeIndex
        start: Date de d√©but (format YYYY-MM-DD ou None)
        end: Date de fin (format YYYY-MM-DD ou None)

    Returns:
        ValidationResult avec DataFrame filtr√© si succ√®s
    """
    if not start and not end:
        return ValidationResult(success=True, value=df)

    result = validate_date_range(start, end)
    if not result.success:
        return result

    start_ts, end_ts = result.value
    filtered_df = df.copy()

    if start_ts is not None:
        filtered_df = filtered_df[filtered_df.index >= start_ts]
    if end_ts is not None:
        filtered_df = filtered_df[filtered_df.index <= end_ts]

    if filtered_df.empty:
        return ValidationResult(
            success=False,
            error=f"Aucune donn√©e dans la p√©riode {start} - {end}"
        )

    return ValidationResult(success=True, value=filtered_df)


# =============================================================================
# VALIDATION M√âTRIQUES
# =============================================================================

METRIC_ALIASES = {
    "sharpe": "sharpe_ratio",
    "sortino": "sortino_ratio",
    "total_return": "total_return_pct",
    "return": "total_return_pct",
    "pnl": "total_pnl",
    "drawdown": "max_drawdown_pct",
    "max_drawdown": "max_drawdown_pct",
    "winrate": "win_rate_pct",
    "win_rate": "win_rate_pct",
    # Formes compl√®tes
    "sharpe_ratio": "sharpe_ratio",
    "sortino_ratio": "sortino_ratio",
    "total_return_pct": "total_return_pct",
    "total_pnl": "total_pnl",
    "max_drawdown_pct": "max_drawdown_pct",
    "win_rate_pct": "win_rate_pct",
    "profit_factor": "profit_factor",
}


def normalize_metric_name(metric: str) -> str:
    """Normalise le nom d'une m√©trique CLI en nom interne."""
    return METRIC_ALIASES.get(metric.lower(), metric)


def validate_metric(metric: str) -> ValidationResult:
    """
    Valide un nom de m√©trique.

    Args:
        metric: Nom de la m√©trique (peut √™tre un alias)

    Returns:
        ValidationResult avec nom normalis√© si succ√®s
    """
    normalized = normalize_metric_name(metric)

    valid_metrics = set(METRIC_ALIASES.values())

    if normalized not in valid_metrics:
        return ValidationResult(
            success=False,
            error=f"M√©trique '{metric}' inconnue. "
                  f"Valides: {', '.join(sorted(valid_metrics))}"
        )

    return ValidationResult(success=True, value=normalized)


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Dataclasses
    "ValidationResult",
    # Strat√©gies
    "validate_strategy",
    "get_strategy_info",
    # Fichiers
    "validate_data_file",
    "extract_symbol_timeframe",
    # Param√®tres
    "validate_param_value",
    "parse_param_grid",
    "parse_params_string",
    # Dates
    "validate_date_range",
    "apply_date_filter",
    # M√©triques
    "METRIC_ALIASES",
    "normalize_metric_name",
    "validate_metric",
]
```
<!-- MODULE-END: validators.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "cli\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `cli\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: cli.__init__

Purpose: Package CLI - parser argparse, routing commands, entry point.

Role in pipeline: CLI interface

Key components: create_parser(), add_subcommands(), main()

Inputs: sys.argv command-line args

Outputs: Dispatched to cmd_* functions

Dependencies: argparse, .commands

Conventions: Sous-commandes via add_parser(); --verbose/-v global; help auto-generated.

Read-if: Ajout/modification sous-commande ou argument structure.

Skip-if: Vous appelez main() depuis __main__.py.
"""

import argparse
from typing import Optional

from .commands import (
    cmd_analyze,
    cmd_backtest,
    cmd_check_gpu,
    cmd_export,
    cmd_grid_backtest,
    cmd_indicators,
    cmd_info,
    cmd_list,
    cmd_llm_optimize,
    cmd_optuna,
    cmd_sweep,
    cmd_validate,
    cmd_visualize,
)


def create_parser() -> argparse.ArgumentParser:
    """Cr√©e le parser principal avec toutes les sous-commandes."""

    parser = argparse.ArgumentParser(
        prog="backtest_core",
        description="Moteur de backtesting pour strat√©gies de trading",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  %(prog)s list strategies              Lister toutes les strat√©gies
  %(prog)s list indicators              Lister tous les indicateurs
  %(prog)s info strategy bollinger_atr  D√©tails d'une strat√©gie
  %(prog)s backtest -s ema_cross -d data.parquet
  %(prog)s sweep -s ema_cross -d data.parquet --granularity 0.3
        """
    )

    # Parser parent avec arguments communs
    common_parser = argparse.ArgumentParser(add_help=False)
    common_parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Mode verbose (debug)"
    )
    common_parser.add_argument(
        "-q", "--quiet",
        action="store_true",
        help="Mode silencieux"
    )
    common_parser.add_argument(
        "--no-color",
        action="store_true",
        help="D√©sactiver les couleurs"
    )
    common_parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Seed pour reproductibilit√© (d√©faut: 42)"
    )
    common_parser.add_argument(
        "--config",
        type=str,
        help="Fichier de configuration TOML"
    )

    # Sous-commandes
    subparsers = parser.add_subparsers(
        title="Commandes",
        dest="command",
        description="Commandes disponibles"
    )

    # === LIST ===
    list_parser = subparsers.add_parser(
        "list",
        parents=[common_parser],
        help="Lister les ressources disponibles",
        description="Liste les strat√©gies, indicateurs, donn√©es ou presets"
    )
    list_parser.add_argument(
        "resource",
        choices=["strategies", "indicators", "data", "presets"],
        help="Type de ressource √† lister"
    )
    list_parser.add_argument(
        "--json",
        action="store_true",
        help="Sortie au format JSON"
    )

    # === INDICATORS (alias list indicators) ===
    indicators_parser = subparsers.add_parser(
        "indicators",
        parents=[common_parser],
        help="Lister les indicateurs disponibles",
        description="Alias de: list indicators"
    )
    indicators_parser.add_argument(
        "--json",
        action="store_true",
        help="Sortie au format JSON"
    )

    # === INFO ===
    info_parser = subparsers.add_parser(
        "info",
        parents=[common_parser],
        help="Informations d√©taill√©es sur une ressource",
        description="Affiche les param√®tres et documentation d'une strat√©gie ou indicateur"
    )
    info_parser.add_argument(
        "resource_type",
        choices=["strategy", "indicator"],
        help="Type de ressource"
    )
    info_parser.add_argument(
        "name",
        help="Nom de la ressource"
    )
    info_parser.add_argument(
        "--json",
        action="store_true",
        help="Sortie au format JSON"
    )

    # === BACKTEST ===
    backtest_parser = subparsers.add_parser(
        "backtest",
        parents=[common_parser],
        help="Ex√©cuter un backtest",
        description="Lance un backtest avec une strat√©gie et des donn√©es"
    )
    backtest_parser.add_argument(
        "-s", "--strategy",
        required=True,
        help="Nom de la strat√©gie"
    )
    backtest_parser.add_argument(
        "-d", "--data",
        required=True,
        help="Chemin vers le fichier de donn√©es OHLCV"
    )
    backtest_parser.add_argument(
        "--start",
        type=str,
        help="Date de debut (format ISO)"
    )
    backtest_parser.add_argument(
        "--end",
        type=str,
        help="Date de fin (format ISO)"
    )
    backtest_parser.add_argument(
        "--symbol",
        type=str,
        help="Symbole (override si non present dans le nom du fichier)"
    )
    backtest_parser.add_argument(
        "--timeframe",
        type=str,
        help="Timeframe (override si non present dans le nom du fichier)"
    )
    backtest_parser.add_argument(
        "-p", "--params",
        type=str,
        default="{}",
        help="Param√®tres strat√©gie en JSON (d√©faut: {})"
    )
    backtest_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    backtest_parser.add_argument(
        "--fees-bps",
        type=int,
        default=10,
        help="Frais en basis points (d√©faut: 10 = 0.1%%)"
    )
    backtest_parser.add_argument(
        "--slippage-bps",
        type=float,
        help="Slippage en basis points (defaut: config)"
    )
    backtest_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour les r√©sultats"
    )
    backtest_parser.add_argument(
        "--format",
        choices=["json", "csv", "parquet"],
        default="json",
        help="Format de sortie (d√©faut: json)"
    )

    # === SWEEP ===
    sweep_parser = subparsers.add_parser(
        "sweep",
        parents=[common_parser],
        help="Optimisation param√©trique",
        description="Lance une optimisation sur grille de param√®tres",
        aliases=["optimize"]
    )
    sweep_parser.add_argument(
        "-s", "--strategy",
        required=True,
        help="Nom de la strat√©gie"
    )
    sweep_parser.add_argument(
        "-d", "--data",
        required=True,
        help="Chemin vers le fichier de donn√©es OHLCV"
    )
    sweep_parser.add_argument(
        "--start",
        type=str,
        help="Date de debut (format ISO)"
    )
    sweep_parser.add_argument(
        "--end",
        type=str,
        help="Date de fin (format ISO)"
    )
    sweep_parser.add_argument(
        "--symbol",
        type=str,
        help="Symbole (override si non present dans le nom du fichier)"
    )
    sweep_parser.add_argument(
        "--timeframe",
        type=str,
        help="Timeframe (override si non present dans le nom du fichier)"
    )
    sweep_parser.add_argument(
        "-g", "--granularity",
        type=float,
        default=0.5,
        help="Granularit√© (0.0=fin, 1.0=grossier, d√©faut: 0.5)"
    )
    sweep_parser.add_argument(
        "--include-optional-params",
        action="store_true",
        help="Inclure les param√®tres optionnels (ex: leverage) dans la grille"
    )
    sweep_parser.add_argument(
        "--max-combinations",
        type=int,
        default=10000,
        help="Limite de combinaisons (d√©faut: 10000)"
    )
    sweep_parser.add_argument(
        "-m", "--metric",
        choices=["sharpe", "sharpe_ratio", "sortino", "sortino_ratio", "total_return", "max_drawdown", "win_rate", "profit_factor"],
        default="sharpe",
        help="M√©trique d'optimisation. Accepte sharpe/sharpe_ratio, sortino/sortino_ratio (d√©faut: sharpe)"
    )
    sweep_parser.add_argument(

        "--parallel",
        type=int,
        default=4,
        help="Nombre de workers parall√®les (d√©faut: 12)"
    )
    sweep_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour les r√©sultats"
    )
    sweep_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    sweep_parser.add_argument(
        "--fees-bps",
        type=int,
        default=10,
        help="Frais en basis points (d√©faut: 10)"
    )
    sweep_parser.add_argument(
        "--slippage-bps",
        type=float,
        help="Slippage en basis points (defaut: config)"
    )
    sweep_parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="Nombre de meilleurs r√©sultats √† afficher (d√©faut: 10)"
    )

    # === VALIDATE ===
    validate_parser = subparsers.add_parser(
        "validate",
        parents=[common_parser],
        help="Valider configuration",
        description="V√©rifie l'int√©grit√© des strat√©gies, indicateurs et donn√©es"
    )
    validate_parser.add_argument(
        "--strategy",
        type=str,
        help="Valider une strat√©gie sp√©cifique"
    )
    validate_parser.add_argument(
        "--data",
        type=str,
        help="Valider un fichier de donn√©es"
    )
    validate_parser.add_argument(
        "--all",
        action="store_true",
        help="Valider tout le syst√®me"
    )

    # === EXPORT ===
    export_parser = subparsers.add_parser(
        "export",
        parents=[common_parser],
        help="Exporter r√©sultats",
        description="Exporte les r√©sultats dans diff√©rents formats"
    )
    export_parser.add_argument(
        "-i", "--input",
        required=True,
        help="Fichier de r√©sultats √† exporter"
    )
    export_parser.add_argument(
        "-f", "--format",
        choices=["html", "excel", "csv"],
        default="html",
        help="Format d'export (d√©faut: html)"
    )
    export_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie"
    )
    export_parser.add_argument(
        "--template",
        type=str,
        help="Template de rapport personnalis√©"
    )

    # === OPTUNA ===
    optuna_parser = subparsers.add_parser(
        "optuna",
        parents=[common_parser],
        help="Optimisation bay√©sienne via Optuna",
        description="Lance une optimisation intelligente des param√®tres (10-100x plus rapide que sweep)"
    )
    optuna_parser.add_argument(
        "-s", "--strategy",
        required=True,
        help="Nom de la strat√©gie"
    )
    optuna_parser.add_argument(
        "-d", "--data",
        required=True,
        help="Chemin vers le fichier de donn√©es OHLCV"
    )
    optuna_parser.add_argument(
        "--start",
        type=str,
        help="Date de debut (format ISO)"
    )
    optuna_parser.add_argument(
        "--end",
        type=str,
        help="Date de fin (format ISO)"
    )
    optuna_parser.add_argument(
        "--symbol",
        type=str,
        help="Symbole (override si non present dans le nom du fichier)"
    )
    optuna_parser.add_argument(
        "--timeframe",
        type=str,
        help="Timeframe (override si non present dans le nom du fichier)"
    )
    optuna_parser.add_argument(
        "-n", "--n-trials",
        type=int,
        default=100,
        help="Nombre de trials (d√©faut: 100)"
    )
    optuna_parser.add_argument(
        "-m", "--metric",
        default="sharpe",
        help="M√©trique √† optimiser. Multi-objectif: 'sharpe,max_drawdown' (d√©faut: sharpe)"
    )
    optuna_parser.add_argument(
        "--sampler",
        choices=["tpe", "cmaes", "random"],
        default="tpe",
        help="Algorithme de sampling (d√©faut: tpe)"
    )
    optuna_parser.add_argument(
        "--pruning",
        action="store_true",
        help="Activer le pruning (arr√™t pr√©coce des trials peu prometteurs)"
    )
    optuna_parser.add_argument(
        "--pruner",
        choices=["median", "hyperband"],
        default="median",
        help="Type de pruner (d√©faut: median)"
    )
    optuna_parser.add_argument(
        "--multi-objective",
        action="store_true",
        help="Mode multi-objectif (Pareto). Utiliser -m 'sharpe,max_drawdown'"
    )
    optuna_parser.add_argument(
        "--param-space",
        type=str,
        help="Espace de param√®tres en JSON (sinon auto-d√©tect√©)"
    )
    optuna_parser.add_argument(
        "-c", "--constraints",
        nargs="*",
        help="Contraintes: 'slow_period,>,fast_period' (param1,op,param2)"
    )
    optuna_parser.add_argument(
        "--timeout",
        type=int,
        help="Timeout en secondes (optionnel)"
    )
    optuna_parser.add_argument(
        "--parallel",
        type=int,
        default=1,
        help="Nombre de jobs parall√®les (d√©faut: 1, utiliser prudemment)"
    )
    optuna_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    optuna_parser.add_argument(
        "--fees-bps",
        type=int,
        default=10,
        help="Frais en basis points (d√©faut: 10)"
    )
    optuna_parser.add_argument(
        "--slippage-bps",
        type=float,
        help="Slippage en basis points (defaut: config)"
    )
    optuna_parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="Nombre de meilleurs r√©sultats √† afficher (d√©faut: 10)"
    )
    optuna_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour les r√©sultats"
    )
    optuna_parser.add_argument(
        "--early-stop-patience",
        type=int,
        help="Arr√™t anticip√© apr√®s N trials sans am√©lioration (None = d√©sactiv√©)"
    )

    # === VISUALIZE ===
    visualize_parser = subparsers.add_parser(
        "visualize",
        parents=[common_parser],
        help="Visualiser les r√©sultats de backtest",
        description="G√©n√®re des graphiques interactifs (candlesticks + trades)"
    )
    visualize_parser.add_argument(
        "-i", "--input",
        required=True,
        help="Fichier de r√©sultats √† visualiser (JSON)"
    )
    visualize_parser.add_argument(
        "-d", "--data",
        type=str,
        help="Fichier de donn√©es OHLCV pour les candlesticks"
    )
    visualize_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier HTML de sortie"
    )
    visualize_parser.add_argument(
        "--html",
        action="store_true",
        help="G√©n√©rer automatiquement un fichier HTML"
    )
    visualize_parser.add_argument(
        "-m", "--metric",
        type=str,
        help="M√©trique pour s√©lectionner le meilleur (pour sweep/optuna)"
    )
    visualize_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    visualize_parser.add_argument(
        "--fees-bps",
        type=int,
        default=10,
        help="Frais en basis points (d√©faut: 10)"
    )
    visualize_parser.add_argument(
        "--no-show",
        action="store_true",
        help="Ne pas ouvrir le graphique dans le navigateur"
    )

    # === CHECK-GPU ===
    check_gpu_parser = subparsers.add_parser(
        "check-gpu",
        parents=[common_parser],
        help="Diagnostic GPU et benchmark",
        description="V√©rifie CuPy, CUDA, GPUs disponibles et benchmark CPU vs GPU"
    )
    check_gpu_parser.add_argument(
        "--benchmark",
        action="store_true",
        help="Ex√©cuter un benchmark CPU vs GPU (EMA 10k points)"
    )

    # === LLM-OPTIMIZE ===
    llm_optimize_parser = subparsers.add_parser(
        "llm-optimize",
        parents=[common_parser],
        help="Optimisation LLM multi-agents",
        description="Lance l'orchestrateur multi-agents (Analyst/Strategist/Critic/Validator) pour optimisation intelligente",
        aliases=["orchestrate"]
    )
    llm_optimize_parser.add_argument(
        "-s", "--strategy",
        required=True,
        help="Nom de la strat√©gie"
    )
    llm_optimize_parser.add_argument(
        "--symbol",
        required=True,
        help="Symbole (ex: BTCUSDC)"
    )
    llm_optimize_parser.add_argument(
        "--timeframe",
        required=True,
        help="Timeframe (ex: 1h, 30m, 1d)"
    )
    llm_optimize_parser.add_argument(
        "--start",
        type=str,
        help="Date de d√©but (format ISO)"
    )
    llm_optimize_parser.add_argument(
        "--end",
        type=str,
        help="Date de fin (format ISO)"
    )
    llm_optimize_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    llm_optimize_parser.add_argument(
        "--max-iterations",
        type=int,
        default=10,
        help="Nombre max d'it√©rations LLM (d√©faut: 10)"
    )
    llm_optimize_parser.add_argument(
        "--model",
        default="deepseek-r1-distill:14b",
        help="Mod√®le LLM √† utiliser (d√©faut: deepseek-r1-distill:14b)"
    )
    llm_optimize_parser.add_argument(
        "--temperature",
        type=float,
        default=0.7,
        help="Temp√©rature LLM (d√©faut: 0.7)"
    )
    llm_optimize_parser.add_argument(
        "--max-tokens",
        type=int,
        default=4096,
        help="Max tokens LLM (d√©faut: 4096)"
    )
    llm_optimize_parser.add_argument(
        "--timeout",
        type=int,
        default=900,
        help="Timeout LLM en secondes (d√©faut: 900 = 15min)"
    )
    llm_optimize_parser.add_argument(
        "--min-sharpe",
        type=float,
        default=1.0,
        help="Sharpe ratio minimum requis (d√©faut: 1.0)"
    )
    llm_optimize_parser.add_argument(
        "--max-drawdown",
        type=float,
        default=0.20,
        help="Max drawdown limite (fraction, d√©faut: 0.20 = 20%%)"
    )
    llm_optimize_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour les r√©sultats"
    )

    # === GRID-BACKTEST ===
    grid_backtest_parser = subparsers.add_parser(
        "grid-backtest",
        parents=[common_parser],
        help="Backtest en mode grille",
        description="Ex√©cute un backtest sur une grille de param√®tres (diff√©rent de sweep)",
        aliases=["grid"]
    )
    grid_backtest_parser.add_argument(
        "-s", "--strategy",
        required=True,
        help="Nom de la strat√©gie"
    )
    grid_backtest_parser.add_argument(
        "--symbol",
        required=True,
        help="Symbole (ex: BTCUSDC)"
    )
    grid_backtest_parser.add_argument(
        "--timeframe",
        required=True,
        help="Timeframe (ex: 1h, 30m, 1d)"
    )
    grid_backtest_parser.add_argument(
        "--start",
        type=str,
        help="Date de d√©but (format ISO)"
    )
    grid_backtest_parser.add_argument(
        "--end",
        type=str,
        help="Date de fin (format ISO)"
    )
    grid_backtest_parser.add_argument(
        "--capital",
        type=float,
        default=10000.0,
        help="Capital initial (d√©faut: 10000)"
    )
    grid_backtest_parser.add_argument(
        "--fees-bps",
        type=int,
        default=10,
        help="Frais en basis points (d√©faut: 10)"
    )
    grid_backtest_parser.add_argument(
        "--slippage-bps",
        type=float,
        help="Slippage en basis points (d√©faut: config)"
    )
    grid_backtest_parser.add_argument(
        "--param-grid",
        type=str,
        help="Grille de param√®tres en JSON (ex: '{\"atr_period\": [10, 14, 20]}'). Si omis, grille auto depuis param_ranges"
    )
    grid_backtest_parser.add_argument(
        "--include-optional-params",
        action="store_true",
        help="Inclure les param√®tres optionnels (ex: leverage) dans la grille auto"
    )
    grid_backtest_parser.add_argument(
        "--max-combinations",
        type=int,
        default=1000,
        help="Limite de combinaisons (d√©faut: 1000)"
    )
    grid_backtest_parser.add_argument(
        "-m", "--metric",
        choices=["sharpe_ratio", "sortino_ratio", "total_return_pct", "max_drawdown", "win_rate", "profit_factor"],
        default="sharpe_ratio",
        help="M√©trique pour trier les r√©sultats (d√©faut: sharpe_ratio)"
    )
    grid_backtest_parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="Nombre de meilleurs r√©sultats √† afficher (d√©faut: 10)"
    )
    grid_backtest_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour les r√©sultats"
    )

    # === ANALYZE ===
    analyze_parser = subparsers.add_parser(
        "analyze",
        parents=[common_parser],
        help="Analyser les r√©sultats de backtests",
        description="Analyse les r√©sultats de backtests stock√©s dans backtest_results/"
    )
    analyze_parser.add_argument(
        "--results-dir",
        type=str,
        default="backtest_results",
        help="R√©pertoire des r√©sultats (d√©faut: backtest_results)"
    )
    analyze_parser.add_argument(
        "--profitable-only",
        action="store_true",
        help="Afficher uniquement les runs profitables"
    )
    analyze_parser.add_argument(
        "--sort-by",
        type=str,
        default="total_pnl",
        help="M√©trique de tri (d√©faut: total_pnl)"
    )
    analyze_parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="Nombre de runs √† afficher (d√©faut: 10)"
    )
    analyze_parser.add_argument(
        "--stats",
        action="store_true",
        help="Afficher les statistiques globales"
    )
    analyze_parser.add_argument(
        "-o", "--output",
        type=str,
        help="Fichier de sortie pour l'analyse"
    )

    return parser


def main(args: Optional[list] = None) -> int:
    """Point d'entr√©e principal du CLI."""
    parser = create_parser()
    parsed = parser.parse_args(args)

    # Si aucune commande, afficher l'aide
    if parsed.command is None:
        parser.print_help()
        return 0

    # Configuration globale
    import numpy as np
    np.random.seed(parsed.seed)

    # Dispatcher vers la commande appropri√©e
    commands = {
        "list": cmd_list,
        "indicators": cmd_indicators,
        "info": cmd_info,
        "backtest": cmd_backtest,
        "sweep": cmd_sweep,
        "optimize": cmd_sweep,
        "optuna": cmd_optuna,
        "validate": cmd_validate,
        "export": cmd_export,
        "visualize": cmd_visualize,
        "check-gpu": cmd_check_gpu,
        "llm-optimize": cmd_llm_optimize,
        "orchestrate": cmd_llm_optimize,
        "grid-backtest": cmd_grid_backtest,
        "grid": cmd_grid_backtest,
        "analyze": cmd_analyze,
    }

    try:
        handler = commands.get(parsed.command)
        if handler:
            return handler(parsed)
        else:
            print(f"Commande inconnue: {parsed.command}")
            return 1
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrompu par l'utilisateur")
        return 130
    except Exception as e:
        if parsed.verbose:
            import traceback
            traceback.print_exc()
        else:
            print(f"‚ùå Erreur: {e}")
        return 1


__all__ = ["main", "create_parser"]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: __main__.py -->
```json
{
  "name": "__main__.py",
  "path": "cli\\__main__.py",
  "ext": ".py",
  "anchor": "main___py"
}
```
## main___py
*Chemin* : `cli\__main__.py`  
*Type* : `.py`  

```python
from __future__ import annotations

from . import main


if __name__ == "__main__":
    raise SystemExit(main())
```
<!-- MODULE-END: __main__.py -->

<!-- MODULE-START: config.py -->
```json
{
  "name": "config.py",
  "path": "data\\config.py",
  "ext": ".py",
  "anchor": "config_py"
}
```
## config_py
*Chemin* : `data\config.py`  
*Type* : `.py`  

```python
"""
Module-ID: data.config

Purpose: Configuration et logique m√©tier pour la gestion des donn√©es OHLCV.
         Extraction de la logique depuis ui/sidebar.py (DDD refactoring).

Role in pipeline: domain / configuration

Key components:
- scan_data_availability: Scan multi-token des donn√©es disponibles
- get_intelligent_timeframe_defaults: S√©lection optimis√©e des TF
- validate_period_for_tokens: Validation multi-token d'une p√©riode
- generate_random_token_suggestions: Suggestions al√©atoires

Dependencies: data.loader, pandas

Conventions: Fonctions pures (pas de Streamlit), retournent des dicts/dataclasses

Read-if: Configuration des donn√©es pour UI ou CLI
Skip-if: Logique de trading
"""

from __future__ import annotations

import random
from dataclasses import dataclass, field
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple, NamedTuple

import pandas as pd
import numpy as np

# ============================================================================
# CONSTANTS
# ============================================================================

# Nombre de suggestions al√©atoires √† afficher
RANDOM_SLOTS_COUNT = 6

# Priorit√© des timeframes pour s√©lection intelligente
TIMEFRAME_PRIORITY_MAP = {
    "1m": 1, "3m": 2, "5m": 3, "15m": 4, "30m": 5,
    "1h": 6, "2h": 7, "4h": 8, "6h": 9, "8h": 10, "12h": 11,
    "1d": 12, "3d": 13, "1w": 14, "1M": 15
}

# Facteur de fr√©quence de trading par timeframe (opportunit√©s relatives)
TIMEFRAME_FREQUENCY_FACTOR = {
    "1m": 1440,   # 1440 barres/jour
    "3m": 480,    # 480 barres/jour
    "5m": 288,    # 288 barres/jour
    "15m": 96,    # 96 barres/jour
    "30m": 48,    # 48 barres/jour
    "1h": 24,     # 24 barres/jour
    "2h": 12,     # 12 barres/jour
    "4h": 6,      # 6 barres/jour
    "6h": 4,      # 4 barres/jour
    "8h": 3,      # 3 barres/jour
    "12h": 2,     # 2 barres/jour
    "1d": 1,      # 1 barre/jour
    "3d": 0.33,   # 0.33 barre/jour
    "1w": 0.14,   # 0.14 barre/jour
    "1M": 0.03    # 0.03 barre/jour
}

# Cat√©gorisation des timeframes pour analyse ind√©pendante
TIMEFRAME_CATEGORIES = {
    "scalping": ["1m", "3m", "5m"],           # Trading haute fr√©quence
    "intraday": ["15m", "30m", "1h", "2h"],   # Trading intraday
    "swing": ["4h", "6h", "8h", "12h"],        # Swing trading
    "position": ["1d", "3d", "1w", "1M"]       # Position trading
}

# Facteurs de tol√©rance aux gaps par cat√©gorie
CATEGORY_GAP_TOLERANCE = {
    "scalping": 0.02,    # 2% de gaps max (tr√®s sensible)
    "intraday": 0.05,    # 5% de gaps max (sensible)
    "swing": 0.10,       # 10% de gaps max (mod√©r√©)
    "position": 0.20     # 20% de gaps max (tol√©rant)
}


class OptimalPeriod(NamedTuple):
    """P√©riode optimale avec m√©tadonn√©es de qualit√©."""
    start_date: pd.Timestamp
    end_date: pd.Timestamp
    completeness_score: float  # 0-100%
    tokens_complete: int
    tokens_total: int
    avg_data_density: float
    description: str
    category: str = "mixed"  # Cat√©gorie de timeframe
    timeframes: List[str] = None  # Timeframes concern√©s


class CategoryAnalysis(NamedTuple):
    """Analyse par cat√©gorie de timeframes."""
    category: str
    timeframes: List[str]
    symbols: List[str]
    optimal_periods: List[OptimalPeriod]
    best_period: Optional[OptimalPeriod]
    data_quality_score: float
    trading_opportunities_score: float


class DataGap(NamedTuple):
    """Repr√©sente un gap dans les donn√©es."""
    start: pd.Timestamp
    end: pd.Timestamp
    duration_days: float
    token: str
    timeframe: str


# ============================================================================
# CONFIGURATION CONSTANTS
# ============================================================================

RANDOM_SLOTS_COUNT = 6

TIMEFRAME_PRIORITY_MAP = {
    "1m": 1, "3m": 2, "5m": 3, "15m": 4, "30m": 5,
    "1h": 6, "2h": 7, "4h": 8, "6h": 9, "12h": 10,
    "1d": 11, "1w": 12, "1M": 13
}


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class DataAvailabilityResult:
    """R√©sultat du scan de disponibilit√© des donn√©es."""
    availability: Dict[Tuple[str, str], Tuple[pd.Timestamp, pd.Timestamp]] = field(default_factory=dict)
    missing_data: List[str] = field(default_factory=list)
    common_start: Optional[pd.Timestamp] = None
    common_end: Optional[pd.Timestamp] = None
    has_common_range: bool = False
    rows: List[Dict[str, Any]] = field(default_factory=list)
    optimal_periods: List[OptimalPeriod] = field(default_factory=list)

    def to_dataframe(self) -> pd.DataFrame:
        """Convertit les lignes en DataFrame pour affichage."""
        if not self.rows:
            return pd.DataFrame()
        return pd.DataFrame(self.rows)

    def get_best_period(self) -> Optional[OptimalPeriod]:
        """Retourne la meilleure p√©riode optimale si disponible."""
        return self.optimal_periods[0] if self.optimal_periods else None


@dataclass
class PeriodValidationResult:
    """R√©sultat de la validation d'une p√©riode."""
    tokens_ok: List[str] = field(default_factory=list)
    tokens_partial: List[str] = field(default_factory=list)
    tokens_missing: List[str] = field(default_factory=list)
    all_ok: bool = False


# ============================================================================
# DATA DISCOVERY FUNCTIONS
# ============================================================================

def get_data_date_range(symbol: str, timeframe: str) -> Optional[Tuple[pd.Timestamp, pd.Timestamp]]:
    """
    R√©cup√®re la plage de dates disponibles pour un symbole/timeframe.

    Args:
        symbol: Le symbole (ex: "BTCUSDC")
        timeframe: Le timeframe (ex: "1h")

    Returns:
        Tuple (start, end) ou None si donn√©es indisponibles
    """
    try:
        from data.loader import load_ohlcv
        df = load_ohlcv(symbol, timeframe)
        if df is not None and not df.empty:
            return (df.index[0], df.index[-1])
    except Exception:
        pass
    return None


def check_data_completeness(
    symbol: str,
    timeframe: str,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None
) -> Tuple[bool, str, int]:
    """
    V√©rifie la compl√©tude des donn√©es dans une plage sp√©cifique.

    Cette fonction charge effectivement les donn√©es avec filtrage pour d√©tecter
    les trous ou donn√©es manquantes que la simple plage d√©but/fin ne r√©v√®le pas.

    Args:
        symbol: Le symbole (ex: "BTCUSDC")
        timeframe: Le timeframe (ex: "1h")
        start_date: Date d√©but du filtrage (optionnel)
        end_date: Date fin du filtrage (optionnel)

    Returns:
        Tuple (is_complete, message, actual_rows)
        - is_complete: True si donn√©es compl√®tes dans la plage
        - message: Description de l'√©tat des donn√©es
        - actual_rows: Nombre de barres effectivement disponibles
    """
    try:
        from data.loader import load_ohlcv

        # Charger avec filtrage de dates si sp√©cifi√©
        start_str = start_date.strftime("%Y-%m-%d") if start_date else None
        end_str = end_date.strftime("%Y-%m-%d") if end_date else None

        df = load_ohlcv(symbol, timeframe, start=start_str, end=end_str)

        if df is None or df.empty:
            return False, f"Aucune donn√©e disponible pour {symbol}/{timeframe}", 0

        actual_rows = len(df)
        period_start = df.index[0]
        period_end = df.index[-1]

        # Calculer la p√©riode effective charg√©e
        period_days = (period_end - period_start).days

        # Estimation approximative du nombre de barres attendues
        # (pas parfait car d√©pend des week-ends/jours f√©ri√©s, mais donne une id√©e)
        if "m" in timeframe:
            minutes_per_bar = int(timeframe.replace("m", ""))
            expected_bars_per_day = 1440 / minutes_per_bar  # 24h * 60min
        elif "h" in timeframe:
            hours_per_bar = int(timeframe.replace("h", ""))
            expected_bars_per_day = 24 / hours_per_bar
        elif "d" in timeframe:
            expected_bars_per_day = 1
        else:
            expected_bars_per_day = 1  # Fallback

        expected_bars = int(period_days * expected_bars_per_day * 0.7)  # 70% pour week-ends

        # V√©rifier si les donn√©es semblent compl√®tes (seuil 50% des barres attendues)
        completeness_ratio = actual_rows / max(expected_bars, 1)

        if completeness_ratio >= 0.5:
            message = f"‚úÖ Donn√©es compl√®tes: {actual_rows} barres sur {period_days} jours"
            return True, message, actual_rows
        else:
            message = f"‚ö†Ô∏è Donn√©es incompl√®tes: {actual_rows} barres (attendu ~{expected_bars})"
            return False, message, actual_rows

    except Exception as e:
        return False, f"‚ùå Erreur chargement: {str(e)}", 0


def analyze_data_gaps(symbol: str, timeframe: str) -> List[DataGap]:
    """
    Analyse les gaps/trous dans les donn√©es d'un token/timeframe.

    Args:
        symbol: Le symbole (ex: "BTCUSDC")
        timeframe: Le timeframe (ex: "1h")

    Returns:
        Liste des gaps d√©tect√©s, tri√©s par dur√©e d√©croissante
    """
    try:
        from data.loader import load_ohlcv
        df = load_ohlcv(symbol, timeframe)

        if df is None or df.empty:
            return []

        gaps = []

        # Calculer l'intervalle attendu entre les barres
        if "m" in timeframe:
            expected_interval = pd.Timedelta(minutes=int(timeframe.replace("m", "")))
        elif "h" in timeframe:
            expected_interval = pd.Timedelta(hours=int(timeframe.replace("h", "")))
        elif "d" in timeframe:
            expected_interval = pd.Timedelta(days=int(timeframe.replace("d", "")))
        else:
            expected_interval = pd.Timedelta(hours=1)  # Fallback

        # Tol√©rance pour d√©tecter les gaps (2x l'intervalle normal)
        gap_threshold = expected_interval * 2

        # Analyser les intervalles entre barres cons√©cutives
        time_diffs = df.index[1:] - df.index[:-1]
        gap_indices = time_diffs > gap_threshold

        if gap_indices.any():
            gap_positions = np.where(gap_indices)[0]

            for gap_idx in gap_positions:
                gap_start = df.index[gap_idx]
                gap_end = df.index[gap_idx + 1]
                duration_days = (gap_end - gap_start).total_seconds() / (24 * 3600)

                if duration_days > 0.1:  # Ignorer gaps < 2.4h
                    gaps.append(DataGap(
                        start=gap_start,
                        end=gap_end,
                        duration_days=duration_days,
                        token=symbol,
                        timeframe=timeframe
                    ))

        # Trier par dur√©e d√©croissante
        return sorted(gaps, key=lambda g: g.duration_days, reverse=True)

    except Exception:
        return []


def find_optimal_periods(
    symbols: List[str],
    timeframes: List[str],
    min_period_days: int = 30,
    max_periods: int = 3
) -> List[OptimalPeriod]:
    """
    Trouve les p√©riodes optimales avec tol√©rance aux gaps selon les timeframes.

    Analyse intelligente qui :
    1. Scan les gaps de tous les tokens/timeframes
    2. Utilise les tol√©rances CATEGORY_GAP_TOLERANCE selon les timeframes
    3. Identifie les segments viables entre les gros gaps
    4. Score les p√©riodes selon la compl√©tude des donn√©es
    5. Retourne les meilleures p√©riodes class√©es

    Args:
        symbols: Liste des symboles √† analyser
        timeframes: Liste des timeframes √† analyser
        min_period_days: P√©riode minimale acceptable (d√©faut: 30 jours)
        max_periods: Nombre maximum de p√©riodes √† retourner

    Returns:
        Liste des p√©riodes optimales, tri√©es par score d√©croissant
    """
    try:
        # 0. D√©terminer la tol√©rance aux gaps selon les timeframes
        categories = categorize_timeframes(timeframes)

        # Prendre la tol√©rance la plus stricte parmi les cat√©gories pr√©sentes
        relevant_tolerances = []
        for category, category_tfs in categories.items():
            if category_tfs:  # Cat√©gorie non vide
                tolerance = CATEGORY_GAP_TOLERANCE.get(category, 0.10)
                relevant_tolerances.append(tolerance)

        gap_tolerance = min(relevant_tolerances) if relevant_tolerances else 0.10
        print(f"üéØ Tol√©rance gaps utilis√©e: {gap_tolerance:.1%} (timeframes: {timeframes})")

        # 1. Collecter toutes les donn√©es disponibles et leurs gaps
        all_data_ranges = {}
        all_gaps = {}

        for symbol in symbols:
            for tf in timeframes:
                combo = (symbol, tf)

                # R√©cup√©rer la plage globale
                date_range = get_data_date_range(symbol, tf)
                if date_range:
                    all_data_ranges[combo] = date_range

                    # Analyser les gaps
                    gaps = analyze_data_gaps(symbol, tf)
                    all_gaps[combo] = gaps

        if not all_data_ranges:
            return []

        # 2. Trouver la plage commune globale
        all_starts = [range_[0] for range_ in all_data_ranges.values()]
        all_ends = [range_[1] for range_ in all_data_ranges.values()]

        global_start = max(all_starts)
        global_end = min(all_ends)

        if global_start >= global_end:
            return []

        # 3. NOUVEAU: Identifier les gros gaps selon la tol√©rance
        total_days = (global_end - global_start).days
        if total_days < min_period_days:
            return []

        # Collecter tous les gaps et filtrer selon la tol√©rance
        major_gaps = []  # Gaps qui cassent vraiment la continuit√©
        for combo, gaps in all_gaps.items():
            for gap in gaps:
                gap_days = (gap.end - gap.start).days

                # Un gap est "majeur" s'il d√©passe la tol√©rance de la cat√©gorie
                # Ex: pour intraday (5% tol√©rance), sur 100 jours, gap > 5 jours = majeur
                period_for_tolerance = max(min_period_days, 30)  # Au moins 30 jours de r√©f√©rence
                gap_threshold_days = period_for_tolerance * gap_tolerance

                if gap_days > gap_threshold_days:
                    major_gaps.append((gap.start, gap.end, gap_days))
                    print(f"   Gap majeur: {gap.start.strftime('%Y-%m-%d')} ‚Üí {gap.end.strftime('%Y-%m-%d')} ({gap_days:.1f}j)")

        # Trier par date de d√©but
        major_gaps.sort(key=lambda x: x[0])
        print(f"   Total gaps majeurs: {len(major_gaps)}")

        # 4. Cr√©er des segments entre les gros gaps
        segments = []
        current_start = global_start

        for gap_start, gap_end, gap_days in major_gaps:
            # Si le gap commence apr√®s current_start, on a un segment potentiel
            if gap_start > current_start:
                segment_end = gap_start
                segment_days = (segment_end - current_start).days

                if segment_days >= min_period_days:
                    segments.append((current_start, segment_end, segment_days))
                    print(f"   Segment viable: {current_start.strftime('%Y-%m-%d')} ‚Üí {segment_end.strftime('%Y-%m-%d')} ({segment_days}j)")

            # Nouveau d√©but apr√®s ce gap
            current_start = max(current_start, gap_end)

        # Dernier segment apr√®s le dernier gap
        if current_start < global_end:
            segment_days = (global_end - current_start).days
            if segment_days >= min_period_days:
                segments.append((current_start, global_end, segment_days))
                print(f"   Segment final: {current_start.strftime('%Y-%m-%d')} ‚Üí {global_end.strftime('%Y-%m-%d')} ({segment_days}j)")

        # 5. Si aucun segment sans gros gaps, prendre toute la plage avec tol√©rance
        if not segments:
            print(f"   Aucun segment sans gaps majeurs, utilisation plage compl√®te avec tol√©rance")
            segments = [(global_start, global_end, total_days)]

        # 6. √âvaluer la qualit√© de chaque segment
        scored_periods = []

        for segment_start, segment_end, segment_days in segments:
            # Compter les donn√©es disponibles dans ce segment
            total_data_points = 0
            total_possible_points = 0
            tolerated_gaps = 0
            tokens_complete = 0

            for symbol in symbols:
                for tf in timeframes:
                    combo = (symbol, tf)
                    if combo not in all_data_ranges:
                        continue

                    # V√©rifier si cette combo a des gaps tol√©rables dans le segment
                    has_major_gaps = False
                    gaps = all_gaps.get(combo, [])

                    for gap in gaps:
                        # Gap chevauche-t-il le segment ?
                        if (gap.start < segment_end and gap.end > segment_start):
                            gap_days = (gap.end - gap.start).days
                            gap_threshold_days = segment_days * gap_tolerance

                            if gap_days > gap_threshold_days:
                                has_major_gaps = True
                                break
                            else:
                                tolerated_gaps += 1

                    if not has_major_gaps:
                        tokens_complete += 1

                    # Calculer densit√© th√©orique
                    freq_factor = TIMEFRAME_FREQUENCY_FACTOR.get(tf, 1440)  # d√©faut = 1d
                    possible_points = segment_days * freq_factor
                    total_possible_points += possible_points

                    # Estimer points r√©els (approximation)
                    total_gap_time = sum(
                        (min(gap.end, segment_end) - max(gap.start, segment_start)).total_seconds() / 3600
                        for gap in gaps
                        if gap.start < segment_end and gap.end > segment_start
                    )

                    gap_ratio = min(1.0, total_gap_time / (segment_days * 24))
                    estimated_points = possible_points * (1 - gap_ratio)
                    total_data_points += max(0, estimated_points)

            # Calculer les m√©triques de qualit√©
            tokens_total = len(symbols) * len(timeframes)

            if tokens_total > 0 and total_possible_points > 0:
                completeness_score = (tokens_complete / tokens_total) * 100
                data_density = min(100.0, total_data_points / total_possible_points * 100)

                # Bonus pour p√©riodes plus longues
                period_bonus = min(1.2, 1.0 + (segment_days - min_period_days) / (min_period_days * 2))

                # Score global : pond√©rer compl√©tude et densit√©
                quality_score = (completeness_score * 0.6) + (data_density * 0.4)
                quality_score *= period_bonus

                description = f"{segment_days}j, {tokens_complete}/{tokens_total} combos compl√®tes"
                if data_density < 90:
                    description += f", densit√© {data_density:.1f}%"
                if tolerated_gaps > 0:
                    description += f", {tolerated_gaps} gaps tol√©r√©s"

                scored_periods.append(OptimalPeriod(
                    start_date=segment_start,
                    end_date=segment_end,
                    completeness_score=completeness_score,
                    tokens_complete=tokens_complete,
                    tokens_total=tokens_total,
                    avg_data_density=data_density / 100.0,
                    description=description
                ))

        # 7. Trier par score et d√©duplicquer les p√©riodes similaires
        scored_periods.sort(key=lambda p: p.completeness_score * p.avg_data_density, reverse=True)

        # D√©duplication : √©viter les p√©riodes qui se chevauchent trop
        unique_periods = []
        for period in scored_periods:
            is_duplicate = False
            for existing in unique_periods:
                overlap_days = min(period.end_date, existing.end_date) - max(period.start_date, existing.start_date)
                overlap_ratio = overlap_days.days / (period.end_date - period.start_date).days

                if overlap_ratio > 0.7:  # 70% de chevauchement = doublon
                    is_duplicate = True
                    break

            if not is_duplicate:
                unique_periods.append(period)

                if len(unique_periods) >= max_periods:
                    break

        return unique_periods

    except Exception:
        return []


def _build_segments_from_gaps(
    data_start: pd.Timestamp,
    data_end: pd.Timestamp,
    gaps: List[DataGap],
    gap_threshold_days: float,
    min_period_days: int,
) -> List[Tuple[pd.Timestamp, pd.Timestamp]]:
    """D√©coupe une plage de donn√©es en segments en excluant les gaps majeurs."""
    if data_start >= data_end:
        return []

    segments: List[Tuple[pd.Timestamp, pd.Timestamp]] = []
    current_start = data_start
    for gap in sorted(gaps, key=lambda g: g.start):
        gap_days = (gap.end - gap.start).days
        if gap_days > gap_threshold_days:
            segment_end = gap.start
            if (segment_end - current_start).days >= min_period_days:
                segments.append((current_start, segment_end))
            current_start = max(current_start, gap.end)

    if (data_end - current_start).days >= min_period_days:
        segments.append((current_start, data_end))

    return segments


def _intersect_segments(
    left: List[Tuple[pd.Timestamp, pd.Timestamp]],
    right: List[Tuple[pd.Timestamp, pd.Timestamp]],
    min_period_days: int,
) -> List[Tuple[pd.Timestamp, pd.Timestamp]]:
    """Intersecte deux listes de segments et filtre par dur√©e minimale."""
    intersections: List[Tuple[pd.Timestamp, pd.Timestamp]] = []
    for left_start, left_end in left:
        for right_start, right_end in right:
            start = max(left_start, right_start)
            end = min(left_end, right_end)
            if start < end and (end - start).days >= min_period_days:
                intersections.append((start, end))
    return intersections


def _estimate_segment_density(
    symbols: List[str],
    timeframe: str,
    segment_start: pd.Timestamp,
    segment_end: pd.Timestamp,
    gaps_by_symbol: Dict[str, List[DataGap]],
) -> float:
    """Estime la densit√© des donn√©es dans un segment via les gaps."""
    segment_hours = max(1.0, (segment_end - segment_start).total_seconds() / 3600.0)
    total_hours = segment_hours * max(1, len(symbols))
    gap_hours = 0.0

    for symbol in symbols:
        for gap in gaps_by_symbol.get(symbol, []):
            overlap_start = max(gap.start, segment_start)
            overlap_end = min(gap.end, segment_end)
            if overlap_start < overlap_end:
                gap_hours += (overlap_end - overlap_start).total_seconds() / 3600.0

    gap_ratio = min(1.0, gap_hours / total_hours) if total_hours > 0 else 1.0
    return max(0.0, 1.0 - gap_ratio)


def find_longest_common_period_for_timeframe(
    symbols: List[str],
    timeframe: str,
    min_period_days: int,
) -> List[OptimalPeriod]:
    """
    Trouve la plus longue p√©riode commune cons√©cutive pour un timeframe.

    Proc√©dure:
    - Pour chaque token, d√©coupe sa plage en segments sans gaps majeurs.
    - Intersecte tous les segments pour obtenir la plage commune.
    - S√©lectionne le segment commun le plus long.
    """
    if not symbols:
        return []

    category = get_timeframe_category(timeframe)
    gap_tolerance = CATEGORY_GAP_TOLERANCE.get(category, 0.10)

    segments_by_symbol: Dict[str, List[Tuple[pd.Timestamp, pd.Timestamp]]] = {}
    gaps_by_symbol: Dict[str, List[DataGap]] = {}

    for symbol in symbols:
        date_range = get_data_date_range(symbol, timeframe)
        if not date_range:
            return []

        data_start, data_end = date_range
        total_days = max(1, (data_end - data_start).days)
        gap_threshold_days = max(1.0, total_days * gap_tolerance)

        gaps = analyze_data_gaps(symbol, timeframe)
        gaps_by_symbol[symbol] = gaps

        segments = _build_segments_from_gaps(
            data_start=data_start,
            data_end=data_end,
            gaps=gaps,
            gap_threshold_days=gap_threshold_days,
            min_period_days=min_period_days,
        )
        if not segments:
            return []
        segments_by_symbol[symbol] = segments

    common_segments = segments_by_symbol[symbols[0]]
    for symbol in symbols[1:]:
        common_segments = _intersect_segments(
            common_segments,
            segments_by_symbol[symbol],
            min_period_days,
        )
        if not common_segments:
            return []

    best_start, best_end = max(
        common_segments,
        key=lambda s: (s[1] - s[0]).days,
    )
    duration_days = (best_end - best_start).days
    avg_density = _estimate_segment_density(
        symbols,
        timeframe,
        best_start,
        best_end,
        gaps_by_symbol,
    )

    description = f"{duration_days}j, commun a {len(symbols)}/{len(symbols)} tokens"
    return [
        OptimalPeriod(
            start_date=best_start,
            end_date=best_end,
            completeness_score=100.0,
            tokens_complete=len(symbols),
            tokens_total=len(symbols),
            avg_data_density=avg_density,
            description=description,
            category=category,
            timeframes=[timeframe],
        )
    ]


def categorize_timeframes(timeframes: List[str]) -> Dict[str, List[str]]:
    """
    Cat√©gorise les timeframes selon leur dur√©e.

    Args:
        timeframes: Liste des timeframes √† cat√©goriser

    Returns:
        Dict avec cl√©s 'scalping', 'intraday', 'swing', 'position'
    """
    categories = {
        'scalping': [],
        'intraday': [],
        'swing': [],
        'position': []
    }

    for tf in timeframes:
        for category, tf_list in TIMEFRAME_CATEGORIES.items():
            if tf in tf_list:
                categories[category].append(tf)
                break

    return categories


def get_min_period_days_for_timeframes(timeframes: List[str]) -> int:
    """
    D√©termine la dur√©e minimale recommand√©e selon les timeframes s√©lectionn√©s.

    Args:
        timeframes: Liste des timeframes √† √©valuer

    Returns:
        Nombre de jours minimum recommand√©
    """
    if not timeframes:
        return 30

    frequency_factor = sum(
        TIMEFRAME_FREQUENCY_FACTOR.get(tf, 1) for tf in timeframes
    )

    if frequency_factor > 100:  # Timeframes tr√®s courts (1m, 5m)
        return 7
    if frequency_factor > 20:  # Timeframes courts (15m, 30m, 1h)
        return 30
    return 90  # Timeframes longs (4h, 1d, 1w)


def get_timeframe_category(timeframe: str) -> str:
    """Retourne la cat√©gorie d'un timeframe ou 'mixed' si inconnue."""
    for category, tf_list in TIMEFRAME_CATEGORIES.items():
        if timeframe in tf_list:
            return category
    return "mixed"


def analyze_by_category(
    symbols: List[str],
    timeframes: List[str],
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None
) -> Dict[str, Any]:
    """
    Analyse les donn√©es par cat√©gorie de timeframe.

    Args:
        symbols: Liste des symboles
        timeframes: Liste des timeframes
        start_date: Date de d√©but (optionnel)
        end_date: Date de fin (optionnel)

    Returns:
        Dict avec analyse par cat√©gorie
    """
    categories = categorize_timeframes(timeframes)
    analysis = {}

    for category, category_timeframes in categories.items():
        if not category_timeframes:
            continue

        # Analyse standard pour cette cat√©gorie
        availability_result = scan_data_availability(symbols, category_timeframes)

        # P√©riodes optimales sp√©cialis√©es pour cette cat√©gorie
        optimal_periods = []
        if availability_result.has_common_range:
            min_period_days = get_min_period_days_for_timeframes(category_timeframes)

            optimal_periods = find_optimal_periods(
                symbols=symbols,
                timeframes=category_timeframes,
                min_period_days=min_period_days,
                max_periods=3
            )

        analysis[category] = {
            'timeframes': category_timeframes,
            'availability': availability_result,
            'optimal_periods': optimal_periods,
            'gap_tolerance': CATEGORY_GAP_TOLERANCE.get(category, 10.0),
            'frequency_factor': sum(TIMEFRAME_FREQUENCY_FACTOR.get(tf, 1) for tf in category_timeframes),
            'recommendations': _get_category_recommendations(category, optimal_periods)
        }

    return analysis


def analyze_by_timeframe(
    symbols: List[str],
    timeframes: List[str],
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None
) -> Dict[str, Any]:
    """
    Analyse les donn√©es par timeframe (plage commune par TF).

    Args:
        symbols: Liste des symboles
        timeframes: Liste des timeframes
        start_date: Date de d√©but (optionnel)
        end_date: Date de fin (optionnel)

    Returns:
        Dict avec analyse par timeframe
    """
    analysis: Dict[str, Any] = {}

    for timeframe in timeframes:
        availability_result = scan_data_availability(symbols, [timeframe])

        optimal_periods: List[OptimalPeriod] = []
        if availability_result.has_common_range:
            min_period_days = get_min_period_days_for_timeframes([timeframe])
            optimal_periods = find_longest_common_period_for_timeframe(
                symbols=symbols,
                timeframe=timeframe,
                min_period_days=min_period_days,
            )

        category = get_timeframe_category(timeframe)

        analysis[timeframe] = {
            "timeframes": [timeframe],
            "availability": availability_result,
            "optimal_periods": optimal_periods,
            "gap_tolerance": CATEGORY_GAP_TOLERANCE.get(category, 0.10),
            "frequency_factor": TIMEFRAME_FREQUENCY_FACTOR.get(timeframe, 1),
            "recommendations": _get_category_recommendations(category, optimal_periods),
        }

    return analysis


def find_harmonized_period(category_analysis: Dict[str, Any]) -> Optional[OptimalPeriod]:
    """
    Trouve une p√©riode harmonis√©e entre toutes les cat√©gories.

    Args:
        category_analysis: R√©sultat d'analyze_by_category()

    Returns:
        P√©riode optimale commune ou None
    """
    all_periods = []
    all_timeframes = []

    # Collecter toutes les p√©riodes et timeframes
    for category, data in category_analysis.items():
        all_periods.extend(data['optimal_periods'])
        all_timeframes.extend(data['timeframes'])

    if not all_periods:
        return None

    # Trouver la p√©riode avec le meilleur score global
    best_period = max(all_periods, key=lambda p: p.completeness_score * p.avg_data_density)

    # Cr√©er une p√©riode harmonis√©e
    return OptimalPeriod(
        start_date=best_period.start_date,
        end_date=best_period.end_date,
        completeness_score=best_period.completeness_score,
        tokens_complete=best_period.tokens_complete,
        tokens_total=best_period.tokens_total,
        avg_data_density=best_period.avg_data_density,
        description=f"P√©riode harmonis√©e (bas√©e sur {best_period.description})",
        category="harmonized",
        timeframes=all_timeframes
    )


def _get_category_recommendations(category: str, optimal_periods: List[OptimalPeriod]) -> List[str]:
    """
    G√©n√®re des recommandations sp√©cifiques √† une cat√©gorie.

    Args:
        category: Nom de la cat√©gorie
        optimal_periods: P√©riodes optimales trouv√©es

    Returns:
        Liste de recommandations
    """
    recommendations = []

    if not optimal_periods:
        recommendations.append(f"‚ùå Aucune p√©riode optimale trouv√©e pour {category}")
        return recommendations

    best_period = optimal_periods[0]

    if category == 'scalping':
        if best_period.avg_data_density < 0.95:
            recommendations.append("‚ö†Ô∏è Scalping n√©cessite des donn√©es tr√®s denses")
        if (best_period.end_date - best_period.start_date).days < 30:
            recommendations.append("‚ö†Ô∏è P√©riode courte pour backtests scalping fiables")

    elif category == 'intraday':
        if best_period.completeness_score < 0.9:
            recommendations.append("‚ö†Ô∏è Gaps de donn√©es probl√©matiques pour intraday")
        duration_days = (best_period.end_date - best_period.start_date).days
        if duration_days > 365:
            recommendations.append("‚úÖ P√©riode longue id√©ale pour intraday")

    elif category == 'swing':
        tolerance = CATEGORY_GAP_TOLERANCE.get(category, 10.0)
        if best_period.completeness_score < (100 - tolerance) / 100:
            recommendations.append("‚ö†Ô∏è Gaps importants m√™me pour swing trading")
        else:
            recommendations.append("‚úÖ Gaps acceptables pour swing trading")

    elif category == 'position':
        if best_period.completeness_score > 0.8:  # Position trading tol√®re plus de gaps
            recommendations.append("‚úÖ Qualit√© suffisante pour position trading")
        duration_days = (best_period.end_date - best_period.start_date).days
        if duration_days > 1000:
            recommendations.append("‚úÖ P√©riode tr√®s longue excellente pour position")

    return recommendations


def discover_available_data() -> Tuple[List[str], List[str]]:
    """
    D√©couvre les donn√©es disponibles dans le syst√®me.

    Returns:
        Tuple (liste de symboles, liste de timeframes)
    """
    try:
        from data.loader import discover_available_data as _discover
        return _discover()
    except Exception:
        return (["BTCUSDC", "ETHUSDC"], ["1h", "4h", "1d"])


# ============================================================================
# AVAILABILITY SCANNING
# ============================================================================

def scan_data_availability(
    symbols: List[str],
    timeframes: List[str],
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    find_optimal: bool = True
) -> DataAvailabilityResult:
    """
    Scanne la disponibilit√© des donn√©es pour toutes les combinaisons symbole/timeframe.

    AM√âLIOR√â:
    - V√©rifie la compl√©tude r√©elle des donn√©es avec filtrage de dates
    - Trouve automatiquement les p√©riodes optimales si find_optimal=True

    Cette fonction fait le calcul m√©tier SANS aucun appel Streamlit.

    Args:
        symbols: Liste des symboles √† scanner
        timeframes: Liste des timeframes √† scanner
        start_date: Date de d√©but pour v√©rification de compl√©tude (optionnel)
        end_date: Date de fin pour v√©rification de compl√©tude (optionnel)
        find_optimal: Si True, calcule aussi les p√©riodes optimales

    Returns:
        DataAvailabilityResult avec toutes les infos de disponibilit√© + p√©riodes optimales
    """
    result = DataAvailabilityResult()

    all_starts: List[pd.Timestamp] = []
    all_ends: List[pd.Timestamp] = []

    for symbol in symbols:
        for tf in timeframes:
            # D'abord v√©rifier la plage globale disponible
            date_range = get_data_date_range(symbol, tf)

            if date_range:
                data_start, data_end = date_range
                result.availability[(symbol, tf)] = date_range
                all_starts.append(data_start)
                all_ends.append(data_end)
                coverage_pct = None
                missing_pct = None
                missing_days = None

                # Si des dates de filtrage sont sp√©cifi√©es, v√©rifier la compl√©tude r√©elle
                if start_date and end_date:
                    is_complete, message, actual_rows = check_data_completeness(
                        symbol, tf, start_date, end_date
                    )

                    if is_complete:
                        status = "‚úÖ"
                        status_msg = f"Complet ({actual_rows} barres)"
                    else:
                        status = "‚ö†Ô∏è"
                        status_msg = message.replace("‚ö†Ô∏è ", "").replace("‚ùå ", "")
                        result.missing_data.append(f"{symbol}/{tf} (donn√©es incompl√®tes)")
                else:
                    # Pas de v√©rification de compl√©tude, analyser les gaps
                    gaps = analyze_data_gaps(symbol, tf)
                    if gaps:
                        total_gap_days = sum(gap.duration_days for gap in gaps)
                        total_days = (data_end - data_start).days
                        gap_ratio = total_gap_days / max(total_days, 1)
                        coverage_pct = max(0.0, 1.0 - gap_ratio) * 100.0
                        missing_pct = gap_ratio * 100.0
                        missing_days = total_gap_days

                        if gap_ratio > 0.1:  # Plus de 10% de gaps
                            status = "‚ö†Ô∏è"
                            status_msg = f"{len(gaps)} gaps ({total_gap_days:.1f}j manquants)"
                        else:
                            status = "‚úÖ"
                            status_msg = f"Quasi-complet ({len(gaps)} petits gaps)"
                    else:
                        status = "‚úÖ"
                        days = (data_end - data_start).days
                        status_msg = f"{days} jours complets"
                        coverage_pct = 100.0
                        missing_pct = 0.0
                        missing_days = 0.0

                result.rows.append({
                    "Token": symbol,
                    "TF": tf,
                    "D√©but": data_start.strftime("%Y-%m-%d"),
                    "Fin": data_end.strftime("%Y-%m-%d"),
                    "Jours": (data_end - data_start).days,
                    "Couverture %": coverage_pct,
                    "Manquant %": missing_pct,
                    "Jours manquants": missing_days,
                    "Plage commune %": None,
                    "Status": status,
                    "D√©tails": status_msg
                })
            else:
                result.missing_data.append(f"{symbol}/{tf}")
                result.rows.append({
                    "Token": symbol,
                    "TF": tf,
                    "D√©but": "-",
                    "Fin": "-",
                    "Jours": 0,
                    "Couverture %": None,
                    "Manquant %": None,
                    "Jours manquants": None,
                    "Plage commune %": None,
                    "Status": "‚ùå",
                    "D√©tails": "Fichier non trouv√©"
                })

    # Calculer la plage commune (intersection)
    if all_starts and all_ends:
        result.common_start = max(all_starts)
        result.common_end = min(all_ends)
        result.has_common_range = result.common_start < result.common_end
        if result.has_common_range:
            common_days = (result.common_end - result.common_start).days
            for row in result.rows:
                days = row.get("Jours", 0) or 0
                if days > 0:
                    row["Plage commune %"] = round((common_days / days) * 100.0, 1)
                else:
                    row["Plage commune %"] = None

    # Trouver les p√©riodes optimales si demand√©
    if find_optimal and len(symbols) > 0 and len(timeframes) > 0:
        optimal_periods = find_optimal_periods(symbols, timeframes)
        # Stocker dans le result pour usage ult√©rieur
        if hasattr(result, 'optimal_periods'):
            result.optimal_periods = optimal_periods
        else:
            # Ajouter dynamiquement l'attribut
            setattr(result, 'optimal_periods', optimal_periods)

    return result


# ============================================================================
# INTELLIGENT DEFAULTS
# ============================================================================

def get_intelligent_timeframe_defaults(
    available_timeframes: List[str],
    common_days: Optional[int] = None
) -> List[str]:
    """
    S√©lectionne des timeframes par d√©faut bas√©s sur la plage commune.

    R√®gles:
    - Plage < 30 jours ‚Üí timeframes courts (15m, 30m, 1h)
    - Plage 30-180 jours ‚Üí timeframes moyens (30m, 1h, 4h)
    - Plage > 180 jours ‚Üí timeframes longs (1h, 4h, 1d)

    Args:
        available_timeframes: Timeframes disponibles
        common_days: Nombre de jours dans la plage commune

    Returns:
        Liste de 1-2 timeframes recommand√©s
    """
    if not available_timeframes:
        return []

    sorted_tfs = sorted(
        available_timeframes,
        key=lambda tf: TIMEFRAME_PRIORITY_MAP.get(tf, 999)
    )

    if common_days is None or common_days >= 180:
        preferred = ["1h", "4h", "1d"]
    elif common_days >= 30:
        preferred = ["30m", "1h", "4h"]
    else:
        preferred = ["15m", "30m", "1h"]

    defaults = []
    for pref in preferred:
        if pref in available_timeframes and len(defaults) < 2:
            defaults.append(pref)

    if not defaults and sorted_tfs:
        defaults = [sorted_tfs[0]]

    return defaults


def generate_random_token_suggestions(
    available_tokens: List[str],
    selected_tokens: List[str],
    count: int = RANDOM_SLOTS_COUNT
) -> List[str]:
    """
    G√©n√®re des suggestions de tokens al√©atoires avec anti-doublons.

    Args:
        available_tokens: Tous les tokens disponibles
        selected_tokens: Tokens d√©j√† s√©lectionn√©s (exclus)
        count: Nombre de suggestions √† g√©n√©rer

    Returns:
        Liste de tokens uniques non s√©lectionn√©s
    """
    pool = [t for t in available_tokens if t not in selected_tokens]

    if not pool:
        return []

    return random.sample(pool, min(count, len(pool)))


# ============================================================================
# PERIOD VALIDATION
# ============================================================================

def validate_period_for_tokens(
    start_date: date,
    end_date: date,
    data_availability: Dict[Tuple[str, str], Tuple[pd.Timestamp, pd.Timestamp]]
) -> PeriodValidationResult:
    """
    Valide une p√©riode s√©lectionn√©e contre les donn√©es disponibles.

    Compare au niveau du jour pour √©viter les faux positifs dus aux heures.

    Args:
        start_date: Date de d√©but s√©lectionn√©e
        end_date: Date de fin s√©lectionn√©e
        data_availability: Dict {(symbol, tf): (start_ts, end_ts)}

    Returns:
        PeriodValidationResult avec tokens ok/partiels/manquants
    """
    result = PeriodValidationResult()

    # Normaliser en dates pures (pas de timestamps)
    start_day = start_date if isinstance(start_date, date) else start_date.date()
    end_day = end_date if isinstance(end_date, date) else end_date.date()

    for (symbol, tf), (data_start, data_end) in data_availability.items():
        token_key = f"{symbol}/{tf}"

        # Comparer au niveau du jour
        data_start_day = data_start.date() if hasattr(data_start, 'date') else data_start
        data_end_day = data_end.date() if hasattr(data_end, 'date') else data_end

        if end_day < data_start_day or start_day > data_end_day:
            result.tokens_missing.append(token_key)
        elif start_day < data_start_day or end_day > data_end_day:
            result.tokens_partial.append(token_key)
        else:
            result.tokens_ok.append(token_key)

    result.all_ok = (
        len(result.tokens_ok) > 0
        and len(result.tokens_missing) == 0
        and len(result.tokens_partial) == 0
    )

    return result


# ============================================================================
# FORMATTING UTILITIES
# ============================================================================

def format_date_fr(date_obj) -> str:
    """
    Formate une date au format fran√ßais JJ/MM/AAAA.

    Args:
        date_obj: datetime.date, pandas.Timestamp ou string

    Returns:
        String au format "01/12/2025"
    """
    if isinstance(date_obj, str):
        try:
            parsed = pd.to_datetime(date_obj)
            return parsed.strftime("%d/%m/%Y")
        except Exception:
            return date_obj
    elif hasattr(date_obj, 'strftime'):
        return date_obj.strftime("%d/%m/%Y")
    else:
        return str(date_obj)


def compute_period_days(start_date: date, end_date: date) -> int:
    """
    Calcule le nombre de jours entre deux dates.

    Args:
        start_date: Date de d√©but
        end_date: Date de fin

    Returns:
        Nombre de jours (inclusif)
    """
    return (end_date - start_date).days
```
<!-- MODULE-END: config.py -->

<!-- MODULE-START: indicator_bank.py -->
```json
{
  "name": "indicator_bank.py",
  "path": "data\\indicator_bank.py",
  "ext": ".py",
  "anchor": "indicator_bank_py"
}
```
## indicator_bank_py
*Chemin* : `data\indicator_bank.py`  
*Type* : `.py`  

```python
"""
Module-ID: data.indicator_bank

Purpose: Cache disque intelligent indicateurs - √©vite recalc via hash param+donn√©es.

Role in pipeline: performance

Key components: IndicatorBank, CacheEntry, CacheStats, hash_indicator_config()

Inputs: Indicator name, params, OHLCV data

Outputs: Cached array ou recalc si stale (TTL), CacheStats {hits, misses, hit_rate}

Dependencies: pandas, hashlib, pickle, pathlib, dataclasses, time

Conventions: TTL 7j d√©faut; cl√© hash (nom, params, donn√©es); √©viction LRU.

Read-if: Modification cache policy ou TTL.

Skip-if: Vous appelez bank.get(indicator_name, params, df).
"""

import hashlib
import json
import pickle
import shutil
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class CacheStats:
    """Statistiques du cache."""
    hits: int = 0
    misses: int = 0
    evictions: int = 0
    total_size_mb: float = 0.0
    entries_count: int = 0

    @property
    def hit_rate(self) -> float:
        """Taux de hit du cache."""
        total = self.hits + self.misses
        return (self.hits / total * 100) if total > 0 else 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "hits": self.hits,
            "misses": self.misses,
            "evictions": self.evictions,
            "hit_rate": self.hit_rate,
            "total_size_mb": self.total_size_mb,
            "entries_count": self.entries_count
        }


@dataclass
class CacheEntry:
    """Entr√©e de cache avec m√©tadonn√©es."""
    key: str
    indicator_name: str
    params_hash: str
    data_hash: str
    created_at: float
    expires_at: float
    size_bytes: int
    filepath: Path

    def is_expired(self) -> bool:
        """V√©rifie si l'entr√©e a expir√©."""
        return time.time() > self.expires_at


class IndicatorBank:
    """
    Cache disque intelligent pour les indicateurs calcul√©s.

    Usage:
        >>> bank = IndicatorBank(cache_dir=".indicator_cache")
        >>>
        >>> # V√©rifier si en cache
        >>> result = bank.get("bollinger", params, df)
        >>> if result is None:
        ...     result = bollinger_bands(df["close"], **params)
        ...     bank.put("bollinger", params, df, result)
    """

    DEFAULT_TTL = 3600 * 24  # 24 heures
    DEFAULT_MAX_SIZE_MB = 500  # 500 MB max

    def __init__(
        self,
        cache_dir: Union[str, Path] = ".indicator_cache",
        ttl: int = DEFAULT_TTL,
        max_size_mb: float = DEFAULT_MAX_SIZE_MB,
        enabled: bool = True,
        memory_max_entries: int = 128
    ):
        """
        Initialise l'IndicatorBank.

        Args:
            cache_dir: R√©pertoire de cache
            ttl: Time-to-live en secondes (d√©faut: 24h)
            max_size_mb: Taille maximale du cache en MB
            enabled: Activer/d√©sactiver le cache
            memory_max_entries: Max entries kept in memory (0 disables)
        """
        self.cache_dir = Path(cache_dir)
        self.ttl = ttl
        self.max_size_mb = max_size_mb
        self.enabled = enabled
        self.memory_max_entries = int(memory_max_entries)

        self.stats = CacheStats()
        self._index: Dict[str, CacheEntry] = {}
        self._memory_cache: Dict[str, Tuple[float, Any]] = {}

        if enabled:
            self._init_cache_dir()
            self._load_index()

    def _init_cache_dir(self) -> None:
        """Cr√©e le r√©pertoire de cache si n√©cessaire."""
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._index_path = self.cache_dir / "index.json"

    def _rebuild_index_from_files(self) -> None:
        """Reconstruit l'index en scannant les fichiers .pkl du cache."""
        logger.info("Reconstruction de l'index du cache √† partir des fichiers existants...")
        self._index = {}

        try:
            pkl_files = list(self.cache_dir.glob("*.pkl"))
            logger.info(f"Trouv√© {len(pkl_files)} fichiers .pkl √† indexer")

            for pkl_file in pkl_files:
                try:
                    # Extraire les m√©tadonn√©es du nom de fichier
                    # Format: {indicator_name}_{params_hash}_{data_hash}.pkl
                    stem = pkl_file.stem
                    parts = stem.rsplit("_", 2)

                    if len(parts) != 3:
                        logger.debug(f"Fichier ignor√© (format invalide): {pkl_file.name}")
                        continue

                    indicator_name, params_hash, data_hash = parts
                    key = stem

                    # Obtenir la taille du fichier
                    size_bytes = pkl_file.stat().st_size
                    created_at = pkl_file.stat().st_mtime
                    expires_at = created_at + self.ttl

                    entry = CacheEntry(
                        key=key,
                        indicator_name=indicator_name,
                        params_hash=params_hash,
                        data_hash=data_hash,
                        created_at=created_at,
                        expires_at=expires_at,
                        size_bytes=size_bytes,
                        filepath=pkl_file
                    )

                    # Ne garder que les entr√©es non expir√©es
                    if not entry.is_expired():
                        self._index[key] = entry
                    else:
                        logger.debug(f"Fichier expir√© supprim√©: {pkl_file.name}")
                        pkl_file.unlink(missing_ok=True)

                except Exception as e:
                    logger.debug(f"Erreur indexation fichier {pkl_file.name}: {e}")
                    continue

            logger.info(f"Index reconstruit: {len(self._index)} entr√©es valides")

            # Sauvegarder le nouvel index
            self._save_index()

        except Exception as e:
            logger.error(f"Erreur lors de la reconstruction de l'index: {e}")
            self._index = {}

    def _load_index(self) -> None:
        """Charge l'index du cache depuis le disque."""
        if self._index_path.exists():
            try:
                with open(self._index_path, "r") as f:
                    data = json.load(f)

                for key, entry_data in data.get("entries", {}).items():
                    entry = CacheEntry(
                        key=entry_data["key"],
                        indicator_name=entry_data["indicator_name"],
                        params_hash=entry_data["params_hash"],
                        data_hash=entry_data["data_hash"],
                        created_at=entry_data["created_at"],
                        expires_at=entry_data["expires_at"],
                        size_bytes=entry_data["size_bytes"],
                        filepath=Path(entry_data["filepath"])
                    )

                    # V√©rifier si le fichier existe encore
                    if entry.filepath.exists() and not entry.is_expired():
                        self._index[key] = entry
                    else:
                        # Nettoyer l'entr√©e invalide
                        self._remove_entry(entry, update_index=False)

                logger.debug(f"Index charg√©: {len(self._index)} entr√©es")

            except Exception as e:
                logger.warning(f"Erreur chargement index: {e}")
                logger.info("Tentative de reconstruction automatique de l'index...")
                self._rebuild_index_from_files()
        else:
            # Index n'existe pas, le reconstruire √† partir des fichiers
            logger.info("Index absent, reconstruction √† partir des fichiers existants...")
            self._rebuild_index_from_files()

    def _save_index(self) -> None:
        """Sauvegarde l'index sur disque."""
        data = {
            "version": "1.0",
            "updated_at": time.time(),
            "entries": {}
        }

        for key, entry in self._index.items():
            data["entries"][key] = {
                "key": entry.key,
                "indicator_name": entry.indicator_name,
                "params_hash": entry.params_hash,
                "data_hash": entry.data_hash,
                "created_at": entry.created_at,
                "expires_at": entry.expires_at,
                "size_bytes": entry.size_bytes,
                "filepath": str(entry.filepath)
            }

        try:
            with open(self._index_path, "w") as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            logger.warning(f"Erreur sauvegarde index: {e}")

    def _get_data_hash(self, df: pd.DataFrame) -> str:
        """Build a short hash for the input data."""
        data_info = {
            "shape": df.shape,
            "columns": list(df.columns),
            "first_idx": str(df.index[0]) if len(df) > 0 else "",
            "last_idx": str(df.index[-1]) if len(df) > 0 else "",
            "checksum": float(df["close"].sum()) if "close" in df.columns else 0.0
        }
        data_str = json.dumps(data_info, sort_keys=True, default=str)
        return hashlib.sha256(data_str.encode("utf-8")).hexdigest()[:12]

    def _generate_key(
        self,
        indicator_name: str,
        params: Dict[str, Any],
        df: pd.DataFrame,
        data_hash: Optional[str] = None
    ) -> Tuple[str, str, str]:
        """
        G√©n√®re une cl√© de cache unique.

        La cl√© inclut automatiquement le backend (CPU/GPU) pour √©viter
        que des r√©sultats GPU (float32) soient utilis√©s en mode CPU (float64).

        Returns:
            Tuple (full_key, params_hash, data_hash)
        """
        # Inclure le backend dans la cl√© de cache pour √©viter collisions CPU/GPU
        if "_backend" not in params:
            # D√©tecter si GPU sera utilis√© (coh√©rent avec logic du registry)
            from performance.gpu import gpu_available
            will_use_gpu = gpu_available() and len(df) >= 5000
            params = {**params, "_backend": "gpu" if will_use_gpu else "cpu"}

        # Hash des param√®tres
        params_str = json.dumps(params, sort_keys=True, default=str)
        params_hash = hashlib.sha256(params_str.encode("utf-8")).hexdigest()[:12]

        # Hash des donn√©es (bas√© sur shape, premier/dernier timestamp, checksum)
        if data_hash is None:
            data_hash = self._get_data_hash(df)

        full_key = f"{indicator_name}_{params_hash}_{data_hash}"

        return full_key, params_hash, data_hash

    def get_data_hash(self, df: pd.DataFrame) -> str:
        """Return a data hash that can be reused across indicators."""
        return self._get_data_hash(df)

    def _memory_get(self, key: str) -> Optional[Any]:
        if self.memory_max_entries <= 0:
            return None
        entry = self._memory_cache.get(key)
        if entry is None:
            return None
        expires_at, result = entry
        if time.time() > expires_at:
            self._memory_cache.pop(key, None)
            return None
        return result

    def _memory_put(self, key: str, expires_at: float, result: Any) -> None:
        if self.memory_max_entries <= 0:
            return
        if key in self._memory_cache:
            self._memory_cache.pop(key, None)
        self._memory_cache[key] = (expires_at, result)
        while len(self._memory_cache) > self.memory_max_entries:
            self._memory_cache.pop(next(iter(self._memory_cache)))

    def get(
        self,
        indicator_name: str,
        params: Dict[str, Any],
        df: pd.DataFrame,
        data_hash: Optional[str] = None,
        backend: str = "cpu"
    ) -> Optional[Any]:
        """
        R√©cup√®re un indicateur depuis le cache.

        Args:
            indicator_name: Nom de l'indicateur
            params: Param√®tres utilis√©s
            df: DataFrame source
            backend: Backend utilis√© ("cpu" ou "gpu") pour diff√©rencier le cache

        Returns:
            R√©sultat cach√© ou None si non trouv√©/expir√©
        """
        if not self.enabled:
            return None

        # Ajouter backend aux params pour diff√©rencier cache CPU vs GPU
        params_with_backend = {**params, "_backend": backend}
        key, _, _ = self._generate_key(indicator_name, params_with_backend, df, data_hash=data_hash)

        # Check memory cache first
        memory_result = self._memory_get(key)
        if memory_result is not None:
            self.stats.hits += 1
            return memory_result

        entry = self._index.get(key)
        if entry is None:
            self.stats.misses += 1
            return None

        # V√©rifier expiration
        if entry.is_expired():
            self._remove_entry(entry)
            self.stats.misses += 1
            return None

        # Charger les donn√©es
        try:
            with open(entry.filepath, "rb") as f:
                result = pickle.load(f)

            self.stats.hits += 1
            self._memory_put(key, entry.expires_at, result)
            logger.debug(f"Cache HIT: {indicator_name} [{key[:16]}]")
            return result

        except Exception as e:
            logger.warning(f"Erreur lecture cache: {e}")
            self._remove_entry(entry)
            self.stats.misses += 1
            return None

    def put(
        self,
        indicator_name: str,
        params: Dict[str, Any],
        df: pd.DataFrame,
        result: Any,
        ttl: Optional[int] = None,
        data_hash: Optional[str] = None,
        backend: str = "cpu"
    ) -> bool:
        """
        Stocke un indicateur dans le cache.

        Args:
            indicator_name: Nom de l'indicateur
            params: Param√®tres utilis√©s
            df: DataFrame source
            result: R√©sultat √† cacher
            ttl: TTL personnalis√© (optionnel)
            backend: Backend utilis√© ("cpu" ou "gpu") pour diff√©rencier le cache

        Returns:
            True si mis en cache avec succ√®s
        """
        if not self.enabled:
            return False

        # Ajouter backend aux params pour diff√©rencier cache CPU vs GPU
        params_with_backend = {**params, "_backend": backend}
        key, params_hash, data_hash = self._generate_key(
            indicator_name, params_with_backend, df, data_hash=data_hash
        )

        # S√©rialiser le r√©sultat
        try:
            data = pickle.dumps(result)
            size_bytes = len(data)
        except Exception as e:
            logger.warning(f"Erreur s√©rialisation: {e}")
            return False

        # V√©rifier la taille
        self._enforce_size_limit(size_bytes)

        # Sauvegarder sur disque
        filepath = self.cache_dir / f"{key}.pkl"
        try:
            with open(filepath, "wb") as f:
                f.write(data)
        except Exception as e:
            logger.warning(f"Erreur √©criture cache: {e}")
            return False

        # Cr√©er l'entr√©e d'index
        now = time.time()
        expires_at = now + (ttl or self.ttl)
        entry = CacheEntry(
            key=key,
            indicator_name=indicator_name,
            params_hash=params_hash,
            data_hash=data_hash,
            created_at=now,
            expires_at=expires_at,
            size_bytes=size_bytes,
            filepath=filepath
        )

        self._index[key] = entry
        self._memory_put(key, expires_at, result)
        self._save_index()
        self._update_stats()

        logger.debug(f"Cache PUT: {indicator_name} [{key[:16]}] ({size_bytes/1024:.1f}KB)")
        return True

    def _remove_entry(self, entry: CacheEntry, update_index: bool = True) -> None:
        """Supprime une entr√©e du cache."""
        try:
            if entry.filepath.exists():
                entry.filepath.unlink()
        except Exception:
            pass

        self._memory_cache.pop(entry.key, None)

        if entry.key in self._index:
            del self._index[entry.key]
            self.stats.evictions += 1

        if update_index:
            self._save_index()

    def _enforce_size_limit(self, new_size: int) -> None:
        """Applique la limite de taille en supprimant les anciennes entr√©es."""
        current_size = sum(e.size_bytes for e in self._index.values())
        target_size = self.max_size_mb * 1024 * 1024

        if current_size + new_size <= target_size:
            return

        # Trier par date de cr√©ation (plus ancien en premier)
        sorted_entries = sorted(
            self._index.values(),
            key=lambda e: e.created_at
        )

        # Supprimer jusqu'√† avoir assez de place
        while current_size + new_size > target_size and sorted_entries:
            entry = sorted_entries.pop(0)
            current_size -= entry.size_bytes
            self._remove_entry(entry, update_index=False)
            logger.debug(f"Eviction: {entry.indicator_name} [{entry.key[:16]}]")

        self._save_index()

    def _update_stats(self) -> None:
        """Met √† jour les statistiques."""
        self.stats.entries_count = len(self._index)
        self.stats.total_size_mb = sum(
            e.size_bytes for e in self._index.values()
        ) / (1024 * 1024)

    def invalidate(self, indicator_name: Optional[str] = None) -> int:
        """
        Invalide des entr√©es du cache.

        Args:
            indicator_name: Si fourni, invalide seulement cet indicateur.
                           Si None, invalide tout le cache.

        Returns:
            Nombre d'entr√©es supprim√©es
        """
        if not self.enabled:
            return 0

        if indicator_name is None:
            self._memory_cache.clear()
        else:
            prefix = f"{indicator_name}_"
            keys_to_drop = [k for k in self._memory_cache if k.startswith(prefix)]
            for key in keys_to_drop:
                self._memory_cache.pop(key, None)

        count = 0
        entries_to_remove = []

        for key, entry in self._index.items():
            if indicator_name is None or entry.indicator_name == indicator_name:
                entries_to_remove.append(entry)

        for entry in entries_to_remove:
            self._remove_entry(entry, update_index=False)
            count += 1

        self._save_index()
        self._update_stats()

        logger.info(f"Cache invalid√©: {count} entr√©es")
        return count

    def clear(self) -> None:
        """Vide compl√®tement le cache."""
        if not self.enabled:
            return

        try:
            shutil.rmtree(self.cache_dir)
            self._init_cache_dir()
            self._index = {}
            self.stats = CacheStats()
            self._memory_cache.clear()
            logger.info("Cache vid√©")
        except Exception as e:
            logger.warning(f"Erreur vidage cache: {e}")

    def cleanup_expired(self) -> int:
        """
        Supprime les entr√©es expir√©es.

        Returns:
            Nombre d'entr√©es supprim√©es
        """
        if not self.enabled:
            return 0

        count = 0
        entries_to_remove = []

        for entry in self._index.values():
            if entry.is_expired():
                entries_to_remove.append(entry)

        for entry in entries_to_remove:
            self._remove_entry(entry, update_index=False)
            count += 1

        if count > 0:
            self._save_index()
            self._update_stats()
            logger.info(f"Nettoyage: {count} entr√©es expir√©es supprim√©es")

        return count

    def get_stats(self) -> CacheStats:
        """Retourne les statistiques du cache."""
        self._update_stats()
        return self.stats

    def list_entries(self) -> List[Dict[str, Any]]:
        """Liste toutes les entr√©es du cache."""
        entries = []
        for entry in self._index.values():
            entries.append({
                "key": entry.key,
                "indicator": entry.indicator_name,
                "created_at": entry.created_at,
                "expires_at": entry.expires_at,
                "size_kb": entry.size_bytes / 1024,
                "expired": entry.is_expired()
            })
        return sorted(entries, key=lambda e: e["created_at"], reverse=True)


# Instance globale
_default_bank: Optional[IndicatorBank] = None


def get_indicator_bank(
    cache_dir: Union[str, Path] = ".indicator_cache",
    **kwargs
) -> IndicatorBank:
    """
    Retourne l'instance globale de l'IndicatorBank.

    Args:
        cache_dir: R√©pertoire de cache
        **kwargs: Arguments suppl√©mentaires pour IndicatorBank

    Returns:
        Instance IndicatorBank
    """
    global _default_bank

    if _default_bank is None:
        _default_bank = IndicatorBank(cache_dir=cache_dir, **kwargs)

    return _default_bank


def cached_indicator(indicator_func):
    """
    D√©corateur pour cacher automatiquement les r√©sultats d'un indicateur.

    Usage:
        @cached_indicator
        def my_indicator(df, params):
            # calculs...
            return result
    """
    def wrapper(df: pd.DataFrame, params: Dict[str, Any]):
        bank = get_indicator_bank()
        indicator_name = indicator_func.__name__

        # V√©rifier le cache
        result = bank.get(indicator_name, params, df)
        if result is not None:
            return result

        # Calculer
        result = indicator_func(df, params)

        # Mettre en cache
        bank.put(indicator_name, params, df, result)

        return result

    wrapper.__name__ = indicator_func.__name__
    wrapper.__doc__ = indicator_func.__doc__
    return wrapper


__all__ = [
    "IndicatorBank",
    "CacheStats",
    "CacheEntry",
    "get_indicator_bank",
    "cached_indicator",
]
```
<!-- MODULE-END: indicator_bank.py -->

<!-- MODULE-START: loader.py -->
```json
{
  "name": "loader.py",
  "path": "data\\loader.py",
  "ext": ".py",
  "anchor": "loader_py"
}
```
## loader_py
*Chemin* : `data\loader.py`  
*Type* : `.py`  

```python
"""
Module-ID: data.loader

Purpose: Chargement OHLCV multi-formats (CSV, Parquet, JSON, Feather) + d√©couverte auto.

Role in pipeline: data input

Key components: load_ohlcv(), discover_available_data(), _get_data_dir()

Inputs: CSV/Parquet/JSON/Feather files, env vars BACKTEST_DATA_DIR/TRADX_DATA_ROOT

Outputs: Normalized pandas DataFrame {timestamp, open, high, low, close, volume}

Dependencies: pandas, pathlib, numpy, functools

Conventions: DatetimeIndex; OHLCV colonnes lowercase; env var priority; @lru_cache.

Read-if: Modification formats supports ou paths par d√©faut.

Skip-if: Vous appelez load_ohlcv(filename).
"""

import os
from functools import lru_cache
from pathlib import Path
from typing import List, Optional, Tuple

import numpy as np
import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)

# Extensions support√©es
SUPPORTED_EXTENSIONS = (".parquet", ".feather", ".csv", ".json")

# R√©pertoire de donn√©es par d√©faut
DEFAULT_DATA_DIR = Path(__file__).parent / "sample_data"

# Chemin ThreadX_big (donn√©es principales)
THREADX_DATA_DIR = Path("D:/ThreadX_big/data/crypto/processed/parquet")

# Chemin gestionnaire multi-timeframe (donn√©es mises √† jour)
GESTIONNAIRE_DATA_DIR = Path("D:/my_soft/gestionnaire_telechargement_multi-timeframe/processed")

# Chemin donn√©es brutes gestionnaire (fallback)
GESTIONNAIRE_RAW_DIR = Path("D:/my_soft/gestionnaire_telechargement_multi-timeframe/raw")


def _get_data_dir() -> Path:
    """D√©termine le r√©pertoire de donn√©es √† utiliser."""
    # Variable d'environnement prioritaire
    env_dir = os.environ.get("BACKTEST_DATA_DIR")
    if env_dir:
        env_path = Path(env_dir)
        if env_path.exists():
            return env_path

    # Variable TRADX_DATA_ROOT (compatibilit√©)
    tradx_dir = os.environ.get("TRADX_DATA_ROOT")
    if tradx_dir:
        tradx_path = Path(tradx_dir)
        if tradx_path.exists():
            return tradx_path

    # Gestionnaire multi-timeframe (donn√©es processed)
    if GESTIONNAIRE_DATA_DIR.exists():
        return GESTIONNAIRE_DATA_DIR

    # Gestionnaire multi-timeframe (donn√©es raw en fallback)
    if GESTIONNAIRE_RAW_DIR.exists():
        return GESTIONNAIRE_RAW_DIR

    # Chemin ThreadX_big (donn√©es principales)
    if THREADX_DATA_DIR.exists():
        return THREADX_DATA_DIR

    # R√©pertoire par d√©faut
    if DEFAULT_DATA_DIR.exists():
        return DEFAULT_DATA_DIR

    # Chercher dans des emplacements courants
    candidates = [
        Path("D:/ThreadX_big/data/crypto/processed/parquet"),
        Path.cwd() / "data" / "sample_data",
        Path.cwd() / "data",
        Path(__file__).parent.parent.parent / "data",
    ]

    for candidate in candidates:
        if candidate.exists():
            return candidate

    # Cr√©er le r√©pertoire par d√©faut
    DEFAULT_DATA_DIR.mkdir(parents=True, exist_ok=True)
    return DEFAULT_DATA_DIR


@lru_cache(maxsize=1)
def _scan_data_files() -> Tuple[Path, ...]:
    """Scanne les fichiers de donn√©es disponibles."""
    data_dir = _get_data_dir()
    files: List[Path] = []

    for ext in SUPPORTED_EXTENSIONS:
        files.extend(data_dir.glob(f"*{ext}"))
        files.extend(data_dir.glob(f"**/*{ext}"))  # R√©cursif

    return tuple(sorted(set(files)))


def discover_available_data() -> Tuple[List[str], List[str]]:
    """
    D√©couvre les tokens et timeframes disponibles.

    Returns:
        Tuple (liste de tokens, liste de timeframes)
    """
    tokens = set()
    timeframes = set()

    for file_path in _scan_data_files():
        # Format attendu: SYMBOL_TIMEFRAME.ext (ex: BTCUSDT_1m.parquet)
        parts = file_path.stem.split("_", 1)
        if len(parts) == 2:
            symbol, tf = parts
            # Valider que le timeframe est dans un format attendu
            # Format valide: <nombre><unit√©> o√π unit√© = m|h|d|w|M
            if _is_valid_timeframe(tf):
                tokens.add(symbol.upper())
                timeframes.add(tf)

    # Tri des timeframes par ordre logique
    def tf_sort_key(tf: str) -> Tuple[int, int]:
        if not tf:
            return (99, 0)
        unit = tf[-1]
        try:
            amount = int(tf[:-1])
        except ValueError:
            amount = 0
        order = {"m": 0, "h": 1, "d": 2, "w": 3, "M": 4}.get(unit, 5)
        return (order, amount)

    return sorted(tokens), sorted(timeframes, key=tf_sort_key)


def _is_valid_timeframe(tf: str) -> bool:
    """
    Valide qu'un timeframe est dans un format correct.

    Args:
        tf: Timeframe √† valider (ex: "1m", "5m", "1h", "4h", "1d")

    Returns:
        True si le timeframe est valide, False sinon
    """
    if not tf or len(tf) < 2:
        return False

    # Validation suppl√©mentaire : rejeter patterns probl√©matiques
    import re
    problematic_patterns = [
        r".*\.meta$",    # Fichiers .meta
        r".*\.data$",    # Fichiers .data
        r".*\.cache$",   # Fichiers cache
        r".*_backup$",   # Fichiers backup
        r".*\.tmp$",     # Fichiers temporaires
    ]

    for pattern in problematic_patterns:
        if re.match(pattern, tf, re.IGNORECASE):
            return False

    # Doit se terminer par m, h, d, w ou M
    unit = tf[-1]
    if unit not in ('m', 'h', 'd', 'w', 'M'):
        return False

    # La partie num√©rique doit √™tre un entier positif
    try:
        amount = int(tf[:-1])
        return amount > 0
    except ValueError:
        return False


def _read_file(path: Path) -> pd.DataFrame:
    """Lit un fichier de donn√©es selon son extension."""
    suffix = path.suffix.lower()

    if suffix == ".parquet":
        return pd.read_parquet(path)
    elif suffix == ".feather":
        return pd.read_feather(path)
    elif suffix == ".csv":
        return pd.read_csv(path, parse_dates=True)
    elif suffix == ".json":
        return pd.read_json(path)
    else:
        raise ValueError(f"Extension non support√©e: {suffix}")


def _find_data_file(symbol: str, timeframe: str) -> Optional[Path]:
    """Cherche le fichier de donn√©es correspondant."""
    symbol = symbol.upper()
    target = f"{symbol}_{timeframe}"

    for file_path in _scan_data_files():
        if file_path.stem.upper() == target.upper():
            return file_path

    return None


def _normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
    """
    Normalise un DataFrame OHLCV au format standard.

    Format de sortie:
    - Index: DatetimeIndex (UTC)
    - Colonnes: open, high, low, close, volume (minuscules)
    - Types: float64 pour OHLCV
    """
    df = df.copy()

    # Normaliser les noms de colonnes (minuscules)
    df.columns = df.columns.str.lower()

    # Mapper les variantes de noms courantes
    column_map = {
        "o": "open", "h": "high", "l": "low", "c": "close", "v": "volume",
        "Open": "open", "High": "high", "Low": "low", "Close": "close", "Volume": "volume",
        "prix_ouverture": "open", "prix_haut": "high", "prix_bas": "low",
        "prix_cloture": "close", "vol": "volume"
    }
    df = df.rename(columns=column_map)

    # V√©rifier colonnes requises
    required = ["open", "high", "low", "close", "volume"]
    missing = [col for col in required if col not in df.columns]
    if missing:
        raise ValueError(f"Colonnes manquantes: {missing}")

    # Configurer l'index datetime
    if not isinstance(df.index, pd.DatetimeIndex):
        # Chercher colonne de temps
        time_cols = ["timestamp", "time", "datetime", "date", "ts"]
        time_col = None
        for col in time_cols:
            if col in df.columns:
                time_col = col
                break

        if time_col:
            # D√©tecter le format du timestamp (millisecondes vs secondes vs datetime)
            sample_ts = df[time_col].iloc[0]
            if isinstance(sample_ts, (int, float, np.integer, np.floating)):
                # Convertir en float pour √©viter probl√®me numpy
                sample_val = float(sample_ts)
                if sample_val > 1e12:
                    # Timestamp en millisecondes
                    df[time_col] = pd.to_datetime(df[time_col], unit='ms')
                elif sample_val > 1e9:
                    # Timestamp en secondes
                    df[time_col] = pd.to_datetime(df[time_col], unit='s')
                else:
                    # Format datetime normal
                    df[time_col] = pd.to_datetime(df[time_col])
            else:
                # String datetime
                df[time_col] = pd.to_datetime(df[time_col])
            df = df.set_index(time_col)
        else:
            # Essayer de parser l'index
            df.index = pd.to_datetime(df.index)

    # Convertir en UTC si n√©cessaire
    if hasattr(df.index, 'tz') and df.index.tz is None:
        df.index = df.index.tz_localize("UTC")  # type: ignore[union-attr]
    elif hasattr(df.index, 'tz') and df.index.tz is not None:
        df.index = df.index.tz_convert("UTC")  # type: ignore[union-attr]

    # S√©lectionner et trier
    df = df[required].copy()
    df = df.sort_index()

    # Convertir types
    for col in required:
        df[col] = df[col].astype(np.float64)

    # Nettoyer NaN
    original_len = len(df)
    df = df.dropna()
    if len(df) < original_len:
        logger.warning(f"Supprim√© {original_len - len(df)} lignes avec NaN")

    return df


def load_ohlcv(
    symbol: str,
    timeframe: str,
    start: Optional[str] = None,
    end: Optional[str] = None
) -> pd.DataFrame:
    """
    Charge les donn√©es OHLCV pour un symbole et timeframe.

    Args:
        symbol: Symbole de l'actif (ex: "BTCUSDT")
        timeframe: Intervalle de temps (ex: "1m", "1h", "1d")
        start: Date de d√©but (optionnel, format ISO)
        end: Date de fin (optionnel, format ISO)

    Returns:
        DataFrame OHLCV normalis√© avec index datetime UTC

    Raises:
        FileNotFoundError: Si aucun fichier correspondant n'est trouv√©
        ValueError: Si le fichier est invalide
    """
    logger.info(f"Chargement donn√©es: {symbol}/{timeframe}")

    # Chercher le fichier
    file_path = _find_data_file(symbol, timeframe)
    if file_path is None:
        data_dir = _get_data_dir()
        raise FileNotFoundError(
            f"Fichier OHLCV introuvable pour {symbol}/{timeframe} dans {data_dir}"
        )

    # Lire et normaliser
    df = _read_file(file_path)
    df = _normalize_ohlcv(df)

    logger.info(f"  P√©riode: {df.index[0]} ‚Üí {df.index[-1]} ({len(df)} barres)")

    # Stocker les bornes disponibles pour message d'erreur
    data_start = df.index[0]
    data_end = df.index[-1]

    # Filtrer par dates si sp√©cifi√©
    if start is not None:
        start_ts = pd.Timestamp(start, tz="UTC")
        df = df[df.index >= start_ts]

    if end is not None:
        end_ts = pd.Timestamp(end, tz="UTC")
        df = df[df.index <= end_ts]

    if df.empty:
        raise ValueError(
            f"Aucune donn√©e dans la p√©riode {start} - {end}. "
            f"Donn√©es disponibles: {data_start.strftime('%Y-%m-%d')} ‚Üí "
            f"{data_end.strftime('%Y-%m-%d')}"
        )

    logger.info(f"  Apr√®s filtrage: {len(df)} barres")

    return df


def get_available_timeframes(symbol: str) -> List[str]:
    """Retourne les timeframes disponibles pour un symbole."""
    symbol = symbol.upper()
    timeframes = set()

    for file_path in _scan_data_files():
        parts = file_path.stem.split("_", 1)
        if len(parts) == 2 and parts[0].upper() == symbol:
            timeframes.add(parts[1])

    return sorted(timeframes)


def get_data_date_range(
    symbol: str,
    timeframe: str
) -> Optional[Tuple[pd.Timestamp, pd.Timestamp]]:
    """
    Retourne la plage de dates disponible pour un symbole/timeframe.

    Args:
        symbol: Symbole de l'actif (ex: "BTCUSDC")
        timeframe: Intervalle de temps (ex: "1h")

    Returns:
        Tuple (date_debut, date_fin) ou None si fichier non trouv√©
    """
    file_path = _find_data_file(symbol, timeframe)
    if file_path is None:
        return None

    try:
        df = _read_file(file_path)
        df = _normalize_ohlcv(df)
        if df.empty:
            return None
        return (df.index[0], df.index[-1])
    except Exception:
        return None


__all__ = ["load_ohlcv", "discover_available_data", "get_available_timeframes", "get_data_date_range"]
```
<!-- MODULE-END: loader.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "data\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `data\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: data.__init__

Purpose: Package data - exports loader functions (load_ohlcv, discover_available_data).

Role in pipeline: data input

Key components: Re-exports load_ohlcv, discover_available_data

Inputs: None (module imports only)

Outputs: Public API via __all__

Dependencies: .loader

Conventions: __all__ d√©finit API publique.

Read-if: Modification exports ou structure package.

Skip-if: Vous importez directement depuis data.loader.
"""

from .loader import discover_available_data, load_ohlcv

__all__ = ["load_ohlcv", "discover_available_data"]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: generate_sample.py -->
```json
{
  "name": "generate_sample.py",
  "path": "data\\sample_data\\generate_sample.py",
  "ext": ".py",
  "anchor": "generate_sample_py"
}
```
## generate_sample_py
*Chemin* : `data\sample_data\generate_sample.py`  
*Type* : `.py`  

```python
"""
Module-ID: data.sample_data.generate_sample

Purpose: G√©n√©rateur donn√©es d'exemple synth√©tiques pour tests unitaires.

Role in pipeline: test data

Key components: generate_sample_btcusdt(), generate_sample_multi_token(), export parquet

Inputs: Output path, nombre barres

Outputs: Fichier parquet OHLCV avec donn√©es r√©alistes

Dependencies: numpy, pandas, pathlib

Conventions: Seed=42 pour reproductibilit√©; colonnes [open, high, low, close, volume]

Read-if: G√©n√©rer donn√©es test ou d√©mo.

Skip-if: Vous utiliser vos donn√©es r√©elles.
"""

from pathlib import Path

import numpy as np
import pandas as pd


def generate_sample_btcusdt(output_path: Path = None):
    """G√©n√®re des donn√©es synth√©tiques similaires √† BTCUSDT."""
    np.random.seed(42)

    n_bars = 10000

    # Prix initial type BTC
    start_price = 42000.0
    volatility = 0.001  # ~0.1% par minute
    trend = 0.00001     # L√©g√®re tendance haussi√®re

    # G√©n√©rer les rendements
    returns = np.random.normal(trend, volatility, n_bars)

    # Ajouter quelques mouvements plus importants (fat tails)
    outliers = np.random.choice(n_bars, size=int(n_bars * 0.01), replace=False)
    returns[outliers] *= np.random.uniform(3, 8, len(outliers))

    # Construire les prix
    prices = start_price * np.exp(np.cumsum(returns))

    # Construire OHLCV
    df = pd.DataFrame()

    # Close prices
    df["close"] = prices

    # Open = previous close + noise
    df["open"] = df["close"].shift(1).fillna(start_price)

    # High/Low avec spread r√©aliste
    spread = np.random.uniform(0.0005, 0.002, n_bars) * prices
    df["high"] = np.maximum(df["open"], df["close"]) + spread
    df["low"] = np.minimum(df["open"], df["close"]) - spread

    # Volume (style crypto avec p√©riodes actives)
    base_volume = np.random.exponential(50, n_bars)
    volatility_volume = np.abs(returns) * 5000  # Plus de volume sur gros mouvements
    df["volume"] = base_volume + volatility_volume

    # Index datetime
    start = pd.Timestamp("2024-01-01 00:00:00", tz="UTC")
    df.index = pd.date_range(start=start, periods=n_bars, freq="1min")
    df.index.name = "timestamp"

    # Arrondir les valeurs
    df["open"] = df["open"].round(2)
    df["high"] = df["high"].round(2)
    df["low"] = df["low"].round(2)
    df["close"] = df["close"].round(2)
    df["volume"] = df["volume"].round(4)

    if output_path:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(output_path)
        print(f"‚úÖ Donn√©es g√©n√©r√©es: {output_path} ({len(df)} lignes)")

    return df


def generate_sample_ethusdt(output_path: Path = None):
    """G√©n√®re des donn√©es synth√©tiques similaires √† ETHUSDT."""
    np.random.seed(123)

    n_bars = 10000
    start_price = 2200.0
    volatility = 0.0015  # ETH plus volatile que BTC
    trend = 0.00002

    returns = np.random.normal(trend, volatility, n_bars)
    prices = start_price * np.exp(np.cumsum(returns))

    df = pd.DataFrame()
    df["close"] = prices
    df["open"] = df["close"].shift(1).fillna(start_price)
    spread = np.random.uniform(0.0005, 0.003, n_bars) * prices
    df["high"] = np.maximum(df["open"], df["close"]) + spread
    df["low"] = np.minimum(df["open"], df["close"]) - spread
    df["volume"] = np.random.exponential(200, n_bars)

    start = pd.Timestamp("2024-01-01 00:00:00", tz="UTC")
    df.index = pd.date_range(start=start, periods=n_bars, freq="1min")
    df.index.name = "timestamp"

    df = df.round(2)

    if output_path:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(output_path)
        print(f"‚úÖ Donn√©es g√©n√©r√©es: {output_path} ({len(df)} lignes)")

    return df


if __name__ == "__main__":
    data_dir = Path(__file__).parent

    print("G√©n√©ration des donn√©es d'exemple...")
    print("=" * 40)

    generate_sample_btcusdt(data_dir / "BTCUSDT_1m_sample.csv")
    generate_sample_ethusdt(data_dir / "ETHUSDT_1m_sample.csv")

    print("\n‚úÖ Termin√©!")
```
<!-- MODULE-END: generate_sample.py -->

<!-- MODULE-START: adx.py -->
```json
{
  "name": "adx.py",
  "path": "indicators\\adx.py",
  "ext": ".py",
  "anchor": "adx_py"
}
```
## adx_py
*Chemin* : `indicators\adx.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.adx

Purpose: Indicateur ADX (force tendance) + DI+ (haussier) + DI- (baissier).

Role in pipeline: data

Key components: adx, calculate_adx, ADXSettings, plus_di, minus_di

Inputs: DataFrame avec high, low, close; period (14 standard)

Outputs: Dict{adx, plus_di, minus_di} ou Tuple

Dependencies: pandas, numpy, dataclasses

Conventions: ADX liss√© 14 p√©riodes; +DI/DI- direction; <20 faible, >40 forte tendance.

Read-if: Modification p√©riode, lissage ADX.

Skip-if: Vous utilisez juste calculate_indicator('adx').
"""

from typing import Dict, Tuple, Union

import numpy as np
import pandas as pd


def directional_movement(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray]
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule les mouvements directionnels (+DM, -DM) et True Range.

    Args:
        high: S√©rie des plus hauts
        low: S√©rie des plus bas
        close: S√©rie des cl√¥tures

    Returns:
        Tuple (+DM, -DM, TR)
    """
    # Convertir en arrays
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    n = len(high)

    # True Range
    tr = np.zeros(n)
    tr[0] = high[0] - low[0]
    for i in range(1, n):
        tr[i] = max(
            high[i] - low[i],
            abs(high[i] - close[i-1]),
            abs(low[i] - close[i-1])
        )

    # Directional Movement
    plus_dm = np.zeros(n)
    minus_dm = np.zeros(n)

    for i in range(1, n):
        up_move = high[i] - high[i-1]
        down_move = low[i-1] - low[i]

        if up_move > down_move and up_move > 0:
            plus_dm[i] = up_move
        if down_move > up_move and down_move > 0:
            minus_dm[i] = down_move

    return plus_dm, minus_dm, tr


def smooth_directional(
    values: np.ndarray,
    period: int
) -> np.ndarray:
    """
    Applique le lissage Wilder (type EMA avec alpha = 1/period).

    Args:
        values: Valeurs √† lisser
        period: P√©riode de lissage

    Returns:
        Valeurs liss√©es
    """
    n = len(values)
    smoothed = np.zeros(n)

    # Premi√®re valeur = somme des N premi√®res valeurs
    smoothed[period-1] = np.sum(values[:period])

    # Lissage Wilder: new = prev - (prev/period) + current
    for i in range(period, n):
        smoothed[i] = smoothed[i-1] - (smoothed[i-1] / period) + values[i]

    return smoothed


def adx(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    period: int = 14
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule l'ADX (Average Directional Index) et les DI.

    Args:
        high: S√©rie des plus hauts
        low: S√©rie des plus bas
        close: S√©rie des cl√¥tures
        period: P√©riode de calcul (d√©faut: 14)

    Returns:
        Tuple (adx, plus_di, minus_di)

    Example:
        >>> adx_val, plus_di, minus_di = adx(df["high"], df["low"], df["close"])
        >>> # Tendance forte si adx_val > 25
        >>> # Tendance haussi√®re si plus_di > minus_di
    """
    # Mouvements directionnels et True Range
    plus_dm, minus_dm, tr = directional_movement(high, low, close)

    # Lissage Wilder
    smoothed_tr = smooth_directional(tr, period)
    smoothed_plus_dm = smooth_directional(plus_dm, period)
    smoothed_minus_dm = smooth_directional(minus_dm, period)

    # √âviter division par z√©ro
    smoothed_tr = np.where(smoothed_tr == 0, 1e-10, smoothed_tr)

    # Directional Indicators (+DI, -DI)
    plus_di = 100 * smoothed_plus_dm / smoothed_tr
    minus_di = 100 * smoothed_minus_dm / smoothed_tr

    # DX (Directional Movement Index)
    di_sum = plus_di + minus_di
    di_sum = np.where(di_sum == 0, 1e-10, di_sum)
    dx = 100 * np.abs(plus_di - minus_di) / di_sum

    # ADX = smoothed DX
    n = len(dx)
    adx_values = np.zeros(n)

    # Premi√®re valeur ADX = moyenne des N premiers DX
    if 2 * period - 1 < n:
        adx_values[2*period-2] = np.mean(dx[period-1:2*period-1])

        # Lissage pour le reste
        for i in range(2*period-1, n):
            adx_values[i] = (adx_values[i-1] * (period-1) + dx[i]) / period

    return adx_values, plus_di, minus_di


def adx_trend_strength(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    period: int = 14
) -> np.ndarray:
    """
    Retourne uniquement la valeur ADX (force de tendance).

    Args:
        high, low, close: S√©ries OHLC
        period: P√©riode

    Returns:
        Array ADX
    """
    adx_val, _, _ = adx(high, low, close, period)
    return adx_val


def adx_signal(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    period: int = 14,
    adx_threshold: float = 25.0
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur ADX/DI.

    Logique:
    - +1: ADX > seuil ET +DI > -DI ET +DI croise -DI √† la hausse
    - -1: ADX > seuil ET -DI > +DI ET -DI croise +DI √† la hausse
    - 0: Sinon

    Args:
        high, low, close: S√©ries OHLC
        period: P√©riode ADX
        adx_threshold: Seuil ADX pour confirmer tendance

    Returns:
        Array de signaux
    """
    adx_val, plus_di, minus_di = adx(high, low, close, period)

    n = len(adx_val)
    signals = np.zeros(n, dtype=np.int8)

    for i in range(1, n):
        if adx_val[i] < adx_threshold:
            continue  # Pas de tendance suffisante

        # Croisement +DI au-dessus de -DI
        if plus_di[i] > minus_di[i] and plus_di[i-1] <= minus_di[i-1]:
            signals[i] = 1
        # Croisement -DI au-dessus de +DI
        elif minus_di[i] > plus_di[i] and minus_di[i-1] <= plus_di[i-1]:
            signals[i] = -1

    return signals


# Pour le registre d'indicateurs
def calculate_adx(df: pd.DataFrame, params: Dict) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame OHLCV
        params: {"period": 14}

    Returns:
        Dict avec adx, plus_di, minus_di
    """
    period = int(params.get("period", 14))

    adx_val, plus_di, minus_di = adx(
        df["high"], df["low"], df["close"], period
    )

    return {
        "adx": adx_val,
        "plus_di": plus_di,
        "minus_di": minus_di
    }


__all__ = [
    "adx",
    "adx_trend_strength",
    "adx_signal",
    "directional_movement",
    "calculate_adx"
]
```
<!-- MODULE-END: adx.py -->

<!-- MODULE-START: amplitude_hunter.py -->
```json
{
  "name": "amplitude_hunter.py",
  "path": "indicators\\amplitude_hunter.py",
  "ext": ".py",
  "anchor": "amplitude_hunter_py"
}
```
## amplitude_hunter_py
*Chemin* : `indicators\amplitude_hunter.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.amplitude_hunter

Purpose: Score l'extr√©mit√© plage intrabar vs baseline roulante - d√©tecte amp volatil√©.

Role in pipeline: technical indicator

Key components: AmplitudeHunterSettings, amplitude_hunter()

Inputs: [high, low], period, threshold

Outputs: numpy array scores [0, 1]

Dependencies: numpy, pandas, indicators.registry

Conventions: Score normalize [0, 1]; settings dataclass

Read-if: Utiliser amplitude hunter pour signaux volatilt√©.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


@dataclass
class AmplitudeHunterSettings:
    """Settings for amplitude hunter."""

    period: int = 20

    def __post_init__(self) -> None:
        if self.period < 1:
            raise ValueError("period must be >= 1")


def amplitude_hunter(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    period: int = 20,
    settings: AmplitudeHunterSettings | None = None,
) -> dict[str, np.ndarray]:
    """
    Compute amplitude score based on range percent and rolling z-score.

    Returns:
        Dict with range_pct and score
    """
    if settings is not None:
        period = settings.period

    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    high = np.asarray(high, dtype=np.float64)
    low = np.asarray(low, dtype=np.float64)
    close = np.asarray(close, dtype=np.float64)

    range_pct = np.where(close != 0, (high - low) / close * 100.0, 0.0)

    range_series = pd.Series(range_pct, dtype="float64")
    mean = range_series.rolling(window=period, min_periods=period).mean()
    std = range_series.rolling(window=period, min_periods=period).std(ddof=0)

    std_values = std.values
    mean_values = mean.values

    score = np.where(std_values != 0, (range_pct - mean_values) / std_values, 0.0)

    return {
        "range_pct": range_pct,
        "score": score,
    }


def calculate_amplitude_hunter(df: pd.DataFrame, **params) -> dict[str, np.ndarray]:
    """
    Wrapper for registry calculation.

    Params:
        period: Rolling window length (default: 20)
    """
    return amplitude_hunter(
        df["high"],
        df["low"],
        df["close"],
        period=int(params.get("period", 20)),
    )


register_indicator(
    "amplitude_hunter",
    calculate_amplitude_hunter,
    settings_class=AmplitudeHunterSettings,
    required_columns=("high", "low", "close"),
    description="Amplitude Hunter Score - Range z-score",
)


__all__ = [
    "amplitude_hunter",
    "calculate_amplitude_hunter",
    "AmplitudeHunterSettings",
]
```
<!-- MODULE-END: amplitude_hunter.py -->

<!-- MODULE-START: aroon.py -->
```json
{
  "name": "aroon.py",
  "path": "indicators\\aroon.py",
  "ext": ".py",
  "anchor": "aroon_py"
}
```
## aroon_py
*Chemin* : `indicators\aroon.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.aroon

Purpose: Indicateur Aroon (Aroon Up/Down) - temps depuis haut/bas.

Role in pipeline: data

Key components: aroon, AroonSettings, calculate_aroon, aroon_up, aroon_down

Inputs: DataFrame avec high, low; period

Outputs: Dict{aroon_up, aroon_down} ou Tuple

Dependencies: pandas, numpy, dataclasses

Conventions: Aroon Up = (period - bars_since_high) / period * 100; >70 tendance, <30 faible.

Read-if: Modification p√©riode, formule bars_since.

Skip-if: Vous utilisez juste calculate_indicator('aroon').
"""

from dataclasses import dataclass
from typing import Tuple

import numpy as np
import pandas as pd


@dataclass
class AroonSettings:
    """Param√®tres Aroon."""
    period: int = 14


def aroon(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    period: int = 14,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule Aroon Up/Down.

    Args:
        high: Prix hauts
        low: Prix bas
        period: P√©riode (d√©faut: 14)

    Returns:
        Tuple (aroon_up, aroon_down) en pourcentage (0-100)
    """
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values

    n = len(high)
    aroon_up = np.full(n, np.nan)
    aroon_down = np.full(n, np.nan)

    for i in range(period - 1, n):
        window_high = high[i - period + 1:i + 1]
        window_low = low[i - period + 1:i + 1]

        bars_since_high = period - 1 - int(np.argmax(window_high))
        bars_since_low = period - 1 - int(np.argmin(window_low))

        aroon_up[i] = 100.0 * (period - bars_since_high) / period
        aroon_down[i] = 100.0 * (period - bars_since_low) / period

    return aroon_up, aroon_down


__all__ = ["aroon", "AroonSettings"]
```
<!-- MODULE-END: aroon.py -->

<!-- MODULE-START: atr.py -->
```json
{
  "name": "atr.py",
  "path": "indicators\\atr.py",
  "ext": ".py",
  "anchor": "atr_py"
}
```
## atr_py
*Chemin* : `indicators\atr.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.atr

Purpose: Indicateur volatilit√© ATR (Average True Range) vectoris√©.

Role in pipeline: data

Key components: atr, ATRSettings, calculate_atr, true_range

Inputs: DataFrame avec high, low, close; period, method (SMA/EMA)

Outputs: np.ndarray (volatilit√© ATR) ou Dict avec TR

Dependencies: pandas, numpy, dataclasses

Conventions: True Range normalis√©; ATR liss√© par SMA ou EMA; vectoris√© NumPy.

Read-if: Modification formula true range, smoothing method.

Skip-if: Vous utilisez juste calculate_indicator('atr').
"""

from dataclasses import dataclass
from typing import Literal, Union

import numpy as np
import pandas as pd


@dataclass
class ATRSettings:
    """Configuration de l'ATR."""

    period: int = 14
    method: Literal["ema", "sma"] = "ema"

    def __post_init__(self):
        if self.period < 1:
            raise ValueError(f"period doit √™tre >= 1, re√ßu: {self.period}")
        if self.method not in ("ema", "sma"):
            raise ValueError(f"method doit √™tre 'ema' ou 'sma', re√ßu: {self.method}")


def true_range(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray]
) -> np.ndarray:
    """
    Calcule le True Range pour chaque barre.

    TR = max(high-low, abs(high-prev_close), abs(low-prev_close))

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture

    Returns:
        Array du True Range (premi√®re valeur = high - low)
    """
    # Convertir en arrays numpy
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    high = np.asarray(high, dtype=np.float64)
    low = np.asarray(low, dtype=np.float64)
    close = np.asarray(close, dtype=np.float64)

    n = len(close)
    tr = np.zeros(n, dtype=np.float64)

    # Premi√®re valeur = high - low
    tr[0] = high[0] - low[0]

    # Calcul vectoris√© pour le reste
    prev_close = close[:-1]
    hl = high[1:] - low[1:]
    hpc = np.abs(high[1:] - prev_close)
    lpc = np.abs(low[1:] - prev_close)

    tr[1:] = np.maximum(hl, np.maximum(hpc, lpc))

    return tr


def atr(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    period: int = 14,
    method: Literal["ema", "sma"] = "ema",
    settings: ATRSettings = None
) -> np.ndarray:
    """
    Calcule l'Average True Range.

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        period: P√©riode de lissage (d√©faut: 14)
        method: M√©thode de lissage 'ema' ou 'sma' (d√©faut: 'ema')
        settings: Configuration alternative

    Returns:
        Array ATR de m√™me longueur que les entr√©es.
        Les premi√®res (period-1) valeurs seront NaN pour SMA,
        ou valeurs progressives pour EMA.
    """
    # Utiliser settings si fourni
    if settings is not None:
        period = settings.period
        method = settings.method

    # Calculer True Range
    tr = true_range(high, low, close)
    period = int(period)  # Assurer que period est un entier
    n = len(tr)

    if n < period:
        raise ValueError(f"Donn√©es insuffisantes: {n} < period={period}")

    # Lissage selon m√©thode
    if method == "sma":
        # SMA simple
        tr_series = pd.Series(tr)
        atr_values = tr_series.rolling(window=period, min_periods=period).mean()
        return atr_values.values

    else:  # EMA (m√©thode Wilder)
        atr_values = np.zeros(n, dtype=np.float64)
        atr_values[:period] = np.nan

        # Premi√®re ATR = SMA des premi√®res p√©riodes
        atr_values[period - 1] = np.mean(tr[:period])

        # EMA avec alpha = 1/period (m√©thode Wilder)
        alpha = 1.0 / period

        for i in range(period, n):
            atr_values[i] = alpha * tr[i] + (1 - alpha) * atr_values[i - 1]

        return atr_values


def atr_percent(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    period: int = 14
) -> np.ndarray:
    """
    Calcule l'ATR en pourcentage du prix.

    Formule: ATR / Close * 100

    Utile pour comparer la volatilit√© entre actifs √† prix diff√©rents.
    """
    if isinstance(close, pd.Series):
        close = close.values
    close = np.asarray(close, dtype=np.float64)

    atr_values = atr(high, low, close, period)

    # √âviter division par z√©ro
    atr_pct = np.where(close != 0, atr_values / close * 100, 0.0)

    return atr_pct


def calculate_stop_loss(
    entry_price: float,
    atr_value: float,
    multiplier: float = 1.5,
    side: Literal["long", "short"] = "long"
) -> float:
    """
    Calcule un niveau de stop-loss bas√© sur l'ATR.

    Args:
        entry_price: Prix d'entr√©e
        atr_value: Valeur ATR actuelle
        multiplier: Multiplicateur ATR (d√©faut: 1.5)
        side: Direction du trade ('long' ou 'short')

    Returns:
        Prix du stop-loss
    """
    distance = atr_value * multiplier

    if side == "long":
        return entry_price - distance
    else:
        return entry_price + distance


__all__ = ["atr", "ATRSettings", "true_range", "atr_percent", "calculate_stop_loss"]
```
<!-- MODULE-END: atr.py -->

<!-- MODULE-START: bollinger.py -->
```json
{
  "name": "bollinger.py",
  "path": "indicators\\bollinger.py",
  "ext": ".py",
  "anchor": "bollinger_py"
}
```
## bollinger_py
*Chemin* : `indicators\bollinger.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.bollinger

Purpose: Indicateur Bandes de Bollinger (volatilit√© + centre) vectoris√©.

Role in pipeline: data

Key components: bollinger_bands, BollingerSettings, calculate_bollinger

Inputs: DataFrame avec close; window, std_dev (nombre d'√©carts-types)

Outputs: Dict{upper, middle, lower} ou Tuple

Dependencies: pandas, numpy, dataclasses

Conventions: middle = SMA; upper/lower = +/- std_dev * volatilit√©; vectoris√©.

Read-if: Modification period, nombre √©carts-types, ou output format.

Skip-if: Vous utilisez juste calculate_indicator('bollinger').
"""

from dataclasses import dataclass
from typing import Tuple, Union

import numpy as np
import pandas as pd


@dataclass
class BollingerSettings:
    """Configuration des Bandes de Bollinger."""

    period: int = 20
    std_dev: float = 2.0

    def __post_init__(self):
        if self.period < 2:
            raise ValueError(f"period doit √™tre >= 2, re√ßu: {self.period}")
        if self.std_dev <= 0:
            raise ValueError(f"std_dev doit √™tre > 0, re√ßu: {self.std_dev}")


def bollinger_bands(
    close: Union[pd.Series, np.ndarray],
    period: int = 20,
    std_dev: float = 2.0,
    settings: BollingerSettings = None
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule les Bandes de Bollinger.

    Args:
        close: Prix de cl√¥ture
        period: P√©riode de la SMA (d√©faut: 20)
        std_dev: Multiplicateur d'√©cart-type (d√©faut: 2.0)
        settings: Configuration alternative (surcharge period/std_dev)

    Returns:
        Tuple (upper_band, middle_band, lower_band) - np.ndarray de m√™me longueur que close
        Les premi√®res (period-1) valeurs seront NaN.
    """
    # Utiliser settings si fourni
    if settings is not None:
        period = settings.period
        std_dev = settings.std_dev

    # Convertir en array numpy
    if isinstance(close, pd.Series):
        close = close.values
    close = np.asarray(close, dtype=np.float64)
    period = int(period)  # Assurer que period est un entier

    n = len(close)
    if n < period:
        raise ValueError(f"Donn√©es insuffisantes: {n} < period={period}")

    # Calcul vectoris√© avec rolling (utilise pandas pour efficacit√©)
    close_series = pd.Series(close)

    # Middle band = SMA
    middle = close_series.rolling(window=period, min_periods=period).mean()

    # √âcart-type rolling
    std = close_series.rolling(window=period, min_periods=period).std(ddof=0)

    # Bandes sup√©rieure et inf√©rieure
    upper = middle + (std_dev * std)
    lower = middle - (std_dev * std)

    return upper.values, middle.values, lower.values


def bollinger_bandwidth(
    close: Union[pd.Series, np.ndarray],
    period: int = 20,
    std_dev: float = 2.0
) -> np.ndarray:
    """
    Calcule le Bollinger Bandwidth (largeur relative des bandes).

    Formule: (Upper - Lower) / Middle * 100

    Utile pour d√©tecter les compressions (squeeze) avant mouvement.
    """
    upper, middle, lower = bollinger_bands(close, period, std_dev)

    # √âviter division par z√©ro
    bandwidth = np.where(
        middle != 0,
        (upper - lower) / middle * 100,
        0.0
    )

    return bandwidth


def bollinger_percent_b(
    close: Union[pd.Series, np.ndarray],
    period: int = 20,
    std_dev: float = 2.0
) -> np.ndarray:
    """
    Calcule le %B (position du prix dans les bandes).

    Formule: (Price - Lower) / (Upper - Lower)

    - %B > 1: Au-dessus de la bande sup√©rieure (surachat)
    - %B < 0: En dessous de la bande inf√©rieure (survente)
    - %B = 0.5: Au milieu (sur la SMA)
    """
    if isinstance(close, pd.Series):
        close = close.values
    close = np.asarray(close, dtype=np.float64)

    upper, middle, lower = bollinger_bands(close, period, std_dev)

    band_width = upper - lower

    # √âviter division par z√©ro
    percent_b = np.where(
        band_width != 0,
        (close - lower) / band_width,
        0.5
    )

    return percent_b


__all__ = ["bollinger_bands", "BollingerSettings", "bollinger_bandwidth", "bollinger_percent_b"]
```
<!-- MODULE-END: bollinger.py -->

<!-- MODULE-START: cci.py -->
```json
{
  "name": "cci.py",
  "path": "indicators\\cci.py",
  "ext": ".py",
  "anchor": "cci_py"
}
```
## cci_py
*Chemin* : `indicators\cci.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.cci

Purpose: Indicateur CCI (Commodity Channel Index) - √©cart normalis√© du prix.

Role in pipeline: data

Key components: cci, CCISettings, calculate_cci

Inputs: DataFrame avec high, low, close; period, constant (0.015)

Outputs: np.ndarray (oscillateur)

Dependencies: pandas, numpy, dataclasses

Conventions: CCI = (prix - SMA) / (constante * mad); >100 surachat, <-100 survente.

Read-if: Modification p√©riode, constante normalisation.

Skip-if: Vous utilisez juste calculate_indicator('cci').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class CCISettings:
    """Param√®tres CCI."""
    period: int = 20
    factor: float = 0.015  # Facteur de normalisation standard


def cci(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    period: int = 20,
    factor: float = 0.015,
) -> np.ndarray:
    """
    Calcule le Commodity Channel Index (CCI).

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        period: P√©riode de calcul (d√©faut: 20)
        factor: Facteur de normalisation (d√©faut: 0.015)

    Returns:
        Valeurs CCI (g√©n√©ralement entre -200 et +200)
    """
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    # Typical Price
    typical_price = (high + low + close) / 3.0
    tp_series = pd.Series(typical_price)

    # SMA du Typical Price
    tp_sma = tp_series.rolling(window=period).mean().values

    # Deviation
    deviation = typical_price - tp_sma

    # Mean Absolute Deviation
    def rolling_mad(arr, window):
        result = np.empty_like(arr)
        result[:window - 1] = np.nan
        for i in range(window - 1, len(arr)):
            result[i] = np.mean(np.abs(arr[i - window + 1:i + 1] - tp_sma[i]))
        return result

    mean_dev = rolling_mad(typical_price, period)

    # CCI
    cci_values = np.where(mean_dev != 0, deviation / (factor * mean_dev), 0.0)

    return cci_values


__all__ = ["cci", "CCISettings"]
```
<!-- MODULE-END: cci.py -->

<!-- MODULE-START: donchian.py -->
```json
{
  "name": "donchian.py",
  "path": "indicators\\donchian.py",
  "ext": ".py",
  "anchor": "donchian_py"
}
```
## donchian_py
*Chemin* : `indicators\donchian.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.donchian

Purpose: Indicateur Donchian Channel (breakout) - hauts/bas sur p√©riode.

Role in pipeline: data

Key components: donchian_channel, DonchianSettings, calculate_donchian

Inputs: DataFrame avec high, low; period

Outputs: Dict{upper, lower, middle} ou Tuple

Dependencies: pandas, numpy, dataclasses

Conventions: upper = max(high); lower = min(low); middle = (upper+lower)/2; breakout signal.

Read-if: Modification p√©riode, output format.

Skip-if: Vous utilisez juste calculate_indicator('donchian').
"""

from dataclasses import dataclass
from typing import Tuple

import numpy as np
import pandas as pd


@dataclass
class DonchianSettings:
    """Param√®tres Donchian Channel."""
    period: int = 20


def donchian_channel(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    period: int = 20,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule Donchian Channel.

    Args:
        high: Prix hauts
        low: Prix bas
        period: P√©riode du canal (d√©faut: 20)

    Returns:
        Tuple (upper, middle, lower)
    """
    if isinstance(high, pd.Series):
        high_series = high
    else:
        high_series = pd.Series(high)

    if isinstance(low, pd.Series):
        low_series = low
    else:
        low_series = pd.Series(low)

    upper = high_series.rolling(window=period).max().values
    lower = low_series.rolling(window=period).min().values
    middle = (upper + lower) / 2.0

    return upper, middle, lower


__all__ = ["donchian_channel", "DonchianSettings"]
```
<!-- MODULE-END: donchian.py -->

<!-- MODULE-START: ema.py -->
```json
{
  "name": "ema.py",
  "path": "indicators\\ema.py",
  "ext": ".py",
  "anchor": "ema_py"
}
```
## ema_py
*Chemin* : `indicators\ema.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.ema

Purpose: Indicateurs EMA (exponentielles) et SMA (simples) vectoris√©s.

Role in pipeline: data

Key components: ema, sma, EMASettings, calculate_ema

Inputs: DataFrame avec close; period

Outputs: np.ndarray (moyennes mobiles)

Dependencies: pandas, numpy, dataclasses

Conventions: Vectoris√© NumPy; SMA simple, EMA avec alpha=2/(n+1); NaN au d√©but.

Read-if: Modification p√©riode, gestion NaN.

Skip-if: Vous utilisez juste calculate_indicator('ema').
"""

from dataclasses import dataclass
from typing import Union

import numpy as np
import pandas as pd


@dataclass
class EMASettings:
    """Configuration des EMAs."""

    period: int = 20

    def __post_init__(self):
        if self.period < 1:
            raise ValueError(f"period doit √™tre >= 1, re√ßu: {self.period}")


def sma(
    data: Union[pd.Series, np.ndarray],
    period: int = 20
) -> np.ndarray:
    """
    Calcule la Simple Moving Average.

    Args:
        data: S√©rie de donn√©es (typiquement close)
        period: P√©riode de la moyenne

    Returns:
        Array SMA de m√™me longueur. Les premi√®res (period-1) valeurs seront NaN.
    """
    if isinstance(data, pd.Series):
        data = data.values
    data = np.asarray(data, dtype=np.float64)
    period = int(period)  # Assurer que period est un entier

    if len(data) < period:
        # Retourner array de NaN au lieu d'erreur pour compatibilit√©
        return np.full(len(data), np.nan)

    # Utiliser pandas rolling pour efficacit√©
    data_series = pd.Series(data)
    sma_values = data_series.rolling(window=period, min_periods=period).mean()

    return sma_values.values


def ema(
    data: Union[pd.Series, np.ndarray],
    period: int = 20,
    adjust: bool = True,
    settings: EMASettings = None
) -> np.ndarray:
    """
    Calcule l'Exponential Moving Average.

    Args:
        data: S√©rie de donn√©es
        period: P√©riode de l'EMA
        adjust: Si True, utilise la formule ajust√©e (d√©faut pandas)
        settings: Configuration alternative

    Returns:
        Array EMA de m√™me longueur.
    """
    if settings is not None:
        period = settings.period

    if isinstance(data, pd.Series):
        data = data.values
    data = np.asarray(data, dtype=np.float64)
    period = int(period)  # Assurer que period est un entier

    if len(data) < period:
        # Retourner array de NaN au lieu d'erreur pour compatibilit√©
        return np.full(len(data), np.nan)

    # Utiliser pandas ewm pour efficacit√©
    data_series = pd.Series(data)
    ema_values = data_series.ewm(span=period, adjust=adjust, min_periods=period).mean()

    return ema_values.values


def ema_crossover(
    data: Union[pd.Series, np.ndarray],
    fast_period: int = 12,
    slow_period: int = 26
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule les EMAs rapide et lente avec d√©tection de croisement.

    Args:
        data: Prix de cl√¥ture
        fast_period: P√©riode de l'EMA rapide
        slow_period: P√©riode de l'EMA lente

    Returns:
        Tuple (ema_fast, ema_slow, crossover_signal)
        crossover_signal: 1 = golden cross, -1 = death cross, 0 = pas de croisement
    """
    ema_fast = ema(data, fast_period)
    ema_slow = ema(data, slow_period)

    n = len(data)
    crossover = np.zeros(n, dtype=np.float64)

    # D√©tecter les croisements
    fast_above = ema_fast > ema_slow
    fast_above_prev = np.roll(fast_above, 1)
    fast_above_prev[0] = fast_above[0]

    # Golden cross: fast passe au-dessus de slow
    golden_cross = fast_above & ~fast_above_prev
    crossover[golden_cross] = 1.0

    # Death cross: fast passe en dessous de slow
    death_cross = ~fast_above & fast_above_prev
    crossover[death_cross] = -1.0

    return ema_fast, ema_slow, crossover


def dema(
    data: Union[pd.Series, np.ndarray],
    period: int = 20
) -> np.ndarray:
    """
    Calcule la Double EMA (DEMA).

    Formule: DEMA = 2 * EMA(data) - EMA(EMA(data))

    Plus r√©active qu'une EMA simple avec moins de lag.
    """
    ema1 = ema(data, period)
    ema2 = ema(ema1, period)

    return 2 * ema1 - ema2


def tema(
    data: Union[pd.Series, np.ndarray],
    period: int = 20
) -> np.ndarray:
    """
    Calcule la Triple EMA (TEMA).

    Formule: TEMA = 3*EMA - 3*EMA(EMA) + EMA(EMA(EMA))

    Encore plus r√©active que DEMA.
    """
    ema1 = ema(data, period)
    ema2 = ema(ema1, period)
    ema3 = ema(ema2, period)

    return 3 * ema1 - 3 * ema2 + ema3


__all__ = ["sma", "ema", "EMASettings", "ema_crossover", "dema", "tema"]
```
<!-- MODULE-END: ema.py -->

<!-- MODULE-START: fear_greed.py -->
```json
{
  "name": "fear_greed.py",
  "path": "indicators\\fear_greed.py",
  "ext": ".py",
  "anchor": "fear_greed_py"
}
```
## fear_greed_py
*Chemin* : `indicators\fear_greed.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.fear_greed

Purpose: Index crypto Peur & Avidite - utilise s√©rie fournie + lissage optionnel.

Role in pipeline: technical indicator

Key components: FearGreedSettings, fear_greed()

Inputs: fear_greed_series, smoothing_window, smoothing_type

Outputs: numpy array fear/greed score

Dependencies: numpy, pandas, indicators.ema, indicators.registry

Conventions: EMA ou SMA lissage; normalisation 0-100

Read-if: Utiliser Fear/Greed index pour contexte march√©.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.ema import ema, sma
from indicators.registry import register_indicator


@dataclass
class FearGreedSettings:
    """Settings for fear/greed index."""

    smooth_period: int = 0
    method: str = "sma"
    column: str = "fear_greed"

    def __post_init__(self) -> None:
        if self.smooth_period < 0:
            raise ValueError("smooth_period must be >= 0")
        if self.method not in ("ema", "sma"):
            raise ValueError("method must be 'ema' or 'sma'")


def fear_greed_index(
    values: pd.Series | np.ndarray,
    smooth_period: int = 0,
    method: str = "sma",
    settings: FearGreedSettings | None = None,
) -> np.ndarray:
    """
    Return a fear/greed series with optional smoothing.

    Args:
        values: Input series (0-100 index preferred)
        smooth_period: Optional smoothing period
        method: 'ema' or 'sma'
        settings: Optional settings override

    Returns:
        Smoothed or raw index values
    """
    if settings is not None:
        smooth_period = settings.smooth_period
        method = settings.method

    if isinstance(values, pd.Series):
        values = values.values

    values = np.asarray(values, dtype=np.float64)

    if smooth_period and smooth_period > 1:
        if method == "ema":
            return ema(values, int(smooth_period))
        return sma(values, int(smooth_period))

    return values


def calculate_fear_greed(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Wrapper for registry calculation.

    Params:
        column: Column name to use (default: fear_greed)
        smooth_period: Optional smoothing period (default: 0)
        method: 'ema' or 'sma' (default: sma)
    """
    column = params.get("column", "fear_greed")
    if column not in df.columns:
        raise ValueError(f"Column not found for fear_greed: {column}")

    return fear_greed_index(
        df[column],
        smooth_period=int(params.get("smooth_period", 0)),
        method=params.get("method", "sma"),
    )


register_indicator(
    "fear_greed",
    calculate_fear_greed,
    settings_class=FearGreedSettings,
    required_columns=(),
    description="Crypto Fear & Greed - External sentiment index",
)


__all__ = [
    "fear_greed_index",
    "calculate_fear_greed",
    "FearGreedSettings",
]
```
<!-- MODULE-END: fear_greed.py -->

<!-- MODULE-START: fibonacci.py -->
```json
{
  "name": "fibonacci.py",
  "path": "indicators\\fibonacci.py",
  "ext": ".py",
  "anchor": "fibonacci_py"
}
```
## fibonacci_py
*Chemin* : `indicators\fibonacci.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.fibonacci

Purpose: Niveaux Fibonacci retracement roulants bas√©s fenetre high/low.

Role in pipeline: technical indicator

Key components: FibonacciSettings, fibonacci()

Inputs: [high, low], period, fibonacci_ratios

Outputs: dict {fib_0, fib_236, fib_382, fib_500, fib_618, fib_786, fib_1}

Dependencies: numpy, pandas, indicators.registry

Conventions: Niveaux standard 0%, 23.6%, 38.2%, 50%, 61.8%, 78.6%, 100%

Read-if: Utiliser Fibonacci pour niveaux support/resistance.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass, field
from typing import Iterable

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


@dataclass
class FibonacciSettings:
    """Settings for Fibonacci levels."""

    period: int = 50
    levels: tuple[float, ...] = field(
        default_factory=lambda: (0.236, 0.382, 0.5, 0.618, 0.786)
    )

    def __post_init__(self) -> None:
        if self.period < 1:
            raise ValueError(f"period must be >= 1, got: {self.period}")


def fibonacci_levels(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    period: int = 50,
    levels: Iterable[float] | None = None,
    settings: FibonacciSettings | None = None,
) -> dict[str, np.ndarray]:
    """
    Compute rolling Fibonacci retracement levels.

    Args:
        high: High price series
        low: Low price series
        period: Lookback window for high/low
        levels: Iterable of retracement levels (0-1)
        settings: Optional settings override

    Returns:
        Dict of level arrays including high/low
    """
    if settings is not None:
        period = settings.period
        levels = settings.levels

    if levels is None:
        levels = (0.236, 0.382, 0.5, 0.618, 0.786)

    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values

    high_series = pd.Series(high, dtype="float64")
    low_series = pd.Series(low, dtype="float64")

    rolling_high = high_series.rolling(window=period, min_periods=period).max().values
    rolling_low = low_series.rolling(window=period, min_periods=period).min().values

    price_range = rolling_high - rolling_low

    results: dict[str, np.ndarray] = {
        "high": rolling_high,
        "low": rolling_low,
    }

    for level in levels:
        key = f"level_{int(round(level * 1000))}"
        results[key] = rolling_high - price_range * float(level)

    return results


def calculate_fibonacci_levels(df: pd.DataFrame, **params) -> dict[str, np.ndarray]:
    """
    Wrapper for registry calculation.

    Params:
        period: Lookback window (default: 50)
    """
    return fibonacci_levels(
        df["high"],
        df["low"],
        period=int(params.get("period", 50)),
    )


register_indicator(
    "fibonacci_levels",
    calculate_fibonacci_levels,
    settings_class=FibonacciSettings,
    required_columns=("high", "low"),
    description="Fibonacci Levels - Rolling retracement bands",
)


__all__ = [
    "fibonacci_levels",
    "calculate_fibonacci_levels",
    "FibonacciSettings",
]
```
<!-- MODULE-END: fibonacci.py -->

<!-- MODULE-START: filters.py -->
```json
{
  "name": "filters.py",
  "path": "indicators\\filters.py",
  "ext": ".py",
  "anchor": "filters_py"
}
```
## filters_py
*Chemin* : `indicators\filters.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.filters

Purpose: Configuration et logique m√©tier pour les filtres de signaux.
         Extraction de la logique depuis ui/sidebar.py (DDD refactoring).

Role in pipeline: domain / configuration

Key components:
- MarkovFilterConfig: Configuration du filtre Markov Switching
- get_markov_options: Options disponibles pour le filtre
- validate_markov_config: Validation de la configuration
- build_markov_params: Construction des param√®tres pour le backtest

Dependencies: indicators.markov_switching

Conventions: Fonctions pures (pas de Streamlit), retournent des dicts/dataclasses

Read-if: Configuration des filtres pour UI ou CLI
Skip-if: Logique de trading pure
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Set


# ============================================================================
# CONFIGURATION CONSTANTS
# ============================================================================

# R√©gimes Markov disponibles
MARKOV_REGIMES = {
    0: "Bull",
    1: "Bear",
    2: "Ranging",
    3: "Bull faible",  # Pour k_regimes=4
}

# Timeframes recommand√©s pour le calcul Markov
MARKOV_RECOMMENDED_TF = ["1h", "4h", "1d"]
MARKOV_UNSTABLE_TF = ["15m", "30m"]

# Nombre de r√©gimes support√©s
MARKOV_K_REGIMES_OPTIONS = [2, 3, 4]

# Configuration par d√©faut
DEFAULT_MARKOV_CONFIG = {
    "enabled": False,  # D√©sactiv√© par d√©faut
    "allowed_regimes": [0, 1, 2],  # Tous = pas d'effet
    "resample": "1h",
    "k_regimes": 3,
}


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class MarkovFilterConfig:
    """Configuration du filtre Markov Switching."""
    enabled: bool = False
    allowed_regimes: List[int] = field(default_factory=lambda: [0, 1, 2])
    forbidden_regimes: List[int] = field(default_factory=list)
    resample_tf: str = "1h"
    k_regimes: int = 3
    filter_mode: str = "allow"  # "allow" ou "forbid"

    @property
    def has_effect(self) -> bool:
        """V√©rifie si le filtre a un effet (pas tous les r√©gimes autoris√©s)."""
        if not self.enabled:
            return False
        all_regimes = set(range(self.k_regimes))
        return set(self.allowed_regimes) != all_regimes

    def to_params_dict(self) -> Dict[str, Any]:
        """Convertit en dict pour injection dans les param√®tres backtest."""
        return {
            "use_markov_filter": self.enabled,
            "markov_allowed_regimes": self.allowed_regimes,
            "markov_resample": self.resample_tf,
            "markov_regimes": self.k_regimes,
        }


@dataclass
class MarkovOptions:
    """Options disponibles pour la configuration Markov."""
    available_regimes: Dict[int, str] = field(default_factory=lambda: MARKOV_REGIMES.copy())
    recommended_timeframes: List[str] = field(default_factory=lambda: MARKOV_RECOMMENDED_TF.copy())
    unstable_timeframes: List[str] = field(default_factory=lambda: MARKOV_UNSTABLE_TF.copy())
    k_regimes_options: List[int] = field(default_factory=lambda: MARKOV_K_REGIMES_OPTIONS.copy())


# ============================================================================
# CONFIGURATION FUNCTIONS
# ============================================================================

def get_markov_options() -> MarkovOptions:
    """
    R√©cup√®re les options disponibles pour le filtre Markov.

    Returns:
        MarkovOptions avec r√©gimes, timeframes, etc.
    """
    return MarkovOptions()


def create_markov_config(
    enabled: bool = False,
    filter_mode: str = "allow",
    selected_regimes: Optional[List[int]] = None,
    resample_tf: str = "1h",
    k_regimes: int = 3
) -> MarkovFilterConfig:
    """
    Cr√©e une configuration Markov √† partir des s√©lections utilisateur.

    Args:
        enabled: Si le filtre est activ√©
        filter_mode: "allow" ou "forbid"
        selected_regimes: R√©gimes s√©lectionn√©s (coch√©s)
        resample_tf: Timeframe pour le calcul
        k_regimes: Nombre de r√©gimes

    Returns:
        MarkovFilterConfig configur√©e
    """
    if selected_regimes is None:
        selected_regimes = [0, 1, 2]

    config = MarkovFilterConfig(
        enabled=enabled,
        resample_tf=resample_tf,
        k_regimes=k_regimes,
        filter_mode=filter_mode,
    )

    # Calculer les r√©gimes autoris√©s selon le mode
    all_regimes = set(range(k_regimes))

    if filter_mode == "allow":
        config.allowed_regimes = selected_regimes
        config.forbidden_regimes = list(all_regimes - set(selected_regimes))
    else:  # forbid
        config.forbidden_regimes = selected_regimes
        config.allowed_regimes = list(all_regimes - set(selected_regimes))

    return config


def validate_markov_config(config: MarkovFilterConfig) -> tuple[bool, Optional[str]]:
    """
    Valide une configuration Markov.

    Args:
        config: Configuration √† valider

    Returns:
        Tuple (is_valid, error_message)
    """
    if not config.enabled:
        return True, None  # D√©sactiv√© = toujours valide

    # V√©rifier qu'au moins un r√©gime est autoris√©
    if not config.allowed_regimes:
        return False, "Aucun r√©gime autoris√© - aucun trade possible"

    # V√©rifier que les r√©gimes sont valides
    valid_regimes = set(range(config.k_regimes))
    for regime in config.allowed_regimes:
        if regime not in valid_regimes:
            return False, f"R√©gime {regime} invalide pour k_regimes={config.k_regimes}"

    # Avertir si timeframe instable
    if config.resample_tf in MARKOV_UNSTABLE_TF:
        return True, f"‚ö†Ô∏è Timeframe {config.resample_tf} peut √™tre instable pour Markov"

    return True, None


def get_regime_display_info(k_regimes: int) -> Dict[int, Dict[str, str]]:
    """
    R√©cup√®re les informations d'affichage pour chaque r√©gime.

    Args:
        k_regimes: Nombre de r√©gimes

    Returns:
        Dict {regime_id: {name, emoji, description}}
    """
    if k_regimes == 2:
        return {
            0: {"name": "Bull", "emoji": "üü¢", "description": "R√©gime haussier"},
            1: {"name": "Bear", "emoji": "üî¥", "description": "R√©gime baissier"},
        }
    elif k_regimes == 3:
        return {
            0: {"name": "Bull", "emoji": "üü¢", "description": "Forte volatilit√© positive"},
            1: {"name": "Bear", "emoji": "üî¥", "description": "Forte volatilit√© n√©gative"},
            2: {"name": "Ranging", "emoji": "üü°", "description": "Consolidation, faible volatilit√©"},
        }
    else:  # k_regimes == 4
        return {
            0: {"name": "Bull fort", "emoji": "üü¢", "description": "Tendance haussi√®re forte"},
            1: {"name": "Bull faible", "emoji": "üü°", "description": "Tendance haussi√®re mod√©r√©e"},
            2: {"name": "Bear", "emoji": "üî¥", "description": "Tendance baissi√®re"},
            3: {"name": "Ranging", "emoji": "‚ö™", "description": "Consolidation"},
        }


def get_recommended_regimes_for_strategy(strategy_key: str) -> List[int]:
    """
    R√©cup√®re les r√©gimes recommand√©s pour une strat√©gie.

    Args:
        strategy_key: Cl√© de la strat√©gie

    Returns:
        Liste des r√©gimes recommand√©s
    """
    # Strat√©gies long ‚Üí pr√©f√©rer Bull + Ranging
    if "long" in strategy_key.lower():
        return [0, 2]  # Bull, Ranging

    # Strat√©gies short ‚Üí pr√©f√©rer Bear + Ranging
    if "short" in strategy_key.lower():
        return [1, 2]  # Bear, Ranging

    # Strat√©gies mean-reversion ‚Üí pr√©f√©rer Ranging
    if "reversal" in strategy_key.lower() or "mean" in strategy_key.lower():
        return [2]  # Ranging

    # Par d√©faut: tous les r√©gimes
    return [0, 1, 2]


# ============================================================================
# PARAMETER INJECTION
# ============================================================================

def inject_markov_params(
    params: Dict[str, Any],
    config: MarkovFilterConfig
) -> Dict[str, Any]:
    """
    Injecte les param√®tres Markov dans un dict de param√®tres backtest.

    Args:
        params: Dict de param√®tres existant
        config: Configuration Markov

    Returns:
        Dict de param√®tres mis √† jour
    """
    updated = dict(params)
    updated.update(config.to_params_dict())
    return updated


def extract_markov_config_from_params(params: Dict[str, Any]) -> MarkovFilterConfig:
    """
    Extrait une configuration Markov depuis un dict de param√®tres.

    Args:
        params: Dict de param√®tres backtest

    Returns:
        MarkovFilterConfig extraite
    """
    return MarkovFilterConfig(
        enabled=params.get("use_markov_filter", False),
        allowed_regimes=params.get("markov_allowed_regimes", [0, 1, 2]),
        resample_tf=params.get("markov_resample", "1h"),
        k_regimes=params.get("markov_regimes", 3),
    )
```
<!-- MODULE-END: filters.py -->

<!-- MODULE-START: fva.py -->
```json
{
  "name": "fva.py",
  "path": "indicators\\fva.py",
  "ext": ".py",
  "anchor": "fva_py"
}
```
## fva_py
*Chemin* : `indicators\fva.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.fva

Purpose: Detection Fair Value Areas (FVA) - zones d'equilibre/consolidation.

Role in pipeline: pattern detection / consolidation zones

Key components: calculate_fva

Inputs: DataFrame avec high/low

Outputs: np.ndarray boolean (True = FVA detecte)

Dependencies: pandas, numpy

Conventions: FVA[i] = True si high[i] < high[i-1] ET low[i] > low[i-1]
             (bar actuelle completement dans le range de la bar precedente)
"""

import numpy as np
import pandas as pd


def calculate_fva(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les Fair Value Areas (zones de consolidation).

    Definition SIMPLIFIEE:
        FVA[i] = True si la bougie i est completement dans le range de i-1
        high[i] < high[i-1] ET low[i] > low[i-1]

    Args:
        df: DataFrame avec colonnes 'high', 'low'
        **params: Ignore (compatibilite registry)

    Returns:
        Boolean array (True aux positions de FVA)
    """
    highs = df['high'].values
    lows = df['low'].values
    n = len(df)

    fva = np.zeros(n, dtype=bool)

    for i in range(1, n):
        # Bar actuelle completement dans le range de la bar precedente
        if highs[i] < highs[i-1] and lows[i] > lows[i-1]:
            fva[i] = True

    return fva


__all__ = ['calculate_fva']
```
<!-- MODULE-END: fva.py -->

<!-- MODULE-START: fvg.py -->
```json
{
  "name": "fvg.py",
  "path": "indicators\\fvg.py",
  "ext": ".py",
  "anchor": "fvg_py"
}
```
## fvg_py
*Chemin* : `indicators\fvg.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.fvg

Purpose: Detection Fair Value Gaps (FVG) - zones d'imbalance.

Role in pipeline: pattern detection / entry zones

Key components: calculate_fvg_bullish, calculate_fvg_bearish, fvg (wrapper)

Inputs: DataFrame avec high/low

Outputs: np.ndarray boolean (True = FVG detecte a cette position)

Dependencies: pandas, numpy

Conventions: FVG bullish si low[i] > high[i-2] (gap haussier)
             FVG bearish si high[i] < low[i-2] (gap baissier)
"""

from typing import Dict

import numpy as np
import pandas as pd


def calculate_fvg_bullish(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les Fair Value Gaps haussiers (bullish FVG).

    Definition:
        FVG bullish[i] = True si low[i] > high[i-2]
        (il y a un gap/imbalance entre bougie i-2 et bougie i)

    Args:
        df: DataFrame avec colonnes 'high', 'low'
        **params: Ignore (compatibilite registry)

    Returns:
        Boolean array (True aux positions de FVG bullish)
    """
    highs = df['high'].values
    lows = df['low'].values
    n = len(df)

    fvg_bull = np.zeros(n, dtype=bool)

    for i in range(2, n):
        # FVG bullish: gap entre i-2 high et i low
        if lows[i] > highs[i-2]:
            fvg_bull[i] = True

    return fvg_bull


def calculate_fvg_bearish(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les Fair Value Gaps baissiers (bearish FVG).

    Definition:
        FVG bearish[i] = True si high[i] < low[i-2]
        (il y a un gap/imbalance entre bougie i-2 et bougie i)

    Args:
        df: DataFrame avec colonnes 'high', 'low'
        **params: Ignore (compatibilite registry)

    Returns:
        Boolean array (True aux positions de FVG bearish)
    """
    highs = df['high'].values
    lows = df['low'].values
    n = len(df)

    fvg_bear = np.zeros(n, dtype=bool)

    for i in range(2, n):
        # FVG bearish: gap entre i-2 low et i high
        if highs[i] < lows[i-2]:
            fvg_bear[i] = True

    return fvg_bear


def fvg(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Wrapper retournant les deux types de FVG.

    Returns:
        Dict avec 'fvg_bullish' et 'fvg_bearish' (boolean arrays)
    """
    return {
        'fvg_bullish': calculate_fvg_bullish(df, **params),
        'fvg_bearish': calculate_fvg_bearish(df, **params)
    }


__all__ = ['calculate_fvg_bullish', 'calculate_fvg_bearish', 'fvg']
```
<!-- MODULE-END: fvg.py -->

<!-- MODULE-START: ichimoku.py -->
```json
{
  "name": "ichimoku.py",
  "path": "indicators\\ichimoku.py",
  "ext": ".py",
  "anchor": "ichimoku_py"
}
```
## ichimoku_py
*Chemin* : `indicators\ichimoku.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.ichimoku

Purpose: Indicateur Ichimoku Cloud - syst√®me complet japonais (5 lignes).

Role in pipeline: data

Key components: ichimoku, calculate_ichimoku, Tenkan, Kijun, Senkou A/B, Chikou

Inputs: DataFrame avec high, low, close; p√©riodes standards (9, 26, 52, 26)

Outputs: Dict{tenkan, kijun, senkou_a, senkou_b, chikou, cloud_position}

Dependencies: pandas, numpy

Conventions: Cloud = Senkou A/B; Tenkan croise Kijun = signal; Chikou retard√© 26 jours.

Read-if: Modification p√©riodes, output format.

Skip-if: Vous utilisez juste calculate_indicator('ichimoku').
"""

from typing import Dict, Tuple

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


def tenkan_sen(high: pd.Series, low: pd.Series, period: int = 9) -> np.ndarray:
    """
    Calcule le Tenkan-sen (Conversion Line).

    Formule: (Plus haut sur N p√©riodes + Plus bas sur N p√©riodes) / 2

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        period: P√©riode de calcul (d√©faut: 9)

    Returns:
        Array du Tenkan-sen
    """
    high_arr = np.asarray(high, dtype=np.float64)
    low_arr = np.asarray(low, dtype=np.float64)
    n = len(high_arr)

    result = np.full(n, np.nan)

    for i in range(period - 1, n):
        highest = np.max(high_arr[i - period + 1:i + 1])
        lowest = np.min(low_arr[i - period + 1:i + 1])
        result[i] = (highest + lowest) / 2

    return result


def kijun_sen(high: pd.Series, low: pd.Series, period: int = 26) -> np.ndarray:
    """
    Calcule le Kijun-sen (Base Line).

    Formule: (Plus haut sur N p√©riodes + Plus bas sur N p√©riodes) / 2

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        period: P√©riode de calcul (d√©faut: 26)

    Returns:
        Array du Kijun-sen
    """
    # M√™me formule que Tenkan-sen mais p√©riode diff√©rente
    return tenkan_sen(high, low, period)


def senkou_span_a(
    tenkan: np.ndarray,
    kijun: np.ndarray,
    displacement: int = 26
) -> np.ndarray:
    """
    Calcule le Senkou Span A (Leading Span A).

    Formule: (Tenkan-sen + Kijun-sen) / 2, d√©cal√© de N p√©riodes dans le futur

    Args:
        tenkan: Array du Tenkan-sen
        kijun: Array du Kijun-sen
        displacement: D√©calage vers le futur (d√©faut: 26)

    Returns:
        Array du Senkou Span A
    """
    n = len(tenkan)
    span_a = (tenkan + kijun) / 2

    # D√©caler vers le futur (ajouter des NaN au d√©but, tronquer la fin)
    result = np.full(n, np.nan)
    if displacement < n:
        result[displacement:] = span_a[:-displacement]

    return result


def senkou_span_b(
    high: pd.Series,
    low: pd.Series,
    period: int = 52,
    displacement: int = 26
) -> np.ndarray:
    """
    Calcule le Senkou Span B (Leading Span B).

    Formule: (Plus haut sur N p√©riodes + Plus bas sur N p√©riodes) / 2,
             d√©cal√© de M p√©riodes dans le futur

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        period: P√©riode de calcul (d√©faut: 52)
        displacement: D√©calage vers le futur (d√©faut: 26)

    Returns:
        Array du Senkou Span B
    """
    # Calculer la ligne de base sur 52 p√©riodes
    span_b_raw = tenkan_sen(high, low, period)

    n = len(span_b_raw)
    result = np.full(n, np.nan)

    # D√©caler vers le futur
    if displacement < n:
        result[displacement:] = span_b_raw[:-displacement]

    return result


def chikou_span(close: pd.Series, displacement: int = 26) -> np.ndarray:
    """
    Calcule le Chikou Span (Lagging Span).

    Formule: Prix de cl√¥ture actuel trac√© N p√©riodes dans le pass√©

    Args:
        close: S√©rie des prix de cl√¥ture
        displacement: D√©calage vers le pass√© (d√©faut: 26)

    Returns:
        Array du Chikou Span
    """
    close_arr = np.asarray(close, dtype=np.float64)
    n = len(close_arr)

    result = np.full(n, np.nan)

    # D√©caler vers le pass√© (prix actuel affich√© 26 p√©riodes en arri√®re)
    if displacement < n:
        result[:-displacement] = close_arr[displacement:]

    return result


def ichimoku(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    tenkan_period: int = 9,
    kijun_period: int = 26,
    senkou_b_period: int = 52,
    displacement: int = 26
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule tous les composants de l'Ichimoku Cloud.

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        close: S√©rie des prix de cl√¥ture
        tenkan_period: P√©riode du Tenkan-sen (d√©faut: 9)
        kijun_period: P√©riode du Kijun-sen (d√©faut: 26)
        senkou_b_period: P√©riode du Senkou Span B (d√©faut: 52)
        displacement: D√©calage pour Senkou et Chikou (d√©faut: 26)

    Returns:
        Tuple (tenkan, kijun, senkou_a, senkou_b, chikou)
    """
    # Calculer les lignes de base
    tenkan = tenkan_sen(high, low, tenkan_period)
    kijun = kijun_sen(high, low, kijun_period)

    # Calculer le cloud (Kumo)
    senkou_a = senkou_span_a(tenkan, kijun, displacement)
    senkou_b = senkou_span_b(high, low, senkou_b_period, displacement)

    # Calculer le Chikou
    chikou = chikou_span(close, displacement)

    return tenkan, kijun, senkou_a, senkou_b, chikou


def ichimoku_cloud_position(
    close: pd.Series,
    senkou_a: np.ndarray,
    senkou_b: np.ndarray
) -> np.ndarray:
    """
    D√©termine la position du prix par rapport au cloud.

    Returns:
        1 = au-dessus du cloud (bullish)
        -1 = en-dessous du cloud (bearish)
        0 = dans le cloud (neutre)
    """
    close_arr = np.asarray(close, dtype=np.float64)
    n = len(close_arr)

    result = np.zeros(n)

    cloud_top = np.maximum(senkou_a, senkou_b)
    cloud_bottom = np.minimum(senkou_a, senkou_b)

    # Au-dessus du cloud
    result[close_arr > cloud_top] = 1
    # En-dessous du cloud
    result[close_arr < cloud_bottom] = -1
    # Dans le cloud = 0 (d√©j√† initialis√©)

    # G√©rer les NaN
    nan_mask = np.isnan(senkou_a) | np.isnan(senkou_b)
    result[nan_mask] = np.nan

    return result


def ichimoku_signal(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    tenkan_period: int = 9,
    kijun_period: int = 26,
    senkou_b_period: int = 52,
    displacement: int = 26
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur l'Ichimoku.

    Signaux:
    - Long (1): Tenkan croise Kijun vers le haut ET prix au-dessus du cloud
    - Short (-1): Tenkan croise Kijun vers le bas ET prix en-dessous du cloud
    - Neutre (0): Autres cas

    Args:
        high, low, close: S√©ries de prix OHLC
        tenkan_period: P√©riode Tenkan (d√©faut: 9)
        kijun_period: P√©riode Kijun (d√©faut: 26)
        senkou_b_period: P√©riode Senkou B (d√©faut: 52)
        displacement: D√©calage (d√©faut: 26)

    Returns:
        Array de signaux (-1, 0, 1)
    """
    tenkan, kijun, senkou_a, senkou_b, chikou = ichimoku(
        high, low, close,
        tenkan_period, kijun_period, senkou_b_period, displacement
    )

    n = len(close)
    signals = np.zeros(n)

    # Position par rapport au cloud
    cloud_pos = ichimoku_cloud_position(close, senkou_a, senkou_b)

    # Croisements Tenkan/Kijun
    for i in range(1, n):
        if np.isnan(tenkan[i]) or np.isnan(kijun[i]):
            continue
        if np.isnan(tenkan[i-1]) or np.isnan(kijun[i-1]):
            continue

        # Croisement haussier: Tenkan passe au-dessus de Kijun
        if tenkan[i-1] <= kijun[i-1] and tenkan[i] > kijun[i]:
            if cloud_pos[i] == 1:  # Au-dessus du cloud
                signals[i] = 1

        # Croisement baissier: Tenkan passe en-dessous de Kijun
        elif tenkan[i-1] >= kijun[i-1] and tenkan[i] < kijun[i]:
            if cloud_pos[i] == -1:  # En-dessous du cloud
                signals[i] = -1

    return signals


def calculate_ichimoku(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame avec colonnes high, low, close
        **params: Param√®tres cl√©-valeur
            - tenkan_period: P√©riode Tenkan (d√©faut: 9)
            - kijun_period: P√©riode Kijun (d√©faut: 26)
            - senkou_b_period: P√©riode Senkou B (d√©faut: 52)
            - displacement: D√©calage (d√©faut: 26)

    Returns:
        Dict avec tenkan, kijun, senkou_a, senkou_b, chikou, cloud_position
    """
    tenkan_period = params.get("tenkan_period", 9)
    kijun_period = params.get("kijun_period", 26)
    senkou_b_period = params.get("senkou_b_period", 52)
    displacement = params.get("displacement", 26)

    tenkan_arr, kijun_arr, senkou_a, senkou_b, chikou = ichimoku(
        df["high"], df["low"], df["close"],
        tenkan_period, kijun_period, senkou_b_period, displacement
    )

    cloud_pos = ichimoku_cloud_position(df["close"], senkou_a, senkou_b)

    return {
        "tenkan": tenkan_arr,
        "kijun": kijun_arr,
        "senkou_a": senkou_a,
        "senkou_b": senkou_b,
        "chikou": chikou,
        "cloud_position": cloud_pos
    }


# Enregistrement dans le registre
register_indicator(
    "ichimoku",
    calculate_ichimoku,
    required_columns=("high", "low", "close"),
    description="Ichimoku Kinko Hyo - Syst√®me d'analyse technique japonais"
)


__all__ = [
    "ichimoku",
    "tenkan_sen",
    "kijun_sen",
    "senkou_span_a",
    "senkou_span_b",
    "chikou_span",
    "ichimoku_cloud_position",
    "ichimoku_signal",
    "calculate_ichimoku",
]
```
<!-- MODULE-END: ichimoku.py -->

<!-- MODULE-START: keltner.py -->
```json
{
  "name": "keltner.py",
  "path": "indicators\\keltner.py",
  "ext": ".py",
  "anchor": "keltner_py"
}
```
## keltner_py
*Chemin* : `indicators\keltner.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.keltner

Purpose: Indicateur Keltner Channel - bandes EMA+ATR (alternative Bollinger).

Role in pipeline: data

Key components: keltner_channel, KeltnerSettings, calculate_keltner

Inputs: DataFrame avec high, low, close; ema_period, atr_period, atr_mult

Outputs: Dict{middle, upper, lower} ou Tuple

Dependencies: pandas, numpy, ema, atr, dataclasses

Conventions: middle = EMA; bands = +/- ATR*mult; plus lisse que Bollinger.

Read-if: Modification EMA/ATR params, output format.

Skip-if: Vous utilisez juste calculate_indicator('keltner').
"""

from dataclasses import dataclass
from typing import Tuple

import numpy as np
import pandas as pd

from .atr import atr
from .ema import ema


@dataclass
class KeltnerSettings:
    """Param√®tres Keltner Channel."""
    ema_period: int = 20
    atr_period: int = 10
    atr_multiplier: float = 2.0


def keltner_channel(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    ema_period: int = 20,
    atr_period: int = 10,
    atr_multiplier: float = 2.0,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule Keltner Channel.

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        ema_period: P√©riode EMA centrale (d√©faut: 20)
        atr_period: P√©riode ATR pour les bandes (d√©faut: 10)
        atr_multiplier: Multiplicateur ATR (d√©faut: 2.0)

    Returns:
        Tuple (middle, upper, lower)
    """
    # Middle = EMA du close
    middle = ema(close, period=ema_period)

    # ATR
    atr_values = atr(high, low, close, period=atr_period)

    # Bandes
    upper = middle + atr_multiplier * atr_values
    lower = middle - atr_multiplier * atr_values

    return middle, upper, lower


__all__ = ["keltner_channel", "KeltnerSettings"]
```
<!-- MODULE-END: keltner.py -->

<!-- MODULE-START: macd.py -->
```json
{
  "name": "macd.py",
  "path": "indicators\\macd.py",
  "ext": ".py",
  "anchor": "macd_py"
}
```
## macd_py
*Chemin* : `indicators\macd.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.macd

Purpose: Indicateur MACD (momentum) - ligne signal + histogram.

Role in pipeline: data

Key components: macd, calculate_macd, MACD line, Signal line, Histogram

Inputs: DataFrame avec close; fast_period, slow_period, signal_period

Outputs: Dict{macd, signal, histogram} ou Tuple

Dependencies: pandas, numpy, ema

Conventions: macd = ema_fast - ema_slow; signal = ema(macd); histogram = macd - signal.

Read-if: Modification p√©riodes, output structure.

Skip-if: Vous utilisez juste calculate_indicator('macd').
"""

from typing import Dict, Tuple, Union

import numpy as np
import pandas as pd

from .ema import ema


def macd(
    data: Union[pd.Series, np.ndarray],
    fast_period: int = 12,
    slow_period: int = 26,
    signal_period: int = 9
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule le MACD (Moving Average Convergence Divergence).

    Args:
        data: S√©rie de prix (g√©n√©ralement close)
        fast_period: P√©riode de l'EMA rapide (d√©faut: 12)
        slow_period: P√©riode de l'EMA lente (d√©faut: 26)
        signal_period: P√©riode du signal (d√©faut: 9)

    Returns:
        Tuple (macd_line, signal_line, histogram)

    Example:
        >>> macd_line, signal, hist = macd(df["close"])
        >>> # Signal d'achat: macd_line croise signal √† la hausse
    """
    # Convertir en array si n√©cessaire
    if isinstance(data, pd.Series):
        values = data.values
    else:
        values = np.asarray(data)

    # Calculer les EMAs
    ema_fast = ema(values, fast_period)
    ema_slow = ema(values, slow_period)

    # MACD Line
    macd_line = ema_fast - ema_slow

    # Signal Line (EMA du MACD)
    signal_line = ema(macd_line, signal_period)

    # Histogram
    histogram = macd_line - signal_line

    return macd_line, signal_line, histogram


def macd_signal(
    data: Union[pd.Series, np.ndarray],
    fast_period: int = 12,
    slow_period: int = 26,
    signal_period: int = 9
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur le MACD.

    Args:
        data: S√©rie de prix
        fast_period: P√©riode EMA rapide
        slow_period: P√©riode EMA lente
        signal_period: P√©riode du signal

    Returns:
        Array de signaux: +1 (achat), -1 (vente), 0 (neutre)
    """
    macd_line, signal_line, _ = macd(data, fast_period, slow_period, signal_period)

    n = len(macd_line)
    signals = np.zeros(n, dtype=np.int8)

    for i in range(1, n):
        # Croisement haussier: MACD passe au-dessus du signal
        if macd_line[i] > signal_line[i] and macd_line[i-1] <= signal_line[i-1]:
            signals[i] = 1
        # Croisement baissier: MACD passe en-dessous du signal
        elif macd_line[i] < signal_line[i] and macd_line[i-1] >= signal_line[i-1]:
            signals[i] = -1

    return signals


def macd_histogram_divergence(
    prices: Union[pd.Series, np.ndarray],
    histogram: np.ndarray,
    lookback: int = 20
) -> np.ndarray:
    """
    D√©tecte les divergences entre prix et histogram MACD.

    Une divergence haussi√®re: prix fait un plus bas, histogram fait un plus haut
    Une divergence baissi√®re: prix fait un plus haut, histogram fait un plus bas

    Args:
        prices: S√©rie de prix
        histogram: Histogram MACD
        lookback: P√©riode de lookback pour trouver les extrema

    Returns:
        Array: +1 (divergence haussi√®re), -1 (divergence baissi√®re), 0 (rien)
    """
    if isinstance(prices, pd.Series):
        prices = prices.values

    n = len(prices)
    divergences = np.zeros(n, dtype=np.int8)

    for i in range(lookback, n):
        window_prices = prices[i-lookback:i+1]
        window_hist = histogram[i-lookback:i+1]

        # Indices des extrema locaux
        price_min_idx = np.argmin(window_prices)
        price_max_idx = np.argmax(window_prices)
        hist_min_idx = np.argmin(window_hist)
        hist_max_idx = np.argmax(window_hist)

        # Divergence haussi√®re: nouveau plus bas prix mais histogram remonte
        if price_min_idx > lookback // 2 and hist_min_idx < lookback // 2:
            if window_prices[-1] < window_prices[0] and window_hist[-1] > window_hist[0]:
                divergences[i] = 1

        # Divergence baissi√®re: nouveau plus haut prix mais histogram descend
        if price_max_idx > lookback // 2 and hist_max_idx < lookback // 2:
            if window_prices[-1] > window_prices[0] and window_hist[-1] < window_hist[0]:
                divergences[i] = -1

    return divergences


# Pour le registre d'indicateurs
def calculate_macd(df: pd.DataFrame, params: Dict) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame OHLCV
        params: {"fast_period": 12, "slow_period": 26, "signal_period": 9}

    Returns:
        Dict avec macd, signal, histogram
    """
    fast = int(params.get("fast_period", 12))
    slow = int(params.get("slow_period", 26))
    signal = int(params.get("signal_period", 9))

    macd_line, signal_line, histogram = macd(df["close"], fast, slow, signal)

    return {
        "macd": macd_line,
        "signal": signal_line,
        "histogram": histogram
    }


__all__ = ["macd", "macd_signal", "macd_histogram_divergence", "calculate_macd"]
```
<!-- MODULE-END: macd.py -->

<!-- MODULE-START: markov_switching.py -->
```json
{
  "name": "markov_switching.py",
  "path": "indicators\\markov_switching.py",
  "ext": ".py",
  "anchor": "markov_switching_py"
}
```
## markov_switching_py
*Chemin* : `indicators\markov_switching.py`  
*Type* : `.py`  

```python
"""
Markov Switching Model pour d√©tection de phases de march√©.

Cet indicateur est SPECIAL : il n'est PAS optimisable via params/sweeps.
Il doit √™tre appel√© explicitement dans les strat√©gies via import direct.

Retourne :
- 'regime' : r√©gime le plus probable (0, 1, 2)
- 'phase' : interpr√©tation lisible ('Bull', 'Bear', 'Ranging')
- 'prob_regime_0', 'prob_regime_1', 'prob_regime_2' : probabilit√©s smoothed

Usage dans une strat√©gie :
    from indicators.markov_switching import calculate_markov_switching

    markov = calculate_markov_switching(df, resample_to="1h", k_regimes=3)
    df["market_phase"] = markov["phase"]
"""

from __future__ import annotations

import logging
from typing import Dict

import numpy as np
import pandas as pd

try:
    from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

logger = logging.getLogger(__name__)


def _calculate_markov_core(
    df: pd.DataFrame,
    price_column: str = "close",
    k_regimes: int = 3,
    switching_variance: bool = True,
    min_periods: int = 252,
) -> Dict[str, pd.Series]:
    """Version core : fit sur le df fourni (doit √™tre stable, ex: daily ou hourly)."""
    if not STATSMODELS_AVAILABLE:
        raise ImportError("statsmodels requis pour Markov Switching Model")

    if len(df) < min_periods:
        logger.warning(f"Donn√©es insuffisantes ({len(df)} < {min_periods})")
        empty = pd.Series(np.nan, index=df.index)
        result = {"regime": empty.copy(), "phase": empty.copy().astype(object)}
        for i in range(k_regimes):
            result[f"prob_regime_{i}"] = empty.copy()
        return result

    returns = np.log(df[price_column]).diff().dropna()

    try:
        model = MarkovRegression(
            returns,
            k_regimes=k_regimes,
            switching_variance=switching_variance,
        )
        res = model.fit(disp=False)
    except Exception as e:
        logger.error(f"Fit Markov √©chou√© : {e}")
        empty = pd.Series(np.nan, index=df.index)
        result = {"regime": empty.copy(), "phase": empty.copy().astype(object)}
        for i in range(k_regimes):
            result[f"prob_regime_{i}"] = empty.copy()
        return result

    probs = res.smoothed_marginal_probabilities
    probs.index = returns.index
    regime = probs.idxmax(axis=1)

    # Identification automatique des r√©gimes par moyenne des returns
    means = res.params[:k_regimes]
    bull_regime = int(np.argmax(means))
    bear_regime = int(np.argmin(means))

    if k_regimes == 3:
        remaining = {0, 1, 2} - {bull_regime, bear_regime}
        ranging_regime = remaining.pop()
        phase_map = {bull_regime: "Bull", bear_regime: "Bear", ranging_regime: "Ranging"}
    else:
        phase_map = {bull_regime: "Bull", bear_regime: "Bear"}

    phase = regime.map(phase_map).fillna("Unknown")

    result = {
        "regime": regime.reindex(df.index).ffill(),
        "phase": phase.reindex(df.index).ffill(),
    }
    for i in range(k_regimes):
        result[f"prob_regime_{i}"] = probs[i].reindex(df.index).ffill()

    logger.info(
        f"Markov fitted : Bull={bull_regime} (Œº={means[bull_regime]:.4f}), "
        f"Bear={bear_regime} (Œº={means[bear_regime]:.4f})"
    )

    return result


def calculate_markov_switching(
    df: pd.DataFrame,
    resample_to: str | None = "1h",
    price_column: str = "close",
    k_regimes: int = 3,
    min_periods: int = 252,
    df_reference: pd.DataFrame | None = None,
) -> Dict[str, pd.Series]:
    """
    Calcule les phases de march√© via Markov Switching Model.

    IMPORTANT: Pour les timeframes courts (5m, 15m, 30m), il est recommand√©
    de fournir df_reference avec des donn√©es 1h/4h charg√©es s√©par√©ment.
    Cela garantit d'avoir assez de donn√©es pour le mod√®le (252+ points).

    Args:
        df: DataFrame OHLCV avec DatetimeIndex (pour l'alignement final)
        resample_to: Timeframe de resample ("1h", "4h", "1d") - utilis√© seulement si df_reference est None
        price_column: Colonne de prix (d√©faut: 'close')
        k_regimes: Nombre de r√©gimes (d√©faut: 3 pour Bull/Bear/Ranging)
        min_periods: Minimum de p√©riodes apr√®s resample (d√©faut: 252)
        df_reference: DataFrame OHLCV du TF sup√©rieur (1h/4h) charg√© s√©par√©ment.
                      Si fourni, utilise ces donn√©es directement sans resample.

    Returns:
        Dict avec 'regime', 'phase', et 'prob_regime_X' align√©s sur df.index
    """
    # Si df_reference fourni, l'utiliser directement (donn√©es 1h/4h pr√©-charg√©es)
    if df_reference is not None and len(df_reference) >= min_periods:
        logger.info(
            f"Markov: utilisation donn√©es r√©f√©rence ({len(df_reference)} barres)"
        )
        markov = _calculate_markov_core(
            df_reference, price_column, k_regimes, min_periods=min_periods
        )
        # R√©aligner sur l'index original du backtest
        for key, series in markov.items():
            markov[key] = series.reindex(df.index, method="ffill")
        return markov

    # Sinon, tenter le resample classique
    if resample_to is None:
        return _calculate_markov_core(
            df, price_column, k_regimes, min_periods=min_periods
        )

    # Resample √† timeframe sup√©rieur pour stabilit√©
    df_resampled = df.resample(resample_to).agg({
        "open": "first",
        "high": "max",
        "low": "min",
        "close": "last",
        "volume": "sum",
    }).dropna()

    # V√©rifier qu'on a assez de donn√©es apr√®s resample
    if len(df_resampled) < min_periods:
        logger.warning(
            f"Donn√©es insuffisantes apr√®s resample vers {resample_to}: "
            f"{len(df_resampled)} < {min_periods}. "
            f"Fournissez df_reference avec des donn√©es 1h/4h pr√©-charg√©es."
        )

    markov = _calculate_markov_core(
        df_resampled, price_column, k_regimes, min_periods=min_periods
    )

    # R√©aligner + forward-fill sur index original
    for key, series in markov.items():
        markov[key] = series.reindex(df.index, method="ffill")

    return markov
```
<!-- MODULE-END: markov_switching.py -->

<!-- MODULE-START: mfi.py -->
```json
{
  "name": "mfi.py",
  "path": "indicators\\mfi.py",
  "ext": ".py",
  "anchor": "mfi_py"
}
```
## mfi_py
*Chemin* : `indicators\mfi.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.mfi

Purpose: Indicateur MFI (Money Flow Index) - RSI pond√©r√© par volume.

Role in pipeline: data

Key components: mfi, MFISettings, calculate_mfi

Inputs: DataFrame avec high, low, close, volume; period (14)

Outputs: np.ndarray (0-100 oscillateur)

Dependencies: pandas, numpy, dataclasses

Conventions: Similaire RSI mais int√®gre volume; >80 surachet√©, <20 survendu.

Read-if: Modification p√©riode, formule flux argent.

Skip-if: Vous utilisez juste calculate_indicator('mfi').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class MFISettings:
    """Param√®tres Money Flow Index."""
    period: int = 14


def mfi(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    volume: pd.Series | np.ndarray,
    period: int = 14,
) -> np.ndarray:
    """
    Calcule Money Flow Index.

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        volume: Volume
        period: P√©riode (d√©faut: 14)

    Returns:
        MFI values (0-100)
    """
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values
    if isinstance(volume, pd.Series):
        volume = volume.values

    # Typical Price
    typical_price = (high + low + close) / 3.0

    # Raw Money Flow
    raw_money_flow = typical_price * volume

    # Direction bas√©e sur typical price
    tp_diff = np.diff(typical_price, prepend=typical_price[0])

    positive_flow = np.where(tp_diff > 0, raw_money_flow, 0)
    negative_flow = np.where(tp_diff < 0, raw_money_flow, 0)

    # Rolling sum
    pos_series = pd.Series(positive_flow)
    neg_series = pd.Series(negative_flow)

    positive_mf = pos_series.rolling(window=period).sum().values
    negative_mf = neg_series.rolling(window=period).sum().values

    # Money Flow Ratio
    mf_ratio = np.where(negative_mf != 0, positive_mf / negative_mf, 1.0)

    # MFI
    mfi_values = 100.0 - (100.0 / (1.0 + mf_ratio))

    return mfi_values


__all__ = ["mfi", "MFISettings"]
```
<!-- MODULE-END: mfi.py -->

<!-- MODULE-START: momentum.py -->
```json
{
  "name": "momentum.py",
  "path": "indicators\\momentum.py",
  "ext": ".py",
  "anchor": "momentum_py"
}
```
## momentum_py
*Chemin* : `indicators\momentum.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.momentum

Purpose: Indicateur Momentum - taux changement prix simple.

Role in pipeline: data

Key components: momentum, MomentumSettings, calculate_momentum

Inputs: DataFrame avec close; period

Outputs: np.ndarray (diff√©rence close actuel - close n periodes avant)

Dependencies: pandas, numpy, dataclasses

Conventions: Momentum = Close - Close[n]; simple mais efficace acc√©l√©ration/d√©c√©l√©ration.

Read-if: Modification p√©riode.

Skip-if: Vous utilisez juste calculate_indicator('momentum').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class MomentumSettings:
    """Param√®tres Momentum."""
    period: int = 14


def momentum(
    close: pd.Series | np.ndarray,
    period: int = 14,
) -> np.ndarray:
    """
    Calcule Momentum.

    Args:
        close: Prix de cl√¥ture
        period: P√©riode (d√©faut: 14)

    Returns:
        Diff√©rence de prix sur la p√©riode
    """
    if isinstance(close, pd.Series):
        close = close.values

    momentum_values = close - np.roll(close, period)
    momentum_values[:period] = np.nan

    return momentum_values


__all__ = ["momentum", "MomentumSettings"]
```
<!-- MODULE-END: momentum.py -->

<!-- MODULE-START: obv.py -->
```json
{
  "name": "obv.py",
  "path": "indicators\\obv.py",
  "ext": ".py",
  "anchor": "obv_py"
}
```
## obv_py
*Chemin* : `indicators\obv.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.obv

Purpose: Indicateur OBV (On-Balance Volume) - volume cumulatif directionnel.

Role in pipeline: data

Key components: obv, OBVSettings, calculate_obv

Inputs: DataFrame avec close, volume

Outputs: np.ndarray (volume cumulatif sign√©)

Dependencies: pandas, numpy, dataclasses

Conventions: Volume cumul√© +/- selon direction prix; fluxargent raw.

Read-if: Modification logique accumulation volume.

Skip-if: Vous utilisez juste calculate_indicator('obv').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class OBVSettings:
    """Param√®tres OBV (pas de param√®tres configurables)."""
    pass


def obv(
    close: pd.Series | np.ndarray,
    volume: pd.Series | np.ndarray,
) -> np.ndarray:
    """
    Calcule On-Balance Volume.

    Args:
        close: Prix de cl√¥ture
        volume: Volume

    Returns:
        OBV values (cumulatif)
    """
    if isinstance(close, pd.Series):
        close = close.values
    if isinstance(volume, pd.Series):
        volume = volume.values

    # Direction: +1 si close > close_prev, -1 si <, 0 si =
    close_diff = np.diff(close, prepend=close[0])
    direction = np.sign(close_diff)

    # OBV = cumsum de (direction * volume)
    obv_values = np.cumsum(direction * volume)

    return obv_values


__all__ = ["obv", "OBVSettings"]
```
<!-- MODULE-END: obv.py -->

<!-- MODULE-START: onchain_smoothing.py -->
```json
{
  "name": "onchain_smoothing.py",
  "path": "indicators\\onchain_smoothing.py",
  "ext": ".py",
  "anchor": "onchain_smoothing_py"
}
```
## onchain_smoothing_py
*Chemin* : `indicators\onchain_smoothing.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.onchain_smoothing

Purpose: Lissage g√©n√©rique on-chain - applique EMA/SMA √† colonne quelconque.

Role in pipeline: technical indicator

Key components: OnchainSmoothingSettings, onchain_smoothing()

Inputs: [on_chain_series] ou colonne quelconque, period, type (ema/sma)

Outputs: numpy array liss√©e

Dependencies: numpy, pandas, indicators.ema, indicators.registry

Conventions: Type: ema ou sma; fleuriste EMA

Read-if: Lisser donn√©es on-chain ou custom.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.ema import ema, sma
from indicators.registry import register_indicator


@dataclass
class OnchainSmoothingSettings:
    """Settings for on-chain smoothing."""

    period: int = 14
    method: str = "ema"
    column: str = "close"

    def __post_init__(self) -> None:
        if self.period < 1:
            raise ValueError(f"period must be >= 1, got: {self.period}")
        if self.method not in ("ema", "sma"):
            raise ValueError("method must be 'ema' or 'sma'")


def onchain_smoothing(
    values: pd.Series | np.ndarray,
    period: int = 14,
    method: str = "ema",
    settings: OnchainSmoothingSettings | None = None,
) -> np.ndarray:
    """
    Smooth a series with EMA or SMA.

    Args:
        values: Input series
        period: Smoothing period
        method: 'ema' or 'sma'
        settings: Optional settings override

    Returns:
        Smoothed series
    """
    if settings is not None:
        period = settings.period
        method = settings.method

    if isinstance(values, pd.Series):
        values = values.values

    if method == "ema":
        return ema(values, period)
    return sma(values, period)


def calculate_onchain_smoothing(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Wrapper for registry calculation.

    Params:
        column: Column name to smooth (default: close)
        period: Smoothing period (default: 14)
        method: 'ema' or 'sma' (default: ema)
    """
    column = params.get("column", "close")
    if column not in df.columns:
        raise ValueError(f"Column not found for onchain_smoothing: {column}")

    return onchain_smoothing(
        df[column],
        period=int(params.get("period", 14)),
        method=params.get("method", "ema"),
    )


register_indicator(
    "onchain_smoothing",
    calculate_onchain_smoothing,
    settings_class=OnchainSmoothingSettings,
    required_columns=("close",),
    description="On-chain Smoothing - EMA/SMA of a selected column",
)


__all__ = [
    "onchain_smoothing",
    "calculate_onchain_smoothing",
    "OnchainSmoothingSettings",
]
```
<!-- MODULE-END: onchain_smoothing.py -->

<!-- MODULE-START: pivot_points.py -->
```json
{
  "name": "pivot_points.py",
  "path": "indicators\\pivot_points.py",
  "ext": ".py",
  "anchor": "pivot_points_py"
}
```
## pivot_points_py
*Chemin* : `indicators\pivot_points.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.pivot_points

Purpose: Points pivot classiques - calcul√©s depuis barre pr√©c√©dente.

Role in pipeline: technical indicator

Key components: PivotPointsSettings, pivot_points()

Inputs: [high, low, close], method (classic/fibonacci/demark/camarilla)

Outputs: dict {pivot, resistance1, resistance2, support1, support2}

Dependencies: numpy, pandas, indicators.registry

Conventions: M√©thodes: classic, fibonacci, demark, camarilla

Read-if: Utiliser pivots pour niveaux support/resistance.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


@dataclass
class PivotPointsSettings:
    """Settings for pivot points."""

    method: str = "classic"

    def __post_init__(self) -> None:
        if self.method not in ("classic", "fibonacci", "woodie"):
            raise ValueError("method must be classic, fibonacci, or woodie")


def pivot_points(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    method: str = "classic",
    settings: PivotPointsSettings | None = None,
) -> dict[str, np.ndarray]:
    """
    Compute pivot points using the previous bar values.

    Args:
        high: High series
        low: Low series
        close: Close series
        method: classic, fibonacci, or woodie
        settings: Optional settings override

    Returns:
        Dict with pivot, r1/r2/r3, s1/s2/s3
    """
    if settings is not None:
        method = settings.method

    if method not in ("classic", "fibonacci", "woodie"):
        raise ValueError("method must be classic, fibonacci, or woodie")

    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    high = np.asarray(high, dtype=np.float64)
    low = np.asarray(low, dtype=np.float64)
    close = np.asarray(close, dtype=np.float64)

    prev_high = np.roll(high, 1)
    prev_low = np.roll(low, 1)
    prev_close = np.roll(close, 1)

    prev_high[0] = np.nan
    prev_low[0] = np.nan
    prev_close[0] = np.nan

    price_range = prev_high - prev_low

    if method == "woodie":
        pivot = (prev_high + prev_low + 2 * prev_close) / 4.0
    else:
        pivot = (prev_high + prev_low + prev_close) / 3.0

    if method == "fibonacci":
        r1 = pivot + 0.382 * price_range
        s1 = pivot - 0.382 * price_range
        r2 = pivot + 0.618 * price_range
        s2 = pivot - 0.618 * price_range
        r3 = pivot + 1.0 * price_range
        s3 = pivot - 1.0 * price_range
    else:
        r1 = 2 * pivot - prev_low
        s1 = 2 * pivot - prev_high
        r2 = pivot + price_range
        s2 = pivot - price_range
        r3 = prev_high + 2 * (pivot - prev_low)
        s3 = prev_low - 2 * (prev_high - pivot)

    return {
        "pivot": pivot,
        "r1": r1,
        "s1": s1,
        "r2": r2,
        "s2": s2,
        "r3": r3,
        "s3": s3,
    }


def _normalize_method(method: object) -> str:
    """Normalize method values coming from CLI/UI/sweep/optuna into a valid string."""
    method_map = {0: "classic", 1: "fibonacci", 2: "woodie"}

    if method is None:
        return "classic"

    if isinstance(method, str):
        m = method.strip().lower()
        if m.isdigit():
            return method_map.get(int(m), "classic")
        if m in ("classic", "fibonacci", "woodie"):
            return m
        return "classic"

    # Handle numpy scalars (np.int64, np.float64, etc.)
    if isinstance(method, np.generic):
        try:
            return _normalize_method(method.item())
        except Exception:
            return "classic"

    if isinstance(method, (int, np.integer)):
        return method_map.get(int(method), "classic")

    if isinstance(method, (float, np.floating)):
        try:
            if np.isnan(method):
                return "classic"
        except TypeError:
            return "classic"
        return method_map.get(int(method), "classic")

    return "classic"


def calculate_pivot_points(
    df: pd.DataFrame,
    **params,
) -> dict[str,  np.ndarray]:
    """
    Wrapper for registry calculation.

    Params:
        method: classic, fibonacci, or woodie (default: classic)
    """
    method = _normalize_method(params.get("method", "classic"))

    return pivot_points(
        df["high"],
        df["low"],
        df["close"],
        method=method,
    )


register_indicator(
    "pivot_points",
    calculate_pivot_points,
    settings_class=PivotPointsSettings,
    required_columns=("high", "low", "close"),
    description="Pivot Points - Classic support/resistance levels",
)


__all__ = [
    "pivot_points",
    "calculate_pivot_points",
    "PivotPointsSettings",
]
```
<!-- MODULE-END: pivot_points.py -->

<!-- MODULE-START: pi_cycle.py -->
```json
{
  "name": "pi_cycle.py",
  "path": "indicators\\pi_cycle.py",
  "ext": ".py",
  "anchor": "pi_cycle_py"
}
```
## pi_cycle_py
*Chemin* : `indicators\pi_cycle.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.pi_cycle

Purpose: Indicateur Pi Cycle BTC - SMA(111) croise au-dessus 2*SMA(350).

Role in pipeline: technical indicator

Key components: PiCycleSettings, pi_cycle()

Inputs: [close], short_period, long_period, multiplier

Outputs: dict {short_sma, long_sma_doubled, signal, crossover}

Dependencies: numpy, pandas, indicators.ema, indicators.registry

Conventions: Signal=1 si court > long*2, sinon 0

Read-if: Utiliser Pi Cycle pour tops BTC.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.ema import sma
from indicators.registry import register_indicator


@dataclass
class PiCycleSettings:
    """Settings for Pi Cycle."""

    short_period: int = 111
    long_period: int = 350
    long_multiplier: float = 2.0

    def __post_init__(self) -> None:
        if self.short_period < 1:
            raise ValueError("short_period must be >= 1")
        if self.long_period < 1:
            raise ValueError("long_period must be >= 1")
        if self.long_period <= self.short_period:
            raise ValueError("long_period must be > short_period")
        if self.long_multiplier <= 0:
            raise ValueError("long_multiplier must be > 0")


def pi_cycle(
    close: pd.Series | np.ndarray,
    short_period: int = 111,
    long_period: int = 350,
    long_multiplier: float = 2.0,
    settings: PiCycleSettings | None = None,
) -> dict[str, np.ndarray]:
    """
    Compute Pi Cycle moving averages and cross signal.

    Returns:
        Dict with short_ma, long_ma, and signal (+1/-1/0)
    """
    if settings is not None:
        short_period = settings.short_period
        long_period = settings.long_period
        long_multiplier = settings.long_multiplier

    if isinstance(close, pd.Series):
        close = close.values

    short_ma = sma(close, int(short_period))
    long_ma = sma(close, int(long_period)) * float(long_multiplier)

    signal = np.zeros(len(close), dtype=np.float64)
    valid = ~np.isnan(short_ma) & ~np.isnan(long_ma)
    if np.any(valid):
        above = short_ma > long_ma
        above_prev = np.roll(above, 1)
        above_prev[0] = above[0]
        cross_up = valid & above & ~above_prev
        cross_down = valid & ~above & above_prev
        signal[cross_up] = 1.0
        signal[cross_down] = -1.0

    return {
        "short_ma": short_ma,
        "long_ma": long_ma,
        "signal": signal,
    }


def calculate_pi_cycle(df: pd.DataFrame, **params) -> dict[str, np.ndarray]:
    """
    Wrapper for registry calculation.

    Params:
        short_period: Short SMA period (default: 111)
        long_period: Long SMA period (default: 350)
        long_multiplier: Long MA multiplier (default: 2.0)
    """
    return pi_cycle(
        df["close"],
        short_period=int(params.get("short_period", 111)),
        long_period=int(params.get("long_period", 350)),
        long_multiplier=float(params.get("long_multiplier", 2.0)),
    )


register_indicator(
    "pi_cycle",
    calculate_pi_cycle,
    settings_class=PiCycleSettings,
    required_columns=("close",),
    description="Pi Cycle - SMA(111) vs 2 * SMA(350)",
)


__all__ = [
    "pi_cycle",
    "calculate_pi_cycle",
    "PiCycleSettings",
]
```
<!-- MODULE-END: pi_cycle.py -->

<!-- MODULE-START: psar.py -->
```json
{
  "name": "psar.py",
  "path": "indicators\\psar.py",
  "ext": ".py",
  "anchor": "psar_py"
}
```
## psar_py
*Chemin* : `indicators\psar.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.psar

Purpose: Indicateur Parabolic SAR - suivi tendance + stop-loss dynamique.

Role in pipeline: data

Key components: parabolic_sar, calculate_psar, SAR, trend, signal

Inputs: DataFrame avec high, low, close; iaf, maxaf, periods

Outputs: Dict{sar, trend, signal} ou Tuple

Dependencies: pandas, numpy

Conventions: SAR = point d'arr√™t; acc√©l√©ration AF jusqu'√† maxaf; trend 1/-1.

Read-if: Modification AF init/max, logique SAR update.

Skip-if: Vous utilisez juste calculate_indicator('psar').
"""

from typing import Dict, Tuple

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


def parabolic_sar(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    af_start: float = 0.02,
    af_increment: float = 0.02,
    af_max: float = 0.20
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule le Parabolic SAR.

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        close: S√©rie des prix de cl√¥ture
        af_start: Facteur d'acc√©l√©ration initial (d√©faut: 0.02)
        af_increment: Incr√©ment du facteur d'acc√©l√©ration (d√©faut: 0.02)
        af_max: Facteur d'acc√©l√©ration maximum (d√©faut: 0.20)

    Returns:
        Tuple (sar_values, trend_direction)
        - sar_values: Array des valeurs SAR
        - trend_direction: 1 = haussier, -1 = baissier
    """
    high_arr = np.asarray(high, dtype=np.float64)
    low_arr = np.asarray(low, dtype=np.float64)
    close_arr = np.asarray(close, dtype=np.float64)
    n = len(high_arr)

    if n < 2:
        return np.full(n, np.nan), np.full(n, np.nan)

    # Initialisation
    sar = np.full(n, np.nan)
    trend = np.zeros(n)  # 1 = up, -1 = down

    # D√©terminer la tendance initiale
    if close_arr[1] > close_arr[0]:
        trend[0] = 1  # Tendance haussi√®re
        sar[0] = low_arr[0]
        ep = high_arr[0]  # Extreme Point
    else:
        trend[0] = -1  # Tendance baissi√®re
        sar[0] = high_arr[0]
        ep = low_arr[0]

    af = af_start

    for i in range(1, n):
        # Calculer le SAR pour cette p√©riode
        if trend[i-1] == 1:  # Tendance haussi√®re
            # SAR ne peut pas √™tre au-dessus des deux derniers bas
            sar[i] = sar[i-1] + af * (ep - sar[i-1])
            sar[i] = min(sar[i], low_arr[i-1])
            if i >= 2:
                sar[i] = min(sar[i], low_arr[i-2])

            # V√©rifier le retournement
            if low_arr[i] < sar[i]:
                # Retournement vers baissier
                trend[i] = -1
                sar[i] = ep  # Le nouveau SAR est l'ancien EP
                ep = low_arr[i]
                af = af_start
            else:
                trend[i] = 1
                # Mettre √† jour EP si nouveau plus haut
                if high_arr[i] > ep:
                    ep = high_arr[i]
                    af = min(af + af_increment, af_max)

        else:  # Tendance baissi√®re
            # SAR ne peut pas √™tre en-dessous des deux derniers hauts
            sar[i] = sar[i-1] + af * (ep - sar[i-1])
            sar[i] = max(sar[i], high_arr[i-1])
            if i >= 2:
                sar[i] = max(sar[i], high_arr[i-2])

            # V√©rifier le retournement
            if high_arr[i] > sar[i]:
                # Retournement vers haussier
                trend[i] = 1
                sar[i] = ep  # Le nouveau SAR est l'ancien EP
                ep = high_arr[i]
                af = af_start
            else:
                trend[i] = -1
                # Mettre √† jour EP si nouveau plus bas
                if low_arr[i] < ep:
                    ep = low_arr[i]
                    af = min(af + af_increment, af_max)

    return sar, trend


def psar_signal(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    af_start: float = 0.02,
    af_increment: float = 0.02,
    af_max: float = 0.20
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur le Parabolic SAR.

    Signaux:
    - Long (1): SAR passe en-dessous du prix (d√©but tendance haussi√®re)
    - Short (-1): SAR passe au-dessus du prix (d√©but tendance baissi√®re)
    - Neutre (0): Pas de changement

    Returns:
        Array de signaux (-1, 0, 1)
    """
    sar, trend = parabolic_sar(high, low, close, af_start, af_increment, af_max)

    n = len(close)
    signals = np.zeros(n)

    # D√©tecter les changements de tendance
    for i in range(1, n):
        if np.isnan(trend[i]) or np.isnan(trend[i-1]):
            continue

        # Passage de baissier √† haussier
        if trend[i-1] == -1 and trend[i] == 1:
            signals[i] = 1

        # Passage de haussier √† baissier
        elif trend[i-1] == 1 and trend[i] == -1:
            signals[i] = -1

    return signals


def psar_stop_loss(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    position: int,
    af_start: float = 0.02,
    af_increment: float = 0.02,
    af_max: float = 0.20
) -> np.ndarray:
    """
    Utilise le PSAR comme niveau de stop-loss dynamique.

    Args:
        high, low, close: S√©ries de prix
        position: Direction de la position (1 = long, -1 = short)
        af_start, af_increment, af_max: Param√®tres PSAR

    Returns:
        Array des niveaux de stop-loss
    """
    sar, trend = parabolic_sar(high, low, close, af_start, af_increment, af_max)

    # Pour une position long, le stop est le SAR quand il est en dessous
    # Pour une position short, le stop est le SAR quand il est au-dessus
    if position == 1:
        # Stop pour position long: SAR en dessous du prix
        stop = np.where(trend == 1, sar, np.nan)
    else:
        # Stop pour position short: SAR au-dessus du prix
        stop = np.where(trend == -1, sar, np.nan)

    return stop


def calculate_psar(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame avec colonnes high, low, close
        **params: Param√®tres cl√©-valeur
            - af_start: Facteur d'acc√©l√©ration initial (d√©faut: 0.02)
            - af_increment: Incr√©ment AF (d√©faut: 0.02)
            - af_max: AF maximum (d√©faut: 0.20)

    Returns:
        Dict avec sar, trend, signal
    """
    af_start = params.get("af_start", 0.02)
    af_increment = params.get("af_increment", 0.02)
    af_max = params.get("af_max", 0.20)

    sar, trend = parabolic_sar(
        df["high"], df["low"], df["close"],
        af_start, af_increment, af_max
    )

    signal = psar_signal(
        df["high"], df["low"], df["close"],
        af_start, af_increment, af_max
    )

    return {
        "sar": sar,
        "trend": trend,
        "signal": signal
    }


# Enregistrement dans le registre
register_indicator(
    "psar",
    calculate_psar,
    required_columns=("high", "low", "close"),
    description="Parabolic SAR - Indicateur de suivi de tendance"
)


__all__ = [
    "parabolic_sar",
    "psar_signal",
    "psar_stop_loss",
    "calculate_psar",
]
```
<!-- MODULE-END: psar.py -->

<!-- MODULE-START: registry.py -->
```json
{
  "name": "registry.py",
  "path": "indicators\\registry.py",
  "ext": ".py",
  "anchor": "registry_py"
}
```
## registry_py
*Chemin* : `indicators\registry.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.registry

Purpose: Registre centralis√© des indicateurs pour calcul + mapping unifi√©.

Role in pipeline: core

Key components: IndicatorRegistry, register_indicator, calculate_indicator, get_indicator

Inputs: Nom indicateur, DataFrame OHLCV, param√®tres

Outputs: R√©sultats indicateur (np.ndarray ou Dict)

Dependencies: Tous les modules indicators, pandas, numpy

Conventions: Registry singleton; API uniforme calculate_indicator(name, df, **params); fallback type checking.

Read-if: Ajout indicateur, modification API registre.

Skip-if: Vous appelez juste calculate_indicator().
"""

from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional, Tuple
import os

import pandas as pd

from .adx import adx, calculate_adx
from .aroon import AroonSettings, aroon
from .atr import ATRSettings, atr

# Imports relatifs des indicateurs
from .bollinger import BollingerSettings, bollinger_bands
from .cci import CCISettings, cci
from .donchian import DonchianSettings, donchian_channel
from .ema import EMASettings, ema, sma
from .keltner import KeltnerSettings, keltner_channel
from .macd import calculate_macd, macd
from .mfi import MFISettings, mfi
from .momentum import MomentumSettings, momentum
from .obv import OBVSettings, obv
from .roc import ROCSettings, roc
from .rsi import RSISettings, rsi
from .stochastic import stochastic
from .supertrend import SuperTrendSettings, supertrend

# Nouveaux indicateurs
from .vwap import VWAPSettings, vwap
from .williams_r import WilliamsRSettings, williams_r

# Cache disque pour √©viter recalculs r√©p√©t√©s
from data.indicator_bank import get_indicator_bank


@dataclass
class IndicatorInfo:
    """M√©tadonn√©es d'un indicateur."""

    name: str
    function: Callable
    settings_class: Optional[type]
    required_columns: Tuple[str, ...]
    description: str


# Registre global des indicateurs
_INDICATOR_REGISTRY: Dict[str, IndicatorInfo] = {}


def register_indicator(
    name: str,
    function: Callable,
    settings_class: Optional[type] = None,
    required_columns: Tuple[str, ...] = ("close",),
    description: str = ""
) -> None:
    """Enregistre un nouvel indicateur."""
    _INDICATOR_REGISTRY[name.lower()] = IndicatorInfo(
        name=name,
        function=function,
        settings_class=settings_class,
        required_columns=required_columns,
        description=description
    )


def get_indicator(name: str) -> Optional[IndicatorInfo]:
    """R√©cup√®re les infos d'un indicateur."""
    return _INDICATOR_REGISTRY.get(name.lower())


def list_indicators() -> list[str]:
    """Liste tous les indicateurs disponibles."""
    return list(_INDICATOR_REGISTRY.keys())


def calculate_indicator(
    name: str,
    df: pd.DataFrame,
    params: Optional[Dict[str, Any]] = None
) -> Any:
    """
    Calcule un indicateur par son nom avec cache intelligent.

    Le cache IndicatorBank est utilis√© si activ√© (via INDICATOR_CACHE_ENABLED=1).
    Gain de performance: ~33x sur sweeps avec param√®tres r√©p√©t√©s.

    Args:
        name: Nom de l'indicateur (bollinger, atr, rsi, ema, sma)
        df: DataFrame OHLCV
        params: Param√®tres de l'indicateur

    Returns:
        R√©sultat du calcul (array ou tuple selon indicateur)

    Raises:
        ValueError: Si indicateur inconnu ou colonnes manquantes
    """
    name = name.lower()
    info = get_indicator(name)

    if info is None:
        available = ", ".join(list_indicators())
        raise ValueError(f"Indicateur inconnu: '{name}'. Disponibles: {available}")

    # V√©rifier colonnes requises
    missing = [col for col in info.required_columns if col not in df.columns]
    if missing:
        raise ValueError(f"Colonnes manquantes pour {name}: {missing}")

    # Pr√©parer les arguments
    params = params or {}

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CACHE INTELLIGENT - √âvite recalculs r√©p√©t√©s (100‚Üí3 runs/sec FIX)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # V√©rifier si cache activ√© (d√©faut: oui en production, non en dev/debug)
    cache_enabled = os.getenv("INDICATOR_CACHE_ENABLED", "1").strip() in ("1", "true", "yes", "on")

    if cache_enabled:
        try:
            bank = get_indicator_bank()

            # D√©terminer le backend (CPU/GPU) pour cl√© de cache correcte
            backend = "cpu"  # D√©faut CPU
            try:
                from performance.gpu import gpu_available
                if gpu_available() and len(df) >= 5000:
                    backend = "gpu"
            except ImportError:
                pass

            # V√©rifier cache
            cached_result = bank.get(name, params, df, backend=backend)
            if cached_result is not None:
                return cached_result
        except Exception:
            # Si cache fail, continuer sans (degraded mode)
            pass

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CALCUL DE L'INDICATEUR (ou r√©cup√©ration depuis cache ci-dessus)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Calculer le r√©sultat (sera mis en cache ensuite)
    result = None

    if name == "bollinger":
        result = bollinger_bands(
            df["close"],
            period=int(params.get("period", 20)),
            std_dev=float(params.get("std_dev", 2.0))
        )

    elif name == "atr":
        result = atr(
            df["high"],
            df["low"],
            df["close"],
            period=int(params.get("period", 14)),
            method=params.get("method", "ema")
        )

    elif name == "rsi":
        result = rsi(
            df["close"],
            period=int(params.get("period", 14))
        )

    elif name == "ema":
        result = ema(
            df["close"],
            period=int(params.get("period", 20))
        )

    elif name == "sma":
        result = sma(
            df["close"],
            period=int(params.get("period", 20))
        )

    elif name == "macd":
        macd_line, signal_line, histogram = macd(
            df["close"],
            fast_period=int(params.get("fast_period", 12)),
            slow_period=int(params.get("slow_period", 26)),
            signal_period=int(params.get("signal_period", 9))
        )
        result = {"macd": macd_line, "signal": signal_line, "histogram": histogram}

    elif name == "adx":
        adx_val, plus_di, minus_di = adx(
            df["high"],
            df["low"],
            df["close"],
            period=int(params.get("period", 14))
        )
        result = {"adx": adx_val, "plus_di": plus_di, "minus_di": minus_di}

    elif name == "stochastic":
        stoch_k, stoch_d = stochastic(
            df["high"],
            df["low"],
            df["close"],
            k_period=int(params.get("k_period", 14)),
            d_period=int(params.get("d_period", 3)),
            smooth_k=int(params.get("smooth_k", 3))
        )
        result = (stoch_k, stoch_d)

    elif name == "vwap":
        result = vwap(
            df["high"], df["low"], df["close"], df["volume"],
            period=params.get("period", None)
        )

    elif name == "donchian":
        upper, middle, lower = donchian_channel(
            df["high"], df["low"],
            period=int(params.get("period", 20))
        )
        result = {"upper": upper, "middle": middle, "lower": lower}

    elif name == "cci":
        result = cci(
            df["high"], df["low"], df["close"],
            period=int(params.get("period", 20))
        )

    elif name == "keltner":
        middle, upper, lower = keltner_channel(
            df["high"], df["low"], df["close"],
            ema_period=int(params.get("ema_period", 20)),
            atr_period=int(params.get("atr_period", 10)),
            atr_multiplier=float(params.get("atr_multiplier", 2.0))
        )
        result = {"middle": middle, "upper": upper, "lower": lower}

    elif name == "mfi":
        result = mfi(
            df["high"], df["low"], df["close"], df["volume"],
            period=int(params.get("period", 14))
        )

    elif name == "williams_r":
        result = williams_r(
            df["high"], df["low"], df["close"],
            period=int(params.get("period", 14))
        )

    elif name == "momentum":
        result = momentum(
            df["close"],
            period=int(params.get("period", 14))
        )

    elif name == "obv":
        result = obv(df["close"], df["volume"])

    elif name == "roc":
        result = roc(
            df["close"],
            period=int(params.get("period", 12))
        )

    elif name == "aroon":
        aroon_up, aroon_down = aroon(
            df["high"], df["low"],
            period=int(params.get("period", 14))
        )
        result = {"aroon_up": aroon_up, "aroon_down": aroon_down}

    elif name == "supertrend":
        st_values, st_direction = supertrend(
            df["high"], df["low"], df["close"],
            atr_period=int(params.get("atr_period", 10)),
            multiplier=float(params.get("multiplier", 3.0))
        )
        result = {"supertrend": st_values, "direction": st_direction}

    else:
        # Appel g√©n√©rique
        result = info.function(df, **params)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # MISE EN CACHE DU R√âSULTAT pour r√©utilisation (restaure 100 runs/sec!)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if cache_enabled and result is not None:
        try:
            bank = get_indicator_bank()
            # D√©terminer backend (coh√©rent avec logique ci-dessus)
            backend = "cpu"
            try:
                from performance.gpu import gpu_available
                if gpu_available() and len(df) >= 5000:
                    backend = "gpu"
            except ImportError:
                pass

            bank.put(name, params, df, result, backend=backend)
        except Exception:
            # Erreur cache non bloquante (degraded mode)
            pass

    return result


# Enregistrement des indicateurs de base
register_indicator(
    name="bollinger",
    function=bollinger_bands,
    settings_class=BollingerSettings,
    required_columns=("close",),
    description="Bandes de Bollinger - Mean reversion indicator"
)

register_indicator(
    name="atr",
    function=atr,
    settings_class=ATRSettings,
    required_columns=("high", "low", "close"),
    description="Average True Range - Volatility indicator"
)

register_indicator(
    name="rsi",
    function=rsi,
    settings_class=RSISettings,
    required_columns=("close",),
    description="Relative Strength Index - Momentum oscillator"
)

register_indicator(
    name="ema",
    function=ema,
    settings_class=EMASettings,
    required_columns=("close",),
    description="Exponential Moving Average"
)

register_indicator(
    name="sma",
    function=sma,
    settings_class=None,
    required_columns=("close",),
    description="Simple Moving Average"
)

register_indicator(
    name="macd",
    function=calculate_macd,
    settings_class=None,
    required_columns=("close",),
    description="Moving Average Convergence Divergence - Momentum indicator"
)

register_indicator(
    name="adx",
    function=calculate_adx,
    settings_class=None,
    required_columns=("high", "low", "close"),
    description="Average Directional Index - Trend strength indicator"
)

register_indicator(
    name="stochastic",
    function=stochastic,
    settings_class=None,
    required_columns=("high", "low", "close"),
    description="Stochastic Oscillator - Momentum indicator for overbought/oversold"
)

# Nouveaux indicateurs

register_indicator(
    name="vwap",
    function=vwap,
    settings_class=VWAPSettings,
    required_columns=("high", "low", "close", "volume"),
    description="Volume Weighted Average Price"
)

register_indicator(
    name="donchian",
    function=donchian_channel,
    settings_class=DonchianSettings,
    required_columns=("high", "low"),
    description="Donchian Channel - Breakout indicator"
)

register_indicator(
    name="cci",
    function=cci,
    settings_class=CCISettings,
    required_columns=("high", "low", "close"),
    description="Commodity Channel Index - Momentum oscillator"
)

register_indicator(
    name="keltner",
    function=keltner_channel,
    settings_class=KeltnerSettings,
    required_columns=("high", "low", "close"),
    description="Keltner Channel - Volatility channel based on EMA and ATR"
)

register_indicator(
    name="mfi",
    function=mfi,
    settings_class=MFISettings,
    required_columns=("high", "low", "close", "volume"),
    description="Money Flow Index - Volume-weighted RSI"
)

register_indicator(
    name="williams_r",
    function=williams_r,
    settings_class=WilliamsRSettings,
    required_columns=("high", "low", "close"),
    description="Williams %R - Momentum oscillator"
)

register_indicator(
    name="momentum",
    function=momentum,
    settings_class=MomentumSettings,
    required_columns=("close",),
    description="Momentum - Absolute price change over period"
)

register_indicator(
    name="obv",
    function=obv,
    settings_class=OBVSettings,
    required_columns=("close", "volume"),
    description="On-Balance Volume - Cumulative volume flow"
)

register_indicator(
    name="roc",
    function=roc,
    settings_class=ROCSettings,
    required_columns=("close",),
    description="Rate of Change - Percentage price change"
)

register_indicator(
    name="aroon",
    function=aroon,
    settings_class=AroonSettings,
    required_columns=("high", "low"),
    description="Aroon Indicator - Trend identification"
)

register_indicator(
    name="supertrend",
    function=supertrend,
    settings_class=SuperTrendSettings,
    required_columns=("high", "low", "close"),
    description="SuperTrend - ATR-based trend follower"
)

# Late imports for indicators that self-register to avoid circular imports.
from . import (
    amplitude_hunter,  # noqa: F401,E402
    fear_greed,  # noqa: F401,E402
    fibonacci,  # noqa: F401,E402
    ichimoku,  # noqa: F401,E402
    onchain_smoothing,  # noqa: F401,E402
    pi_cycle,  # noqa: F401,E402
    pivot_points,  # noqa: F401,E402
    psar,  # noqa: F401,E402
    standard_deviation,  # noqa: F401,E402
    volume_oscillator,  # noqa: F401,E402
    vortex,  # noqa: F401,E402
)


class IndicatorRegistry:
    """
    Classe wrapper pour le registre d'indicateurs.

    Permet une utilisation orient√©e objet et potentiellement
    le caching des r√©sultats dans le futur.
    """

    def __init__(self):
        self._cache: Dict[str, Any] = {}
        self._cache_enabled = False

    def enable_cache(self) -> None:
        """Active le cache des calculs."""
        self._cache_enabled = True

    def disable_cache(self) -> None:
        """D√©sactive et vide le cache."""
        self._cache_enabled = False
        self._cache.clear()

    def clear_cache(self) -> None:
        """Vide le cache."""
        self._cache.clear()

    def calculate(
        self,
        name: str,
        df: pd.DataFrame,
        params: Optional[Dict[str, Any]] = None
    ) -> Any:
        """
        Calcule un indicateur, avec mise en cache optionnelle.
        """
        cache_key = f"{name}_{hash(df.index[0])}_{hash(df.index[-1])}_{str(params)}"

        if self._cache_enabled and cache_key in self._cache:
            return self._cache[cache_key]

        result = calculate_indicator(name, df, params)

        if self._cache_enabled:
            self._cache[cache_key] = result

        return result

    def calculate_multiple(
        self,
        df: pd.DataFrame,
        indicator_configs: Dict[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Calcule plusieurs indicateurs d'un coup.

        Args:
            df: DataFrame OHLCV
            indicator_configs: Dict {nom_indicateur: {params}}

        Returns:
            Dict {nom_indicateur: r√©sultat}
        """
        results = {}
        for name, params in indicator_configs.items():
            results[name] = self.calculate(name, df, params)
        return results

    @staticmethod
    def list_available() -> list[str]:
        """Liste les indicateurs disponibles."""
        return list_indicators()

    @staticmethod
    def get_info(name: str) -> Optional[IndicatorInfo]:
        """R√©cup√®re les infos d'un indicateur."""
        return get_indicator(name)


__all__ = [
    "IndicatorRegistry",
    "calculate_indicator",
    "list_indicators",
    "register_indicator",
    "get_indicator"
]
```
<!-- MODULE-END: registry.py -->

<!-- MODULE-START: roc.py -->
```json
{
  "name": "roc.py",
  "path": "indicators\\roc.py",
  "ext": ".py",
  "anchor": "roc_py"
}
```
## roc_py
*Chemin* : `indicators\roc.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.roc

Purpose: Indicateur ROC (Rate of Change) - changement % prix.

Role in pipeline: data

Key components: roc, ROCSettings, calculate_roc

Inputs: DataFrame avec close; period

Outputs: np.ndarray (% changement)

Dependencies: pandas, numpy, dataclasses

Conventions: ROC = (Close - Close[n]) / Close[n] * 100; momentum en pourcent.

Read-if: Modification p√©riode, normalisation %.

Skip-if: Vous utilisez juste calculate_indicator('roc').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class ROCSettings:
    """Param√®tres ROC."""
    period: int = 12


def roc(
    close: pd.Series | np.ndarray,
    period: int = 12,
) -> np.ndarray:
    """
    Calcule Rate of Change.

    Args:
        close: Prix de cl√¥ture
        period: P√©riode (d√©faut: 12)

    Returns:
        ROC en pourcentage
    """
    if isinstance(close, pd.Series):
        close = close.values

    close_shifted = np.roll(close, period)
    roc_values = ((close - close_shifted) / close_shifted) * 100.0
    roc_values[:period] = np.nan

    return roc_values


__all__ = ["roc", "ROCSettings"]
```
<!-- MODULE-END: roc.py -->

<!-- MODULE-START: rsi.py -->
```json
{
  "name": "rsi.py",
  "path": "indicators\\rsi.py",
  "ext": ".py",
  "anchor": "rsi_py"
}
```
## rsi_py
*Chemin* : `indicators\rsi.py`  
*Type* : `.py`  

```python
"D:\backtest_core\docs\Code_de_backtest_corev2_2_4_1.md""""
Module-ID: indicators.rsi

Purpose: Indicateur RSI (Relative Strength Index) momentum vectoris√©.

Role in pipeline: data

Key components: rsi, RSISettings, calculate_rsi

Inputs: DataFrame avec close; period (typique 14)

Outputs: np.ndarray (0-100 oscillateur)

Dependencies: pandas, numpy, dataclasses

Conventions: Valeurs 0-100; >70 surachat, <30 survente; RSI liss√©.

Read-if: Modification p√©riode, lissage gains/pertes.

Skip-if: Vous utilisez juste calculate_indicator('rsi').
"""

from dataclasses import dataclass
from typing import Union

import numpy as np
import pandas as pd


@dataclass
class RSISettings:
    """Configuration du RSI."""

    period: int = 14
    overbought: float = 70.0
    oversold: float = 30.0

    def __post_init__(self):
        if self.period < 1:
            raise ValueError(f"period doit √™tre >= 1, re√ßu: {self.period}")
        if not 0 <= self.oversold < self.overbought <= 100:
            raise ValueError(
                f"Niveaux invalides: oversold={self.oversold}, overbought={self.overbought}"
            )


def rsi(
    close: Union[pd.Series, np.ndarray],
    period: int = 14,
    settings: RSISettings = None
) -> np.ndarray:
    """
    Calcule le Relative Strength Index.

    Args:
        close: Prix de cl√¥ture
        period: P√©riode du RSI (d√©faut: 14)
        settings: Configuration alternative

    Returns:
        Array RSI de valeurs entre 0 et 100.
        Les premi√®res 'period' valeurs seront NaN.
    """
    # Utiliser settings si fourni
    if settings is not None:
        period = settings.period

    # Convertir en array numpy
    if isinstance(close, pd.Series):
        close = close.values
    close = np.asarray(close, dtype=np.float64)

    n = len(close)
    if n <= period:
        raise ValueError(f"Donn√©es insuffisantes: {n} <= period={period}")

    # Calcul des variations
    deltas = np.diff(close)
    gains = np.where(deltas > 0, deltas, 0.0)
    losses = np.where(deltas < 0, -deltas, 0.0)

    # Initialiser les moyennes
    rsi_values = np.full(n, np.nan, dtype=np.float64)

    # Premi√®re moyenne (SMA sur la premi√®re fen√™tre)
    avg_gain = np.mean(gains[:period])
    avg_loss = np.mean(losses[:period])

    # Premi√®re valeur RSI
    if avg_loss == 0:
        rsi_values[period] = 100.0 if avg_gain > 0 else 50.0
    else:
        rs = avg_gain / avg_loss
        rsi_values[period] = 100.0 - (100.0 / (1.0 + rs))

    # EMA pour le reste (m√©thode Wilder)
    alpha = 1.0 / period

    for i in range(period, n - 1):
        avg_gain = (1 - alpha) * avg_gain + alpha * gains[i]
        avg_loss = (1 - alpha) * avg_loss + alpha * losses[i]

        if avg_loss == 0:
            rsi_values[i + 1] = 100.0 if avg_gain > 0 else 50.0
        else:
            rs = avg_gain / avg_loss
            rsi_values[i + 1] = 100.0 - (100.0 / (1.0 + rs))

    return rsi_values


def rsi_signal(
    close: Union[pd.Series, np.ndarray],
    period: int = 14,
    overbought: float = 70.0,
    oversold: float = 30.0
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur le RSI.

    Args:
        close: Prix de cl√¥ture
        period: P√©riode du RSI
        overbought: Niveau de surachat (d√©faut: 70)
        oversold: Niveau de survente (d√©faut: 30)

    Returns:
        Array de signaux: 1 (achat), -1 (vente), 0 (neutre)
    """
    rsi_values = rsi(close, period)

    signals = np.zeros(len(close), dtype=np.float64)

    # Signal d'achat: RSI < oversold
    signals[rsi_values < oversold] = 1.0

    # Signal de vente: RSI > overbought
    signals[rsi_values > overbought] = -1.0

    return signals


def rsi_divergence(
    close: Union[pd.Series, np.ndarray],
    period: int = 14,
    lookback: int = 14
) -> np.ndarray:
    """
    D√©tecte les divergences RSI/Prix.

    Retourne:
        1 = Divergence haussi√®re (prix plus bas, RSI plus haut)
       -1 = Divergence baissi√®re (prix plus haut, RSI plus bas)
        0 = Pas de divergence
    """
    if isinstance(close, pd.Series):
        close = close.values
    close = np.asarray(close, dtype=np.float64)

    rsi_values = rsi(close, period)
    n = len(close)

    divergence = np.zeros(n, dtype=np.float64)

    for i in range(period + lookback, n):
        price_change = close[i] - close[i - lookback]
        rsi_change = rsi_values[i] - rsi_values[i - lookback]

        # Divergence haussi√®re
        if price_change < 0 and rsi_change > 0:
            divergence[i] = 1.0
        # Divergence baissi√®re
        elif price_change > 0 and rsi_change < 0:
            divergence[i] = -1.0

    return divergence


__all__ = ["rsi", "RSISettings", "rsi_signal", "rsi_divergence"]
```
<!-- MODULE-END: rsi.py -->

<!-- MODULE-START: scoring.py -->
```json
{
  "name": "scoring.py",
  "path": "indicators\\scoring.py",
  "ext": ".py",
  "anchor": "scoring_py"
}
```
## scoring_py
*Chemin* : `indicators\scoring.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.scoring

Purpose: Calcul score directionnel bull/bear base sur patterns.

Role in pipeline: decision / bias calculation

Key components: calculate_bull_score, calculate_bear_score

Inputs: DataFrame avec swing, fvg, fva, smart_legs

Outputs: np.ndarray float (score 0.0-1.0)

Dependencies: pandas, numpy

Conventions: Score = somme ponderee patterns detectes, normalise 0-1
"""

from typing import Dict

import numpy as np
import pandas as pd


def calculate_bull_score(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Calcule le score haussier base sur patterns detectes.

    Composantes:
        +1 si swing_low detecte (support potentiel)
        +1 si fvg_bullish actif
        +1 si smart_leg_bullish actif
        +1 si fva presente (consolidation avant reprise)

    Args:
        df: DataFrame avec colonnes pattern
        **params: Ignore

    Returns:
        Float array (score 0.0-1.0, normalise par max possible)
    """
    n = len(df)
    score = np.zeros(n, dtype=float)

    # Composantes optionnelles
    if 'swing_low' in df.columns:
        score += df['swing_low'].values.astype(float)

    if 'fvg_bullish' in df.columns:
        score += df['fvg_bullish'].values.astype(float)

    if 'smart_leg_bullish' in df.columns:
        score += df['smart_leg_bullish'].values.astype(float)

    if 'fva' in df.columns:
        score += df['fva'].values.astype(float) * 0.5  # Poids reduit

    # Normaliser par max possible (3.5)
    max_score = 3.5
    score_normalized = np.clip(score / max_score, 0.0, 1.0)

    return score_normalized


def calculate_bear_score(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Calcule le score baissier base sur patterns detectes.

    Composantes:
        +1 si swing_high detecte (resistance potentielle)
        +1 si fvg_bearish actif
        +1 si smart_leg_bearish actif
        +1 si fva presente (consolidation avant chute)

    Args:
        df: DataFrame avec colonnes pattern
        **params: Ignore

    Returns:
        Float array (score 0.0-1.0, normalise par max possible)
    """
    n = len(df)
    score = np.zeros(n, dtype=float)

    # Composantes optionnelles
    if 'swing_high' in df.columns:
        score += df['swing_high'].values.astype(float)

    if 'fvg_bearish' in df.columns:
        score += df['fvg_bearish'].values.astype(float)

    if 'smart_leg_bearish' in df.columns:
        score += df['smart_leg_bearish'].values.astype(float)

    if 'fva' in df.columns:
        score += df['fva'].values.astype(float) * 0.5  # Poids reduit

    # Normaliser par max possible (3.5)
    max_score = 3.5
    score_normalized = np.clip(score / max_score, 0.0, 1.0)

    return score_normalized


def directional_bias(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Calcule le biais directionnel net.

    Returns:
        Dict avec:
            'bull_score': score haussier 0-1
            'bear_score': score baissier 0-1
            'net_bias': bull_score - bear_score (-1 a +1)
    """
    bull = calculate_bull_score(df, **params)
    bear = calculate_bear_score(df, **params)

    return {
        'bull_score': bull,
        'bear_score': bear,
        'net_bias': bull - bear
    }


__all__ = ['calculate_bull_score', 'calculate_bear_score', 'directional_bias']
```
<!-- MODULE-END: scoring.py -->

<!-- MODULE-START: smart_legs.py -->
```json
{
  "name": "smart_legs.py",
  "path": "indicators\\smart_legs.py",
  "ext": ".py",
  "anchor": "smart_legs_py"
}
```
## smart_legs_py
*Chemin* : `indicators\smart_legs.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.smart_legs

Purpose: Construction smart legs (segments directionnels valides).

Role in pipeline: structure detection / trend validation

Key components: calculate_smart_legs_bullish, calculate_smart_legs_bearish

Inputs: DataFrame avec swing_high, swing_low, fvg_bullish, fvg_bearish

Outputs: np.ndarray boolean (True = position fait partie d'un smart leg)

Dependencies: pandas, numpy

Conventions: Smart leg valide = segment entre 2 swings contenant >= 1 FVG
"""

from typing import Dict

import numpy as np
import pandas as pd


def calculate_smart_legs_bullish(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les smart legs haussiers.

    Definition:
        Segment entre swing_low[i] et swing_high[j] (j > i)
        contenant au moins 1 FVG bullish

    Args:
        df: DataFrame avec 'swing_low', 'swing_high', 'fvg_bullish'
        **params: Ignore

    Returns:
        Boolean array (True = position dans un smart leg bullish)
    """
    n = len(df)
    smart_leg_bull = np.zeros(n, dtype=bool)

    # Verifier que les colonnes existent
    required_cols = ['swing_low', 'swing_high', 'fvg_bullish']
    if not all(col in df.columns for col in required_cols):
        return smart_leg_bull

    swing_lows = df['swing_low'].values
    swing_highs = df['swing_high'].values
    fvg_bull = df['fvg_bullish'].values

    # Parcourir les swing lows
    swing_low_indices = np.where(swing_lows)[0]

    for start_idx in swing_low_indices:
        # Chercher le prochain swing high
        future_highs = np.where(swing_highs[start_idx+1:])[0]

        if len(future_highs) == 0:
            continue

        end_idx = start_idx + 1 + future_highs[0]

        # Verifier presence FVG dans le segment
        segment_has_fvg = np.any(fvg_bull[start_idx:end_idx+1])

        if segment_has_fvg:
            # Marquer toutes les positions du segment
            smart_leg_bull[start_idx:end_idx+1] = True

    return smart_leg_bull


def calculate_smart_legs_bearish(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les smart legs baissiers.

    Definition:
        Segment entre swing_high[i] et swing_low[j] (j > i)
        contenant au moins 1 FVG bearish

    Args:
        df: DataFrame avec 'swing_high', 'swing_low', 'fvg_bearish'
        **params: Ignore

    Returns:
        Boolean array (True = position dans un smart leg bearish)
    """
    n = len(df)
    smart_leg_bear = np.zeros(n, dtype=bool)

    # Verifier que les colonnes existent
    required_cols = ['swing_low', 'swing_high', 'fvg_bearish']
    if not all(col in df.columns for col in required_cols):
        return smart_leg_bear

    swing_lows = df['swing_low'].values
    swing_highs = df['swing_high'].values
    fvg_bear = df['fvg_bearish'].values

    # Parcourir les swing highs
    swing_high_indices = np.where(swing_highs)[0]

    for start_idx in swing_high_indices:
        # Chercher le prochain swing low
        future_lows = np.where(swing_lows[start_idx+1:])[0]

        if len(future_lows) == 0:
            continue

        end_idx = start_idx + 1 + future_lows[0]

        # Verifier presence FVG dans le segment
        segment_has_fvg = np.any(fvg_bear[start_idx:end_idx+1])

        if segment_has_fvg:
            # Marquer toutes les positions du segment
            smart_leg_bear[start_idx:end_idx+1] = True

    return smart_leg_bear


def smart_legs(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Wrapper retournant les deux types de smart legs.

    Returns:
        Dict avec 'smart_leg_bullish' et 'smart_leg_bearish'
    """
    return {
        'smart_leg_bullish': calculate_smart_legs_bullish(df, **params),
        'smart_leg_bearish': calculate_smart_legs_bearish(df, **params)
    }


__all__ = ['calculate_smart_legs_bullish', 'calculate_smart_legs_bearish', 'smart_legs']
```
<!-- MODULE-END: smart_legs.py -->

<!-- MODULE-START: standard_deviation.py -->
```json
{
  "name": "standard_deviation.py",
  "path": "indicators\\standard_deviation.py",
  "ext": ".py",
  "anchor": "standard_deviation_py"
}
```
## standard_deviation_py
*Chemin* : `indicators\standard_deviation.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.standard_deviation

Purpose: √âcart-type roulant d'une s√©rie de prix - mesure volatilit√©.

Role in pipeline: technical indicator

Key components: StandardDeviationSettings, standard_deviation()

Inputs: [close] ou [prix], period

Outputs: numpy array standard deviation

Dependencies: numpy, pandas, indicators.registry

Conventions: √ât√© pond√©r√© par d√©faut (ddof=0)

Read-if: Analyser volatilit√© prix.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


@dataclass
class StandardDeviationSettings:
    """Settings for standard deviation."""

    period: int = 20

    def __post_init__(self) -> None:
        if self.period < 1:
            raise ValueError(f"period must be >= 1, got: {self.period}")


def standard_deviation(
    close: pd.Series | np.ndarray,
    period: int = 20,
    settings: StandardDeviationSettings | None = None,
) -> np.ndarray:
    """
    Compute rolling standard deviation.

    Args:
        close: Price series
        period: Rolling window length
        settings: Optional settings override

    Returns:
        Rolling standard deviation values
    """
    if settings is not None:
        period = settings.period

    if isinstance(close, pd.Series):
        close = close.values

    close_series = pd.Series(close, dtype="float64")
    std_values = close_series.rolling(window=period, min_periods=period).std(ddof=0)
    return std_values.values


def calculate_standard_deviation(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Wrapper for registry calculation.

    Params:
        period: Rolling window length (default: 20)
    """
    return standard_deviation(
        df["close"],
        period=int(params.get("period", 20)),
    )


register_indicator(
    "standard_deviation",
    calculate_standard_deviation,
    settings_class=StandardDeviationSettings,
    required_columns=("close",),
    description="Standard Deviation - Rolling volatility of close",
)


__all__ = [
    "standard_deviation",
    "calculate_standard_deviation",
    "StandardDeviationSettings",
]
```
<!-- MODULE-END: standard_deviation.py -->

<!-- MODULE-START: stochastic.py -->
```json
{
  "name": "stochastic.py",
  "path": "indicators\\stochastic.py",
  "ext": ".py",
  "anchor": "stochastic_py"
}
```
## stochastic_py
*Chemin* : `indicators\stochastic.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.stochastic

Purpose: Indicateur Stochastic (%K + %D signal) - timing survente/surachat.

Role in pipeline: data

Key components: stochastic, StochasticSettings, calculate_stochastic, %K, %D

Inputs: DataFrame avec high, low, close; k_period, d_period

Outputs: Dict{stoch_k, stoch_d} ou Tuple

Dependencies: pandas, numpy, dataclasses

Conventions: %K position prix dans range; %D = SMA(%K); <20 survente, >80 surachat.

Read-if: Modification p√©riodes K/D, formule %K.

Skip-if: Vous utilisez juste calculate_indicator('stochastic').
"""

from typing import Tuple, Union

import numpy as np
import pandas as pd


def stochastic(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    k_period: int = 14,
    d_period: int = 3,
    smooth_k: int = 3,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule le Stochastic Oscillator.

    Formule:
        %K = 100 * (Close - Lowest Low) / (Highest High - Lowest Low)
        %K_smooth = SMA(%K, smooth_k)
        %D = SMA(%K_smooth, d_period)

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        k_period: P√©riode pour highest high et lowest low (d√©faut: 14)
        d_period: P√©riode pour la ligne %D (d√©faut: 3)
        smooth_k: Lissage de %K (d√©faut: 3)

    Returns:
        Tuple (stoch_k, stoch_d) en numpy arrays [0, 100]

    Example:
        >>> k, d = stochastic(df["high"], df["low"], df["close"])
        >>> oversold = k < 20
        >>> overbought = k > 80
    """
    # Convertir en arrays numpy
    if isinstance(high, pd.Series):
        high_vals = high.values
    else:
        high_vals = np.asarray(high)

    if isinstance(low, pd.Series):
        low_vals = low.values
    else:
        low_vals = np.asarray(low)

    if isinstance(close, pd.Series):
        close_vals = close.values
    else:
        close_vals = np.asarray(close)

    n = len(close_vals)

    # Calcul rolling highest high et lowest low
    highest_high = np.full(n, np.nan)
    lowest_low = np.full(n, np.nan)

    for i in range(k_period - 1, n):
        highest_high[i] = np.max(high_vals[i - k_period + 1:i + 1])
        lowest_low[i] = np.min(low_vals[i - k_period + 1:i + 1])

    # %K brut
    range_hl = highest_high - lowest_low
    range_hl = np.where(range_hl == 0, np.nan, range_hl)  # √âviter division par z√©ro

    stoch_k_raw = 100 * (close_vals - lowest_low) / range_hl

    # Lissage de %K (slow stochastic)
    if smooth_k > 1:
        stoch_k = _sma(stoch_k_raw, smooth_k)
    else:
        stoch_k = stoch_k_raw

    # %D = SMA de %K
    stoch_d = _sma(stoch_k, d_period)

    return stoch_k, stoch_d


def _sma(data: np.ndarray, period: int) -> np.ndarray:
    """Calcule une simple moving average."""
    n = len(data)
    result = np.full(n, np.nan)

    for i in range(period - 1, n):
        window = data[i - period + 1:i + 1]
        valid = window[~np.isnan(window)]
        if len(valid) > 0:
            result[i] = np.mean(valid)

    return result


def stochastic_signal(
    high: Union[pd.Series, np.ndarray],
    low: Union[pd.Series, np.ndarray],
    close: Union[pd.Series, np.ndarray],
    k_period: int = 14,
    d_period: int = 3,
    smooth_k: int = 3,
    oversold: float = 20.0,
    overbought: float = 80.0,
) -> np.ndarray:
    """
    G√©n√®re des signaux bas√©s sur le Stochastic.

    Signaux:
        - +1: %K sort de zone survente (<oversold) et croise %D vers le haut
        - -1: %K sort de zone surachat (>overbought) et croise %D vers le bas
        -  0: Neutre

    Args:
        high, low, close: Prix OHLC
        k_period: P√©riode %K (d√©faut: 14)
        d_period: P√©riode %D (d√©faut: 3)
        smooth_k: Lissage %K (d√©faut: 3)
        oversold: Seuil survente (d√©faut: 20)
        overbought: Seuil surachat (d√©faut: 80)

    Returns:
        np.ndarray de signaux (-1, 0, +1)
    """
    stoch_k, stoch_d = stochastic(high, low, close, k_period, d_period, smooth_k)

    n = len(stoch_k)
    signals = np.zeros(n, dtype=np.float64)

    for i in range(1, n):
        if np.isnan(stoch_k[i]) or np.isnan(stoch_d[i]):
            continue

        k_prev = stoch_k[i - 1]
        k_curr = stoch_k[i]
        d_prev = stoch_d[i - 1]
        d_curr = stoch_d[i]

        if np.isnan(k_prev) or np.isnan(d_prev):
            continue

        # Signal LONG: %K croise %D vers le haut en zone survente
        if k_prev < d_prev and k_curr >= d_curr:
            if k_curr < oversold + 10:  # Proche de la zone survente
                signals[i] = 1.0

        # Signal SHORT: %K croise %D vers le bas en zone surachat
        if k_prev > d_prev and k_curr <= d_curr:
            if k_curr > overbought - 10:  # Proche de la zone surachat
                signals[i] = -1.0

    return signals


# Alias pour compatibilit√©
stoch = stochastic
```
<!-- MODULE-END: stochastic.py -->

<!-- MODULE-START: stoch_rsi.py -->
```json
{
  "name": "stoch_rsi.py",
  "path": "indicators\\stoch_rsi.py",
  "ext": ".py",
  "anchor": "stoch_rsi_py"
}
```
## stoch_rsi_py
*Chemin* : `indicators\stoch_rsi.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.stoch_rsi

Purpose: Indicateur Stochastic RSI - stochastique appliqu√© √† RSI.

Role in pipeline: data

Key components: stochastic_rsi, calculate_stoch_rsi, %K, %D, signal

Inputs: DataFrame avec close; rsi_period, stoch_period, k_smooth, d_smooth

Outputs: Dict{k, d, signal} ou Tuple

Dependencies: pandas, numpy, rsi

Conventions: RSI liss√©, puis stochastique appliqu√©e; sensibilit√© augment√©e surachat/survente.

Read-if: Modification p√©riodes RSI/Stoch, lissages K/D.

Skip-if: Vous utilisez juste calculate_indicator('stoch_rsi').
"""

from typing import Dict, Tuple

import numpy as np
import pandas as pd

from indicators.registry import register_indicator
from indicators.rsi import rsi


def stochastic_rsi(
    close: pd.Series,
    rsi_period: int = 14,
    stoch_period: int = 14,
    k_smooth: int = 3,
    d_smooth: int = 3
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule le Stochastic RSI (%K et %D).

    Formule:
    1. Calculer le RSI
    2. Appliquer la formule stochastique au RSI:
       StochRSI = (RSI - RSI_min) / (RSI_max - RSI_min)
    3. Lisser avec SMA pour obtenir %K et %D

    Args:
        close: S√©rie des prix de cl√¥ture
        rsi_period: P√©riode du RSI (d√©faut: 14)
        stoch_period: P√©riode du stochastique (d√©faut: 14)
        k_smooth: P√©riode de lissage %K (d√©faut: 3)
        d_smooth: P√©riode de lissage %D (d√©faut: 3)

    Returns:
        Tuple (%K, %D) - valeurs entre 0 et 100
    """
    # Calculer le RSI
    rsi_values = rsi(close, period=rsi_period)

    n = len(rsi_values)
    stoch_rsi = np.full(n, np.nan)

    # Appliquer la formule stochastique au RSI
    for i in range(stoch_period - 1, n):
        window = rsi_values[i - stoch_period + 1:i + 1]
        valid = window[~np.isnan(window)]

        if len(valid) < 2:
            continue

        rsi_min = np.min(valid)
        rsi_max = np.max(valid)

        if rsi_max - rsi_min > 0:
            stoch_rsi[i] = (rsi_values[i] - rsi_min) / (rsi_max - rsi_min) * 100
        else:
            stoch_rsi[i] = 50  # Neutre si pas de variation

    # Calculer %K (SMA du StochRSI)
    k_line = np.full(n, np.nan)
    for i in range(k_smooth - 1, n):
        window = stoch_rsi[i - k_smooth + 1:i + 1]
        valid = window[~np.isnan(window)]
        if len(valid) > 0:
            k_line[i] = np.mean(valid)

    # Calculer %D (SMA de %K)
    d_line = np.full(n, np.nan)
    for i in range(d_smooth - 1, n):
        window = k_line[i - d_smooth + 1:i + 1]
        valid = window[~np.isnan(window)]
        if len(valid) > 0:
            d_line[i] = np.mean(valid)

    return k_line, d_line


def stoch_rsi_signal(
    close: pd.Series,
    rsi_period: int = 14,
    stoch_period: int = 14,
    k_smooth: int = 3,
    d_smooth: int = 3,
    oversold: float = 20,
    overbought: float = 80
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur le Stochastic RSI.

    Signaux:
    - Long (1): %K croise %D vers le haut depuis zone de survente (<20)
    - Short (-1): %K croise %D vers le bas depuis zone de surachat (>80)
    - Neutre (0): Autres cas

    Args:
        close: S√©rie des prix de cl√¥ture
        rsi_period: P√©riode du RSI
        stoch_period: P√©riode du stochastique
        k_smooth: P√©riode de lissage %K
        d_smooth: P√©riode de lissage %D
        oversold: Seuil de survente (d√©faut: 20)
        overbought: Seuil de surachat (d√©faut: 80)

    Returns:
        Array de signaux (-1, 0, 1)
    """
    k_line, d_line = stochastic_rsi(close, rsi_period, stoch_period, k_smooth, d_smooth)

    n = len(close)
    signals = np.zeros(n)

    for i in range(1, n):
        if np.isnan(k_line[i]) or np.isnan(d_line[i]):
            continue
        if np.isnan(k_line[i-1]) or np.isnan(d_line[i-1]):
            continue

        # Croisement haussier depuis zone de survente
        if k_line[i-1] <= d_line[i-1] and k_line[i] > d_line[i]:
            if k_line[i-1] < oversold or d_line[i-1] < oversold:
                signals[i] = 1

        # Croisement baissier depuis zone de surachat
        elif k_line[i-1] >= d_line[i-1] and k_line[i] < d_line[i]:
            if k_line[i-1] > overbought or d_line[i-1] > overbought:
                signals[i] = -1

    return signals


def stoch_rsi_divergence(
    close: pd.Series,
    k_line: np.ndarray,
    lookback: int = 14
) -> np.ndarray:
    """
    D√©tecte les divergences entre le prix et le Stochastic RSI.

    Args:
        close: S√©rie des prix de cl√¥ture
        k_line: Valeurs %K du Stochastic RSI
        lookback: P√©riode de recherche (d√©faut: 14)

    Returns:
        1 = divergence haussi√®re, -1 = divergence baissi√®re, 0 = pas de divergence
    """
    close_arr = np.asarray(close, dtype=np.float64)
    n = len(close_arr)

    divergence = np.zeros(n)

    for i in range(lookback, n):
        price_window = close_arr[i - lookback:i + 1]
        stoch_window = k_line[i - lookback:i + 1]

        valid_mask = ~np.isnan(stoch_window)
        if np.sum(valid_mask) < lookback // 2:
            continue

        # Trouver les min/max locaux
        price_min_idx = np.nanargmin(price_window)
        price_max_idx = np.nanargmax(price_window)
        np.nanargmin(stoch_window)
        np.nanargmax(stoch_window)

        # Divergence haussi√®re: prix fait un plus bas, mais StochRSI fait un plus haut
        if price_min_idx > lookback // 2:  # R√©cent creux de prix
            if stoch_window[price_min_idx] > stoch_window[0]:
                divergence[i] = 1

        # Divergence baissi√®re: prix fait un plus haut, mais StochRSI fait un plus bas
        if price_max_idx > lookback // 2:  # R√©cent pic de prix
            if stoch_window[price_max_idx] < stoch_window[0]:
                divergence[i] = -1

    return divergence


def calculate_stoch_rsi(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame avec colonne close
        **params: Param√®tres cl√©-valeur
            - rsi_period: P√©riode du RSI (d√©faut: 14)
            - stoch_period: P√©riode du stochastique (d√©faut: 14)
            - k_smooth: Lissage %K (d√©faut: 3)
            - d_smooth: Lissage %D (d√©faut: 3)
            - oversold: Seuil survente (d√©faut: 20)
            - overbought: Seuil surachat (d√©faut: 80)

    Returns:
        Dict avec k, d, signal
    """
    rsi_period = params.get("rsi_period", 14)
    stoch_period = params.get("stoch_period", 14)
    k_smooth = params.get("k_smooth", 3)
    d_smooth = params.get("d_smooth", 3)
    oversold = params.get("oversold", 20)
    overbought = params.get("overbought", 80)

    k_line, d_line = stochastic_rsi(
        df["close"], rsi_period, stoch_period, k_smooth, d_smooth
    )

    signal = stoch_rsi_signal(
        df["close"], rsi_period, stoch_period, k_smooth, d_smooth,
        oversold, overbought
    )

    return {
        "k": k_line,
        "d": d_line,
        "signal": signal
    }


# Enregistrement dans le registre
register_indicator(
    "stoch_rsi",
    calculate_stoch_rsi,
    required_columns=("close",),
    description="Stochastic RSI - RSI avec oscillateur stochastique"
)


__all__ = [
    "stochastic_rsi",
    "stoch_rsi_signal",
    "stoch_rsi_divergence",
    "calculate_stoch_rsi",
]
```
<!-- MODULE-END: stoch_rsi.py -->

<!-- MODULE-START: supertrend.py -->
```json
{
  "name": "supertrend.py",
  "path": "indicators\\supertrend.py",
  "ext": ".py",
  "anchor": "supertrend_py"
}
```
## supertrend_py
*Chemin* : `indicators\supertrend.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.supertrend

Purpose: Indicateur SuperTrend - suivi tendance bas√© ATR (tr√®s populaire).

Role in pipeline: data

Key components: supertrend, SuperTrendSettings, calculate_supertrend

Inputs: DataFrame avec high, low, close; atr_period, atr_mult

Outputs: Dict{supertrend, direction} ou Tuple

Dependencies: pandas, numpy, atr, dataclasses

Conventions: bandes = hl_avg +/- ATR*mult; direction 1/-1; support/r√©sistance dynamique.

Read-if: Modification ATR params, output format.

Skip-if: Vous utilisez juste calculate_indicator('supertrend').
"""

from dataclasses import dataclass
from typing import Tuple

import numpy as np
import pandas as pd

from .atr import atr


@dataclass
class SuperTrendSettings:
    """Param√®tres SuperTrend."""
    atr_period: int = 10
    multiplier: float = 3.0


def supertrend(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    atr_period: int = 10,
    multiplier: float = 3.0,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule SuperTrend.

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        atr_period: P√©riode ATR (d√©faut: 10)
        multiplier: Multiplicateur ATR (d√©faut: 3.0)

    Returns:
        Tuple (supertrend_values, trend_direction)
        - trend_direction: 1 = haussier, -1 = baissier
    """
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values

    # ATR
    atr_values = atr(high, low, close, period=atr_period)

    # Basic bands
    hl_avg = (high + low) / 2.0
    basic_upper = hl_avg + multiplier * atr_values
    basic_lower = hl_avg - multiplier * atr_values

    n = len(close)

    # Final bands (state machine)
    final_upper = basic_upper.copy()
    final_lower = basic_lower.copy()

    for i in range(1, n):
        # Upper band
        if basic_upper[i] < final_upper[i - 1] or close[i - 1] > final_upper[i - 1]:
            final_upper[i] = basic_upper[i]
        else:
            final_upper[i] = final_upper[i - 1]

        # Lower band
        if basic_lower[i] > final_lower[i - 1] or close[i - 1] < final_lower[i - 1]:
            final_lower[i] = basic_lower[i]
        else:
            final_lower[i] = final_lower[i - 1]

    # SuperTrend et direction
    supertrend_values = np.empty(n)
    trend_direction = np.empty(n, dtype=int)

    # Initialisation
    if close[0] <= final_upper[0]:
        supertrend_values[0] = final_upper[0]
        trend_direction[0] = -1
    else:
        supertrend_values[0] = final_lower[0]
        trend_direction[0] = 1

    for i in range(1, n):
        prev_trend = trend_direction[i - 1]

        if prev_trend == 1:  # Was bullish
            if close[i] <= final_lower[i]:
                trend_direction[i] = -1
                supertrend_values[i] = final_upper[i]
            else:
                trend_direction[i] = 1
                supertrend_values[i] = final_lower[i]
        else:  # Was bearish
            if close[i] >= final_upper[i]:
                trend_direction[i] = 1
                supertrend_values[i] = final_lower[i]
            else:
                trend_direction[i] = -1
                supertrend_values[i] = final_upper[i]

    return supertrend_values, trend_direction


__all__ = ["supertrend", "SuperTrendSettings"]
```
<!-- MODULE-END: supertrend.py -->

<!-- MODULE-START: swing.py -->
```json
{
  "name": "swing.py",
  "path": "indicators\\swing.py",
  "ext": ".py",
  "anchor": "swing_py"
}
```
## swing_py
*Chemin* : `indicators\swing.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.swing

Purpose: Detection swing highs/lows (fractals) - COMPARAISON ADJACENTE UNIQUEMENT.

Role in pipeline: data / pattern detection

Key components: calculate_swing_high, calculate_swing_low, swing (wrapper)

Inputs: DataFrame avec high/low; pas de parametre lookback

Outputs: np.ndarray boolean (True = swing detected)

Dependencies: pandas, numpy

Conventions: SwingHigh[i] = (high[i] > high[i-1] AND high[i] > high[i+1])
             SwingLow[i] = (low[i] < low[i-1] AND low[i] < low[i+1])

CRITICAL: NE PAS utiliser de lookback variable - c'est une erreur conceptuelle.
"""

from typing import Dict

import numpy as np
import pandas as pd


def calculate_swing_high(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les swing highs (fractals haussiers).

    Definition STRICTE:
        swing_high[i] = True si high[i] > high[i-1] ET high[i] > high[i+1]

    Args:
        df: DataFrame avec colonne 'high'
        **params: Ignore (compatibilite registry)

    Returns:
        Boolean array (True aux positions de swing high)
    """
    highs = df['high'].values
    n = len(highs)
    swing = np.zeros(n, dtype=bool)

    # CORRECTIF: Comparaison ADJACENTE uniquement
    for i in range(1, n - 1):
        if highs[i] > highs[i-1] and highs[i] > highs[i+1]:
            swing[i] = True

    return swing


def calculate_swing_low(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Detecte les swing lows (fractals baissiers).

    Definition STRICTE:
        swing_low[i] = True si low[i] < low[i-1] ET low[i] < low[i+1]

    Args:
        df: DataFrame avec colonne 'low'
        **params: Ignore (compatibilite registry)

    Returns:
        Boolean array (True aux positions de swing low)
    """
    lows = df['low'].values
    n = len(lows)
    swing = np.zeros(n, dtype=bool)

    # CORRECTIF: Comparaison ADJACENTE uniquement
    for i in range(1, n - 1):
        if lows[i] < lows[i-1] and lows[i] < lows[i+1]:
            swing[i] = True

    return swing


def swing(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Wrapper retournant les deux types de swings.

    Returns:
        Dict avec 'swing_high' et 'swing_low' (boolean arrays)
    """
    return {
        'swing_high': calculate_swing_high(df, **params),
        'swing_low': calculate_swing_low(df, **params)
    }


__all__ = ['calculate_swing_high', 'calculate_swing_low', 'swing']
```
<!-- MODULE-END: swing.py -->

<!-- MODULE-START: volume_oscillator.py -->
```json
{
  "name": "volume_oscillator.py",
  "path": "indicators\\volume_oscillator.py",
  "ext": ".py",
  "anchor": "volume_oscillator_py"
}
```
## volume_oscillator_py
*Chemin* : `indicators\volume_oscillator.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.volume_oscillator

Purpose: Oscillateur volume - compare MMA court vs long du volume.

Role in pipeline: technical indicator

Key components: VolumeOscillatorSettings, volume_oscillator()

Inputs: [volume], period_short, period_long, type (ema/sma)

Outputs: numpy array oscillateur (short_ma - long_ma)

Dependencies: numpy, pandas, indicators.ema, indicators.registry

Conventions: MA court < long pour divergences; EMA par d√©faut

Read-if: Analyser momentum volume.

Skip-if: Indicateur non utilis√©.
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd

from indicators.ema import ema, sma
from indicators.registry import register_indicator


@dataclass
class VolumeOscillatorSettings:
    """Settings for Volume Oscillator."""

    short_period: int = 14
    long_period: int = 28
    method: str = "ema"

    def __post_init__(self) -> None:
        if self.short_period < 1:
            raise ValueError(f"short_period must be >= 1, got: {self.short_period}")
        if self.long_period < 1:
            raise ValueError(f"long_period must be >= 1, got: {self.long_period}")
        if self.long_period <= self.short_period:
            raise ValueError("long_period must be > short_period")
        if self.method not in ("ema", "sma"):
            raise ValueError("method must be 'ema' or 'sma'")


def volume_oscillator(
    volume: pd.Series | np.ndarray,
    short_period: int = 14,
    long_period: int = 28,
    method: str = "ema",
    settings: VolumeOscillatorSettings | None = None,
) -> np.ndarray:
    """
    Compute the Volume Oscillator (percent).

    Args:
        volume: Volume series
        short_period: Short MA period
        long_period: Long MA period
        method: 'ema' or 'sma'
        settings: Optional settings override

    Returns:
        Oscillator values in percent
    """
    if settings is not None:
        short_period = settings.short_period
        long_period = settings.long_period
        method = settings.method

    if isinstance(volume, pd.Series):
        volume = volume.values

    if method == "ema":
        short_ma = ema(volume, short_period)
        long_ma = ema(volume, long_period)
    else:
        short_ma = sma(volume, short_period)
        long_ma = sma(volume, long_period)

    oscillator = np.where(long_ma != 0, (short_ma - long_ma) / long_ma * 100.0, 0.0)
    return oscillator


def calculate_volume_oscillator(df: pd.DataFrame, **params) -> np.ndarray:
    """
    Wrapper for registry calculation.

    Params:
        short_period: Short MA period (default: 14)
        long_period: Long MA period (default: 28)
        method: 'ema' or 'sma' (default: 'ema')
    """
    return volume_oscillator(
        df["volume"],
        short_period=int(params.get("short_period", 14)),
        long_period=int(params.get("long_period", 28)),
        method=params.get("method", "ema"),
    )


register_indicator(
    "volume_oscillator",
    calculate_volume_oscillator,
    settings_class=VolumeOscillatorSettings,
    required_columns=("volume",),
    description="Volume Oscillator - Short vs long volume MA",
)


__all__ = [
    "volume_oscillator",
    "calculate_volume_oscillator",
    "VolumeOscillatorSettings",
]
```
<!-- MODULE-END: volume_oscillator.py -->

<!-- MODULE-START: vortex.py -->
```json
{
  "name": "vortex.py",
  "path": "indicators\\vortex.py",
  "ext": ".py",
  "anchor": "vortex_py"
}
```
## vortex_py
*Chemin* : `indicators\vortex.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.vortex

Purpose: Indicateur Vortex (VI+ et VI-) - force mouvement haussier/baissier.

Role in pipeline: data

Key components: vortex, calculate_vortex, vi_plus, vi_minus, oscillator, signal

Inputs: DataFrame avec high, low, close; period

Outputs: Dict{vi_plus, vi_minus, signal, oscillator} ou Tuple

Dependencies: pandas, numpy

Conventions: VI+ > VI- tendance haussi√®re; oscillator = VI+ - VI-.

Read-if: Modification p√©riode, output format.

Skip-if: Vous utilisez juste calculate_indicator('vortex').
"""

from typing import Dict, Tuple

import numpy as np
import pandas as pd

from indicators.registry import register_indicator


def vortex_movement(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Calcule les mouvements Vortex (+VM, -VM) et le True Range.

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        close: S√©rie des prix de cl√¥ture

    Returns:
        Tuple (plus_vm, minus_vm, true_range)
    """
    high_arr = np.asarray(high, dtype=np.float64)
    low_arr = np.asarray(low, dtype=np.float64)
    close_arr = np.asarray(close, dtype=np.float64)
    n = len(high_arr)

    # +VM = |High actuel - Low pr√©c√©dent|
    plus_vm = np.full(n, np.nan)
    plus_vm[1:] = np.abs(high_arr[1:] - low_arr[:-1])

    # -VM = |Low actuel - High pr√©c√©dent|
    minus_vm = np.full(n, np.nan)
    minus_vm[1:] = np.abs(low_arr[1:] - high_arr[:-1])

    # True Range
    tr = np.full(n, np.nan)
    tr[0] = high_arr[0] - low_arr[0]
    for i in range(1, n):
        tr[i] = max(
            high_arr[i] - low_arr[i],
            abs(high_arr[i] - close_arr[i-1]),
            abs(low_arr[i] - close_arr[i-1])
        )

    return plus_vm, minus_vm, tr


def vortex(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    period: int = 14
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calcule les indicateurs Vortex VI+ et VI-.

    Formule:
    - VI+ = SUM(+VM, N) / SUM(TR, N)
    - VI- = SUM(-VM, N) / SUM(TR, N)

    Args:
        high: S√©rie des prix hauts
        low: S√©rie des prix bas
        close: S√©rie des prix de cl√¥ture
        period: P√©riode de calcul (d√©faut: 14)

    Returns:
        Tuple (vi_plus, vi_minus)
    """
    plus_vm, minus_vm, tr = vortex_movement(high, low, close)

    n = len(high)
    vi_plus = np.full(n, np.nan)
    vi_minus = np.full(n, np.nan)

    for i in range(period, n):
        # Somme sur la p√©riode
        vm_plus_sum = np.nansum(plus_vm[i - period + 1:i + 1])
        vm_minus_sum = np.nansum(minus_vm[i - period + 1:i + 1])
        tr_sum = np.nansum(tr[i - period + 1:i + 1])

        if tr_sum > 0:
            vi_plus[i] = vm_plus_sum / tr_sum
            vi_minus[i] = vm_minus_sum / tr_sum

    return vi_plus, vi_minus


def vortex_signal(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    period: int = 14,
    threshold: float = 0.0
) -> np.ndarray:
    """
    G√©n√®re des signaux de trading bas√©s sur le Vortex Indicator.

    Signaux:
    - Long (1): VI+ croise VI- vers le haut
    - Short (-1): VI+ croise VI- vers le bas
    - Neutre (0): Pas de croisement

    Args:
        high, low, close: S√©ries de prix
        period: P√©riode du Vortex
        threshold: Seuil minimum de diff√©rence pour g√©n√©rer un signal

    Returns:
        Array de signaux (-1, 0, 1)
    """
    vi_plus, vi_minus = vortex(high, low, close, period)

    n = len(close)
    signals = np.zeros(n)

    for i in range(1, n):
        if np.isnan(vi_plus[i]) or np.isnan(vi_minus[i]):
            continue
        if np.isnan(vi_plus[i-1]) or np.isnan(vi_minus[i-1]):
            continue

        diff_prev = vi_plus[i-1] - vi_minus[i-1]
        diff_curr = vi_plus[i] - vi_minus[i]

        # Croisement haussier: VI+ passe au-dessus de VI-
        if diff_prev <= threshold and diff_curr > threshold:
            signals[i] = 1

        # Croisement baissier: VI+ passe en-dessous de VI-
        elif diff_prev >= -threshold and diff_curr < -threshold:
            signals[i] = -1

    return signals


def vortex_trend_strength(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    period: int = 14
) -> np.ndarray:
    """
    Mesure la force de la tendance bas√©e sur la diff√©rence VI+ - VI-.

    Returns:
        Valeurs positives = tendance haussi√®re forte
        Valeurs n√©gatives = tendance baissi√®re forte
        Valeurs proches de 0 = pas de tendance claire
    """
    vi_plus, vi_minus = vortex(high, low, close, period)
    return vi_plus - vi_minus


def vortex_oscillator(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    period: int = 14
) -> np.ndarray:
    """
    Oscillateur Vortex normalis√© entre -100 et +100.

    Formule: (VI+ - VI-) / (VI+ + VI-) * 100

    Returns:
        Oscillateur entre -100 et +100
    """
    vi_plus, vi_minus = vortex(high, low, close, period)

    # √âviter la division par z√©ro
    denominator = vi_plus + vi_minus
    oscillator = np.where(
        denominator > 0,
        (vi_plus - vi_minus) / denominator * 100,
        0
    )

    # Propager les NaN
    nan_mask = np.isnan(vi_plus) | np.isnan(vi_minus)
    oscillator[nan_mask] = np.nan

    return oscillator


def calculate_vortex(df: pd.DataFrame, **params) -> Dict[str, np.ndarray]:
    """
    Fonction wrapper pour le registre d'indicateurs.

    Args:
        df: DataFrame avec colonnes high, low, close
        **params: Param√®tres cl√©-valeur
            - period: P√©riode de calcul (d√©faut: 14)
            - threshold: Seuil pour les signaux (d√©faut: 0.0)

    Returns:
        Dict avec vi_plus, vi_minus, signal, oscillator
    """
    period = params.get("period", 14)
    threshold = params.get("threshold", 0.0)

    vi_plus, vi_minus = vortex(df["high"], df["low"], df["close"], period)
    signal = vortex_signal(df["high"], df["low"], df["close"], period, threshold)
    oscillator = vortex_oscillator(df["high"], df["low"], df["close"], period)

    return {
        "vi_plus": vi_plus,
        "vi_minus": vi_minus,
        "signal": signal,
        "oscillator": oscillator
    }


# Enregistrement dans le registre
register_indicator(
    "vortex",
    calculate_vortex,
    required_columns=("high", "low", "close"),
    description="Vortex Indicator - Mesure la force des tendances"
)


__all__ = [
    "vortex",
    "vortex_movement",
    "vortex_signal",
    "vortex_trend_strength",
    "vortex_oscillator",
    "calculate_vortex",
]
```
<!-- MODULE-END: vortex.py -->

<!-- MODULE-START: vwap.py -->
```json
{
  "name": "vwap.py",
  "path": "indicators\\vwap.py",
  "ext": ".py",
  "anchor": "vwap_py"
}
```
## vwap_py
*Chemin* : `indicators\vwap.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.vwap

Purpose: Indicateur VWAP (prix moyen pond√©r√© par volume) institutionnel.

Role in pipeline: data

Key components: vwap, VWAPSettings, calculate_vwap

Inputs: DataFrame avec high, low, close, volume; anchored, period flags

Outputs: np.ndarray (VWAP cumulatif ou glissant)

Dependencies: pandas, numpy, dataclasses

Conventions: VWAP = somme(prix*vol) / somme(vol); ancr√© ou glissant; prix institutionnel de ref.

Read-if: Modification ancrage, p√©riode glissante.

Skip-if: Vous utilisez juste calculate_indicator('vwap').
"""

from dataclasses import dataclass
from typing import Optional

import numpy as np
import pandas as pd


@dataclass
class VWAPSettings:
    """Param√®tres VWAP."""
    anchored: bool = False  # Si True, ancr√© au d√©but des donn√©es
    period: Optional[int] = None  # Si fourni, VWAP glissant


def vwap(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    volume: pd.Series | np.ndarray,
    period: Optional[int] = None,
) -> np.ndarray:
    """
    Calcule VWAP (Volume Weighted Average Price).

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        volume: Volume
        period: P√©riode glissante (None = ancr√© depuis d√©but)

    Returns:
        Valeurs VWAP
    """
    if isinstance(high, pd.Series):
        high = high.values
    if isinstance(low, pd.Series):
        low = low.values
    if isinstance(close, pd.Series):
        close = close.values
    if isinstance(volume, pd.Series):
        volume = volume.values

    # Typical Price
    typical_price = (high + low + close) / 3.0
    tp_volume = typical_price * volume

    if period is None:
        # VWAP ancr√© (depuis d√©but)
        cumulative_tp_volume = np.cumsum(tp_volume)
        cumulative_volume = np.cumsum(volume)
        vwap_values = np.where(
            cumulative_volume != 0,
            cumulative_tp_volume / cumulative_volume,
            typical_price
        )
    else:
        # VWAP glissant
        tp_series = pd.Series(tp_volume)
        vol_series = pd.Series(volume)
        rolling_tp = tp_series.rolling(window=period).sum().values
        rolling_vol = vol_series.rolling(window=period).sum().values
        vwap_values = np.where(rolling_vol != 0, rolling_tp / rolling_vol, typical_price)

    return vwap_values


__all__ = ["vwap", "VWAPSettings"]
```
<!-- MODULE-END: vwap.py -->

<!-- MODULE-START: williams_r.py -->
```json
{
  "name": "williams_r.py",
  "path": "indicators\\williams_r.py",
  "ext": ".py",
  "anchor": "williams_r_py"
}
```
## williams_r_py
*Chemin* : `indicators\williams_r.py`  
*Type* : `.py`  

```python
"""
Module-ID: indicators.williams_r

Purpose: Indicateur Williams %R - oscillateur momentum surachat/survente.

Role in pipeline: data

Key components: williams_r, WilliamsRSettings, calculate_williams_r

Inputs: DataFrame avec high, low, close; period

Outputs: np.ndarray (-100 √† 0)

Dependencies: pandas, numpy, dataclasses

Conventions: >-20 surachat, <-80 survente; inverse de %K Stochastic.

Read-if: Modification p√©riode, interpr√©tation seuils.

Skip-if: Vous utilisez juste calculate_indicator('williams_r').
"""

from dataclasses import dataclass

import numpy as np
import pandas as pd


@dataclass
class WilliamsRSettings:
    """Param√®tres Williams %R."""
    period: int = 14


def williams_r(
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    period: int = 14,
) -> np.ndarray:
    """
    Calcule Williams %R.

    Formula: %R = (Highest High - Close) / (Highest High - Lowest Low) * -100

    Args:
        high: Prix hauts
        low: Prix bas
        close: Prix de cl√¥ture
        period: P√©riode (d√©faut: 14)

    Returns:
        Valeurs entre -100 (survente) et 0 (surachat)
    """
    if isinstance(high, pd.Series):
        high_series = high
    else:
        high_series = pd.Series(high)

    if isinstance(low, pd.Series):
        low_series = low
    else:
        low_series = pd.Series(low)

    if isinstance(close, pd.Series):
        close = close.values

    highest_high = high_series.rolling(window=period).max().values
    lowest_low = low_series.rolling(window=period).min().values

    range_hl = highest_high - lowest_low

    williams_values = np.where(
        range_hl != 0,
        ((highest_high - close) / range_hl) * -100.0,
        -50.0
    )

    return williams_values


__all__ = ["williams_r", "WilliamsRSettings"]
```
<!-- MODULE-END: williams_r.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "indicators\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `indicators\__init__.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Indicators Package
==================================

Indicateurs techniques vectoris√©s avec NumPy.
"""

from .adx import adx, calculate_adx
from .amplitude_hunter import (
    AmplitudeHunterSettings,
    amplitude_hunter,
    calculate_amplitude_hunter,
)
from .aroon import AroonSettings, aroon
from .atr import ATRSettings, atr
from .bollinger import BollingerSettings, bollinger_bands
from .cci import CCISettings, cci
from .donchian import DonchianSettings, donchian_channel
from .ema import EMASettings, ema, sma
from .fear_greed import (
    FearGreedSettings,
    calculate_fear_greed,
    fear_greed_index,
)
from .fibonacci import (
    FibonacciSettings,
    calculate_fibonacci_levels,
    fibonacci_levels,
)
from .fva import calculate_fva
from .fvg import calculate_fvg_bearish, calculate_fvg_bullish, fvg

# Indicateurs Phase 2 (13/12/2025)
from .ichimoku import calculate_ichimoku, ichimoku, ichimoku_signal
from .keltner import KeltnerSettings, keltner_channel
from .macd import macd, macd_signal
from .mfi import MFISettings, mfi
from .momentum import MomentumSettings, momentum
from .obv import OBVSettings, obv
from .onchain_smoothing import (
    OnchainSmoothingSettings,
    calculate_onchain_smoothing,
    onchain_smoothing,
)
from .pi_cycle import (
    PiCycleSettings,
    calculate_pi_cycle,
    pi_cycle,
)
from .pivot_points import (
    PivotPointsSettings,
    calculate_pivot_points,
    pivot_points,
)
from .psar import calculate_psar, parabolic_sar, psar_signal
from .registry import calculate_indicator, list_indicators
from .roc import ROCSettings, roc
from .rsi import RSISettings, rsi
from .scoring import calculate_bear_score, calculate_bull_score, directional_bias
from .smart_legs import calculate_smart_legs_bearish, calculate_smart_legs_bullish, smart_legs
from .standard_deviation import (
    StandardDeviationSettings,
    calculate_standard_deviation,
    standard_deviation,
)
from .stoch_rsi import calculate_stoch_rsi, stoch_rsi_signal, stochastic_rsi
from .stochastic import stochastic, stochastic_signal
from .supertrend import SuperTrendSettings, supertrend

# FairValOseille indicators (03/01/2026)
from .swing import calculate_swing_high, calculate_swing_low, swing

# Additional indicators
from .volume_oscillator import (
    VolumeOscillatorSettings,
    calculate_volume_oscillator,
    volume_oscillator,
)
from .vortex import calculate_vortex, vortex, vortex_signal

# Indicateurs ajout√©s 12/12/2025
from .vwap import VWAPSettings, vwap
from .williams_r import WilliamsRSettings, williams_r

__all__ = [
    # Indicateurs de base
    "bollinger_bands",
    "BollingerSettings",
    "atr",
    "ATRSettings",
    "rsi",
    "RSISettings",
    "ema",
    "sma",
    "EMASettings",
    "macd",
    "macd_signal",
    "adx",
    "calculate_adx",
    "stochastic",
    "stochastic_signal",
    # Indicateurs 12/12/2025
    "vwap",
    "VWAPSettings",
    "donchian_channel",
    "DonchianSettings",
    "cci",
    "CCISettings",
    "keltner_channel",
    "KeltnerSettings",
    "mfi",
    "MFISettings",
    "williams_r",
    "WilliamsRSettings",
    "momentum",
    "MomentumSettings",
    "obv",
    "OBVSettings",
    "roc",
    "ROCSettings",
    "aroon",
    "AroonSettings",
    "supertrend",
    "SuperTrendSettings",
    # Phase 2 (13/12/2025)
    "ichimoku",
    "ichimoku_signal",
    "calculate_ichimoku",
    "parabolic_sar",
    "psar_signal",
    "calculate_psar",
    "stochastic_rsi",
    "stoch_rsi_signal",
    "calculate_stoch_rsi",
    "vortex",
    "vortex_signal",
    "calculate_vortex",
    # Additional indicators
    "volume_oscillator",
    "calculate_volume_oscillator",
    "VolumeOscillatorSettings",
    "standard_deviation",
    "calculate_standard_deviation",
    "StandardDeviationSettings",
    "fibonacci_levels",
    "calculate_fibonacci_levels",
    "FibonacciSettings",
    "pivot_points",
    "calculate_pivot_points",
    "PivotPointsSettings",
    "onchain_smoothing",
    "calculate_onchain_smoothing",
    "OnchainSmoothingSettings",
    "fear_greed_index",
    "calculate_fear_greed",
    "FearGreedSettings",
    "pi_cycle",
    "calculate_pi_cycle",
    "PiCycleSettings",
    "amplitude_hunter",
    "calculate_amplitude_hunter",
    "AmplitudeHunterSettings",
    # FairValOseille (03/01/2026)
    "swing",
    "calculate_swing_high",
    "calculate_swing_low",
    "fvg",
    "calculate_fvg_bullish",
    "calculate_fvg_bearish",
    "calculate_fva",
    "smart_legs",
    "calculate_smart_legs_bullish",
    "calculate_smart_legs_bearish",
    "directional_bias",
    "calculate_bull_score",
    "calculate_bear_score",
    # Registre
    "calculate_indicator",
    "list_indicators",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: lab_launcher.py -->
```json
{
  "name": "lab_launcher.py",
  "path": "labs\\lab_launcher.py",
  "ext": ".py",
  "anchor": "lab_launcher_py"
}
```
## lab_launcher_py
*Chemin* : `labs\lab_launcher.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
üß™ Quick Lab Launcher - Backtest Core

Script de lancement rapide pour les outils du laboratoire
"""

import os
import sys
from pathlib import Path

def main():
    """Menu principal du laboratoire"""

    print("üß™ LABORATOIRE DE RECHERCHE - BACKTEST CORE")
    print("=" * 50)
    print()

    while True:
        print("Choisissez une action:")
        print("1. üîç Analyser les r√©sultats Bollinger ATR")
        print("2. üìä Diagnostic approfondi Bollinger ATR")
        print("3. üêõ Debug simulateur complet")
        print("4. ‚ö° Debug sweep bloqu√©")
        print("5. üéØ Reproduire bug MACD -inf")
        print("6. üíª Diagnostic GPU/performance")
        print("7. üìÅ Voir structure du laboratoire")
        print("0. ‚ùå Quitter")
        print()

        choice = input("Votre choix (0-7): ").strip()

        if choice == "0":
            print("üëã Au revoir !")
            break
        elif choice == "1":
            run_script("analysis/analyze_bollinger_atr_results.py")
        elif choice == "2":
            run_script("analysis/detailed_bollinger_analysis.py")
        elif choice == "3":
            run_script("debug/debug_full_simulator.py")
        elif choice == "4":
            run_script("debug/diagnostic_sweep_blocked.py")
        elif choice == "5":
            run_script("debug/reproduce_macd_inf.py")
        elif choice == "6":
            run_script("debug/diagnose_gpu.py")
        elif choice == "7":
            show_lab_structure()
        else:
            print("‚ùå Choix invalide. Veuillez choisir entre 0 et 7.")

        print("\n" + "="*50 + "\n")

def run_script(script_path):
    """Ex√©cute un script du laboratoire"""
    labs_dir = Path(__file__).parent
    script_full_path = labs_dir / script_path

    if not script_full_path.exists():
        print(f"‚ùå Script non trouv√©: {script_path}")
        return

    print(f"üöÄ Ex√©cution de {script_path}...")
    print("-" * 30)

    # Changer vers le r√©pertoire racine pour les imports
    original_dir = os.getcwd()
    os.chdir(labs_dir.parent)

    try:
        # Ex√©cuter le script
        exec(open(script_full_path).read())
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution: {e}")
    finally:
        os.chdir(original_dir)

def show_lab_structure():
    """Affiche la structure du laboratoire"""
    labs_dir = Path(__file__).parent

    print("üìÅ STRUCTURE DU LABORATOIRE:")
    print("-" * 30)

    for subdir in ["analysis", "debug", "optimization", "performance"]:
        subdir_path = labs_dir / subdir
        if subdir_path.exists():
            files = list(subdir_path.glob("*.py"))
            print(f"üìÇ {subdir}/ ({len(files)} fichiers)")
            for file in sorted(files):
                print(f"   üìÑ {file.name}")
        else:
            print(f"üìÇ {subdir}/ (vide)")
        print()

if __name__ == "__main__":
    main()
```
<!-- MODULE-END: lab_launcher.py -->

<!-- MODULE-START: analyze_bollinger_atr_results.py -->
```json
{
  "name": "analyze_bollinger_atr_results.py",
  "path": "labs\\analysis\\analyze_bollinger_atr_results.py",
  "ext": ".py",
  "anchor": "analyze_bollinger_atr_results_py"
}
```
## analyze_bollinger_atr_results_py
*Chemin* : `labs\analysis\analyze_bollinger_atr_results.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Analyse des r√©sultats Bollinger ATR pour identifier les plages optimales des param√®tres
et proposer des ranges resserr√©s vers les zones profitables.
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns

def load_bollinger_atr_results() -> pd.DataFrame:
    """Charge tous les r√©sultats bollinger_atr depuis backtest_results"""

    results = []
    backtest_dir = Path("backtest_results")

    print("üìä Chargement des r√©sultats bollinger_atr individuels...")

    # Rechercher tous les dossiers de backtest bollinger_atr
    backtest_dirs = [d for d in backtest_dir.iterdir()
                    if d.is_dir() and "bollinger_atr" in d.name.lower()]

    print(f"üîç Trouv√© {len(backtest_dirs)} dossiers de r√©sultats bollinger_atr")

    for result_dir in backtest_dirs:
        try:
            metadata_file = result_dir / "metadata.json"
            if not metadata_file.exists():
                continue

            with open(metadata_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            params = data.get("params", {})
            metrics = data.get("metrics", {})

            # Ne garder que les r√©sultats avec des param√®tres bollinger_atr complets
            required_params = ["bb_period", "bb_std", "entry_z", "atr_period", "atr_percentile", "k_sl"]
            if not all(param in params for param in required_params):
                # Essayer les noms alternatifs
                param_mapping = {
                    "entry_z": ["entry_level"],
                    "k_sl": ["sl_level"]
                }

                missing_count = 0
                for param in required_params:
                    if param not in params:
                        alternatives = param_mapping.get(param, [])
                        found_alternative = False
                        for alt in alternatives:
                            if alt in params:
                                params[param] = params[alt]
                                found_alternative = True
                                break
                        if not found_alternative:
                            missing_count += 1

                if missing_count > 2:  # Trop de param√®tres manquants
                    continue

            # Extraire informations du nom du dossier
            dir_name = result_dir.name
            parts = dir_name.split('_')
            if len(parts) >= 4:
                strategy = '_'.join(parts[0:-2])  # bollinger_atr
                symbol = parts[-2]  # BTCUSDC
                timeframe = parts[-1].split('_')[0]  # 30m
            else:
                strategy, symbol, timeframe = "bollinger_atr", "UNKNOWN", "UNKNOWN"

            # Valeurs par d√©faut pour param√®tres manquants
            default_values = {
                "bb_period": 20,
                "bb_std": 2.0,
                "entry_z": 2.0,
                "atr_period": 14,
                "atr_percentile": 30,
                "k_sl": 1.5
            }

            row = {
                # M√©tadonn√©es
                "strategy": strategy,
                "symbol": symbol,
                "timeframe": timeframe,
                "run_id": data.get("run_id", dir_name),

                # Param√®tres (avec valeurs par d√©faut si manquant)
                "bb_period": params.get("bb_period", default_values["bb_period"]),
                "bb_std": params.get("bb_std", default_values["bb_std"]),
                "entry_z": params.get("entry_z", default_values["entry_z"]),
                "atr_period": params.get("atr_period", default_values["atr_period"]),
                "atr_percentile": params.get("atr_percentile", default_values["atr_percentile"]),
                "k_sl": params.get("k_sl", default_values["k_sl"]),

                # M√©triques de performance
                "total_pnl": metrics.get("total_pnl", 0.0),
                "sharpe_ratio": metrics.get("sharpe_ratio", 0.0),
                "total_return_pct": metrics.get("total_return_pct", 0.0),
                "max_drawdown_pct": abs(metrics.get("max_drawdown_pct", 0.0)),
                "total_trades": metrics.get("total_trades", 0),
                "win_rate_pct": metrics.get("win_rate_pct", 0.0),
                "profit_factor": metrics.get("profit_factor", 0.0),
                "account_ruined": metrics.get("account_ruined", False),
            }

            results.append(row)

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement de {result_dir}: {e}")
            continue

    df = pd.DataFrame(results)
    print(f"‚úÖ Charg√© {len(df)} r√©sultats individuels")

    return df

def analyze_profitable_ranges(df: pd.DataFrame) -> Dict[str, Tuple[float, float]]:
    """Analyse les plages optimales pour chaque param√®tre bas√© sur les r√©sultats profitables"""

    print("\nüéØ Analyse des plages profitables...")

    if len(df) == 0:
        print("‚ùå Aucune donn√©e √† analyser")
        return {}

    # Filtrer les r√©sultats profitables (PnL > 0 ET Sharpe > 0)
    profitable = df[
        (df["total_pnl"] > 0) &
        (df["sharpe_ratio"] > 0) &
        (df["total_trades"] > 5)  # Minimum de trades pour √™tre significatif
    ].copy()

    print(f"üìà {len(profitable)} r√©sultats profitables sur {len(df)} total ({len(profitable)/len(df)*100:.1f}%)")

    if len(profitable) == 0:
        print("‚ùå Aucun r√©sultat profitable trouv√©")
        return {}

    # Analyser les top 25% des r√©sultats par Sharpe ratio
    top_quartile_threshold = profitable["sharpe_ratio"].quantile(0.75)
    top_results = profitable[profitable["sharpe_ratio"] >= top_quartile_threshold].copy()

    print(f"üèÜ {len(top_results)} r√©sultats dans le top 25% (Sharpe >= {top_quartile_threshold:.2f})")

    # Analyser les plages pour chaque param√®tre
    param_ranges = {}
    parameters = ["bb_period", "bb_std", "entry_z", "atr_period", "atr_percentile", "k_sl"]

    print(f"\nüìä Statistiques des param√®tres (top 25% des r√©sultats):")
    print("=" * 80)

    for param in parameters:
        if param not in top_results.columns:
            continue

        values = top_results[param].dropna()
        if len(values) == 0:
            continue

        # Statistiques descriptives
        mean_val = values.mean()
        std_val = values.std()
        min_val = values.min()
        max_val = values.max()
        median_val = values.median()
        p25 = values.quantile(0.25)
        p75 = values.quantile(0.75)

        # Plage sugg√©r√©e : P25 - P75 (quartiles interm√©diaires)
        suggested_min = p25
        suggested_max = p75

        # √âlargir l√©g√®rement si la plage est trop √©troite
        if suggested_max - suggested_min < std_val / 2:
            suggested_min = max(min_val, mean_val - std_val)
            suggested_max = min(max_val, mean_val + std_val)

        param_ranges[param] = (suggested_min, suggested_max)

        print(f"{param:15} ‚îÇ Min: {min_val:6.2f} ‚îÇ P25: {p25:6.2f} ‚îÇ M√©diane: {median_val:6.2f} ‚îÇ P75: {p75:6.2f} ‚îÇ Max: {max_val:6.2f}")
        print(f"{'':15} ‚îÇ Moyenne: {mean_val:5.2f} ‚îÇ StdDev: {std_val:5.2f} ‚îÇ üéØ Sugg√©r√©: [{suggested_min:.2f} - {suggested_max:.2f}]")
        print("-" * 80)

    return param_ranges

def calculate_combination_reduction(current_ranges: Dict, suggested_ranges: Dict) -> None:
    """Calcule la r√©duction du nombre de combinaisons"""

    print("\nüßÆ Calcul de la r√©duction du nombre de combinaisons:")
    print("=" * 60)

    # Ranges actuels (de bollinger_atr.py)
    current_total = 1
    suggested_total = 1

    param_details = {
        "bb_period": {"current": (10, 50, 1), "type": "int"},
        "bb_std": {"current": (1.5, 3.0, 0.1), "type": "float"},
        "entry_z": {"current": (1.0, 3.0, 0.1), "type": "float"},
        "atr_period": {"current": (7, 21, 1), "type": "int"},
        "atr_percentile": {"current": (0, 60, 1), "type": "int"},
        "k_sl": {"current": (1.0, 3.0, 0.1), "type": "float"},
    }

    for param, info in param_details.items():
        current_min, current_max, step = info["current"]
        param_type = info["type"]

        # Calculer nombre de valeurs actuelles
        if param_type == "int":
            current_count = (current_max - current_min) // step + 1
        else:
            current_count = len(np.arange(current_min, current_max + step/2, step))

        current_total *= current_count

        # Calculer nombre de valeurs sugg√©r√©es
        if param in suggested_ranges:
            sugg_min, sugg_max = suggested_ranges[param]

            # Arrondir aux valeurs valides selon le step
            if param_type == "int":
                sugg_min = max(current_min, int(sugg_min))
                sugg_max = min(current_max, int(sugg_max))
                suggested_count = (sugg_max - sugg_min) // step + 1
            else:
                sugg_min = max(current_min, round(sugg_min / step) * step)
                sugg_max = min(current_max, round(sugg_max / step) * step)
                suggested_count = len(np.arange(sugg_min, sugg_max + step/2, step))

            suggested_total *= suggested_count

            reduction_pct = (1 - suggested_count / current_count) * 100

            print(f"{param:15} ‚îÇ Actuel: {current_count:3d} ‚îÇ Sugg√©r√©: {suggested_count:3d} ‚îÇ R√©duction: {reduction_pct:5.1f}%")
        else:
            suggested_total *= current_count
            print(f"{param:15} ‚îÇ Actuel: {current_count:3d} ‚îÇ Sugg√©r√©: {current_count:3d} ‚îÇ R√©duction:   0.0%")

    print("-" * 60)
    print(f"üî• TOTAL ACTUEL     : {current_total:,} combinaisons")
    print(f"üéØ TOTAL SUGG√âR√â    : {suggested_total:,} combinaisons")

    if current_total > 0:
        total_reduction_pct = (1 - suggested_total / current_total) * 100
        speedup_factor = current_total / suggested_total if suggested_total > 0 else float('inf')

        print(f"‚ö° R√âDUCTION GLOBALE : {total_reduction_pct:.1f}%")
        print(f"üöÄ ACC√âL√âRATION     : {speedup_factor:.1f}x plus rapide")

        # Temps estim√©s
        time_current_hours = current_total / (100 * 3600)  # 100 bt/s
        time_suggested_hours = suggested_total / (100 * 3600)

        print(f"‚è±Ô∏è TEMPS ACTUEL     : {time_current_hours:.1f} heures")
        print(f"‚è±Ô∏è TEMPS SUGG√âR√â    : {time_suggested_hours:.1f} heures")

def generate_optimized_parameter_specs(suggested_ranges: Dict) -> str:
    """G√©n√®re le code Python pour les parameter_specs optimis√©s"""

    code = '''    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications optimis√©es bas√©es sur l'analyse des r√©sultats profitables.

        üéØ RANGES OPTIMIS√âS via analyse de donn√©es r√©elles :
        - Analyse de {total_results} r√©sultats de backtest
        - Focus sur top 25% des r√©sultats par Sharpe ratio
        - R√©duction des combinaisons : {reduction}% ({combo_before:,} ‚Üí {combo_after:,})
        - Acc√©l√©ration estim√©e : {speedup}x plus rapide
        """
        return {{'''

    param_configs = {
        "bb_period": {
            "original": (10, 50, 1),
            "type": "int",
            "description": "P√©riode des Bandes de Bollinger"
        },
        "bb_std": {
            "original": (1.5, 3.0, 0.1),
            "type": "float",
            "description": "√âcarts-types pour les bandes"
        },
        "entry_z": {
            "original": (1.0, 3.0, 0.1),
            "type": "float",
            "description": "Seuil z-score pour entree"
        },
        "atr_period": {
            "original": (7, 21, 1),
            "type": "int",
            "description": "P√©riode de l'ATR"
        },
        "atr_percentile": {
            "original": (0, 60, 1),
            "type": "int",
            "description": "Percentile volatilite minimum (ATR)"
        },
        "k_sl": {
            "original": (1.0, 3.0, 0.1),
            "type": "float",
            "description": "Multiplicateur ATR pour stop-loss"
        },
    }

    # Calculer les totaux pour les placeholders
    total_before = 1
    total_after = 1

    for param, config in param_configs.items():
        orig_min, orig_max, step = config["original"]
        param_type = config["type"]

        if param_type == "int":
            orig_count = (orig_max - orig_min) // step + 1
        else:
            orig_count = len(np.arange(orig_min, orig_max + step/2, step))

        total_before *= orig_count

        if param in suggested_ranges:
            sugg_min, sugg_max = suggested_ranges[param]
            if param_type == "int":
                sugg_min = max(orig_min, int(sugg_min))
                sugg_max = min(orig_max, int(sugg_max))
                sugg_count = (sugg_max - sugg_min) // step + 1
            else:
                sugg_min = max(orig_min, round(sugg_min / step) * step)
                sugg_max = min(orig_max, round(sugg_max / step) * step)
                sugg_count = len(np.arange(sugg_min, sugg_max + step/2, step))

            total_after *= sugg_count
        else:
            total_after *= orig_count

    reduction_pct = (1 - total_after / total_before) * 100 if total_before > 0 else 0
    speedup = total_before / total_after if total_after > 0 else float('inf')

    # G√©n√©rer le code pour chaque param√®tre
    for param, config in param_configs.items():
        orig_min, orig_max, step = config["original"]
        param_type = config["type"]
        description = config["description"]

        if param in suggested_ranges:
            sugg_min, sugg_max = suggested_ranges[param]

            if param_type == "int":
                sugg_min = max(orig_min, int(sugg_min))
                sugg_max = min(orig_max, int(sugg_max))
                default_val = int((sugg_min + sugg_max) / 2)
            else:
                sugg_min = max(orig_min, round(sugg_min / step) * step)
                sugg_max = min(orig_max, round(sugg_max / step) * step)
                default_val = round((sugg_min + sugg_max) / 2, 1)

            code += f'''
            "{param}": ParameterSpec(
                name="{param}",
                min_val={sugg_min}, max_val={sugg_max}, default={default_val},  # üéØ Optimis√©: √©tait ({orig_min}-{orig_max})
                param_type="{param_type}",
                description="{description}"
            ),'''
        else:
            # Garder les valeurs originales si pas de suggestion
            default_val = int((orig_min + orig_max) / 2) if param_type == "int" else round((orig_min + orig_max) / 2, 1)
            code += f'''
            "{param}": ParameterSpec(
                name="{param}",
                min_val={orig_min}, max_val={orig_max}, default={default_val},  # Original (pas assez de donn√©es)
                param_type="{param_type}",
                description="{description}"
            ),'''

    code += '''
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }'''

    # Remplacer les placeholders
    code = code.replace("{total_results}", "XXX")  # √Ä remplir manuellement
    code = code.replace("{reduction}", f"{reduction_pct:.1f}")
    code = code.replace("{combo_before}", str(total_before))
    code = code.replace("{combo_after}", str(total_after))
    code = code.replace("{speedup}", f"{speedup:.1f}")

    return code

def main():
    """Fonction principale d'analyse"""

    print("üîç ANALYSE DES R√âSULTATS BOLLINGER ATR")
    print("=" * 50)

    # Charger les donn√©es
    df = load_bollinger_atr_results()

    if len(df) == 0:
        print("‚ùå Aucune donn√©e trouv√©e. V√©rifiez que des sweeps bollinger_atr existent.")
        return

    # Analyser les plages profitables
    suggested_ranges = analyze_profitable_ranges(df)

    # Calculer la r√©duction des combinaisons
    calculate_combination_reduction({}, suggested_ranges)

    # G√©n√©rer le code optimis√©
    optimized_code = generate_optimized_parameter_specs(suggested_ranges)

    print(f"\nüíæ CODE OPTIMIS√â G√âN√âR√â:")
    print("=" * 50)
    print(optimized_code)

    # Sauvegarder dans un fichier
    output_file = "bollinger_atr_optimized_ranges.py"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Code optimis√© pour bollinger_atr parameter_specs\n")
        f.write("# G√©n√©r√© automatiquement par analyse des r√©sultats\n\n")
        f.write(optimized_code)

    print(f"\n‚úÖ Code sauvegard√© dans: {output_file}")
    print("\nüéØ NEXT STEPS:")
    print("1. Copier le code g√©n√©r√© dans strategies/bollinger_atr.py")
    print("2. Tester avec un petit sweep pour valider les performances")
    print("3. Lancer un multi-sweep complet avec les nouvelles plages")

if __name__ == "__main__":
    main()
```
<!-- MODULE-END: analyze_bollinger_atr_results.py -->

<!-- MODULE-START: analyze_code_health.py -->
```json
{
  "name": "analyze_code_health.py",
  "path": "labs\\analysis\\analyze_code_health.py",
  "ext": ".py",
  "anchor": "analyze_code_health_py"
}
```
## analyze_code_health_py
*Chemin* : `labs\analysis\analyze_code_health.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Outil d'analyse de la sant√© du code et d√©tection de code mort
Utilise plusieurs m√©thodes pour identifier les probl√®mes potentiels
"""
import os
import ast
import sys
from pathlib import Path
import re
from collections import defaultdict
from typing import Dict, List, Set, Tuple

class CodeHealthAnalyzer:
    def __init__(self, root_path: str):
        self.root_path = Path(root_path)
        self.all_functions = set()
        self.all_classes = set()
        self.all_imports = defaultdict(set)
        self.function_calls = defaultdict(set)
        self.class_usage = defaultdict(set)
        self.file_dependencies = defaultdict(set)

    def analyze_file(self, file_path: Path) -> Dict:
        """Analyse un fichier Python pour extraire les m√©tadonn√©es"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            # Collecte des informations
            functions = []
            classes = []
            imports = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                    self.all_functions.add(f"{file_path.stem}.{node.name}")

                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                    self.all_classes.add(f"{file_path.stem}.{node.name}")

                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                        self.all_imports[str(file_path)].add(alias.name)

                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    for alias in node.names:
                        import_name = f"{module}.{alias.name}" if module else alias.name
                        imports.append(import_name)
                        self.all_imports[str(file_path)].add(import_name)

                elif isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
                    self.function_calls[str(file_path)].add(node.func.id)

            return {
                'functions': functions,
                'classes': classes,
                'imports': imports,
                'lines': len(content.split('\n')),
                'size_kb': file_path.stat().st_size / 1024
            }

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur analyse {file_path}: {e}")
            return {'functions': [], 'classes': [], 'imports': [], 'lines': 0, 'size_kb': 0}

    def find_large_files(self, min_lines: int = 500) -> List[Tuple[Path, int, float]]:
        """Trouve les fichiers volumineux candidats √† la refactorisation"""
        large_files = []

        for py_file in self.root_path.rglob("*.py"):
            if ".venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = len(f.read().split('\n'))
                size_kb = py_file.stat().st_size / 1024

                if lines >= min_lines:
                    large_files.append((py_file, lines, size_kb))
            except:
                continue

        return sorted(large_files, key=lambda x: x[1], reverse=True)

    def find_unused_imports(self) -> Dict[str, List[str]]:
        """D√©tecte les imports potentiellement inutilis√©s"""
        unused_imports = defaultdict(list)

        for file_path, imports in self.all_imports.items():
            file_calls = self.function_calls.get(file_path, set())

            for import_name in imports:
                # Extraction du nom de base pour la v√©rification
                base_name = import_name.split('.')[-1]

                # V√©rification si l'import est utilis√©
                if (base_name not in file_calls and
                    not any(base_name in call for call in file_calls)):
                    unused_imports[file_path].append(import_name)

        return unused_imports

    def find_complex_functions(self, min_complexity: int = 10) -> List[Tuple[str, int]]:
        """Trouve les fonctions complexes (approximation basique)"""
        complex_funcs = []

        for py_file in self.root_path.rglob("*.py"):
            if ".venv" in str(py_file):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Recherche approximative de complexit√© (nombre de if/for/while/try)
                complexity_keywords = ['if ', 'for ', 'while ', 'try:', 'except:', 'elif ']

                in_function = False
                current_function = None
                function_complexity = 0

                for line in content.split('\n'):
                    line_stripped = line.strip()

                    if line_stripped.startswith('def '):
                        if current_function and function_complexity >= min_complexity:
                            complex_funcs.append((f"{py_file.name}::{current_function}", function_complexity))

                        current_function = line_stripped.split('(')[0].replace('def ', '')
                        function_complexity = 0
                        in_function = True

                    elif in_function and any(kw in line_stripped for kw in complexity_keywords):
                        function_complexity += 1

                    elif line_stripped.startswith('def ') or line_stripped.startswith('class '):
                        if current_function and function_complexity >= min_complexity:
                            complex_funcs.append((f"{py_file.name}::{current_function}", function_complexity))
                        in_function = False
                        current_function = None
                        function_complexity = 0

            except:
                continue

        return sorted(complex_funcs, key=lambda x: x[1], reverse=True)

    def find_duplicate_code(self, min_length: int = 5) -> List[Tuple[str, str, str]]:
        """D√©tecte les duplications de code potentielles"""
        code_blocks = defaultdict(list)

        for py_file in self.root_path.rglob("*.py"):
            if ".venv" in str(py_file):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.read().split('\n')

                # Recherche de blocs de code similaires
                for i in range(len(lines) - min_length):
                    block = '\n'.join(lines[i:i+min_length])
                    block_clean = re.sub(r'\s+', ' ', block.strip())

                    if len(block_clean) > 50:  # Ignorer les petits blocs
                        code_blocks[block_clean].append((str(py_file), i+1))

            except:
                continue

        duplicates = []
        for block, locations in code_blocks.items():
            if len(locations) > 1:
                for loc in locations:
                    duplicates.append((loc[0], f"Line {loc[1]}", block[:100] + "..."))

        return duplicates

    def generate_report(self):
        """G√©n√®re un rapport complet"""
        print("üè• ANALYSE DE SANT√â DU CODE")
        print("=" * 50)

        # 1. Fichiers volumineux
        print("\nüìä FICHIERS VOLUMINEUX (candidats refactorisation)")
        large_files = self.find_large_files(300)
        for i, (file_path, lines, size_kb) in enumerate(large_files[:10]):
            priority = "üî¥ HAUTE" if lines > 1000 else "üü° MOYENNE" if lines > 600 else "üü¢ FAIBLE"
            print(f"{i+1:2d}. {file_path.name:<30} {lines:4d} lignes {size_kb:5.1f}KB {priority}")

        # 2. Analyse complexit√©
        print("\nüß† FONCTIONS COMPLEXES (candidats simplification)")
        complex_funcs = self.find_complex_functions(8)
        for func, complexity in complex_funcs[:10]:
            print(f"  ‚Ä¢ {func:<50} Complexit√©: {complexity}")

        # 3. Imports inutilis√©s
        print("\nüßπ IMPORTS POTENTIELLEMENT INUTILIS√âS")
        unused = self.find_unused_imports()
        files_with_unused = [(f, imports) for f, imports in unused.items() if imports]
        files_with_unused.sort(key=lambda x: len(x[1]), reverse=True)

        for file_path, imports in files_with_unused[:5]:
            file_name = Path(file_path).name
            print(f"  üìÅ {file_name:<30} {len(imports)} imports suspects")
            for imp in imports[:3]:
                print(f"     ‚Üí {imp}")

        # 4. Duplications
        print("\nüîÑ CODE DUPLIQU√â")
        duplicates = self.find_duplicate_code(4)
        dup_groups = defaultdict(list)
        for file_path, location, code in duplicates:
            dup_groups[code].append((file_path, location))

        for i, (code, locations) in enumerate(list(dup_groups.items())[:5]):
            if len(locations) > 1:
                print(f"  üîÑ Duplication #{i+1}: {len(locations)} occurrences")
                for loc in locations[:3]:
                    print(f"     ‚Üí {Path(loc[0]).name} ({loc[1]})")

        # 5. Recommandations
        print("\nüí° RECOMMANDATIONS PRIORITAIRES")
        if large_files:
            top_file = large_files[0]
            print(f"  1. Refactoriser {top_file[0].name} ({top_file[1]} lignes)")
            if 'ui' in str(top_file[0]) and 'sidebar' in str(top_file[0]):
                print(f"     ‚Üí S√©parer logique m√©tier / affichage UI")
            elif 'cli' in str(top_file[0]):
                print(f"     ‚Üí Extraire handlers de commandes")
            elif 'agent' in str(top_file[0]):
                print(f"     ‚Üí S√©parer agents par responsabilit√©")

        if complex_funcs:
            print(f"  2. Simplifier fonctions complexes (complexit√© > 8)")

        if unused:
            total_unused = sum(len(imports) for imports in unused.values())
            print(f"  3. Nettoyer {total_unused} imports inutilis√©s")

        print(f"\n‚úÖ Analyse termin√©e sur {len(list(self.root_path.rglob('*.py')))} fichiers Python")


def main():
    if len(sys.argv) > 1:
        root_path = sys.argv[1]
    else:
        root_path = "."

    analyzer = CodeHealthAnalyzer(root_path)
    analyzer.generate_report()


if __name__ == "__main__":
    main()
```
<!-- MODULE-END: analyze_code_health.py -->

<!-- MODULE-START: analyze_trade6.py -->
```json
{
  "name": "analyze_trade6.py",
  "path": "labs\\analysis\\analyze_trade6.py",
  "ext": ".py",
  "anchor": "analyze_trade6_py"
}
```
## analyze_trade6_py
*Chemin* : `labs\analysis\analyze_trade6.py`  
*Type* : `.py`  

```python
"""Analyse du trade #6 qui a dur√© 4.5 mois."""
import pandas as pd
import numpy as np
from data.loader import load_ohlcv

# Charger les donnees
df = load_ohlcv('BTCUSDC', '30m', start='2019-06-06', end='2019-10-24')

# Calculer Bollinger
period = 20
std_dev = 2.0
close = df['close']
middle = close.rolling(period).mean()
std = close.rolling(period).std()
upper = middle + std_dev * std
lower = middle - std_dev * std

df['bb_upper'] = upper
df['bb_lower'] = lower
width = upper - lower

# Calculer bb_pos pour high et low
df['bb_pos_high'] = (df['high'] - lower) / width
df['bb_pos_low'] = (df['low'] - lower) / width

# Filtrer pendant le trade #6 (2019-06-06 18:00 -> 2019-10-23 16:00)
trade_start = '2019-06-06 18:00:00'
trade_end = '2019-10-23 16:00:00'

in_trade = df[(df.index >= trade_start) & (df.index <= trade_end)]

print(f'=== TRADE #6: {trade_start} -> {trade_end} ===')
print(f'Barres pendant le trade: {len(in_trade)}')
print()

# Combien de fois le TP (0.9) aurait du etre touche ?
tp_touches = (in_trade['bb_pos_high'] >= 0.9).sum()
print(f'Barres ou high >= 0.9 (TP aurait du trigger): {tp_touches}')

# Combien de fois le SL (-0.32) aurait du etre touche ?
sl_touches = (in_trade['bb_pos_low'] <= -0.32).sum()
print(f'Barres ou low <= -0.32 (SL aurait du trigger): {sl_touches}')

print()
bb_high_min = in_trade['bb_pos_high'].min()
bb_high_max = in_trade['bb_pos_high'].max()
bb_high_mean = in_trade['bb_pos_high'].mean()
print(f'=== Stats bb_pos_high pendant le trade ===')
print(f'Min: {bb_high_min:.3f}')
print(f'Max: {bb_high_max:.3f}')
print(f'Mean: {bb_high_mean:.3f}')

print()
print('=== Premieres 5 barres ou TP (>=0.9) aurait du etre touche ===')
tp_bars = in_trade[in_trade['bb_pos_high'] >= 0.9].head(5)
if len(tp_bars) > 0:
    print(tp_bars[['high', 'bb_upper', 'bb_lower', 'bb_pos_high']])
else:
    print('AUCUNE BARRE!')

print()
print('=== Premiere barre apres entree ===')
first_bar = in_trade.iloc[0:3]
print(first_bar[['close', 'high', 'low', 'bb_upper', 'bb_lower', 'bb_pos_high', 'bb_pos_low']])
```
<!-- MODULE-END: analyze_trade6.py -->

<!-- MODULE-START: detailed_bollinger_analysis.py -->
```json
{
  "name": "detailed_bollinger_analysis.py",
  "path": "labs\\analysis\\detailed_bollinger_analysis.py",
  "ext": ".py",
  "anchor": "detailed_bollinger_analysis_py"
}
```
## detailed_bollinger_analysis_py
*Chemin* : `labs\analysis\detailed_bollinger_analysis.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Analyse d√©taill√©e des r√©sultats Bollinger ATR et proposition de plages th√©oriquement sens√©es
bas√©es sur les meilleures pratiques de l'analyse technique.
"""

import pandas as pd
import numpy as np
from analyze_bollinger_atr_results import load_bollinger_atr_results

def analyze_performance_issues(df: pd.DataFrame):
    """Analyse les probl√®mes de performance de la strat√©gie"""

    print("üîç DIAGNOSTIC BOLLINGER ATR - PROBL√àMES DE PERFORMANCE")
    print("=" * 70)

    if len(df) == 0:
        print("‚ùå Aucune donn√©e √† analyser")
        return

    # Statistiques g√©n√©rales
    total_runs = len(df)
    profitable = df[df["total_pnl"] > 0]
    ruined = df[df["account_ruined"] == True]

    print(f"üìä STATISTIQUES G√âN√âRALES :")
    print(f"   ‚Ä¢ Total runs        : {total_runs}")
    print(f"   ‚Ä¢ Runs profitables  : {len(profitable)} ({len(profitable)/total_runs*100:.1f}%)")
    print(f"   ‚Ä¢ Comptes ruin√©s    : {len(ruined)} ({len(ruined)/total_runs*100:.1f}%)")
    print(f"   ‚Ä¢ PnL moyen         : ${df['total_pnl'].mean():.2f}")
    print(f"   ‚Ä¢ PnL m√©dian        : ${df['total_pnl'].median():.2f}")
    print(f"   ‚Ä¢ Sharpe moyen      : {df['sharpe_ratio'].mean():.2f}")

    # Distribution des pertes
    negative_pnl = df[df["total_pnl"] < 0]["total_pnl"]
    if len(negative_pnl) > 0:
        print(f"\nüìâ DISTRIBUTION DES PERTES :")
        print(f"   ‚Ä¢ Perte moyenne     : ${negative_pnl.mean():.2f}")
        print(f"   ‚Ä¢ Pire perte        : ${negative_pnl.min():.2f}")
        print(f"   ‚Ä¢ P75 des pertes    : ${negative_pnl.quantile(0.75):.2f}")

    # Analyse des param√®tres probl√©matiques
    print(f"\nüéØ PARAM√àTRES PROBL√âMATIQUES IDENTIFI√âS :")

    # entry_z probl√©matique
    weird_entry_z = df[(df["entry_z"] < 0.5) | (df["entry_z"] > 4.0)]
    if len(weird_entry_z) > 0:
        print(f"   ‚Ä¢ entry_z aberrants : {len(weird_entry_z)} runs avec entry_z hors [0.5-4.0]")

    # k_sl probl√©matique
    weird_k_sl = df[(df["k_sl"] < 0) | (df["k_sl"] > 5.0)]
    if len(weird_k_sl) > 0:
        print(f"   ‚Ä¢ k_sl aberrants    : {len(weird_k_sl)} runs avec k_sl n√©gatif ou >5.0")

    # bb_std extr√™mes
    weird_bb_std = df[(df["bb_std"] < 1.0) | (df["bb_std"] > 4.0)]
    if len(weird_bb_std) > 0:
        print(f"   ‚Ä¢ bb_std extr√™mes   : {len(weird_bb_std)} runs avec bb_std hors [1.0-4.0]")

    return profitable

def suggest_theory_based_ranges():
    """Propose des plages bas√©es sur la th√©orie de l'analyse technique"""

    print(f"\nüéì PLAGES SUGG√âR√âES BAS√âES SUR LA TH√âORIE FINANCI√àRE")
    print("=" * 60)
    print(f"üìñ Plut√¥t que de suivre les 4.9% de r√©sultats 'profitables' douteux,")
    print(f"   utilisons les meilleures pratiques de l'analyse technique :")
    print()

    ranges = {
        "bb_period": {
            "theory_min": 15,   # Minimum pour capturer tendances court terme
            "theory_max": 35,   # Maximum pour √©viter lag excessif
            "optimal": 20,      # Standard de Bollinger
            "rationale": "John Bollinger recommande 20 p√©riodes comme standard"
        },
        "bb_std": {
            "theory_min": 1.8,  # Bandes plus serr√©es pour march√©s stables
            "theory_max": 2.5,  # Bandes plus larges pour march√©s volatils
            "optimal": 2.0,     # Standard de Bollinger
            "rationale": "2.0 capture ~95% des mouvements, 1.8-2.5 couvre diff√©rents r√©gimes"
        },
        "entry_z": {
            "theory_min": 1.5,  # Touch band standard
            "theory_max": 2.2,  # Au-del√† de la band externe
            "optimal": 2.0,     # √Ä la band elle-m√™me
            "rationale": "1.5-2.2 permet variations autour de la band standard"
        },
        "atr_period": {
            "theory_min": 10,   # Volatilit√© plus r√©active
            "theory_max": 21,   # Volatilit√© plus liss√©e
            "optimal": 14,      # Standard ATR de Wilder
            "rationale": "14 p√©riodes recommand√© par Wilder, 10-21 couvre court/moyen terme"
        },
        "atr_percentile": {
            "theory_min": 20,   # Volatilit√© relativement faible
            "theory_max": 50,   # Volatilit√© relativement √©lev√©e
            "optimal": 30,      # √âquilibre
            "rationale": "20-50 filtre les march√©s trop calmes/agit√©s"
        },
        "k_sl": {
            "theory_min": 1.2,  # Stop serr√©
            "theory_max": 2.5,  # Stop large
            "optimal": 1.5,     # √âquilibre risk/reward
            "rationale": "1.2-2.5 ATR couvre diff√©rents styles de gestion du risque"
        }
    }

    total_combos = 1
    for param, info in ranges.items():
        # Calculer le nombre de valeurs selon le type
        if param in ["bb_period", "atr_period", "atr_percentile"]:
            # Entiers avec step = 1
            count = info["theory_max"] - info["theory_min"] + 1
        else:
            # Floats avec step = 0.1
            count = int((info["theory_max"] - info["theory_min"]) / 0.1) + 1

        total_combos *= count

        print(f"{param:15} ‚îÇ {info['theory_min']:4} - {info['theory_max']:4} ‚îÇ Optimal: {info['optimal']:4} ‚îÇ {count:2d} vals ‚îÇ {info['rationale']}")

    print("-" * 120)
    print(f"üéØ TOTAL TH√âORIQUE : {total_combos:,} combinaisons")

    # Temps estim√©
    time_hours = total_combos / (100 * 3600)  # 100 bt/s
    if time_hours < 1:
        time_str = f"{time_hours*60:.1f} minutes"
    else:
        time_str = f"{time_hours:.1f} heures"

    print(f"‚è±Ô∏è TEMPS ESTIM√â    : {time_str}")
    print(f"üß† RATIONALE      : Bas√© sur les standards de l'industrie, pas sur des donn√©es biais√©es")

    return ranges

def generate_theory_based_code(ranges):
    """G√©n√®re le code Python optimis√© bas√© sur la th√©orie"""

    code = '''    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications bas√©es sur la th√©orie de l'analyse technique.

        üéì RANGES TH√âORIQUES optimis√©s :
        - Bas√© sur les standards de John Bollinger et Welles Wilder
        - √âvite les valeurs aberrantes des backtests (entry_z<0.5, k_sl n√©gatif)
        - R√©duit l'espace de recherche √† ~{total_combos:,} combinaisons viables
        - Focus sur les plages utilis√©es par les traders professionnels

        ‚ö†Ô∏è ATTENTION : Les r√©sultats backtests montrent 95.1% d'√©checs.
        Cette strat√©gie n√©cessite peut-√™tre une r√©vision fondamentale de sa logique.
        """
        return {{'''

    param_configs = {
        "bb_period": {"type": "int", "step": 1},
        "bb_std": {"type": "float", "step": 0.1},
        "entry_z": {"type": "float", "step": 0.1},
        "atr_period": {"type": "int", "step": 1},
        "atr_percentile": {"type": "int", "step": 1},
        "k_sl": {"type": "float", "step": 0.1},
    }

    # Calculer le total pour le placeholder
    total_combos = 1
    for param, config in param_configs.items():
        param_range = ranges[param]
        if config["type"] == "int":
            count = param_range["theory_max"] - param_range["theory_min"] + 1
        else:
            count = int((param_range["theory_max"] - param_range["theory_min"]) / config["step"]) + 1
        total_combos *= count

    # G√©n√©rer le code pour chaque param√®tre
    for param, param_range in ranges.items():
        config = param_configs[param]

        min_val = param_range["theory_min"]
        max_val = param_range["theory_max"]
        optimal = param_range["optimal"]
        rationale = param_range["rationale"]

        if config["type"] == "int":
            code += f'''
            "{param}": ParameterSpec(
                name="{param}",
                min_val={min_val}, max_val={max_val}, default={optimal},  # üéì Th√©orique: {rationale}
                param_type="{config['type']}",
                description="{get_param_description(param)}"
            ),'''
        else:
            code += f'''
            "{param}": ParameterSpec(
                name="{param}",
                min_val={min_val}, max_val={max_val}, default={optimal},  # üéì Th√©orique: {rationale}
                param_type="{config['type']}",
                description="{get_param_description(param)}"
            ),'''

    code += '''
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }'''

    # Remplacer le placeholder
    code = code.replace("{total_combos:,}", f"{total_combos:,}")

    return code

def get_param_description(param):
    """Retourne la description du param√®tre"""
    descriptions = {
        "bb_period": "P√©riode des Bandes de Bollinger",
        "bb_std": "√âcarts-types pour les bandes",
        "entry_z": "Seuil z-score pour entree",
        "atr_period": "P√©riode de l'ATR",
        "atr_percentile": "Percentile volatilite minimum (ATR)",
        "k_sl": "Multiplicateur ATR pour stop-loss"
    }
    return descriptions.get(param, "Param√®tre de trading")

def main():
    """Fonction principale d'analyse d√©taill√©e"""

    # Charger les donn√©es
    df = load_bollinger_atr_results()

    if len(df) == 0:
        print("‚ùå Aucune donn√©e trouv√©e.")
        return

    # Analyser les probl√®mes de performance
    profitable_df = analyze_performance_issues(df)

    # Proposer des plages th√©oriques
    theory_ranges = suggest_theory_based_ranges()

    # G√©n√©rer le code optimis√©
    theory_code = generate_theory_based_code(theory_ranges)

    print(f"\nüíæ CODE TH√âORIQUE G√âN√âR√â :")
    print("=" * 50)
    print(theory_code)

    # Sauvegarder
    output_file = "bollinger_atr_theory_ranges.py"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Code th√©orique pour bollinger_atr parameter_specs\n")
        f.write("# Bas√© sur les standards de l'analyse technique\n\n")
        f.write(theory_code)

    print(f"\n‚úÖ Code th√©orique sauvegard√© dans: {output_file}")

    print(f"\nüéØ RECOMMANDATIONS FINALES :")
    print(f"1. üîß **R√âVISER LA LOGIQUE** de la strat√©gie (95.1% d'√©checs)")
    print(f"2. üß™ **TESTER** les plages th√©oriques sur un petit √©chantillon")
    print(f"3. üéØ **ANALYSER** pourquoi entry_z et k_sl produisent des valeurs aberrantes")
    print(f"4. üìä **COMPARER** les nouvelles plages vs anciennes sur m√™mes donn√©es")
    print(f"5. üîç **INVESTIGUER** les 4 seuls r√©sultats 'profitables' pour comprendre")

if __name__ == "__main__":
    main()
```
<!-- MODULE-END: detailed_bollinger_analysis.py -->

<!-- MODULE-START: debug_full_simulator.py -->
```json
{
  "name": "debug_full_simulator.py",
  "path": "labs\\debug\\debug_full_simulator.py",
  "ext": ".py",
  "anchor": "debug_full_simulator_py"
}
```
## debug_full_simulator_py
*Chemin* : `labs\debug\debug_full_simulator.py`  
*Type* : `.py`  

```python
"""Debug COMPLET du simulateur - pourquoi le SL n'est jamais d√©clench√© ?"""
import pandas as pd
import numpy as np
from data.loader import load_ohlcv
from indicators.bollinger import bollinger_bands

# Charger les donn√©es exactes du backtest
df = load_ohlcv('BTCUSDC', '30m', start='2019-06-01', end='2019-10-31')

# Calculer Bollinger
upper, middle, lower = bollinger_bands(df['close'].values, period=20, std_dev=2.0)
upper = pd.Series(upper, index=df.index)
middle = pd.Series(middle, index=df.index)
lower = pd.Series(lower, index=df.index)

# Calculer bb_pos
width = upper - lower
bb_pos_low = (df['low'] - lower) / width
bb_pos_high = (df['high'] - lower) / width

# Ajouter au DataFrame comme le fait la strat√©gie
df['bb_upper'] = upper
df['bb_middle'] = middle
df['bb_lower'] = lower
df['bb_width'] = width
df['bb_pos_low'] = bb_pos_low
df['bb_pos_high'] = bb_pos_high
df['sl_level'] = -0.32  # Constante
df['tp_level'] = 0.9    # Constante
df['entry_level'] = 0.0

# V√©rifier les colonnes
print("=== VERIFICATION COLONNES ===")
required_cols = ["bb_pos_low", "bb_pos_high", "sl_level", "tp_level"]
has_bbpos = all(col in df.columns for col in required_cols)
print(f"has_bbpos = {has_bbpos}")
for col in required_cols:
    print(f"  {col}: present={col in df.columns}, dtype={df[col].dtype if col in df.columns else 'N/A'}")

# V√©rifier les NaN
print("\n=== VERIFICATION NaN ===")
invalid_mask = np.isnan(df['bb_pos_low'].values) | np.isnan(df['bb_pos_high'].values)
print(f"Barres avec bb_pos invalide (NaN): {invalid_mask.sum()} / {len(df)}")

# Localiser le trade #6
entry_time = pd.Timestamp('2019-06-06 18:00:00+00:00')
exit_time = pd.Timestamp('2019-10-23 16:00:00+00:00')

# Trouver les indices
entry_idx = df.index.get_indexer([entry_time], method='nearest')[0]
exit_idx = df.index.get_indexer([exit_time], method='nearest')[0]

print(f"\n=== TRADE #6 ===")
print(f"Entry: index {entry_idx}, time {df.index[entry_idx]}")
print(f"Exit: index {exit_idx}, time {df.index[exit_idx]}")
print(f"Dur√©e: {exit_idx - entry_idx} barres")

# V√©rifier les valeurs pendant le trade
trade_df = df.iloc[entry_idx:exit_idx+1]
sl_level = -0.32
tp_level = 0.9

print(f"\n=== PENDANT LE TRADE ({len(trade_df)} barres) ===")

# Compter les conditions
sl_triggered = trade_df['bb_pos_low'] <= sl_level
tp_triggered = trade_df['bb_pos_high'] >= tp_level
invalid_during = np.isnan(trade_df['bb_pos_low'].values) | np.isnan(trade_df['bb_pos_high'].values)

print(f"Barres o√π bb_pos_low <= {sl_level} (SL): {sl_triggered.sum()}")
print(f"Barres o√π bb_pos_high >= {tp_level} (TP): {tp_triggered.sum()}")
print(f"Barres avec bb_pos invalide: {invalid_during.sum()}")

# V√©rifier sl_level_array et tp_level_array
print(f"\n=== VERIFICATION sl_level / tp_level ARRAYS ===")
sl_level_array = df['sl_level'].values
tp_level_array = df['tp_level'].values
print(f"sl_level_array unique values: {np.unique(sl_level_array)}")
print(f"tp_level_array unique values: {np.unique(tp_level_array)}")
print(f"sl_level_array has NaN: {np.isnan(sl_level_array).any()}")
print(f"tp_level_array has NaN: {np.isnan(tp_level_array).any()}")

# SIMULATION MANUELLE du check SL/TP
print(f"\n=== SIMULATION MANUELLE DU CHECK SL/TP ===")
bb_pos_low_arr = df['bb_pos_low'].values
bb_pos_high_arr = df['bb_pos_high'].values

# Simuler exactement le code du simulateur
position = 1  # On est en position long
stop_count = 0
tp_count = 0
invalid_count = 0

for i in range(entry_idx, exit_idx + 1):
    # Code exact du simulateur ligne 224-226
    invalid = np.isnan(bb_pos_low_arr[i]) or np.isnan(bb_pos_high_arr[i])

    if invalid:
        invalid_count += 1
        continue

    stop_hit = bb_pos_low_arr[i] <= sl_level_array[i]
    tp_hit = bb_pos_high_arr[i] >= tp_level_array[i]

    if stop_hit:
        stop_count += 1
    if tp_hit:
        tp_count += 1

print(f"Barres o√π stop_hit serait True: {stop_count}")
print(f"Barres o√π tp_hit serait True: {tp_count}")
print(f"Barres invalides (skipped): {invalid_count}")

# Premi√®re barre o√π SL devrait trigger
print(f"\n=== PREMIERE BARRE OU SL DEVRAIT TRIGGER ===")
for i in range(entry_idx, min(entry_idx + 10, exit_idx + 1)):
    invalid = np.isnan(bb_pos_low_arr[i]) or np.isnan(bb_pos_high_arr[i])
    stop_hit = bb_pos_low_arr[i] <= sl_level_array[i] if not invalid else False
    tp_hit = bb_pos_high_arr[i] >= tp_level_array[i] if not invalid else False

    print(f"Barre {i} ({df.index[i]}): "
          f"bb_pos_low={bb_pos_low_arr[i]:.4f}, "
          f"sl_level={sl_level_array[i]:.4f}, "
          f"stop_hit={stop_hit}, "
          f"tp_hit={tp_hit}, "
          f"invalid={invalid}")

# VERIFIER LE FLUX COMPLET DU SIMULATEUR
print(f"\n=== LIRE LE CODE DU SIMULATEUR ===")
print("V√©rifions si le bloc SL/TP est bien ex√©cut√©...")

# Charger et analyser le code du simulateur
with open('backtest/simulator.py', 'r', encoding='utf-8') as f:
    code = f.read()

# Chercher la structure if/elif
import re

# Trouver le bloc d'entr√©e et de sortie
entry_match = re.search(r'if position == 0 and signal != 0:', code)
exit_match = re.search(r'elif position != 0:', code)

if entry_match and exit_match:
    print(f"Bloc entr√©e trouv√© √† position {entry_match.start()}")
    print(f"Bloc sortie trouv√© √† position {exit_match.start()}")

    # Le elif signifie que si on entre, on NE v√©rifie PAS la sortie sur la m√™me barre
    # MAIS ce n'est pas le probl√®me car le trade dure 4.5 mois

# Chercher le bloc SL/TP bb_pos
bbpos_check = re.search(r'if position == 1 and has_bbpos', code)
if bbpos_check:
    print(f"Bloc check bb_pos trouv√© √† position {bbpos_check.start()}")
    # Extraire les lignes autour
    start = code.rfind('\n', 0, bbpos_check.start()) + 1
    end = code.find('\n', bbpos_check.end() + 200)
    print("\nCode du bloc:")
    print(code[start:end])
```
<!-- MODULE-END: debug_full_simulator.py -->

<!-- MODULE-START: debug_multi_sweep.py -->
```json
{
  "name": "debug_multi_sweep.py",
  "path": "labs\\debug\\debug_multi_sweep.py",
  "ext": ".py",
  "anchor": "debug_multi_sweep_py"
}
```
## debug_multi_sweep_py
*Chemin* : `labs\debug\debug_multi_sweep.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Script de diagnostic du syst√®me multi-sweep
Date: 23/01/2026
"""

import sys
import os

# Ajouter le r√©pertoire racine au path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_sidebar_state():
    """Test de la configuration de la sidebar"""

    print("=== Diagnostic Syst√®me Multi-Sweep ===\n")

    # Simuler des s√©lections multiples comme l'utilisateur
    test_symbols = ["BTCUSDC", "ETHUSDC"]
    test_timeframes = ["5m", "15m", "30m"]
    test_strategy_keys = ["bollinger_long_test", "ema_cross"]

    print(f"S√©lections de test:")
    print(f"  - Symbols: {test_symbols} (len={len(test_symbols)})")
    print(f"  - Timeframes: {test_timeframes} (len={len(test_timeframes)})")
    print(f"  - Strategy keys: {test_strategy_keys} (len={len(test_strategy_keys)})")

    # Test d√©tection multi-sweep
    is_multi_sweep = (len(test_strategy_keys) > 1 or len(test_symbols) > 1 or len(test_timeframes) > 1)
    print(f"\nD√©tection multi-sweep: {is_multi_sweep}")

    if is_multi_sweep:
        total_combinations = len(test_strategy_keys) * len(test_symbols) * len(test_timeframes)
        print(f"Total combinaisons attendues: {total_combinations}")

        print("\nCombinaisongs qui seraient trait√©es:")
        counter = 0
        for strategy in test_strategy_keys:
            for symbol in test_symbols:
                for timeframe in test_timeframes:
                    counter += 1
                    print(f"  {counter:2d}. {strategy} √ó {symbol} √ó {timeframe}")

    print()

def test_data_availability():
    """Test disponibilit√© des donn√©es"""
    try:
        from data.loader import discover_available_data

        print("=== Test Disponibilit√© Donn√©es ===")
        symbols, timeframes = discover_available_data()
        print(f"Symbols disponibles: {len(symbols)} - {symbols[:5]}{'...' if len(symbols) > 5 else ''}")
        print(f"Timeframes disponibles: {len(timeframes)} - {timeframes}")

        # Test sp√©cifique pour les symboles utilisateur
        test_symbols = ["BTCUSDC", "ETHUSDC"]
        test_timeframes = ["5m", "15m", "30m"]

        print(f"\nV√©rification des s√©lections utilisateur:")
        for symbol in test_symbols:
            available = symbol in symbols
            print(f"  {symbol}: {'‚úÖ Disponible' if available else '‚ùå Manquant'}")

        for tf in test_timeframes:
            available = tf in timeframes
            print(f"  {tf}: {'‚úÖ Disponible' if available else '‚ùå Manquant'}")

    except Exception as e:
        print(f"Erreur scan donn√©es: {e}")

if __name__ == "__main__":
    test_sidebar_state()
    test_data_availability()

    print("\n=== Recommandations ===")
    print("1. V√©rifiez que les s√©lections multiples sont bien transmises au state")
    print("2. Ajoutez des logs dans les boucles multi-sweep pour tracer l'ex√©cution")
    print("3. V√©rifiez que les donn√©es sont disponibles pour tous les symboles/timeframes")
    print("4. Testez avec des symboles/timeframes tr√®s simples d'abord")
```
<!-- MODULE-END: debug_multi_sweep.py -->

<!-- MODULE-START: debug_optimal_periods.py -->
```json
{
  "name": "debug_optimal_periods.py",
  "path": "labs\\debug\\debug_optimal_periods.py",
  "ext": ".py",
  "anchor": "debug_optimal_periods_py"
}
```
## debug_optimal_periods_py
*Chemin* : `labs\debug\debug_optimal_periods.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Debug: Pourquoi aucune p√©riode optimale n'est trouv√©e ?
"""

import sys
from pathlib import Path

# Ajouter le r√©pertoire parent au path
sys.path.append(str(Path(__file__).parent.parent.parent))

from data.config import (
    scan_data_availability,
    find_optimal_periods,
    analyze_data_gaps
)

def debug_optimal_periods():
    """Debug d√©taill√© pour comprendre pourquoi aucune p√©riode n'est trouv√©e"""
    print("üîç Debug: Recherche de p√©riodes optimales")

    symbols = ["BTCUSDC"]
    timeframes = ["15m"]  # Test avec un seul timeframe simple

    print(f"Test avec: {symbols} sur {timeframes}")

    # 1. V√©rifier la disponibilit√© des donn√©es
    print("\n1. Scan de disponibilit√©:")
    availability = scan_data_availability(symbols, timeframes)
    print(f"   Plage commune: {availability.has_common_range}")
    if availability.has_common_range:
        print(f"   D√©but: {availability.common_start}")
        print(f"   Fin: {availability.common_end}")
        duration = (availability.common_end - availability.common_start).days
        print(f"   Dur√©e: {duration} jours")

    # 2. Analyser les gaps
    print("\n2. Analyse des gaps:")
    gaps = analyze_data_gaps(symbols[0], timeframes[0])
    print(f"   Nombre de gaps trouv√©s: {len(gaps)}")

    if gaps:
        print("   Premiers gaps:")
        for i, gap in enumerate(gaps[:5]):
            gap_duration = (gap.end - gap.start).total_seconds() / 3600
            print(f"     Gap #{i+1}: {gap.start} ‚Üí {gap.end} ({gap_duration:.1f}h)")

    # 3. Tenter de trouver des p√©riodes optimales avec diff√©rents param√®tres
    print("\n3. Recherche de p√©riodes optimales:")

    test_params = [
        {"min_period_days": 7, "max_periods": 5},
        {"min_period_days": 30, "max_periods": 5},
        {"min_period_days": 90, "max_periods": 5},
        {"min_period_days": 1, "max_periods": 10}  # Tr√®s permissif
    ]

    for i, params in enumerate(test_params):
        print(f"\n   Test #{i+1}: min_period_days={params['min_period_days']}")
        try:
            periods = find_optimal_periods(
                symbols=symbols,
                timeframes=timeframes,
                **params
            )
            print(f"     R√©sultat: {len(periods)} p√©riodes trouv√©es")

            if periods:
                best = periods[0]
                duration = (best.end_date - best.start_date).days
                print(f"     Meilleure: {best.start_date.strftime('%Y-%m-%d')} ‚Üí {best.end_date.strftime('%Y-%m-%d')} ({duration}j)")
                print(f"     Score: {best.completeness_score:.1f}%, Densit√©: {best.avg_data_density:.3f}")
                print(f"     Description: {best.description}")
        except Exception as e:
            print(f"     Erreur: {e}")

    # 4. Test direct avec plage manuelle
    print("\n4. Test avec plage manuelle:")
    if availability.has_common_range:
        try:
            # Test avec une plage tr√®s courte mais r√©cente
            from datetime import datetime, timedelta
            import pandas as pd

            recent_end = availability.common_end
            recent_start = recent_end - timedelta(days=30)  # Derniers 30 jours

            print(f"   Plage test: {recent_start} ‚Üí {recent_end}")

            # Simulation de find_optimal_periods avec debug
            from data.loader import get_data_date_range
            date_range = get_data_date_range(symbols[0], timeframes[0])
            print(f"   Range des donn√©es: {date_range}")

        except Exception as e:
            print(f"   Erreur: {e}")

if __name__ == "__main__":
    debug_optimal_periods()
```
<!-- MODULE-END: debug_optimal_periods.py -->

<!-- MODULE-START: debug_simulator_trace.py -->
```json
{
  "name": "debug_simulator_trace.py",
  "path": "labs\\debug\\debug_simulator_trace.py",
  "ext": ".py",
  "anchor": "debug_simulator_trace_py"
}
```
## debug_simulator_trace_py
*Chemin* : `labs\debug\debug_simulator_trace.py`  
*Type* : `.py`  

```python
"""Debug COMPLET v2 - Simuler exactement le simulateur avec trace"""
import pandas as pd
import numpy as np
from data.loader import load_ohlcv
from indicators.bollinger import bollinger_bands

# Charger les donn√©es exactes du backtest
df = load_ohlcv('BTCUSDC', '30m', start='2019-06-01', end='2019-10-31')

# Calculer Bollinger
upper, middle, lower = bollinger_bands(df['close'].values, period=20, std_dev=2.0)
upper = pd.Series(upper, index=df.index)
middle = pd.Series(middle, index=df.index)
lower = pd.Series(lower, index=df.index)

# Calculer bb_pos
width = upper - lower
bb_pos_low = (df['low'] - lower) / width
bb_pos_high = (df['high'] - lower) / width

# Ajouter au DataFrame
df['bb_pos_low'] = bb_pos_low
df['bb_pos_high'] = bb_pos_high
df['sl_level'] = -0.32
df['tp_level'] = 0.9
df['entry_level'] = 0.0

# G√©n√©rer les signaux comme la strat√©gie
entry_level = 0.0
crossed = (bb_pos_low <= entry_level) & (bb_pos_low.shift(1) > entry_level)
invalid_width = (width <= 0) | width.isna()
crossed = crossed & (~invalid_width)

signals = pd.Series(0.0, index=df.index)
signals[crossed.fillna(False)] = 1.0

print("=== SIGNAUX GENERES ===")
print(f"Nombre de signaux d'entr√©e: {(signals == 1).sum()}")
signal_times = df.index[signals == 1]
print(f"Premiers signaux: {list(signal_times[:10])}")

# SIMULATION COMPLETE comme le simulateur
print("\n=== SIMULATION COMPLETE ===")

bb_pos_low_arr = df['bb_pos_low'].values
bb_pos_high_arr = df['bb_pos_high'].values
sl_level_arr = df['sl_level'].values
tp_level_arr = df['tp_level'].values
signal_values = signals.values
closes = df['close'].values
invalid_bbpos = np.isnan(bb_pos_low_arr) | np.isnan(bb_pos_high_arr)

position = 0
entry_idx = None
trades = []
n_bars = len(df)

# Variables pour tracer le trade #6
trade_6_entry = None
trade_6_barres_check = []

for i in range(n_bars):
    signal = signal_values[i]

    # === Entr√©e en position ===
    if position == 0 and signal != 0:
        position = int(signal)
        entry_idx = i
        entry_price = closes[i]

        # Est-ce le trade #6 (autour de 2019-06-06 18:00) ?
        if len(trades) == 5:  # C'est le 6√®me trade (index 5)
            trade_6_entry = i
            print(f"\n*** TRADE #6 ENTREE √† barre {i} ({df.index[i]}) ***")
            print(f"    Signal: {signal}, Position: {position}")
            print(f"    bb_pos_low: {bb_pos_low_arr[i]:.4f}")
            print(f"    sl_level: {sl_level_arr[i]:.4f}")
            print(f"    stop_hit serait: {bb_pos_low_arr[i] <= sl_level_arr[i]}")

    # === En position: v√©rifier sortie ===
    elif position != 0:
        exit_condition = False
        exit_reason = ""

        # Check SL/TP bb_pos
        if position == 1 and not invalid_bbpos[i]:
            stop_hit = bb_pos_low_arr[i] <= sl_level_arr[i]
            tp_hit = bb_pos_high_arr[i] >= tp_level_arr[i]

            # Tracer pour trade #6
            if trade_6_entry is not None and entry_idx == trade_6_entry:
                if stop_hit or tp_hit:
                    trade_6_barres_check.append({
                        'barre': i,
                        'time': df.index[i],
                        'bb_pos_low': bb_pos_low_arr[i],
                        'bb_pos_high': bb_pos_high_arr[i],
                        'stop_hit': stop_hit,
                        'tp_hit': tp_hit
                    })

            if stop_hit and tp_hit:
                exit_condition = True
                exit_reason = "stop_loss"
            elif stop_hit:
                exit_condition = True
                exit_reason = "stop_loss"
            elif tp_hit:
                exit_condition = True
                exit_reason = "take_profit"

        # === Ex√©cuter sortie ===
        if exit_condition:
            exit_price = closes[i]
            pnl = (exit_price - entry_price) * (1 if position == 1 else -1)

            trades.append({
                'entry_idx': entry_idx,
                'exit_idx': i,
                'entry_time': df.index[entry_idx],
                'exit_time': df.index[i],
                'entry_price': entry_price,
                'exit_price': exit_price,
                'pnl': pnl,
                'reason': exit_reason,
                'duration_bars': i - entry_idx
            })

            if entry_idx == trade_6_entry:
                print(f"\n*** TRADE #6 SORTIE √† barre {i} ({df.index[i]}) ***")
                print(f"    Raison: {exit_reason}")
                print(f"    Dur√©e: {i - entry_idx} barres")
                print(f"    PnL: {pnl:.2f}")

            position = 0
            entry_idx = None

print(f"\n=== RESULTATS ===")
print(f"Nombre total de trades: {len(trades)}")

# Afficher tous les trades
print("\n=== LISTE DES TRADES ===")
for idx, t in enumerate(trades):
    print(f"Trade #{idx+1}: {t['entry_time']} -> {t['exit_time']}, "
          f"dur√©e={t['duration_bars']} barres, raison={t['reason']}, PnL={t['pnl']:.2f}")

# Trade #6 sp√©cifiquement
if len(trades) >= 6:
    t6 = trades[5]
    print(f"\n=== TRADE #6 DETAILS ===")
    print(f"Entr√©e: {t6['entry_time']}")
    print(f"Sortie: {t6['exit_time']}")
    print(f"Dur√©e: {t6['duration_bars']} barres ({t6['duration_bars'] * 0.5} heures)")
    print(f"Raison sortie: {t6['reason']}")

    if trade_6_barres_check:
        print(f"\nBarres o√π SL/TP aurait d√ª trigger ({len(trade_6_barres_check)} trouv√©es):")
        for check in trade_6_barres_check[:20]:
            print(f"  Barre {check['barre']} ({check['time']}): "
                  f"stop_hit={check['stop_hit']}, tp_hit={check['tp_hit']}")
```
<!-- MODULE-END: debug_simulator_trace.py -->

<!-- MODULE-START: debug_tp_bug.py -->
```json
{
  "name": "debug_tp_bug.py",
  "path": "labs\\debug\\debug_tp_bug.py",
  "ext": ".py",
  "anchor": "debug_tp_bug_py"
}
```
## debug_tp_bug_py
*Chemin* : `labs\debug\debug_tp_bug.py`  
*Type* : `.py`  

```python
"""Debug du bug TP - comparaison prix fixes vs bb_pos dynamique"""
import pandas as pd
import numpy as np
from data.loader import load_ohlcv
from indicators.registry import calculate_indicator

# Charger les donn√©es
df = load_ohlcv('BTCUSDC', '30m', start='2019-06-06', end='2019-10-24')

# Calculer Bollinger avec period=20, std=2.0
from indicators.bollinger import bollinger_bands
upper, middle, lower = bollinger_bands(df['close'].values, period=20, std_dev=2.0)

# Convertir en Series
upper = pd.Series(upper, index=df.index)
middle = pd.Series(middle, index=df.index)
lower = pd.Series(lower, index=df.index)

# Calculer bb_pos
width = upper - lower
bb_pos_low = (df['low'] - lower) / width
bb_pos_high = (df['high'] - lower) / width

# Trouver l'entr√©e du trade #6 (premi√®re barre apr√®s 2019-06-06 18:00)
entry_time = pd.Timestamp('2019-06-06 18:00:00+00:00')
entry_idx = df.index.get_indexer([entry_time], method='nearest')[0]
entry_bar = df.index[entry_idx]

print("=== TRADE #6 ENTREE ===")
print(f"Barre entree: {entry_bar}")
print(f"Prix close: {df.iloc[entry_idx]['close']:.2f}")
print(f"Lower band: {lower.iloc[entry_idx]:.2f}")
print(f"Upper band: {upper.iloc[entry_idx]:.2f}")
print(f"Width: {width.iloc[entry_idx]:.2f}")
print(f"bb_pos_low: {bb_pos_low.iloc[entry_idx]:.4f}")
print(f"bb_pos_high: {bb_pos_high.iloc[entry_idx]:.4f}")

# Calculer les PRIX FIXES de SL et TP √† l'entr√©e
sl_level = -0.32
tp_level = 0.9

entry_lower = lower.iloc[entry_idx]
entry_upper = upper.iloc[entry_idx]
entry_width = width.iloc[entry_idx]

sl_price_fixed = entry_lower + sl_level * entry_width
tp_price_fixed = entry_lower + tp_level * entry_width

print()
print("=== NIVEAUX FIXES A L'ENTREE ===")
print(f"SL level: {sl_level} -> SL price: ${sl_price_fixed:.2f}")
print(f"TP level: {tp_level} -> TP price: ${tp_price_fixed:.2f}")
print(f"(Lower={entry_lower:.2f}, Upper={entry_upper:.2f}, Width={entry_width:.2f})")

# Chercher quand ces prix auraient √©t√© touch√©s
period_after_entry = df.iloc[entry_idx:]
lows_after = period_after_entry['low']
highs_after = period_after_entry['high']

# Premi√®re fois que high >= tp_price_fixed
tp_hits = highs_after[highs_after >= tp_price_fixed]
sl_hits = lows_after[lows_after <= sl_price_fixed]

print()
print("=== AVEC PRIX FIXES (CORRECT) ===")
if len(tp_hits) > 0:
    first_tp = tp_hits.index[0]
    print(f"Premier TP hit: {first_tp}")
    print(f"  High={highs_after.loc[first_tp]:.2f} >= TP={tp_price_fixed:.2f}")
    delta = first_tp - entry_bar
    print(f"  -> {delta.total_seconds()/3600:.1f}h apres entree")
else:
    print(f"TP jamais touche (prix fixe ${tp_price_fixed:.2f})")

if len(sl_hits) > 0:
    first_sl = sl_hits.index[0]
    print(f"Premier SL hit: {first_sl}")
    print(f"  Low={lows_after.loc[first_sl]:.2f} <= SL={sl_price_fixed:.2f}")
else:
    print(f"SL jamais touche (prix fixe ${sl_price_fixed:.2f})")

# Quel aurait √©t√© le r√©sultat CORRECT ?
if len(tp_hits) > 0 and len(sl_hits) > 0:
    if tp_hits.index[0] < sl_hits.index[0]:
        print("\n*** RESULTAT CORRECT: TP touch√© en premier! ***")
    else:
        print("\n*** RESULTAT CORRECT: SL touch√© en premier ***")
elif len(tp_hits) > 0:
    print("\n*** RESULTAT CORRECT: TP touch√© (SL jamais) ***")
elif len(sl_hits) > 0:
    print("\n*** RESULTAT CORRECT: SL touch√© (TP jamais) ***")

# Maintenant comparons avec la m√©thode bb_pos DYNAMIQUE (le bug actuel)
print()
print("=== AVEC bb_pos DYNAMIQUE (BUG ACTUEL) ===")
bb_pos_high_after = bb_pos_high.iloc[entry_idx:]
bb_pos_low_after = bb_pos_low.iloc[entry_idx:]

# Premi√®re fois que bb_pos_high >= 0.9
tp_hits_bbpos = bb_pos_high_after[bb_pos_high_after >= tp_level]
sl_hits_bbpos = bb_pos_low_after[bb_pos_low_after <= sl_level]

if len(tp_hits_bbpos) > 0:
    first_tp_bbpos = tp_hits_bbpos.index[0]
    print(f"Premier TP bb_pos hit: {first_tp_bbpos}")
    print(f"  bb_pos_high={bb_pos_high_after.loc[first_tp_bbpos]:.4f} >= {tp_level}")
    delta = first_tp_bbpos - entry_bar
    print(f"  -> {delta.total_seconds()/3600:.1f}h apres entree")
else:
    print(f"TP bb_pos jamais >= {tp_level}")

if len(sl_hits_bbpos) > 0:
    first_sl_bbpos = sl_hits_bbpos.index[0]
    print(f"Premier SL bb_pos hit: {first_sl_bbpos}")
    print(f"  bb_pos_low={bb_pos_low_after.loc[first_sl_bbpos]:.4f} <= {sl_level}")
else:
    print(f"SL bb_pos jamais <= {sl_level}")

# Statistiques
print()
print("=== STATISTIQUES bb_pos PENDANT LE TRADE ===")
print(f"bb_pos_high max: {bb_pos_high_after.max():.4f}")
print(f"bb_pos_high mean: {bb_pos_high_after.mean():.4f}")
print(f"bb_pos_low min: {bb_pos_low_after.min():.4f}")
print(f"bb_pos_low mean: {bb_pos_low_after.mean():.4f}")

# Compter les opportunit√©s
print()
print("=== OPPORTUNITES RATEES ===")
print(f"Barres o√π bb_pos_high >= {tp_level}: {len(tp_hits_bbpos)}")
print(f"Barres o√π bb_pos_low <= {sl_level}: {len(sl_hits_bbpos)}")
```
<!-- MODULE-END: debug_tp_bug.py -->

<!-- MODULE-START: diagnose_gpu.py -->
```json
{
  "name": "diagnose_gpu.py",
  "path": "labs\\debug\\diagnose_gpu.py",
  "ext": ".py",
  "anchor": "diagnose_gpu_py"
}
```
## diagnose_gpu_py
*Chemin* : `labs\debug\diagnose_gpu.py`  
*Type* : `.py`  

```python
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    import sys
from pathlib import Path
import os

# Setup python path
ROOT_DIR = Path.cwd()
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

try:
    import cupy as cp
    print(f"CuPy Version: {cp.__version__}")

    dev_count = cp.cuda.runtime.getDeviceCount()
    print(f"Detected {dev_count} GPUs via CuPy/CUDA Runtime.")


    for i in range(dev_count):
        props = cp.cuda.runtime.getDeviceProperties(i)
        name = props["name"].decode() if isinstance(props["name"], bytes) else props["name"]

        # Get memory info by switching
        try:
            with cp.cuda.Device(i):
                mem_info = cp.cuda.runtime.memGetInfo()
                free_gb = mem_info[0] / (1024**3)
                total_gb = mem_info[1] / (1024**3)
                pci_bus_id = props["pciBusID"]
                print(f"GPU {i}: {name} (Total: {total_gb:.2f} GB, Free: {free_gb:.2f} GB) PCI Bus: {pci_bus_id}")
        except Exception as e:
            print(f"GPU {i}: Error getting memory info: {e}")

    # Check Environment Variables
    print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
    print(f"BACKTEST_GPU_ID: {os.environ.get('BACKTEST_GPU_ID')}")

except ImportError:
    print("CuPy not installed.")
except Exception as e:
    print(f"Error during GPU check: {e}")
```
<!-- MODULE-END: diagnose_gpu.py -->

<!-- MODULE-START: diagnose_startup.py -->
```json
{
  "name": "diagnose_startup.py",
  "path": "labs\\debug\\diagnose_startup.py",
  "ext": ".py",
  "anchor": "diagnose_startup_py"
}
```
## diagnose_startup_py
*Chemin* : `labs\debug\diagnose_startup.py`  
*Type* : `.py`  

```python
import sys
from pathlib import Path
import os
import traceback

# Setup python path like ui/app.py
ROOT_DIR = Path.cwd()
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

print(f"Diagnostics: Root Dir: {ROOT_DIR}")
print(f"Diagnostics: Python Path: {sys.path[0]}")

print("\n--- Testing Imports from ui.context ---")
try:
    from ui import context
    print(f"BACKEND_AVAILABLE: {context.BACKEND_AVAILABLE}")
    print(f"IMPORT_ERROR: '{context.IMPORT_ERROR}'")

    if not context.BACKEND_AVAILABLE:
        print("Backend unavailable. Attempting individual imports to isolate error:")
        try:
            from backtest.engine import BacktestEngine
            print("  - backtest.engine imported OK")
        except Exception as e:
            print(f"  - backtest.engine FAILED: {e}")

        try:
            from backtest.storage import get_storage
            print("  - backtest.storage imported OK")
        except Exception as e:
            print(f"  - backtest.storage FAILED: {e}")

        try:
            from data.loader import load_ohlcv
            print("  - data.loader imported OK")
        except Exception as e:
            print(f"  - data.loader FAILED: {e}")

        try:
            from strategies.base import get_strategy
            print("  - strategies.base imported OK")
        except Exception as e:
            print(f"  - strategies.base FAILED: {e}")

except Exception as e:
    print(f"Critical error importing ui.context: {e}")
    traceback.print_exc()

print("\n--- Testing GPU Detection ---")
try:
    from performance.gpu import GPUDeviceManager, _instance
    # Force re-init if possible or check static content
    print("Imported GPUDeviceManager.")

    try:
        import cupy as cp
        print(f"CuPy imported: {cp.__version__}")
        count = cp.cuda.runtime.getDeviceCount()
        print(f"Device Count: {count}")
        for i in range(count):
            props = cp.cuda.runtime.getDeviceProperties(i)
            name = props["name"].decode() if isinstance(props["name"], bytes) else props["name"]
            print(f"  Device {i}: {name}")
    except ImportError:
        print("CuPy not installed or not working.")
    except Exception as e:
        print(f"CuPy error: {e}")

except Exception as e:
    print(f"GPU module import error: {e}")
```
<!-- MODULE-END: diagnose_startup.py -->

<!-- MODULE-START: diagnostic_sweep_blocked.py -->
```json
{
  "name": "diagnostic_sweep_blocked.py",
  "path": "labs\\debug\\diagnostic_sweep_blocked.py",
  "ext": ".py",
  "anchor": "diagnostic_sweep_blocked_py"
}
```
## diagnostic_sweep_blocked_py
*Chemin* : `labs\debug\diagnostic_sweep_blocked.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
üö® DIAGNOSTIC SWEEP BOLLINGER ATR - Probl√®me de grille gigantesque
================================================================

Ce script diagnostique pourquoi le sweep multi-tokens/timeframes se bloque
et propose des solutions pour r√©duire l'espace de recherche.
"""

def calculate_bollinger_atr_grid_size():
    """Calcule la taille de la grille Bollinger ATR"""

    # Param√®tres bollinger_atr avec leurs plages
    params = {
        "bb_period": {"min": 10, "max": 50, "step": 1},      # 41 valeurs
        "bb_std": {"min": 1.5, "max": 3.0, "step": 0.1},    # 16 valeurs
        "entry_z": {"min": 1.0, "max": 3.0, "step": 0.1},   # 21 valeurs
        "atr_period": {"min": 7, "max": 21, "step": 1},     # 15 valeurs
        "atr_percentile": {"min": 0, "max": 60, "step": 1}, # 61 valeurs
        "k_sl": {"min": 1.0, "max": 3.0, "step": 0.1},      # 21 valeurs
    }

    total_combinations = 1
    param_counts = {}

    print("üìä ANALYSE ESPACE DE RECHERCHE BOLLINGER ATR")
    print("=" * 50)

    for param, config in params.items():
        if config["step"] == 1:
            # Param√®tre entier
            count = config["max"] - config["min"] + 1
        else:
            # Param√®tre float
            import numpy as np
            values = np.arange(config["min"], config["max"] + config["step"]/2, config["step"])
            count = len(values)

        param_counts[param] = count
        total_combinations *= count
        print(f"  {param:15} : {config['min']:4} ‚Üí {config['max']:4} = {count:3} valeurs")

    print("\nüî• R√âSULTAT TOTAL:")
    calculation = " √ó ".join([f"{count}" for count in param_counts.values()])
    print(f"  {calculation}")
    print(f"  = {total_combinations:,} combinaisons")

    # Estimation taille m√©moire (tr√®s approximative)
    bytes_per_combo = 200  # Dict Python + overhead
    total_mb = (total_combinations * bytes_per_combo) / (1024 * 1024)
    print(f"  ‚âà {total_mb:,.0f} MB juste pour la grille en m√©moire")

    # Temps d'ex√©cution estim√©
    bt_per_sec = 100  # Optimiste avec parall√©lisme
    total_hours = total_combinations / bt_per_sec / 3600
    print(f"  ‚âà {total_hours:,.0f} heures √† 100 bt/s")

    return total_combinations, param_counts

def propose_solutions():
    """Propose des solutions pour r√©duire l'espace de recherche"""

    print("\nüéØ SOLUTIONS RECOMMAND√âES")
    print("=" * 30)

    print("\n1Ô∏è‚É£ R√âDUCTION DRASTIQUE DES PLAGES:")
    print("   bb_period: 15-30 (au lieu de 10-50) ‚Üí 16 valeurs")
    print("   bb_std: 1.8-2.5 step=0.1 ‚Üí 8 valeurs")
    print("   entry_z: 1.5-2.5 step=0.2 ‚Üí 6 valeurs")
    print("   atr_period: 10-20 ‚Üí 11 valeurs")
    print("   atr_percentile: 10-50 step=10 ‚Üí 5 valeurs")
    print("   k_sl: 1.2-2.0 step=0.2 ‚Üí 5 valeurs")
    print("   ‚Üí 16√ó8√ó6√ó11√ó5√ó5 = 211,200 combinaisons (g√©rable !)")

    print("\n2Ô∏è‚É£ UTILISER OPTUNA (OPTIMISATION BAY√âSIENNE):")
    print("   Au lieu de tester TOUTES les combinaisons,")
    print("   Optuna teste intelligemment ~1000-5000 points")
    print("   ‚Üí 1000x plus rapide !")

    print("\n3Ô∏è‚É£ SWEEP S√âQUENTIEL PAR PARAM√àTRE:")
    print("   Fixer 5 param√®tres, optimiser 1 seul")
    print("   Puis fixer le meilleur, optimiser le suivant")
    print("   ‚Üí 41+16+21+15+61+21 = 175 runs seulement")

    print("\n4Ô∏è‚É£ UTILISER MAX_COMBOS LIMITE:")
    print("   L'interface a max_combos=50000 par d√©faut")
    print("   Augmenter √† 100K-500K max pour tests")

def create_reduced_params():
    """Cr√©e des param√®tres r√©duits pour test rapide"""

    print("\nüí° PARAM√àTRES R√âDUITS POUR TEST:")
    print("=" * 35)

    reduced = {
        "bb_period": [15, 20, 25, 30],           # 4 valeurs
        "bb_std": [1.8, 2.0, 2.2, 2.5],         # 4 valeurs
        "entry_z": [1.5, 2.0, 2.5],             # 3 valeurs
        "atr_period": [10, 14, 18],              # 3 valeurs
        "atr_percentile": [20, 30, 40],          # 3 valeurs
        "k_sl": [1.2, 1.5, 2.0],                # 3 valeurs
    }

    total = 1
    for param, values in reduced.items():
        count = len(values)
        total *= count
        print(f"  {param:15} : {values} ‚Üí {count} valeurs")

    print(f"\n  TOTAL R√âDUIT : {total:,} combinaisons")
    print(f"  Temps estim√© : ~{total/100/60:.0f} minutes √† 100 bt/s")

    return reduced

if __name__ == "__main__":
    print("üö® DIAGNOSTIC BOLLINGER ATR SWEEP BLOQU√â")
    print("==========================================")

    total_combos, param_counts = calculate_bollinger_atr_grid_size()

    if total_combos > 1_000_000:
        print("\n‚ùå PROBL√àME D√âTECT√â: Grille trop grande!")
        print("   Le syst√®me se bloque en essayant de g√©n√©rer")
        print("   675 millions de combinaisons en m√©moire.")
        print("   C'est pourquoi √ßa ne d√©marre pas depuis 15min.")

    propose_solutions()
    create_reduced_params()

    print("\nüîß ACTIONS RECOMMAND√âES:")
    print("1. R√©duire les plages de param√®tres")
    print("2. Utiliser Optuna au lieu de Grid Search")
    print("3. Tester sur 1 seul token/timeframe d'abord")
    print("4. Augmenter max_combos si n√©cessaire")
```
<!-- MODULE-END: diagnostic_sweep_blocked.py -->

<!-- MODULE-START: fix_streamlit_config.py -->
```json
{
  "name": "fix_streamlit_config.py",
  "path": "labs\\debug\\fix_streamlit_config.py",
  "ext": ".py",
  "anchor": "fix_streamlit_config_py"
}
```
## fix_streamlit_config_py
*Chemin* : `labs\debug\fix_streamlit_config.py`  
*Type* : `.py`  

```python
import os
import sys
import toml
from pathlib import Path

def fix_global_config():
    """
    Fixes the 'general.email' error in the global Streamlit config.
    """
    home = Path.home()
    global_config_path = home / ".streamlit" / "config.toml"

    print(f"Checking global config at: {global_config_path}")

    if not global_config_path.exists():
        print("Global config not found. No fix needed.")
        return

    try:
        # Read content manually to preserve comments if possible, but TOML lib is safer for structure
        with open(global_config_path, "r", encoding="utf-8") as f:
            content = f.read()

        if "[general]" not in content and "email" not in content:
            print("No 'general.email' found in global config.")
            return

        # Parse with toml
        config = toml.loads(content)

        changed = False
        if "general" in config:
            if "email" in config["general"]:
                print("Found 'general.email'. Removing...")
                del config["general"]["email"]
                changed = True

            # Remove empty [general] section
            if not config["general"]:
                del config["general"]
                changed = True

        if changed:
            with open(global_config_path, "w", encoding="utf-8") as f:
                toml.dump(config, f)
            print("Global config updated successfully!")
        else:
            print("Configuration appeared clean via TOML parser.")

    except Exception as e:
        print(f"Error fixing config: {e}")
        # Fallback: Manual string replacement if TOML lib fails or isn't installed
        try:
            with open(global_config_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            new_lines = []
            skip_section = False
            for line in lines:
                stripped = line.strip()
                if stripped == "[general]":
                    skip_section = True
                    print("Removing [general] section via fallback...")
                    continue
                if skip_section and stripped.startswith("["):
                    skip_section = False

                if skip_section:
                    if stripped.startswith("email"):
                        continue

                new_lines.append(line)

            with open(global_config_path, "w", encoding="utf-8") as f:
                f.writelines(new_lines)
            print("Global config updated via fallback method.")

        except Exception as e2:
            print(f"Fallback failed: {e2}")

if __name__ == "__main__":
    # Ensure toml is installed (it usually is with streamlit)
    try:
        import toml
        fix_global_config()
    except ImportError:
        print("TOML module not found. Attempting fallback...")
        fix_global_config()
```
<!-- MODULE-END: fix_streamlit_config.py -->

<!-- MODULE-START: reproduce_macd_inf.py -->
```json
{
  "name": "reproduce_macd_inf.py",
  "path": "labs\\debug\\reproduce_macd_inf.py",
  "ext": ".py",
  "anchor": "reproduce_macd_inf_py"
}
```
## reproduce_macd_inf_py
*Chemin* : `labs\debug\reproduce_macd_inf.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Test pour reproduire exactement le bug PnL = -inf du sweep MACD
"""

import pandas as pd
import numpy as np
from data.loader import load_ohlcv
from strategies.macd_cross import MACDCrossStrategy
from backtest.engine import BacktestEngine
import itertools

def reproduce_macd_inf_bug():
    """Reproduire le bug PnL = -inf en testant des combinaisons probl√©matiques."""
    print("üîç REPRODUCTION BUG MACD PnL = -inf")
    print("=" * 45)

    # Charger donn√©es
    df = load_ohlcv("BTCUSDC", "30m")
    if df.empty:
        print("‚ùå Pas de donn√©es BTCUSDC/30m")
        return

    # Prendre diff√©rentes tailles d'√©chantillon pour tester
    test_sizes = [50, 100, 200, 500]

    # Param√®tres probl√©matiques potentiels (tir√©s du ParameterSpec de macd_cross)
    fast_periods = [5, 10, 15, 25, 30]  # min_val=5, max_val=30
    slow_periods = [15, 20, 30, 40, 50]  # min_val=15, max_val=50
    signal_periods = [5, 10, 15, 20]      # min_val=5, max_val=20

    print(f"üß™ Test de {len(fast_periods) * len(slow_periods) * len(signal_periods)} combinaisons")

    bug_found = False
    strategy = MACDCrossStrategy()

    for size in test_sizes:
        if bug_found:
            break

        df_test = df.head(size)
        print(f"\nüìä Test avec {size} barres...")

        bug_combos = []

        for fast, slow, signal in itertools.product(fast_periods, slow_periods, signal_periods):
            # V√©rifier contraintes logiques
            if fast >= slow:  # fast doit √™tre < slow
                continue

            params = {
                "fast_period": fast,
                "slow_period": slow,
                "signal_period": signal,
                "leverage": 1
            }

            try:
                engine = BacktestEngine(initial_capital=10000.0)
                result = engine.run(
                    df=df_test,
                    strategy=strategy,
                    params=params,
                    symbol="BTCUSDC",
                    timeframe="30m",
                    silent_mode=True  # √âviter les logs
                )

                pnl = result.metrics.get("total_pnl", 0)

                # V√©rifier si on a trouv√© le bug
                if pnl == float('-inf') or pnl == float('inf') or np.isnan(pnl):
                    print(f"‚ùå BUG TROUV√â! Params: {params}")
                    print(f"   PnL: {pnl}")
                    print(f"   Sharpe: {result.metrics.get('sharpe_ratio', 'N/A')}")
                    print(f"   Trades: {result.metrics.get('total_trades', 'N/A')}")
                    print(f"   Account ruin√©: {result.metrics.get('account_ruined', 'N/A')}")

                    # Analyser l'√©quit√©
                    if hasattr(result, 'equity'):
                        print(f"   √âquit√© min: ${result.equity.min():.2f}")
                        print(f"   √âquit√© max: ${result.equity.max():.2f}")
                        print(f"   √âquit√© finale: ${result.equity.iloc[-1]:.2f}")

                        # Chercher valeurs infinies dans equity
                        inf_count = np.isinf(result.equity).sum()
                        nan_count = np.isnan(result.equity).sum()
                        print(f"   √âquit√© inf: {inf_count}/{len(result.equity)}")
                        print(f"   √âquit√© NaN: {nan_count}/{len(result.equity)}")

                    bug_combos.append(params)
                    bug_found = True

                    if len(bug_combos) >= 3:  # Arr√™ter apr√®s 3 bugs trouv√©s
                        break

            except Exception as e:
                # V√©rifier si l'exception contient "inf"
                if "inf" in str(e).lower():
                    print(f"‚ùå EXCEPTION INF! Params: {params}")
                    print(f"   Erreur: {e}")
                    bug_combos.append(params)
                    bug_found = True

        if bug_combos:
            print(f"\nüéØ {len(bug_combos)} combinaisons probl√©matiques trouv√©es avec {size} barres")
            break

    if not bug_found:
        print("\n‚ö†Ô∏è Bug PnL = -inf non reproduit avec ces param√®tres")
        print("Le probl√®me pourrait venir de:")
        print("- Donn√©es sp√©cifiques √† certains tokens/timeframes")
        print("- Param√®tres encore plus extr√™mes")
        print("- Probl√®me dans le calcul des m√©triques")
        print("- Race conditions en mode parall√®le")

        # Tester avec des param√®tres encore plus extr√™mes
        print("\nüî¨ Test avec param√®tres extr√™mes...")
        extreme_params = [
            {"fast_period": 29, "slow_period": 30, "signal_period": 5},   # Tr√®s proche
            {"fast_period": 5, "slow_period": 50, "signal_period": 20},   # Tr√®s √©cart√©
            {"fast_period": 10, "slow_period": 15, "signal_period": 20},  # Signal > slow
        ]

        for params in extreme_params:
            try:
                engine = BacktestEngine(initial_capital=10000.0)
                result = engine.run(
                    df=df.head(100),
                    strategy=strategy,
                    params=params,
                    symbol="BTCUSDC",
                    timeframe="30m"
                )

                pnl = result.metrics.get("total_pnl", 0)
                print(f"Params {params}: PnL = {pnl}")

            except Exception as e:
                print(f"Params {params}: ERREUR - {e}")

    print("\n‚úÖ Test termin√©")

if __name__ == "__main__":
    reproduce_macd_inf_bug()
```
<!-- MODULE-END: reproduce_macd_inf.py -->

<!-- MODULE-START: bollinger_atr_optimized_ranges.py -->
```json
{
  "name": "bollinger_atr_optimized_ranges.py",
  "path": "labs\\optimization\\bollinger_atr_optimized_ranges.py",
  "ext": ".py",
  "anchor": "bollinger_atr_optimized_ranges_py"
}
```
## bollinger_atr_optimized_ranges_py
*Chemin* : `labs\optimization\bollinger_atr_optimized_ranges.py`  
*Type* : `.py`  

```python
# Code optimis√© pour bollinger_atr parameter_specs
# G√©n√©r√© automatiquement par analyse des r√©sultats

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications optimis√©es bas√©es sur l'analyse des r√©sultats profitables.

        üéØ RANGES OPTIMIS√âS via analyse de donn√©es r√©elles :
        - Analyse de XXX r√©sultats de backtest
        - Focus sur top 25% des r√©sultats par Sharpe ratio
        - R√©duction des combinaisons : 100.0% ({combo_before:,} ‚Üí {combo_after:,})
        - Acc√©l√©ration estim√©e : infx plus rapide
        """
        return {{
            "bb_period": ParameterSpec(
                name="bb_period",
                min_val=29, max_val=29, default=29,  # üéØ Optimis√©: √©tait (10-50)
                param_type="int",
                description="P√©riode des Bandes de Bollinger"
            ),
            "bb_std": ParameterSpec(
                name="bb_std",
                min_val=2.5, max_val=2.5, default=2.5,  # üéØ Optimis√©: √©tait (1.5-3.0)
                param_type="float",
                description="√âcarts-types pour les bandes"
            ),
            "entry_z": ParameterSpec(
                name="entry_z",
                min_val=1.0, max_val=0.2, default=0.6,  # üéØ Optimis√©: √©tait (1.0-3.0)
                param_type="float",
                description="Seuil z-score pour entree"
            ),
            "atr_period": ParameterSpec(
                name="atr_period",
                min_val=14, max_val=14, default=14,  # üéØ Optimis√©: √©tait (7-21)
                param_type="int",
                description="P√©riode de l'ATR"
            ),
            "atr_percentile": ParameterSpec(
                name="atr_percentile",
                min_val=30, max_val=30, default=30,  # üéØ Optimis√©: √©tait (0-60)
                param_type="int",
                description="Percentile volatilite minimum (ATR)"
            ),
            "k_sl": ParameterSpec(
                name="k_sl",
                min_val=1.0, max_val=-0.2, default=0.4,  # üéØ Optimis√©: √©tait (1.0-3.0)
                param_type="float",
                description="Multiplicateur ATR pour stop-loss"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }
```
<!-- MODULE-END: bollinger_atr_optimized_ranges.py -->

<!-- MODULE-START: bollinger_atr_theory_ranges.py -->
```json
{
  "name": "bollinger_atr_theory_ranges.py",
  "path": "labs\\optimization\\bollinger_atr_theory_ranges.py",
  "ext": ".py",
  "anchor": "bollinger_atr_theory_ranges_py"
}
```
## bollinger_atr_theory_ranges_py
*Chemin* : `labs\optimization\bollinger_atr_theory_ranges.py`  
*Type* : `.py`  

```python
# Code th√©orique pour bollinger_atr parameter_specs
# Bas√© sur les standards de l'analyse technique

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications bas√©es sur la th√©orie de l'analyse technique.

        üéì RANGES TH√âORIQUES optimis√©s :
        - Bas√© sur les standards de John Bollinger et Welles Wilder
        - √âvite les valeurs aberrantes des backtests (entry_z<0.5, k_sl n√©gatif)
        - R√©duit l'espace de recherche √† ~6,124,608 combinaisons viables
        - Focus sur les plages utilis√©es par les traders professionnels

        ‚ö†Ô∏è ATTENTION : Les r√©sultats backtests montrent 95.1% d'√©checs.
        Cette strat√©gie n√©cessite peut-√™tre une r√©vision fondamentale de sa logique.
        """
        return {{
            "bb_period": ParameterSpec(
                name="bb_period",
                min_val=15, max_val=35, default=20,  # üéì Th√©orique: John Bollinger recommande 20 p√©riodes comme standard
                param_type="int",
                description="P√©riode des Bandes de Bollinger"
            ),
            "bb_std": ParameterSpec(
                name="bb_std",
                min_val=1.8, max_val=2.5, default=2.0,  # üéì Th√©orique: 2.0 capture ~95% des mouvements, 1.8-2.5 couvre diff√©rents r√©gimes
                param_type="float",
                description="√âcarts-types pour les bandes"
            ),
            "entry_z": ParameterSpec(
                name="entry_z",
                min_val=1.5, max_val=2.2, default=2.0,  # üéì Th√©orique: 1.5-2.2 permet variations autour de la band standard
                param_type="float",
                description="Seuil z-score pour entree"
            ),
            "atr_period": ParameterSpec(
                name="atr_period",
                min_val=10, max_val=21, default=14,  # üéì Th√©orique: 14 p√©riodes recommand√© par Wilder, 10-21 couvre court/moyen terme
                param_type="int",
                description="P√©riode de l'ATR"
            ),
            "atr_percentile": ParameterSpec(
                name="atr_percentile",
                min_val=20, max_val=50, default=30,  # üéì Th√©orique: 20-50 filtre les march√©s trop calmes/agit√©s
                param_type="int",
                description="Percentile volatilite minimum (ATR)"
            ),
            "k_sl": ParameterSpec(
                name="k_sl",
                min_val=1.2, max_val=2.5, default=1.5,  # üéì Th√©orique: 1.2-2.5 ATR couvre diff√©rents styles de gestion du risque
                param_type="float",
                description="Multiplicateur ATR pour stop-loss"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }
```
<!-- MODULE-END: bollinger_atr_theory_ranges.py -->

<!-- MODULE-START: profile_backtest.py -->
```json
{
  "name": "profile_backtest.py",
  "path": "labs\\optimization\\profile_backtest.py",
  "ext": ".py",
  "anchor": "profile_backtest_py"
}
```
## profile_backtest_py
*Chemin* : `labs\optimization\profile_backtest.py`  
*Type* : `.py`  

```python

#!/usr/bin/env python3
"""
Script de profiling complet pour identifier les goulots d'√©tranglement.

Usage:
    python profile_backtest.py                    # Profiling complet
    python profile_backtest.py --quick            # Profiling rapide (1000 barres)
    python profile_backtest.py --detailed         # Profiling ligne par ligne
    python profile_backtest.py --memory           # Profiling m√©moire
"""

import cProfile
import io
import math
import os
import pstats
import sys
import time
from pathlib import Path
from typing import Optional

# Ajouter le r√©pertoire racine au PYTHONPATH
ROOT_DIR = Path(__file__).parent
sys.path.insert(0, str(ROOT_DIR))

import numpy as np
import pandas as pd


def create_test_data(n_bars: int = 10000) -> pd.DataFrame:
    """Cr√©e des donn√©es OHLCV de test."""
    np.random.seed(42)

    # G√©n√©rer un prix avec tendance + bruit
    base_price = 100.0
    returns = np.random.normal(0.0001, 0.02, n_bars)
    prices = base_price * np.exp(np.cumsum(returns))

    # Cr√©er OHLCV
    high = prices * (1 + np.abs(np.random.normal(0, 0.01, n_bars)))
    low = prices * (1 - np.abs(np.random.normal(0, 0.01, n_bars)))
    open_ = prices + np.random.normal(0, 0.5, n_bars)
    volume = np.random.uniform(1000, 10000, n_bars)

    # Index temporel
    dates = pd.date_range(start="2020-01-01", periods=n_bars, freq="1h")

    df = pd.DataFrame({
        "open": open_,
        "high": high,
        "low": low,
        "close": prices,
        "volume": volume,
    }, index=dates)

    return df


def profile_indicators(df: pd.DataFrame, iterations: int = 10) -> dict:
    """Profile tous les indicateurs."""
    from indicators.registry import calculate_indicator

    results = {}
    indicators_to_test = [
        ("bollinger", {"period": 20, "std_dev": 2.0}),
        ("atr", {"period": 14}),
        ("rsi", {"period": 14}),
        ("ema", {"period": 20}),
        ("macd", {"fast_period": 12, "slow_period": 26, "signal_period": 9}),
        ("stochastic", {"k_period": 14, "d_period": 3}),
        ("adx", {"period": 14}),
        ("supertrend", {"period": 10, "multiplier": 3.0}),
        ("vwap", {}),
    ]

    print("\n" + "="*60)
    print("üìä PROFILING INDICATEURS")
    print("="*60)

    for name, params in indicators_to_test:
        try:
            # Warmup
            calculate_indicator(name, df, params)

            # Mesure
            times = []
            for _ in range(iterations):
                start = time.perf_counter()
                calculate_indicator(name, df, params)
                times.append(time.perf_counter() - start)

            avg_time = np.mean(times) * 1000  # ms
            std_time = np.std(times) * 1000

            results[name] = {
                "avg_ms": avg_time,
                "std_ms": std_time,
                "calls_per_sec": 1000 / avg_time if avg_time > 0 else 0,
            }

            speed_icon = "üöÄ" if avg_time < 5 else "‚ö°" if avg_time < 20 else "üê¢"
            print(f"{speed_icon} {name:20s}: {avg_time:8.2f}ms ¬± {std_time:.2f}ms ({results[name]['calls_per_sec']:.0f}/s)")

        except Exception as e:
            print(f"‚ùå {name:20s}: Erreur - {e}")

    return results


def profile_simulator(df: pd.DataFrame, iterations: int = 5) -> dict:
    """Profile le simulateur de trades."""
    from backtest.simulator_fast import simulate_trades_fast, HAS_NUMBA
    from backtest.simulator import simulate_trades

    results = {}

    print("\n" + "="*60)
    print("üéØ PROFILING SIMULATEUR")
    print(f"   Numba: {'‚úÖ Activ√©' if HAS_NUMBA else '‚ùå D√©sactiv√© (LENT!)'}")
    print("="*60)

    # G√©n√©rer des signaux de test
    np.random.seed(42)
    n = len(df)
    signals = np.zeros(n)
    # Cr√©er ~50 trades
    trade_points = np.random.choice(n, size=100, replace=False)
    trade_points.sort()
    for i in range(0, len(trade_points), 2):
        if i + 1 < len(trade_points):
            signals[trade_points[i]] = 1  # Entry
            signals[trade_points[i+1]] = 0  # Exit

    signals_series = pd.Series(signals, index=df.index)

    # Param√®tres pour le simulateur (nouvelle API)
    params = {
        "initial_capital": 10000.0,
        "position_size": 0.1,
        "fees_bps": 10,
        "slippage_bps": 5,
        "k_sl": 0.02,
        "leverage": 1.0,
    }

    # Test simulator_fast
    print("\nüî• simulate_trades_fast (Numba):")
    times_fast = []
    trades_fast = None
    for _ in range(iterations):
        start = time.perf_counter()
        trades_fast = simulate_trades_fast(df=df, signals=signals_series, params=params)
        times_fast.append(time.perf_counter() - start)

    avg_fast = np.mean(times_fast) * 1000
    num_trades_fast = len(trades_fast) if trades_fast is not None else 0
    results["simulator_fast"] = {
        "avg_ms": avg_fast,
        "trades": num_trades_fast,
        "bt_per_sec": 1000 / avg_fast if avg_fast > 0 else 0,
    }
    print(f"   Temps moyen: {avg_fast:.2f}ms ({results['simulator_fast']['bt_per_sec']:.0f} bt/s)")
    print(f"   Trades g√©n√©r√©s: {num_trades_fast}")

    # Test simulator lent (r√©f√©rence)
    print("\nüê¢ simulate_trades (Python pur):")
    times_slow = []
    trades_slow = None
    for _ in range(min(iterations, 2)):  # Moins d'it√©rations car lent
        start = time.perf_counter()
        trades_slow = simulate_trades(df=df, signals=signals_series, params=params)
        times_slow.append(time.perf_counter() - start)

    avg_slow = np.mean(times_slow) * 1000
    num_trades_slow = len(trades_slow) if trades_slow is not None else 0
    results["simulator_slow"] = {
        "avg_ms": avg_slow,
        "trades": num_trades_slow,
        "bt_per_sec": 1000 / avg_slow if avg_slow > 0 else 0,
    }
    print(f"   Temps moyen: {avg_slow:.2f}ms ({results['simulator_slow']['bt_per_sec']:.0f} bt/s)")

    # Ratio d'acc√©l√©ration
    speedup = avg_slow / avg_fast if avg_fast > 0 else 0
    print(f"\nüìà Acc√©l√©ration Numba: {speedup:.1f}x plus rapide")

    return results


def profile_engine(df: pd.DataFrame, iterations: int = 3) -> dict:
    """Profile le moteur de backtest complet."""
    from backtest.engine import BacktestEngine
    from strategies import get_strategy
    from utils.config import Config

    results = {}

    print("\n" + "="*60)
    print("üîß PROFILING MOTEUR COMPLET")
    print("="*60)

    strategies_to_test = ["ema_cross", "rsi_reversal", "macd_cross"]
    config = Config(fees_bps=10, slippage_bps=5)

    for strategy_name in strategies_to_test:
        try:
            strategy_class = get_strategy(strategy_name)
            if strategy_class is None:
                continue

            strategy = strategy_class()  # Instancier la strat√©gie
            engine = BacktestEngine(initial_capital=10000.0, config=config)

            # Warmup
            engine.run(df, strategy, strategy.default_params, fast_metrics=True)

            # Mesure
            times = []
            for _ in range(iterations):
                engine = BacktestEngine(initial_capital=10000.0, config=config)
                start = time.perf_counter()
                result = engine.run(df, strategy, strategy.default_params, fast_metrics=True)
                times.append(time.perf_counter() - start)

            avg_time = np.mean(times) * 1000
            results[strategy_name] = {
                "avg_ms": avg_time,
                "bt_per_sec": 1000 / avg_time if avg_time > 0 else 0,
                "trades": result.metrics.get("total_trades", 0),
            }

            speed_icon = "üöÄ" if avg_time < 100 else "‚ö°" if avg_time < 500 else "üê¢"
            print(f"{speed_icon} {strategy_name:20s}: {avg_time:8.2f}ms ({results[strategy_name]['bt_per_sec']:.1f} bt/s) - {results[strategy_name]['trades']} trades")

        except Exception as e:
            print(f"‚ùå {strategy_name:20s}: Erreur - {e}")

    return results


def profile_sweep_simulation(df: pd.DataFrame, n_combinations: int = 100) -> dict:
    """Simule un mini-sweep pour estimer le temps total."""
    from backtest.engine import BacktestEngine
    from strategies import get_strategy
    from utils.config import Config

    print("\n" + "="*60)
    print(f"üîÑ SIMULATION SWEEP ({n_combinations} combinaisons)")
    print("="*60)

    strategy_class = get_strategy("ema_cross")
    if strategy_class is None:
        print("‚ùå Strat√©gie ema_cross non trouv√©e")
        return {}

    strategy = strategy_class()  # Instancier la strat√©gie
    config = Config(fees_bps=10, slippage_bps=5)

    # G√©n√©rer des combinaisons de param√®tres
    fast_periods = [5, 8, 10, 12, 15]
    slow_periods = [20, 25, 30, 35, 40]

    combinations = []
    for fast in fast_periods:
        for slow in slow_periods:
            if fast < slow:
                combinations.append({"fast_period": fast, "slow_period": slow})

    combinations = combinations[:n_combinations]

    # Mesurer le temps
    start = time.perf_counter()
    completed = 0

    for params in combinations:
        engine = BacktestEngine(initial_capital=10000.0, config=config)
        result = engine.run(df, strategy, params, fast_metrics=True)
        completed += 1

        if completed % 10 == 0:
            elapsed = time.perf_counter() - start
            bt_per_sec = completed / elapsed
            eta = (len(combinations) - completed) / bt_per_sec
            print(f"   {completed}/{len(combinations)} - {bt_per_sec:.1f} bt/s - ETA: {eta:.1f}s")

    total_time = time.perf_counter() - start
    bt_per_sec = len(combinations) / total_time

    print(f"\nüìä R√©sultat:")
    print(f"   Combinaisons: {len(combinations)}")
    print(f"   Temps total: {total_time:.2f}s")
    print(f"   Vitesse: {bt_per_sec:.1f} bt/s")

    # Extrapolation
    print(f"\nüìà Extrapolation:")
    for target in [1000, 10000, 100000, 1000000]:
        est_time = target / bt_per_sec
        if est_time < 60:
            print(f"   {target:>10,} combinaisons: {est_time:.0f}s")
        elif est_time < 3600:
            print(f"   {target:>10,} combinaisons: {est_time/60:.1f}min")
        elif est_time < 86400:
            print(f"   {target:>10,} combinaisons: {est_time/3600:.1f}h")
        else:
            print(f"   {target:>10,} combinaisons: {est_time/86400:.1f}j")

    return {
        "combinations": len(combinations),
        "total_time_s": total_time,
        "bt_per_sec": bt_per_sec,
    }


def profile_grid_sweep(
    df: pd.DataFrame,
    n_combinations: int = 64,
    workers: Optional[int] = None,
    use_processes: bool = True,
) -> dict:
    """Profile un sweep grille r√©el via SweepEngine."""
    from backtest.sweep import SweepEngine
    from strategies import get_strategy

    print("\n" + "="*60)
    print(f"üßÆ PROFILING SWEEP GRILLE (~{n_combinations} combinaisons)")
    print("="*60)

    strategy_class = get_strategy("rsi_reversal")
    if strategy_class is None:
        print("‚ùå Strat√©gie rsi_reversal non trouv√©e")
        return {}

    strategy = strategy_class()
    grid_size = max(1, int(round(math.sqrt(n_combinations))))
    rsi_periods = list(range(10, 10 + grid_size))
    oversold_levels = list(range(20, 20 + grid_size))

    param_grid = {
        "rsi_period": rsi_periods,
        "oversold_level": oversold_levels,
    }

    total_combos = len(rsi_periods) * len(oversold_levels)
    max_workers = workers if workers and workers > 0 else min(4, os.cpu_count() or 4)

    engine = SweepEngine(
        max_workers=max_workers,
        use_processes=use_processes,
        auto_save=False,
    )

    start = time.perf_counter()
    results = engine.run_sweep(
        df=df,
        strategy=strategy,
        param_grid=param_grid,
        show_progress=False,
    )
    elapsed = time.perf_counter() - start
    bt_per_sec = total_combos / elapsed if elapsed > 0 else 0

    print(f"   Mode: {'processes' if use_processes else 'threads'}")
    print(f"   Workers: {max_workers}")
    print(f"   Combinaisons: {total_combos}")
    print(f"   Temps total: {elapsed:.2f}s")
    print(f"   Vitesse: {bt_per_sec:.1f} bt/s")
    print(f"   Completed: {results.n_completed} | Failed: {results.n_failed}")

    return {
        "combinations": total_combos,
        "total_time_s": elapsed,
        "bt_per_sec": bt_per_sec,
        "completed": results.n_completed,
        "failed": results.n_failed,
    }


def detailed_cprofile(df: pd.DataFrame) -> None:
    """Profiling d√©taill√© avec cProfile."""
    from backtest.engine import BacktestEngine
    from strategies.registry import get_strategy

    print("\n" + "="*60)
    print("üî¨ PROFILING D√âTAILL√â (cProfile)")
    print("="*60)

    strategy = get_strategy("ema_cross")

    # Profiler
    profiler = cProfile.Profile()
    profiler.enable()

    # Ex√©cuter 10 backtests
    for _ in range(10):
        engine = BacktestEngine(initial_capital=10000.0, fees_bps=10)
        engine.run(df, strategy, strategy.default_params)

    profiler.disable()

    # Analyser
    stream = io.StringIO()
    stats = pstats.Stats(profiler, stream=stream)
    stats.sort_stats("cumulative")
    stats.print_stats(30)

    print(stream.getvalue())

    # Sauvegarder
    output_file = "profile_results.prof"
    stats.dump_stats(output_file)
    print(f"\nüíæ R√©sultats sauvegard√©s dans {output_file}")
    print("   Visualiser avec: snakeviz profile_results.prof")


def identify_bottlenecks(indicators_results: dict, simulator_results: dict, engine_results: dict) -> None:
    """Identifie les principaux goulots d'√©tranglement."""
    print("\n" + "="*60)
    print("üéØ ANALYSE DES GOULOTS D'√âTRANGLEMENT")
    print("="*60)

    issues = []
    recommendations = []

    # Analyser indicateurs
    slow_indicators = [(name, data) for name, data in indicators_results.items() if data["avg_ms"] > 20]
    if slow_indicators:
        issues.append(f"‚ùå {len(slow_indicators)} indicateur(s) lent(s) (>20ms)")
        for name, data in slow_indicators:
            recommendations.append(f"   ‚Üí {name}: vectoriser avec NumPy ou ajouter @njit")

    # Analyser simulateur
    if simulator_results.get("simulator_fast", {}).get("avg_ms", 0) > 50:
        issues.append("‚ùå Simulateur fast >50ms (devrait √™tre <20ms)")
        recommendations.append("   ‚Üí V√©rifier que Numba compile bien (@njit warmup)")

    # Comparer fast vs slow
    fast = simulator_results.get("simulator_fast", {}).get("avg_ms", 1)
    slow = simulator_results.get("simulator_slow", {}).get("avg_ms", 1)
    speedup = slow / fast if fast > 0 else 0

    if speedup < 10:
        issues.append(f"‚ö†Ô∏è Acc√©l√©ration Numba faible ({speedup:.1f}x, attendu >50x)")
        recommendations.append("   ‚Üí V√©rifier que Numba fonctionne correctement")
        recommendations.append("   ‚Üí pip install numba --upgrade")

    # Analyser moteur complet
    slow_engines = [(name, data) for name, data in engine_results.items() if data.get("avg_ms", 0) > 500]
    if slow_engines:
        issues.append(f"‚ö†Ô∏è {len(slow_engines)} strat√©gie(s) lente(s) (>500ms)")
        for name, data in slow_engines:
            recommendations.append(f"   ‚Üí {name}: optimiser generate_signals()")

    # R√©sum√©
    if issues:
        print("\nüî¥ PROBL√àMES D√âTECT√âS:")
        for issue in issues:
            print(f"   {issue}")

        print("\nüí° RECOMMANDATIONS:")
        for rec in recommendations:
            print(rec)
    else:
        print("\n‚úÖ Aucun goulot d'√©tranglement majeur d√©tect√©!")

    # Performance globale
    avg_bt_per_sec = np.mean([data.get("bt_per_sec", 0) for data in engine_results.values() if data.get("bt_per_sec", 0) > 0])

    print(f"\nüìä PERFORMANCE GLOBALE:")
    print(f"   Vitesse moyenne: {avg_bt_per_sec:.1f} bt/s")

    if avg_bt_per_sec < 10:
        print("   ‚ö†Ô∏è LENT - V√©rifier Numba et vectorisation")
    elif avg_bt_per_sec < 50:
        print("   ‚ö° CORRECT - Am√©liorations possibles")
    else:
        print("   üöÄ RAPIDE - Performance optimale")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Profiling du syst√®me de backtest")
    parser.add_argument("--quick", action="store_true", help="Mode rapide (1000 barres)")
    parser.add_argument("--detailed", action="store_true", help="Profiling cProfile d√©taill√©")
    parser.add_argument("--memory", action="store_true", help="Profiling m√©moire")
    parser.add_argument("--bars", type=int, default=10000, help="Nombre de barres de test")
    parser.add_argument("--grid", action="store_true", help="Profiling sweep grille (SweepEngine)")
    parser.add_argument("--grid-combos", type=int, default=64, help="Nombre approx de combinaisons")
    parser.add_argument("--grid-workers", type=int, default=0, help="Nombre de workers (0=auto)")
    parser.add_argument("--grid-threads", action="store_true", help="Utiliser ThreadPoolExecutor (√©vite fork)")
    args = parser.parse_args()

    n_bars = 1000 if args.quick else args.bars

    print("="*60)
    print("üî¨ PROFILING SYST√àME BACKTEST CORE")
    print("="*60)
    print(f"Barres de test: {n_bars:,}")
    print(f"Mode: {'Rapide' if args.quick else 'Complet'}")

    # Cr√©er donn√©es de test
    print("\nüìä Cr√©ation donn√©es de test...")
    df = create_test_data(n_bars)
    print(f"   DataFrame: {len(df)} barres, {df.memory_usage(deep=True).sum() / 1024:.1f} KB")

    # Profiler les diff√©rentes composantes
    indicators_results = profile_indicators(df)
    simulator_results = profile_simulator(df)
    engine_results = profile_engine(df)

    # Simulation de sweep
    sweep_results = profile_sweep_simulation(df, n_combinations=50)

    # Profiling sweep grille r√©el
    if args.grid:
        profile_grid_sweep(
            df,
            n_combinations=args.grid_combos,
            workers=args.grid_workers if args.grid_workers > 0 else None,
            use_processes=not args.grid_threads,
        )

    # Profiling d√©taill√© si demand√©
    if args.detailed:
        detailed_cprofile(df)

    # Analyse des goulots d'√©tranglement
    identify_bottlenecks(indicators_results, simulator_results, engine_results)

    print("\n" + "="*60)
    print("‚úÖ PROFILING TERMIN√â")
    print("="*60)


if __name__ == "__main__":
    main()
```
<!-- MODULE-END: profile_backtest.py -->

<!-- MODULE-START: quick_ranges_test.py -->
```json
{
  "name": "quick_ranges_test.py",
  "path": "labs\\optimization\\quick_ranges_test.py",
  "ext": ".py",
  "anchor": "quick_ranges_test_py"
}
```
## quick_ranges_test_py
*Chemin* : `labs\optimization\quick_ranges_test.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Test rapide des nouvelles plages th√©oriques bollinger_atr
"""

import pandas as pd
from backtest.engine import BacktestEngine
from strategies.bollinger_atr import BollingerATRStrategy
from utils.config import Config
import time

def load_sample_data():
    """Charge les donn√©es d'exemple"""
    df = pd.read_csv("data/sample_data/ETHUSDT_1m_sample.csv")
    df['datetime'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('datetime')
    return df

def test_new_ranges():
    """Test des nouvelles plages th√©oriques"""

    print(f"üéØ TEST DES NOUVELLES PLAGES TH√âORIQUES")
    print("=" * 50)

    # Test configurations
    test_configs = [
        {
            "name": "Standard Th√©orique",
            "params": {
                "bb_period": 20,
                "bb_std": 2.0,
                "entry_z": 2.0,
                "atr_period": 14,
                "atr_percentile": 30,
                "k_sl": 1.5,
                "leverage": 1
            }
        },
        {
            "name": "Conservateur",
            "params": {
                "bb_period": 25,
                "bb_std": 1.8,
                "entry_z": 2.2,
                "atr_period": 18,
                "atr_percentile": 25,
                "k_sl": 1.2,
                "leverage": 1
            }
        },
        {
            "name": "Agressif",
            "params": {
                "bb_period": 15,
                "bb_std": 2.4,
                "entry_z": 1.6,
                "atr_period": 10,
                "atr_percentile": 45,
                "k_sl": 2.2,
                "leverage": 1
            }
        }
    ]

    # Charger les donn√©es
    df = load_sample_data()
    print(f"üìä Donn√©es charg√©es: {len(df)} barres")

    strategy = BollingerATRStrategy()

    # Utiliser l'initialisation simple
    engine = BacktestEngine(initial_capital=10000)

    results = []

    for test_config in test_configs:
        print(f"\nüî∏ {test_config['name']}:")

        params = test_config['params']
        for key, value in params.items():
            if key != 'leverage':
                print(f"   ‚Ä¢ {key:15} = {value}")

        engine = BacktestEngine(initial_capital=10000)

        try:
            start_time = time.time()
            result = engine.run(
                df=df,
                strategy=strategy,
                params=params,
                symbol="ETHUSDT",
                timeframe="1m",
                silent_mode=True
            )
            duration = time.time() - start_time

            metrics = result.metrics
            pnl = metrics['total_pnl']
            sharpe = metrics['sharpe_ratio']
            trades = metrics.get('total_trades', 0)
            win_rate = metrics.get('win_rate_pct', 0)
            ruined = metrics.get('account_ruined', False)
            max_dd = metrics.get('max_drawdown_pct', 0)

            print(f"   üìä PnL: ${pnl:.2f} | Sharpe: {sharpe:.2f} | Trades: {trades}")
            print(f"   üìà Win Rate: {win_rate:.1f}% | Max DD: {max_dd:.1f}% | Ruined: {ruined}")
            print(f"   ‚è±Ô∏è Dur√©e: {duration:.2f}s")

            results.append({
                'name': test_config['name'],
                'pnl': pnl,
                'sharpe': sharpe,
                'trades': trades,
                'win_rate': win_rate,
                'ruined': ruined,
                'max_dd': max_dd
            })

        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
            results.append({
                'name': test_config['name'],
                'pnl': float('-inf'),
                'sharpe': float('-inf'),
                'trades': 0,
                'win_rate': 0,
                'ruined': True,
                'max_dd': 100
            })

    # R√©sum√© comparatif
    print(f"\nüîç R√âSUM√â COMPARATIF:")
    print("=" * 70)
    print(f"{'Config':<20} {'PnL':<12} {'Sharpe':<8} {'Trades':<7} {'Win%':<6} {'DD%':<6} {'Ruined'}")
    print("-" * 70)

    best_pnl = float('-inf')
    best_config = ""

    for result in results:
        ruined_mark = "‚ùå" if result['ruined'] else "‚úÖ"
        print(f"{result['name']:<20} ${result['pnl']:>8.2f} {result['sharpe']:>6.2f}  {result['trades']:>5d}   {result['win_rate']:>4.1f}% {result['max_dd']:>5.1f}%   {ruined_mark}")

        if result['pnl'] > best_pnl:
            best_pnl = result['pnl']
            best_config = result['name']

    print("-" * 70)

    # Analyse
    negative_count = sum(1 for r in results if r['pnl'] < 0)
    ruined_count = sum(1 for r in results if r['ruined'])

    print(f"\nüí° ANALYSE:")
    print(f"   ‚Ä¢ Meilleur r√©sultat  : {best_config} (${best_pnl:.2f})")
    print(f"   ‚Ä¢ R√©sultats n√©gatifs : {negative_count}/{len(results)} ({negative_count/len(results)*100:.1f}%)")
    print(f"   ‚Ä¢ Comptes ruin√©s     : {ruined_count}/{len(results)} ({ruined_count/len(results)*100:.1f}%)")

    if negative_count == len(results):
        print(f"   ‚ö†Ô∏è PROBL√àME: Toutes les configurations sont n√©gatives")
        print(f"   üîß RECOMMANDATION: R√©viser la logique de la strat√©gie")
    elif ruined_count > len(results) / 2:
        print(f"   ‚ö†Ô∏è PROBL√àME: Trop de comptes ruin√©s")
        print(f"   üîß RECOMMANDATION: R√©viser la gestion du risque")
    elif best_pnl > 0:
        print(f"   ‚úÖ POSITIF: Au moins une configuration profitable")
        print(f"   üéØ RECOMMANDATION: Focus sur les param√®tres du meilleur r√©sultat")
    else:
        print(f"   ‚ö†Ô∏è NEUTRE: Aucun r√©sultat vraiment positif")
        print(f"   üîß RECOMMANDATION: Ajuster les plages ou revoir la strat√©gie")

if __name__ == "__main__":
    test_new_ranges()
```
<!-- MODULE-END: quick_ranges_test.py -->

<!-- MODULE-START: validate_rsi_reversal.py -->
```json
{
  "name": "validate_rsi_reversal.py",
  "path": "labs\\optimization\\validate_rsi_reversal.py",
  "ext": ".py",
  "anchor": "validate_rsi_reversal_py"
}
```
## validate_rsi_reversal_py
*Chemin* : `labs\optimization\validate_rsi_reversal.py`  
*Type* : `.py`  

```python
#!/usr/bin/env python3
"""
Script de validation de la strat√©gie RSI Reversal.
Reproduit le bug de m√©trique Sharpe=87.89 avec account_ruined=true.
"""

import pandas as pd
import numpy as np
from backtest.engine import BacktestEngine
from strategies.base import get_strategy
from data.loader import load_ohlcv

def test_rsi_reversal_bug():
    """Teste la strat√©gie RSI reversal avec les param√®tres suspects."""
    print("üîç VALIDATION RSI REVERSAL - Reproduction Bug Sharpe")
    print("=" * 60)

    # Param√®tres suspects du metadata.json
    params = {
        "rsi_period": 17,
        "oversold_level": 34,
        "overbought_level": 90,
        "leverage": 1  # Verrouill√© √† 1
    }

    # Charger donn√©es Bitcoin 1h (du metadata original)
    try:
        df = load_ohlcv("BTCUSDC", "1h")
        if df.empty:
            print("‚ùå Pas de donn√©es BTCUSDC 1h disponibles")
            return

        print(f"üìä Donn√©es: {len(df)} barres, {df.index[0]} -> {df.index[-1]}")

        # Filtrer m√™me p√©riode que le metadata si possible
        # Ou prendre 1 an r√©cent
        if len(df) > 8760:  # Plus d'un an
            df = df.tail(8760)  # Derni√®re ann√©e

    except Exception as e:
        print(f"‚ùå Erreur chargement donn√©es: {e}")
        return

    # Cr√©er engine et strat√©gie
    engine = BacktestEngine(initial_capital=10000.0)

    # Instancier la strat√©gie directement
    try:
        from strategies.rsi_reversal import RSIReversalStrategy
        strategy = RSIReversalStrategy()
    except ImportError:
        print("‚ùå Impossible d'importer RSIReversalStrategy")
        return

    print(f"üìà Strat√©gie: {strategy.__class__.__name__}")
    print(f"‚öôÔ∏è  Param√®tres: {params}")

    # Ex√©cuter backtest
    print("\nüöÄ Ex√©cution backtest...")
    try:
        result = engine.run(
            df=df,
            strategy=strategy,
            params=params,
            symbol="BTCUSDC",
            timeframe="1h"
        )

        print("\nüìä R√âSULTATS")
        print("=" * 30)
        print(f"Total P&L: ${result.metrics.get('total_pnl', 0):,.2f}")
        print(f"Sharpe Ratio: {result.metrics.get('sharpe_ratio', 0):.2f}")
        print(f"Sortino Ratio: {result.metrics.get('sortino_ratio', 0):.2f}")
        print(f"Max Drawdown: {result.metrics.get('max_drawdown', 0):.1f}%")
        print(f"Win Rate: {result.metrics.get('win_rate', 0):.1f}%")
        print(f"Total Trades: {result.metrics.get('total_trades', 0)}")
        print(f"Account Ruined: {result.metrics.get('account_ruined', False)}")

        # V√©rifier incoh√©rences
        account_ruined = result.metrics.get('account_ruined', False)
        sharpe = result.metrics.get('sharpe_ratio', 0)
        pnl = result.metrics.get('total_pnl', 0)

        print(f"\nüîç DIAGNOSTIC BUG")
        print("=" * 30)

        if account_ruined and sharpe > 10:
            print("‚ùå BUG D√âTECT√â: Account ruin√© mais Sharpe √©lev√©")
            print(f"   Sharpe: {sharpe:.2f} (suspect si >10 avec ruine)")

        if account_ruined and pnl > 0:
            print("‚ö†Ô∏è  INCOH√âRENCE: Account ruin√© mais PnL positif")
            print("   Cela peut arriver si recovery apr√®s ruine")

        if abs(sharpe) > 20:
            print("‚ùå BUG MAX_SHARPE: Sharpe d√©passe limite ¬±20")

        # Analyser √©quit√©
        min_equity = result.equity.min()
        print(f"\nüí∞ ANALYSE √âQUIT√â")
        print("=" * 30)
        print(f"√âquit√© initiale: ${engine.initial_capital:,.2f}")
        print(f"√âquit√© finale: ${result.equity.iloc[-1]:,.2f}")
        print(f"√âquit√© minimale: ${min_equity:,.2f}")

        if min_equity <= 0:
            print(f"üíÄ RUINE CONFIRM√âE: √âquit√© minimale = ${min_equity:,.2f}")
            ruine_date = result.equity[result.equity <= 0].index[0] if (result.equity <= 0).any() else None
            if ruine_date:
                print(f"üìÖ Date de ruine: {ruine_date}")

        # Analyser trades suspects
        n_trades = len(result.trades)
        if n_trades > 0:
            avg_pnl_per_trade = result.trades['net_pnl'].mean() if 'net_pnl' in result.trades.columns else 0
            print(f"\nüìã ANALYSE TRADES")
            print("=" * 30)
            print(f"Nombre trades: {n_trades}")
            print(f"PnL moyen/trade: ${avg_pnl_per_trade:,.2f}")

            if 'net_pnl' in result.trades.columns:
                win_trades = result.trades[result.trades['net_pnl'] > 0]
                loss_trades = result.trades[result.trades['net_pnl'] <= 0]
                print(f"Trades gagnants: {len(win_trades)}")
                print(f"Trades perdants: {len(loss_trades)}")

                if len(win_trades) > 0:
                    max_win = win_trades['net_pnl'].max()
                    print(f"Plus gros gain: ${max_win:,.2f}")

                if len(loss_trades) > 0:
                    max_loss = loss_trades['net_pnl'].min()
                    print(f"Plus grosse perte: ${max_loss:,.2f}")

        print(f"\n‚úÖ Validation termin√©e")
        print(f"üîß Correctifs appliqu√©s dans engine.py et performance.py")

    except Exception as e:
        print(f"‚ùå Erreur ex√©cution: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_rsi_reversal_bug()
```
<!-- MODULE-END: validate_rsi_reversal.py -->

<!-- MODULE-START: benchmark.py -->
```json
{
  "name": "benchmark.py",
  "path": "performance\\benchmark.py",
  "ext": ".py",
  "anchor": "benchmark_py"
}
```
## benchmark_py
*Chemin* : `performance\benchmark.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.benchmark

Purpose: Suite benchmarks - compare impl√©mentations (vectoris√©, Numba, GPU).

Role in pipeline: performance testing

Key components: Benchmark, BenchmarkResult, @timeit, run_suite(), compare()

Inputs: Callable function/method, test data, iterations

Outputs: BenchmarkResult {duration_ms, memory_mb, throughput_items/s}

Dependencies: time, numpy, pandas, dataclasses

Conventions: CSV export; statistical analysis (min/max/mean); outlier removal.

Read-if: Modification benchmark methodology ou metrics.

Skip-if: Vous appelez Benchmark().run() ou compare_functions().
"""

from __future__ import annotations

import time
from contextlib import contextmanager
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional

import numpy as np
import pandas as pd

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class BenchmarkResult:
    """R√©sultat d'un benchmark."""
    name: str
    duration_ms: float
    memory_mb: float
    throughput_items_per_sec: float
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __str__(self) -> str:
        return (
            f"{self.name:30s} | "
            f"{self.duration_ms:8.2f} ms | "
            f"{self.memory_mb:7.1f} MB | "
            f"{self.throughput_items_per_sec:10,.0f} items/s"
        )


@dataclass
class BenchmarkComparison:
    """Comparaison de plusieurs benchmarks."""
    results: List[BenchmarkResult]
    baseline_name: Optional[str] = None

    def summary(self) -> str:
        """G√©n√®re un r√©sum√© comparatif."""
        if not self.results:
            return "Aucun r√©sultat"

        # Trier par dur√©e
        sorted_results = sorted(self.results, key=lambda r: r.duration_ms)
        baseline = self._get_baseline()

        lines = []
        lines.append("=" * 90)
        lines.append("BENCHMARK RESULTS")
        lines.append("=" * 90)
        lines.append(
            f"{'Name':<30} | {'Time (ms)':>8} | {'Memory':>7} | {'Throughput':>10} | {'Speedup':>8}"
        )
        lines.append("-" * 90)

        for result in sorted_results:
            speedup = baseline.duration_ms / result.duration_ms if baseline else 1.0
            speedup_str = f"{speedup:7.2f}x" if speedup != 1.0 else "baseline"
            lines.append(f"{result} | {speedup_str:>8}")

        lines.append("=" * 90)

        # Winner
        winner = sorted_results[0]
        if baseline and winner.name != baseline.name:
            improvement = (baseline.duration_ms - winner.duration_ms) / baseline.duration_ms * 100
            lines.append(f"\nüèÜ Winner: {winner.name}")
            lines.append(f"   {improvement:.1f}% faster than baseline")

        return "\n".join(lines)

    def _get_baseline(self) -> Optional[BenchmarkResult]:
        """Retourne le r√©sultat baseline."""
        if self.baseline_name:
            for result in self.results:
                if result.name == self.baseline_name:
                    return result
        return self.results[0] if self.results else None


@contextmanager
def timer():
    """Context manager pour mesurer le temps d'ex√©cution."""
    start = time.perf_counter()
    yield lambda: (time.perf_counter() - start) * 1000  # ms


def get_memory_usage() -> float:
    """Retourne l'utilisation m√©moire actuelle en MB."""
    try:
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / (1024 ** 2)
    except ImportError:
        return 0.0


def benchmark_function(
    func: Callable,
    *args,
    name: str = None,
    n_items: int = None,
    warmup_runs: int = 2,
    benchmark_runs: int = 5,
    **kwargs
) -> BenchmarkResult:
    """
    Benchmark une fonction.

    Args:
        func: Fonction √† benchmarker
        *args: Arguments positionnels
        name: Nom du benchmark
        n_items: Nombre d'items trait√©s (pour throughput)
        warmup_runs: Nombre de runs de warm-up
        benchmark_runs: Nombre de runs de benchmark
        **kwargs: Arguments nomm√©s

    Returns:
        BenchmarkResult
    """
    func_name = name or func.__name__

    # Warm-up
    for _ in range(warmup_runs):
        func(*args, **kwargs)

    # Benchmark
    durations = []
    mem_before = get_memory_usage()

    for _ in range(benchmark_runs):
        with timer() as get_time:
            func(*args, **kwargs)
        durations.append(get_time())

    mem_after = get_memory_usage()

    # Stats
    avg_duration = np.mean(durations)
    memory_used = max(0, mem_after - mem_before)

    throughput = 0.0
    if n_items and avg_duration > 0:
        throughput = (n_items * 1000) / avg_duration  # items per second

    return BenchmarkResult(
        name=func_name,
        duration_ms=avg_duration,
        memory_mb=memory_used,
        throughput_items_per_sec=throughput,
        metadata={
            "runs": benchmark_runs,
            "std_ms": np.std(durations),
            "min_ms": np.min(durations),
            "max_ms": np.max(durations),
        }
    )


# =============================================================================
# BENCHMARKS SP√âCIFIQUES
# =============================================================================

def benchmark_indicator_calculation(
    data_size: int = 10000,
    period: int = 20
) -> BenchmarkComparison:
    """
    Benchmark le calcul d'indicateurs techniques.

    Compare:
    - Calcul natif pandas
    - Calcul NumPy vectoris√©
    - Calcul avec Numba (si disponible)
    """
    # Donn√©es de test
    np.random.seed(42)
    prices = 100 + np.cumsum(np.random.randn(data_size) * 0.5)
    prices_series = pd.Series(prices)

    results = []

    # 1. Pandas rolling
    def pandas_sma():
        return prices_series.rolling(window=period).mean().values

    results.append(benchmark_function(
        pandas_sma,
        name="Pandas Rolling SMA",
        n_items=data_size
    ))

    # 2. NumPy convolve
    def numpy_convolve():
        kernel = np.ones(period) / period
        return np.convolve(prices, kernel, mode='same')

    results.append(benchmark_function(
        numpy_convolve,
        name="NumPy Convolve SMA",
        n_items=data_size
    ))

    # 3. Numba (si disponible)
    try:
        from numba import njit

        @njit(cache=True)
        def numba_sma(prices, period):
            n = len(prices)
            result = np.empty(n)
            result[:period-1] = np.nan

            for i in range(period-1, n):
                result[i] = np.mean(prices[i-period+1:i+1])

            return result

        # Warm-up compilation
        _ = numba_sma(prices, period)

        results.append(benchmark_function(
            lambda: numba_sma(prices, period),
            name="Numba JIT SMA",
            n_items=data_size
        ))
    except ImportError:
        logger.warning("Numba non disponible pour benchmark")

    return BenchmarkComparison(results, baseline_name="Pandas Rolling SMA")


def benchmark_simulator_performance(
    n_bars: int = 10000,
    n_signals: int = 500
) -> BenchmarkComparison:
    """
    Benchmark la simulation de trades.

    Compare:
    - Simulateur Python pur (simulator.py)
    - Simulateur Numba (simulator_fast.py)
    """
    from backtest.simulator import simulate_trades

    # Donn√©es de test
    np.random.seed(42)
    dates = pd.date_range("2020-01-01", periods=n_bars, freq="1h")
    close = 100 + np.cumsum(np.random.randn(n_bars) * 0.5)

    df = pd.DataFrame({
        "timestamp": dates,
        "open": close,
        "high": close * 1.01,
        "low": close * 0.99,
        "close": close,
        "volume": np.random.randint(1000, 10000, n_bars)
    }).set_index("timestamp")

    # Signaux al√©atoires
    signals = pd.Series(np.random.choice([0, 1, -1], size=n_bars, p=[0.95, 0.025, 0.025]), index=df.index)

    params = {
        "leverage": 1,
        "k_sl": 1.5,
        "initial_capital": 10000,
        "fees_bps": 10,
        "slippage_bps": 5
    }

    results = []

    # 1. Simulateur standard
    results.append(benchmark_function(
        simulate_trades,
        df, signals, params,
        name="Simulator (Python)",
        n_items=n_bars,
        benchmark_runs=3
    ))

    # 2. Simulateur Numba (si disponible)
    try:
        from backtest.simulator_fast import HAS_NUMBA, simulate_trades_fast

        if HAS_NUMBA:
            results.append(benchmark_function(
                simulate_trades_fast,
                df, signals, params,
                name="Simulator (Numba JIT)",
                n_items=n_bars,
                benchmark_runs=3
            ))
    except ImportError:
        logger.warning("simulator_fast non disponible")

    return BenchmarkComparison(results, baseline_name="Simulator (Python)")


def benchmark_gpu_vs_cpu(
    data_size: int = 100000
) -> BenchmarkComparison:
    """
    Benchmark calculs GPU vs CPU.

    Requiert CuPy pour GPU.
    """
    from performance.device_backend import ArrayBackend

    backend = ArrayBackend()
    results = []

    # Donn√©es de test
    np.random.seed(42)
    data = np.random.randn(data_size)

    # 1. CPU (NumPy)
    def numpy_operations():
        x = np.array(data)
        y = np.sqrt(np.abs(x))
        z = np.exp(-y ** 2)
        return np.sum(z)

    results.append(benchmark_function(
        numpy_operations,
        name="NumPy (CPU)",
        n_items=data_size
    ))

    # 2. GPU (CuPy) si disponible
    if backend.gpu_available:
        try:
            import cupy as cp

            # Transf√©rer donn√©es vers GPU
            data_gpu = cp.array(data)

            def cupy_operations():
                x = data_gpu
                y = cp.sqrt(cp.abs(x))
                z = cp.exp(-y ** 2)
                result = cp.sum(z)
                cp.cuda.Device().synchronize()
                return float(result)

            results.append(benchmark_function(
                cupy_operations,
                name="CuPy (GPU)",
                n_items=data_size
            ))
        except ImportError:
            logger.warning("CuPy non disponible")

    return BenchmarkComparison(results, baseline_name="NumPy (CPU)")


def run_all_benchmarks(verbose: bool = True) -> Dict[str, BenchmarkComparison]:
    """
    Ex√©cute tous les benchmarks.

    Args:
        verbose: Afficher les r√©sultats

    Returns:
        Dict des comparaisons par cat√©gorie
    """
    benchmarks = {}

    logger.info("=" * 80)
    logger.info("D√âMARRAGE SUITE DE BENCHMARKS")
    logger.info("=" * 80)

    # 1. Indicateurs
    logger.info("\n[1/3] Benchmark Indicateurs...")
    benchmarks["indicators"] = benchmark_indicator_calculation()
    if verbose:
        print(benchmarks["indicators"].summary())

    # 2. Simulateur
    logger.info("\n[2/3] Benchmark Simulateur...")
    benchmarks["simulator"] = benchmark_simulator_performance()
    if verbose:
        print(benchmarks["simulator"].summary())

    # 3. GPU vs CPU
    logger.info("\n[3/3] Benchmark GPU vs CPU...")
    benchmarks["gpu"] = benchmark_gpu_vs_cpu()
    if verbose:
        print(benchmarks["gpu"].summary())

    logger.info("\n" + "=" * 80)
    logger.info("BENCHMARKS TERMIN√âS")
    logger.info("=" * 80)

    return benchmarks


# =============================================================================
# CLI
# =============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Ex√©cuter les benchmarks de performance")
    parser.add_argument(
        "--category",
        choices=["indicators", "simulator", "gpu", "all"],
        default="all",
        help="Cat√©gorie de benchmark √† ex√©cuter"
    )
    parser.add_argument(
        "--size",
        type=int,
        default=10000,
        help="Taille des donn√©es de test"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Mode silencieux (pas d'affichage)"
    )

    args = parser.parse_args()

    if args.category == "all":
        run_all_benchmarks(verbose=not args.quiet)
    elif args.category == "indicators":
        comp = benchmark_indicator_calculation(data_size=args.size)
        if not args.quiet:
            print(comp.summary())
    elif args.category == "simulator":
        comp = benchmark_simulator_performance(n_bars=args.size)
        if not args.quiet:
            print(comp.summary())
    elif args.category == "gpu":
        comp = benchmark_gpu_vs_cpu(data_size=args.size)
        if not args.quiet:
            print(comp.summary())
```
<!-- MODULE-END: benchmark.py -->

<!-- MODULE-START: device_backend.py -->
```json
{
  "name": "device_backend.py",
  "path": "performance\\device_backend.py",
  "ext": ".py",
  "anchor": "device_backend_py"
}
```
## device_backend_py
*Chemin* : `performance\device_backend.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.device_backend

Purpose: Backend abstrait NumPy‚ÜîCuPy - basculement transparent CPU/GPU.

Role in pipeline: performance optimization

Key components: ArrayBackend, DeviceType enum, DeviceInfo, gpu_context()

Inputs: NumPy/CuPy array, device_type (CPU/GPU/AUTO)

Outputs: Operations via unified API (solve, dot, reduce, etc.)

Dependencies: numpy, cupy (optionnel), contextmanager

Conventions: AUTO d√©tecte GPU; fallback CPU; memory pooling GPU.

Read-if: Modification device switching ou operation dispatch.

Skip-if: Vous appelez backend = ArrayBackend.create() ‚Üí backend.dot().
"""

from __future__ import annotations

import logging
import os
from contextlib import contextmanager
from dataclasses import dataclass
from enum import Enum
from typing import Any, Optional, Tuple

import numpy as np

logger = logging.getLogger(__name__)


class DeviceType(Enum):
    """Type de device pour les calculs."""
    CPU = "cpu"
    GPU = "gpu"
    AUTO = "auto"


@dataclass
class DeviceInfo:
    """Informations sur un device."""
    device_type: DeviceType
    name: str
    memory_total: Optional[int] = None  # En bytes
    memory_free: Optional[int] = None
    compute_capability: Optional[Tuple[int, int]] = None

    def __str__(self) -> str:
        if self.device_type == DeviceType.CPU:
            return f"CPU: {self.name}"
        mem_gb = (self.memory_total or 0) / (1024**3)
        return f"GPU: {self.name} ({mem_gb:.1f} GB)"


class ArrayBackend:
    """
    Backend abstrait pour calculs sur arrays.

    Fournit une API unifi√©e compatible NumPy/CuPy.
    """

    _instance: Optional["ArrayBackend"] = None
    _initialized: bool = False

    def __new__(cls) -> "ArrayBackend":
        """Singleton pattern."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialise le backend."""
        if self._initialized:
            return

        self._device_type = DeviceType.CPU
        self._np = np  # Module numpy ou cupy
        self._gpu_available = False
        self._device_info: Optional[DeviceInfo] = None

        # Tenter d'initialiser CuPy
        self._try_init_gpu()
        self._initialized = True

    def _try_init_gpu(self) -> bool:
        """Tente d'initialiser le support GPU."""
        # V√©rifier si d√©sactiv√© par env var
        if os.environ.get("BACKTEST_DISABLE_GPU", "").lower() in ("1", "true", "yes"):
            logger.info("GPU d√©sactiv√© par BACKTEST_DISABLE_GPU")
            self._setup_cpu()
            return False

        try:
            import cupy as cp

            # V√©rifier qu'un GPU est disponible
            device = cp.cuda.Device(0)
            device.use()

            # R√©cup√©rer infos
            props = cp.cuda.runtime.getDeviceProperties(0)
            mem_info = device.mem_info

            self._gpu_available = True
            self._device_info = DeviceInfo(
                device_type=DeviceType.GPU,
                name=props["name"].decode() if isinstance(props["name"], bytes) else str(props["name"]),
                memory_total=mem_info[1],
                memory_free=mem_info[0],
                compute_capability=(props["major"], props["minor"]),
            )

            logger.info(f"GPU disponible: {self._device_info}")
            return True

        except ImportError:
            logger.debug("CuPy non install√©, utilisation CPU")
            self._setup_cpu()
            return False

        except Exception as e:
            logger.warning(f"Impossible d'initialiser GPU: {e}")
            self._setup_cpu()
            return False

    def _setup_cpu(self):
        """Configure le backend CPU."""
        import platform

        self._device_info = DeviceInfo(
            device_type=DeviceType.CPU,
            name=platform.processor() or "Unknown CPU",
        )

    @property
    def device_type(self) -> DeviceType:
        """Retourne le type de device actuel."""
        return self._device_type

    @property
    def device_info(self) -> DeviceInfo:
        """Retourne les infos du device."""
        return self._device_info

    @property
    def gpu_available(self) -> bool:
        """Indique si un GPU est disponible."""
        return self._gpu_available

    @property
    def xp(self):
        """
        Retourne le module array (numpy ou cupy).

        Utilisez comme: backend.xp.array([1,2,3])
        """
        return self._np

    def use_device(self, device: DeviceType) -> bool:
        """
        Change le device actif.

        Args:
            device: Type de device souhait√©

        Returns:
            True si le changement a r√©ussi
        """
        if device == DeviceType.AUTO:
            device = DeviceType.GPU if self._gpu_available else DeviceType.CPU

        if device == DeviceType.GPU:
            if not self._gpu_available:
                logger.warning("GPU non disponible, utilisation CPU")
                device = DeviceType.CPU
            else:
                import cupy as cp
                self._np = cp
                self._device_type = DeviceType.GPU
                return True

        self._np = np
        self._device_type = DeviceType.CPU
        return True

    @contextmanager
    def device_context(self, device: DeviceType):
        """
        Context manager pour changer temporairement de device.

        Example:
            >>> with backend.device_context(DeviceType.GPU):
            >>>     result = backend.xp.sum(data)
        """
        old_device = self._device_type
        old_np = self._np

        try:
            self.use_device(device)
            yield
        finally:
            self._device_type = old_device
            self._np = old_np

    # === Array Operations ===

    def array(self, data, dtype=None) -> Any:
        """Cr√©e un array sur le device actif."""
        return self._np.array(data, dtype=dtype)

    def zeros(self, shape, dtype=None) -> Any:
        """Cr√©e un array de z√©ros."""
        return self._np.zeros(shape, dtype=dtype)

    def ones(self, shape, dtype=None) -> Any:
        """Cr√©e un array de uns."""
        return self._np.ones(shape, dtype=dtype)

    def empty(self, shape, dtype=None) -> Any:
        """Cr√©e un array non initialis√©."""
        return self._np.empty(shape, dtype=dtype)

    def arange(self, *args, **kwargs) -> Any:
        """Cr√©e une s√©quence."""
        return self._np.arange(*args, **kwargs)

    def linspace(self, *args, **kwargs) -> Any:
        """Cr√©e un espace lin√©aire."""
        return self._np.linspace(*args, **kwargs)

    # === Math Operations ===

    def sum(self, a, axis=None, **kwargs) -> Any:
        """Somme."""
        return self._np.sum(a, axis=axis, **kwargs)

    def mean(self, a, axis=None, **kwargs) -> Any:
        """Moyenne."""
        return self._np.mean(a, axis=axis, **kwargs)

    def std(self, a, axis=None, **kwargs) -> Any:
        """√âcart-type."""
        return self._np.std(a, axis=axis, **kwargs)

    def var(self, a, axis=None, **kwargs) -> Any:
        """Variance."""
        return self._np.var(a, axis=axis, **kwargs)

    def min(self, a, axis=None, **kwargs) -> Any:
        """Minimum."""
        return self._np.min(a, axis=axis, **kwargs)

    def max(self, a, axis=None, **kwargs) -> Any:
        """Maximum."""
        return self._np.max(a, axis=axis, **kwargs)

    def sqrt(self, x) -> Any:
        """Racine carr√©e."""
        return self._np.sqrt(x)

    def exp(self, x) -> Any:
        """Exponentielle."""
        return self._np.exp(x)

    def log(self, x) -> Any:
        """Logarithme naturel."""
        return self._np.log(x)

    def abs(self, x) -> Any:
        """Valeur absolue."""
        return self._np.abs(x)

    def clip(self, a, a_min, a_max) -> Any:
        """Clip values."""
        return self._np.clip(a, a_min, a_max)

    def diff(self, a, n=1, axis=-1) -> Any:
        """Diff√©rences."""
        return self._np.diff(a, n=n, axis=axis)

    def cumsum(self, a, axis=None) -> Any:
        """Somme cumulative."""
        return self._np.cumsum(a, axis=axis)

    def cumprod(self, a, axis=None) -> Any:
        """Produit cumulatif."""
        return self._np.cumprod(a, axis=axis)

    # === Comparison Operations ===

    def where(self, condition, x, y) -> Any:
        """Where conditionnel."""
        return self._np.where(condition, x, y)

    def argmax(self, a, axis=None) -> Any:
        """Index du maximum."""
        return self._np.argmax(a, axis=axis)

    def argmin(self, a, axis=None) -> Any:
        """Index du minimum."""
        return self._np.argmin(a, axis=axis)

    def maximum(self, x1, x2) -> Any:
        """Maximum element-wise."""
        return self._np.maximum(x1, x2)

    def minimum(self, x1, x2) -> Any:
        """Minimum element-wise."""
        return self._np.minimum(x1, x2)

    # === Rolling Operations ===

    def rolling_mean(self, data: Any, window: int) -> Any:
        """
        Moyenne mobile.

        Note: Cette op√©ration est optimis√©e pour GPU via convolution.
        """
        if len(data) < window:
            return self._np.full(len(data), self._np.nan)

        # Utiliser convolve pour efficacit√©
        kernel = self._np.ones(window) / window
        result = self._np.convolve(data, kernel, mode='full')[:len(data)]
        result[:window-1] = self._np.nan

        return result

    def rolling_std(self, data: Any, window: int) -> Any:
        """
        √âcart-type mobile.
        """
        n = len(data)
        if n < window:
            return self._np.full(n, self._np.nan)

        result = self._np.empty(n)
        result[:window-1] = self._np.nan

        for i in range(window - 1, n):
            result[i] = self._np.std(data[i-window+1:i+1])

        return result

    def rolling_max(self, data: Any, window: int) -> Any:
        """Maximum mobile."""
        n = len(data)
        if n < window:
            return self._np.full(n, self._np.nan)

        result = self._np.empty(n)
        result[:window-1] = self._np.nan

        for i in range(window - 1, n):
            result[i] = self._np.max(data[i-window+1:i+1])

        return result

    def rolling_min(self, data: Any, window: int) -> Any:
        """Minimum mobile."""
        n = len(data)
        if n < window:
            return self._np.full(n, self._np.nan)

        result = self._np.empty(n)
        result[:window-1] = self._np.nan

        for i in range(window - 1, n):
            result[i] = self._np.min(data[i-window+1:i+1])

        return result

    # === Conversion ===

    def to_numpy(self, arr) -> np.ndarray:
        """Convertit en numpy array (depuis GPU si n√©cessaire)."""
        if self._device_type == DeviceType.GPU:
            import cupy as cp
            if isinstance(arr, cp.ndarray):
                return cp.asnumpy(arr)
        return np.asarray(arr)

    def from_numpy(self, arr: np.ndarray) -> Any:
        """Convertit numpy vers device actif."""
        if self._device_type == DeviceType.GPU:
            import cupy as cp
            return cp.asarray(arr)
        return arr

    # === Memory Management ===

    def memory_info(self) -> dict:
        """Retourne les infos m√©moire du device."""
        if self._device_type == DeviceType.GPU:
            import cupy as cp
            mem = cp.cuda.Device(0).mem_info
            return {
                "device": "GPU",
                "free": mem[0],
                "total": mem[1],
                "used": mem[1] - mem[0],
            }

        import psutil
        mem = psutil.virtual_memory()
        return {
            "device": "CPU",
            "free": mem.available,
            "total": mem.total,
            "used": mem.used,
        }

    def clear_memory(self):
        """Lib√®re la m√©moire GPU (si applicable)."""
        if self._device_type == DeviceType.GPU:
            import cupy as cp
            cp.get_default_memory_pool().free_all_blocks()
            cp.get_default_pinned_memory_pool().free_all_blocks()


# Singleton global
_backend: Optional[ArrayBackend] = None


def get_backend() -> ArrayBackend:
    """Retourne le backend singleton."""
    global _backend
    if _backend is None:
        _backend = ArrayBackend()
    return _backend


def use_gpu(enable: bool = True) -> bool:
    """
    Active ou d√©sactive l'utilisation du GPU.

    Args:
        enable: True pour GPU, False pour CPU

    Returns:
        True si le changement a r√©ussi
    """
    backend = get_backend()
    device = DeviceType.GPU if enable else DeviceType.CPU
    return backend.use_device(device)


def use_cpu() -> bool:
    """Force l'utilisation du CPU."""
    return use_gpu(False)


def is_gpu_available() -> bool:
    """V√©rifie si un GPU est disponible."""
    return get_backend().gpu_available


def get_device_info() -> DeviceInfo:
    """Retourne les infos du device actuel."""
    return get_backend().device_info


@contextmanager
def gpu_context():
    """Context manager pour utiliser temporairement le GPU."""
    backend = get_backend()
    with backend.device_context(DeviceType.GPU):
        yield backend


@contextmanager
def cpu_context():
    """Context manager pour utiliser temporairement le CPU."""
    backend = get_backend()
    with backend.device_context(DeviceType.CPU):
        yield backend


def array_like(data, dtype=None):
    """Cr√©e un array sur le device actif."""
    return get_backend().array(data, dtype=dtype)


__all__ = [
    "DeviceType",
    "DeviceInfo",
    "ArrayBackend",
    "get_backend",
    "use_gpu",
    "use_cpu",
    "is_gpu_available",
    "get_device_info",
    "gpu_context",
    "cpu_context",
    "array_like",
]
```
<!-- MODULE-END: device_backend.py -->

<!-- MODULE-START: gpu.py -->
```json
{
  "name": "gpu.py",
  "path": "performance\\gpu.py",
  "ext": ".py",
  "anchor": "gpu_py"
}
```
## gpu_py
*Chemin* : `performance\gpu.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.gpu

Purpose: Acc√©l√©ration GPU optionnelle - CuPy arrays, Numba CUDA kernels, d√©tection.

Role in pipeline: performance optimization

Key components: gpu_available(), GPUIndicatorCalculator, CuPy/Numba wrappers, fallback CPU

Inputs: NumPy arrays, GPU device ID

Outputs: CuPy GPU arrays (si disponible) sinon NumPy CPU arrays

Dependencies: cupy (optionnel), numba (optionnel), numpy

Conventions: GPU optional; transparent CPU fallback; device management.

Read-if: Modification GPU kernel ou device selection.

Skip-if: Vous appelez gpu_available() ou GPUIndicatorCalculator.sma().
"""

from __future__ import annotations

import logging
import os
import time
from typing import Any, List, Optional, Tuple, Union

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

# ======================== D√©tection GPU ========================

# CuPy (GPU array operations)
try:
    import cupy as cp
    HAS_CUPY = True
    try:
        version = cp.__version__
    except AttributeError:
        version = "unknown"
    logger.info(f"CuPy disponible: version {version}")
except ImportError:
    HAS_CUPY = False
    cp = None

# Numba CUDA (JIT GPU kernels)
# NOTE: D√©sactiv√© car incompatible avec RTX 5080 (sm_90)
# Numba CUDA 0.61 ne supporte pas les architectures Blackwell.
# Utiliser CuPy √† la place qui fonctionne correctement.
HAS_NUMBA_CUDA = False
cuda = None
float64 = None  # Pour √©viter NameError si utilis√© quelque part


# ======================== GPU Device Manager ========================

class GPUDeviceManager:
    """
    Gestionnaire de device GPU - Approche prudente single-GPU.

    Strat√©gie:
    1. D√©tecte tous les GPUs disponibles
    2. S√©lectionne le plus puissant (par m√©moire) par d√©faut
    3. Verrouille sur ce device pour toute la session
    4. √âvite les switch de device intempestifs

    Environment variables:
        CUDA_VISIBLE_DEVICES: Limite les GPUs visibles
        BACKTEST_GPU_ID: Force un GPU sp√©cifique (0, 1, ...)
    """

    _instance: Optional['GPUDeviceManager'] = None
    _initialized: bool = False

    def __new__(cls):
        """Singleton pattern."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if GPUDeviceManager._initialized:
            return

        self._device_id: Optional[int] = None
        self._device_name: str = "CPU"
        self._device_memory_gb: float = 0.0
        self._available_devices: List[dict] = []
        self._locked: bool = False

        if HAS_CUPY:
            self._detect_devices()
            self._select_best_device()

        GPUDeviceManager._initialized = True

    def _detect_devices(self) -> None:
        """D√©tecte tous les GPUs disponibles."""
        if not HAS_CUPY:
            return

        try:
            device_count = cp.cuda.runtime.getDeviceCount()
            logger.info(f"GPUDeviceManager: {device_count} GPU(s) d√©tect√©(s)")

            for device_id in range(device_count):
                try:
                    props = cp.cuda.runtime.getDeviceProperties(device_id)
                    name = props["name"].decode() if isinstance(props["name"], bytes) else props["name"]

                    # R√©cup√©rer m√©moire en activant temporairement le device
                    with cp.cuda.Device(device_id):
                        mem_info = cp.cuda.runtime.memGetInfo()
                        total_mem_gb = mem_info[1] / (1024**3)
                        free_mem_gb = mem_info[0] / (1024**3)

                    device_info = {
                        "id": device_id,
                        "name": name,
                        "total_memory_gb": total_mem_gb,
                        "free_memory_gb": free_mem_gb,
                        "compute_capability": (props["major"], props["minor"]),
                    }
                    self._available_devices.append(device_info)
                    logger.info(f"  GPU {device_id}: {name} ({total_mem_gb:.1f} GB)")

                except Exception as e:
                    logger.warning(f"  GPU {device_id}: Erreur d√©tection - {e}")

        except Exception as e:
            logger.error(f"GPUDeviceManager: Erreur √©num√©ration GPUs - {e}")

    def _select_best_device(self) -> None:
        """
        S√©lectionne le meilleur GPU (5080 > 4090 > Memory).
        Stabilit√© renforc√©e pour √©viter les changements d'ID intempestifs.
        """
        if not self._available_devices:
            logger.warning("GPUDeviceManager: Aucun GPU disponible")
            return

        # 1. V√©rifier si un GPU est forc√© via variable d'environnement
        forced_gpu = os.environ.get("BACKTEST_GPU_ID")
        if forced_gpu is not None:
            try:
                forced_id = int(forced_gpu)
                matching = [d for d in self._available_devices if d["id"] == forced_id]
                if matching:
                    self._set_device(matching[0])
                    logger.info(f"GPUDeviceManager: GPU {forced_id} forc√© via BACKTEST_GPU_ID")
                    return
                else:
                    logger.warning(f"GPUDeviceManager: GPU {forced_id} non trouv√©, fallback auto selection")
            except ValueError:
                logger.warning(f"GPUDeviceManager: BACKTEST_GPU_ID invalide: {forced_gpu}")

        # 2. Score heuristic pour priorit√© (5080 > 4090 > 3090 > Autres)
        def get_device_score(device: dict) -> tuple:
            name = device["name"].upper()
            total_mem = device["total_memory_gb"]
            device_id = device["id"]

            # Priorit√© par mod√®le (Tier S)
            if "5080" in name:
                tier = 100
            elif "4090" in name:
                tier = 90
            elif "3090" in name or "TITAN" in name:
                tier = 80
            elif "5070" in name or "4080" in name:
                tier = 70
            elif "2080" in name or "1080" in name:
                tier = 60
            else:
                tier = 0

            # Tuple de tri: (Tier, Memory, -ID)
            # -ID pour pr√©f√©rer 0 si √©galit√©
            return (tier, total_mem, -device_id)

        # 3. Trier et s√©lectionner
        # On utilise une sort key plut√¥t que max() direct pour debug potentiel
        sorted_devices = sorted(self._available_devices, key=get_device_score, reverse=True)
        best_device = sorted_devices[0]

        logger.info(f"GPUDeviceManager: S√©lection automatique -> {best_device['name']} (ID={best_device['id']}, {best_device['total_memory_gb']:.1f}GB)")

        # Log des autres choix possibles
        if len(sorted_devices) > 1:
            alternatives = [f"{d['name']} (ID={d['id']})" for d in sorted_devices[1:]]
            logger.info(f"GPUDeviceManager: Alternatives ignor√©es -> {', '.join(alternatives)}")

        self._set_device(best_device)

        if len(self._available_devices) > 1:
            logger.info(
                f"GPUDeviceManager: S√©lection automatique du GPU le plus puissant: "
                f"{best_device['name']} (GPU {best_device['id']})"
            )

    def _set_device(self, device_info: dict) -> None:
        """Configure et verrouille sur un device."""
        if not HAS_CUPY:
            return

        self._device_id = device_info["id"]
        self._device_name = device_info["name"]
        self._device_memory_gb = device_info["total_memory_gb"]

        # Activer le device et le verrouiller
        cp.cuda.Device(self._device_id).use()
        self._locked = True

        logger.info(
            f"GPUDeviceManager: Verrouill√© sur GPU {self._device_id} "
            f"({self._device_name}, {self._device_memory_gb:.1f} GB)"
        )

    @property
    def device_id(self) -> Optional[int]:
        """ID du device actif."""
        return self._device_id

    @property
    def device_name(self) -> str:
        """Nom du device actif."""
        return self._device_name

    @property
    def available_devices(self) -> List[dict]:
        """Liste des devices disponibles."""
        return self._available_devices.copy()

    def ensure_device(self) -> None:
        """S'assure que le bon device est actif (appeler avant calculs GPU)."""
        if self._locked and self._device_id is not None and HAS_CUPY:
            current_device = cp.cuda.Device().id
            if current_device != self._device_id:
                logger.warning(
                    f"GPUDeviceManager: Device chang√©! "
                    f"Attendu {self._device_id}, actuel {current_device}. Correction..."
                )
                cp.cuda.Device(self._device_id).use()

    def get_info(self) -> dict:
        """Retourne les informations sur le GPU actif."""
        return {
            "device_id": self._device_id,
            "device_name": self._device_name,
            "device_memory_gb": self._device_memory_gb,
            "available_devices": len(self._available_devices),
            "locked": self._locked,
        }


# Singleton global - initialis√© au premier acc√®s
_gpu_manager: Optional[GPUDeviceManager] = None


def get_gpu_manager() -> GPUDeviceManager:
    """Retourne le gestionnaire GPU singleton."""
    global _gpu_manager
    if _gpu_manager is None:
        _gpu_manager = GPUDeviceManager()
    return _gpu_manager


# Initialisation automatique au chargement du module si CuPy disponible
if HAS_CUPY:
    try:
        _gpu_manager = GPUDeviceManager()
    except Exception as e:
        logger.error(f"Erreur initialisation GPUDeviceManager: {e}")
        _gpu_manager = None


def gpu_available() -> bool:
    """V√©rifie si le GPU est disponible."""
    return HAS_CUPY or HAS_NUMBA_CUDA


def get_gpu_info() -> dict:
    """Retourne les informations sur le GPU."""
    info = {
        "cupy_available": HAS_CUPY,
        "numba_cuda_available": HAS_NUMBA_CUDA,
        "gpu_available": gpu_available(),
    }

    if HAS_CUPY and _gpu_manager:
        manager_info = _gpu_manager.get_info()
        info.update({
            "cupy_device": manager_info["device_id"],
            "cupy_device_name": manager_info["device_name"],
            "cupy_memory_total_gb": manager_info["device_memory_gb"],
            "device_locked": manager_info["locked"],
            "available_gpu_count": manager_info["available_devices"],
        })

        # Ajouter m√©moire libre actuelle
        if manager_info["device_id"] is not None:
            try:
                _gpu_manager.ensure_device()
                mem_info = cp.cuda.runtime.memGetInfo()
                info["cupy_memory_free_gb"] = mem_info[0] / (1024**3)
            except Exception as e:
                info["cupy_error"] = str(e)

    return info


# ======================== Array Abstraction ========================

def to_gpu(arr: np.ndarray) -> Any:
    """Transf√®re un array numpy vers le GPU."""
    if HAS_CUPY:
        return cp.asarray(arr)
    return arr


def to_cpu(arr: Any) -> np.ndarray:
    """Transf√®re un array GPU vers le CPU."""
    if HAS_CUPY and isinstance(arr, cp.ndarray):
        return cp.asnumpy(arr)
    return np.asarray(arr)


def get_array_module(arr: Any):
    """Retourne le module array (numpy ou cupy) pour un array."""
    if HAS_CUPY:
        return cp.get_array_module(arr)
    return np


# ======================== GPU Indicator Calculator ========================

class GPUIndicatorCalculator:
    """
    Calculateur d'indicateurs avec acc√©l√©ration GPU.

    Utilise CuPy pour les op√©rations vectorielles sur GPU.
    Fallback automatique sur CPU si GPU non disponible.

    Le GPUDeviceManager garantit l'utilisation d'un seul GPU
    (le plus puissant par d√©faut) pour √©viter les probl√®mes
    de switch entre GPUs.

    Example:
        >>> calc = GPUIndicatorCalculator(use_gpu=True)
        >>>
        >>> # SMA sur GPU
        >>> sma = calc.sma(prices, period=20)
        >>>
        >>> # EMA sur GPU
        >>> ema = calc.ema(prices, period=12)
        >>>
        >>> # Bollinger Bands sur GPU
        >>> upper, middle, lower = calc.bollinger_bands(prices, period=20, std=2.0)
    """

    # Seuil minimum pour utiliser le GPU (overhead transfert)
    MIN_SAMPLES_FOR_GPU = 5000

    def __init__(self, use_gpu: bool = True, min_samples: int = 5000):
        """
        Initialise le calculateur GPU.

        Args:
            use_gpu: Activer le GPU si disponible
            min_samples: Seuil minimum pour utiliser le GPU
        """
        self.use_gpu = use_gpu and gpu_available()
        self.min_samples = min_samples
        self._gpu_manager = get_gpu_manager() if self.use_gpu else None

        if self.use_gpu and self._gpu_manager:
            info = self._gpu_manager.get_info()
            logger.info(
                f"GPUIndicatorCalculator: GPU activ√© - {info['device_name']} "
                f"(GPU {info['device_id']})"
            )
        else:
            logger.info("GPUIndicatorCalculator: Mode CPU")

    def _ensure_device(self) -> None:
        """S'assure que le bon GPU est actif avant calcul."""
        if self._gpu_manager:
            self._gpu_manager.ensure_device()

    def _should_use_gpu(self, n_samples: int) -> bool:
        """D√©termine si le GPU doit √™tre utilis√© pour cette taille de donn√©es."""
        return self.use_gpu and n_samples >= self.min_samples

    def _to_array(self, data: Union[np.ndarray, pd.Series], use_gpu: bool) -> Any:
        """Convertit les donn√©es en array (GPU ou CPU)."""
        if isinstance(data, pd.Series):
            arr = data.values.astype(np.float64)
        else:
            arr = np.asarray(data, dtype=np.float64)

        if use_gpu and HAS_CUPY:
            self._ensure_device()  # V√©rifier device avant transfert
            return cp.asarray(arr)
        return arr

    def _to_numpy(self, arr: Any) -> np.ndarray:
        """Convertit un array en numpy."""
        if HAS_CUPY and isinstance(arr, cp.ndarray):
            return cp.asnumpy(arr)
        return np.asarray(arr)

    def sma(self, prices: Union[np.ndarray, pd.Series], period: int) -> np.ndarray:
        """
        Simple Moving Average avec acc√©l√©ration GPU.

        Args:
            prices: Array de prix
            period: P√©riode de la moyenne

        Returns:
            Array SMA (m√™me taille que prices)
        """
        n = len(prices)
        use_gpu = self._should_use_gpu(n)
        xp = cp if use_gpu and HAS_CUPY else np

        arr = self._to_array(prices, use_gpu)
        result = xp.full(n, xp.nan, dtype=xp.float64)

        # Calcul rolling mean
        cumsum = xp.cumsum(arr)
        result[period-1:] = (cumsum[period-1:] - xp.concatenate([[0], cumsum[:-period]])) / period

        return self._to_numpy(result)

    def ema(self, prices: Union[np.ndarray, pd.Series], period: int) -> np.ndarray:
        """
        Exponential Moving Average avec acc√©l√©ration GPU.

        Args:
            prices: Array de prix
            period: P√©riode de l'EMA

        Returns:
            Array EMA
        """
        n = len(prices)
        use_gpu = self._should_use_gpu(n)
        xp = cp if use_gpu and HAS_CUPY else np

        arr = self._to_array(prices, use_gpu)

        # Alpha = 2 / (period + 1)
        alpha = 2.0 / (period + 1)

        # EMA r√©cursif (difficile √† parall√©liser enti√®rement)
        # On utilise une approximation ou on fait sur CPU si trop petit
        if not use_gpu or n < 10000:
            # CPU version (plus pr√©cise pour EMA r√©cursif)
            arr_cpu = self._to_numpy(arr)
            ema = np.zeros(n, dtype=np.float64)
            ema[0] = arr_cpu[0]
            for i in range(1, n):
                ema[i] = alpha * arr_cpu[i] + (1 - alpha) * ema[i-1]
            return ema

        # GPU approximation avec filter
        result = xp.zeros(n, dtype=xp.float64)
        result[0] = arr[0]

        # Vectorized approximation (moins pr√©cis mais plus rapide)
        xp.power(1 - alpha, xp.arange(n))
        for i in range(1, n):
            result[i] = alpha * arr[i] + (1 - alpha) * result[i-1]

        return self._to_numpy(result)

    def rsi(self, prices: Union[np.ndarray, pd.Series], period: int = 14) -> np.ndarray:
        """
        Relative Strength Index avec acc√©l√©ration GPU.

        Args:
            prices: Array de prix
            period: P√©riode RSI (d√©faut: 14)

        Returns:
            Array RSI (0-100)
        """
        n = len(prices)
        use_gpu = self._should_use_gpu(n)
        xp = cp if use_gpu and HAS_CUPY else np

        arr = self._to_array(prices, use_gpu)

        # Calcul des deltas
        delta = xp.diff(arr)

        # Gains et pertes
        gains = xp.where(delta > 0, delta, 0)
        losses = xp.where(delta < 0, -delta, 0)

        # Moyennes mobiles exponentielles
        alpha = 1.0 / period

        avg_gain = xp.zeros(n, dtype=xp.float64)
        avg_loss = xp.zeros(n, dtype=xp.float64)

        # Premier calcul: moyenne simple
        if n > period:
            avg_gain[period] = xp.mean(gains[:period])
            avg_loss[period] = xp.mean(losses[:period])

            # EMA r√©cursif
            for i in range(period + 1, n):
                avg_gain[i] = alpha * gains[i-1] + (1 - alpha) * avg_gain[i-1]
                avg_loss[i] = alpha * losses[i-1] + (1 - alpha) * avg_loss[i-1]

        # RSI (√©viter division par z√©ro avec np.errstate)
        with np.errstate(divide='ignore', invalid='ignore'):
            rs = xp.where(avg_loss != 0, avg_gain / avg_loss, 100)
        rsi = 100 - (100 / (1 + rs))

        # NaN pour les premi√®res valeurs
        rsi[:period] = xp.nan

        return self._to_numpy(rsi)

    def bollinger_bands(
        self,
        prices: Union[np.ndarray, pd.Series],
        period: int = 20,
        std_dev: float = 2.0
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Bollinger Bands avec acc√©l√©ration GPU.

        Args:
            prices: Array de prix
            period: P√©riode de la moyenne (d√©faut: 20)
            std_dev: Nombre d'√©carts-types (d√©faut: 2.0)

        Returns:
            Tuple (upper_band, middle_band, lower_band)
        """
        n = len(prices)
        use_gpu = self._should_use_gpu(n)
        xp = cp if use_gpu and HAS_CUPY else np

        arr = self._to_array(prices, use_gpu)

        # Middle band = SMA
        middle = xp.full(n, xp.nan, dtype=xp.float64)
        std = xp.full(n, xp.nan, dtype=xp.float64)

        # Rolling mean et std
        for i in range(period - 1, n):
            window = arr[i - period + 1:i + 1]
            middle[i] = xp.mean(window)
            std[i] = xp.std(window)

        # Upper et lower bands
        upper = middle + std_dev * std
        lower = middle - std_dev * std

        return (
            self._to_numpy(upper),
            self._to_numpy(middle),
            self._to_numpy(lower)
        )

    def atr(
        self,
        high: Union[np.ndarray, pd.Series],
        low: Union[np.ndarray, pd.Series],
        close: Union[np.ndarray, pd.Series],
        period: int = 14
    ) -> np.ndarray:
        """
        Average True Range avec acc√©l√©ration GPU.

        Args:
            high: Array des plus hauts
            low: Array des plus bas
            close: Array des cl√¥tures
            period: P√©riode ATR (d√©faut: 14)

        Returns:
            Array ATR
        """
        n = len(close)
        use_gpu = self._should_use_gpu(n)
        xp = cp if use_gpu and HAS_CUPY else np

        high_arr = self._to_array(high, use_gpu)
        low_arr = self._to_array(low, use_gpu)
        close_arr = self._to_array(close, use_gpu)

        # True Range
        tr1 = high_arr - low_arr
        tr2 = xp.abs(high_arr - xp.concatenate([[close_arr[0]], close_arr[:-1]]))
        tr3 = xp.abs(low_arr - xp.concatenate([[close_arr[0]], close_arr[:-1]]))

        tr = xp.maximum(tr1, xp.maximum(tr2, tr3))

        # ATR = EMA du True Range
        atr = xp.full(n, xp.nan, dtype=xp.float64)
        atr[period-1] = xp.mean(tr[:period])

        alpha = 1.0 / period
        for i in range(period, n):
            atr[i] = alpha * tr[i] + (1 - alpha) * atr[i-1]

        return self._to_numpy(atr)

    def macd(
        self,
        prices: Union[np.ndarray, pd.Series],
        fast_period: int = 12,
        slow_period: int = 26,
        signal_period: int = 9
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        MACD avec acc√©l√©ration GPU.

        Args:
            prices: Array de prix
            fast_period: P√©riode EMA rapide (d√©faut: 12)
            slow_period: P√©riode EMA lente (d√©faut: 26)
            signal_period: P√©riode ligne signal (d√©faut: 9)

        Returns:
            Tuple (macd_line, signal_line, histogram)
        """
        # EMA rapide et lente
        fast_ema = self.ema(prices, fast_period)
        slow_ema = self.ema(prices, slow_period)

        # MACD line
        macd_line = fast_ema - slow_ema

        # Signal line (EMA du MACD)
        signal_line = self.ema(macd_line, signal_period)

        # Histogram
        histogram = macd_line - signal_line

        return macd_line, signal_line, histogram


# ======================== Benchmark GPU vs CPU ========================

def benchmark_gpu_cpu(n_samples: int = 100000, n_runs: int = 5) -> dict:
    """
    Compare les performances GPU vs CPU.

    Args:
        n_samples: Nombre d'√©chantillons
        n_runs: Nombre de runs pour moyenne

    Returns:
        Dict avec timings et speedup
    """
    prices = np.random.randn(n_samples).cumsum() + 100

    results = {
        "n_samples": n_samples,
        "n_runs": n_runs,
        "gpu_available": gpu_available(),
    }

    # CPU benchmark
    calc_cpu = GPUIndicatorCalculator(use_gpu=False)

    cpu_times = []
    for _ in range(n_runs):
        start = time.time()
        calc_cpu.sma(prices, 20)
        calc_cpu.ema(prices, 12)
        calc_cpu.rsi(prices, 14)
        calc_cpu.bollinger_bands(prices, 20, 2.0)
        cpu_times.append(time.time() - start)

    results["cpu_avg_time"] = np.mean(cpu_times)

    # GPU benchmark (si disponible)
    if gpu_available():
        calc_gpu = GPUIndicatorCalculator(use_gpu=True, min_samples=0)

        # Warmup
        calc_gpu.sma(prices[:1000], 20)

        gpu_times = []
        for _ in range(n_runs):
            start = time.time()
            calc_gpu.sma(prices, 20)
            calc_gpu.ema(prices, 12)
            calc_gpu.rsi(prices, 14)
            calc_gpu.bollinger_bands(prices, 20, 2.0)
            gpu_times.append(time.time() - start)

        results["gpu_avg_time"] = np.mean(gpu_times)
        results["speedup"] = results["cpu_avg_time"] / results["gpu_avg_time"]

    return results
```
<!-- MODULE-END: gpu.py -->

<!-- MODULE-START: memory.py -->
```json
{
  "name": "memory.py",
  "path": "performance\\memory.py",
  "ext": ".py",
  "anchor": "memory_py"
}
```
## memory_py
*Chemin* : `performance\memory.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.memory

Purpose: Gestion intelligente m√©moire - chunking, pr√©chargement, auto-cleanup.

Role in pipeline: performance optimization

Key components: ChunkedProcessor, MemoryManager, @chunked, auto_gc()

Inputs: Large DataFrame/Array, chunk_size, memory_limit_gb

Outputs: Processed chunks, memory usage stats, freed memory

Dependencies: numpy, pandas, gc, weakref, tempfile, psutil (optionnel)

Conventions: Chunks power-of-2; GC auto apr√®s threshold; spill disk si limit exceeded.

Read-if: Modification chunking strategy ou memory limits.

Skip-if: Vous appelez processor.process(df) iterator.
"""

from __future__ import annotations

import gc
import logging
import sys
import tempfile
import time
import weakref
from contextlib import contextmanager
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, Generator, List, Optional, TypeVar

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

# psutil pour monitoring m√©moire
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

T = TypeVar("T")


@dataclass
class MemoryStats:
    """Statistiques m√©moire."""
    used_gb: float
    available_gb: float
    total_gb: float
    percent: float
    process_rss_gb: float  # Resident Set Size du process


def get_memory_info() -> MemoryStats:
    """Retourne les informations m√©moire actuelles."""
    if HAS_PSUTIL:
        mem = psutil.virtual_memory()
        process = psutil.Process()
        rss = process.memory_info().rss / (1024**3)

        return MemoryStats(
            used_gb=mem.used / (1024**3),
            available_gb=mem.available / (1024**3),
            total_gb=mem.total / (1024**3),
            percent=mem.percent,
            process_rss_gb=rss,
        )
    else:
        return MemoryStats(
            used_gb=0.0,
            available_gb=8.0,
            total_gb=8.0,
            percent=0.0,
            process_rss_gb=0.0,
        )


def get_available_ram_gb() -> float:
    """Retourne la RAM disponible en GB."""
    return get_memory_info().available_gb


def get_object_size_mb(obj: Any) -> float:
    """Estime la taille d'un objet en MB."""
    if isinstance(obj, pd.DataFrame):
        return obj.memory_usage(deep=True).sum() / (1024**2)
    elif isinstance(obj, np.ndarray):
        return obj.nbytes / (1024**2)
    elif isinstance(obj, (list, tuple)):
        return sum(get_object_size_mb(item) for item in obj) + sys.getsizeof(obj) / (1024**2)
    elif isinstance(obj, dict):
        size = sys.getsizeof(obj)
        for k, v in obj.items():
            size += sys.getsizeof(k) + get_object_size_mb(v) * (1024**2)
        return size / (1024**2)
    else:
        return sys.getsizeof(obj) / (1024**2)


class ChunkedProcessor:
    """
    Processeur qui divise les donn√©es en chunks pour √©conomiser la m√©moire.

    Utile pour traiter de grands DataFrames sans saturer la RAM.

    Example:
        >>> processor = ChunkedProcessor(chunk_size=10000)
        >>>
        >>> results = []
        >>> for chunk_df in processor.iter_chunks(large_df):
        ...     result = process_data(chunk_df)
        ...     results.append(result)
        >>>
        >>> final = pd.concat(results)
    """

    def __init__(
        self,
        chunk_size: int = 10000,
        overlap: int = 0,
        memory_limit_gb: Optional[float] = None,
    ):
        """
        Initialise le processeur de chunks.

        Args:
            chunk_size: Nombre de lignes par chunk
            overlap: Chevauchement entre chunks (pour indicateurs rolling)
            memory_limit_gb: Limite m√©moire optionnelle
        """
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.memory_limit_gb = memory_limit_gb

        self._adaptive_size = chunk_size

    def _adjust_chunk_size(self):
        """Ajuste dynamiquement la taille des chunks selon la m√©moire disponible."""
        if not self.memory_limit_gb:
            return

        mem = get_memory_info()

        # Si m√©moire faible, r√©duire la taille des chunks
        if mem.available_gb < 1.0:
            self._adaptive_size = max(1000, self.chunk_size // 4)
            logger.warning(f"M√©moire faible! Chunk size r√©duit √† {self._adaptive_size}")
        elif mem.available_gb < 2.0:
            self._adaptive_size = max(2000, self.chunk_size // 2)
        else:
            self._adaptive_size = self.chunk_size

    def iter_chunks(
        self,
        df: pd.DataFrame,
        copy: bool = False
    ) -> Generator[pd.DataFrame, None, None]:
        """
        It√®re sur les chunks d'un DataFrame.

        Args:
            df: DataFrame √† diviser
            copy: Cr√©er une copie de chaque chunk (plus s√ªr mais plus lent)

        Yields:
            Chunks du DataFrame
        """
        n_rows = len(df)

        for start in range(0, n_rows, self._adaptive_size - self.overlap):
            self._adjust_chunk_size()

            end = min(start + self._adaptive_size, n_rows)

            if copy:
                yield df.iloc[start:end].copy()
            else:
                yield df.iloc[start:end]

            # Forcer garbage collection entre chunks si m√©moire limite
            if self.memory_limit_gb:
                gc.collect()

    def process(
        self,
        df: pd.DataFrame,
        func: Callable[[pd.DataFrame], T],
        combine_func: Optional[Callable[[List[T]], T]] = None,
    ) -> T:
        """
        Traite un DataFrame par chunks et combine les r√©sultats.

        Args:
            df: DataFrame √† traiter
            func: Fonction √† appliquer sur chaque chunk
            combine_func: Fonction pour combiner les r√©sultats (None = list)

        Returns:
            R√©sultat combin√©
        """
        results = []

        for i, chunk in enumerate(self.iter_chunks(df)):
            logger.debug(f"Processing chunk {i+1}, size={len(chunk)}")
            result = func(chunk)
            results.append(result)

        if combine_func:
            return combine_func(results)
        else:
            # Par d√©faut, concat si DataFrames, sinon list
            if results and isinstance(results[0], pd.DataFrame):
                return pd.concat(results, ignore_index=True)
            return results  # type: ignore


class MemoryManager:
    """
    Gestionnaire de m√©moire avec limites et nettoyage automatique.

    Example:
        >>> with MemoryManager(limit_gb=8.0, auto_gc=True) as mm:
        ...     data = load_large_data()
        ...     results = process(data)
        ...     mm.check_and_cleanup()  # Nettoie si n√©cessaire
    """

    def __init__(
        self,
        limit_gb: Optional[float] = None,
        auto_gc: bool = True,
        gc_threshold_percent: float = 80.0,
    ):
        """
        Initialise le gestionnaire m√©moire.

        Args:
            limit_gb: Limite m√©moire en GB (None = pas de limite)
            auto_gc: Activer garbage collection automatique
            gc_threshold_percent: Seuil de m√©moire pour d√©clencher GC
        """
        self.limit_gb = limit_gb
        self.auto_gc = auto_gc
        self.gc_threshold = gc_threshold_percent

        self._tracked_objects: List[weakref.ref] = []
        self._start_memory: float = 0.0
        self._gc_count: int = 0

    def __enter__(self):
        self._start_memory = get_memory_info().process_rss_gb
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # Nettoyer les objets track√©s
        self._tracked_objects.clear()

        # Forcer GC final
        gc.collect()

        end_memory = get_memory_info().process_rss_gb
        logger.debug(
            f"MemoryManager: d√©but={self._start_memory:.2f}GB, "
            f"fin={end_memory:.2f}GB, GC={self._gc_count}"
        )

        return False

    def track(self, obj: Any) -> Any:
        """
        Track un objet pour nettoyage automatique.

        Args:
            obj: Objet √† tracker

        Returns:
            L'objet lui-m√™me
        """
        self._tracked_objects.append(weakref.ref(obj))
        return obj

    def check_and_cleanup(self, force: bool = False) -> bool:
        """
        V√©rifie la m√©moire et nettoie si n√©cessaire.

        Args:
            force: Forcer le nettoyage m√™me si sous le seuil

        Returns:
            True si nettoyage effectu√©
        """
        mem = get_memory_info()

        should_cleanup = force

        if self.limit_gb and mem.process_rss_gb > self.limit_gb:
            should_cleanup = True
            logger.warning(f"Limite m√©moire d√©pass√©e: {mem.process_rss_gb:.2f}GB > {self.limit_gb}GB")

        if mem.percent > self.gc_threshold:
            should_cleanup = True
            logger.warning(f"Seuil m√©moire syst√®me atteint: {mem.percent:.1f}%")

        if should_cleanup and self.auto_gc:
            gc.collect()
            self._gc_count += 1
            return True

        return False

    def get_usage(self) -> Dict[str, float]:
        """Retourne les stats d'usage m√©moire."""
        mem = get_memory_info()
        return {
            "process_gb": mem.process_rss_gb,
            "system_used_gb": mem.used_gb,
            "system_available_gb": mem.available_gb,
            "system_percent": mem.percent,
            "delta_gb": mem.process_rss_gb - self._start_memory,
        }


class DataFrameCache:
    """
    Cache intelligent pour DataFrames avec gestion m√©moire.

    Supporte le spillage sur disque si la m√©moire est satur√©e.

    Example:
        >>> cache = DataFrameCache(max_memory_gb=2.0)
        >>>
        >>> cache.put("btc_1h", btc_df)
        >>> cache.put("eth_1h", eth_df)
        >>>
        >>> btc = cache.get("btc_1h")
    """

    def __init__(
        self,
        max_memory_gb: float = 2.0,
        spill_to_disk: bool = True,
        cache_dir: Optional[str] = None,
    ):
        """
        Initialise le cache.

        Args:
            max_memory_gb: M√©moire max pour le cache
            spill_to_disk: √âcrire sur disque si m√©moire satur√©e
            cache_dir: R√©pertoire pour fichiers temporaires
        """
        self.max_memory_gb = max_memory_gb
        self.spill_to_disk = spill_to_disk
        self.cache_dir = Path(cache_dir) if cache_dir else Path(tempfile.gettempdir()) / "backtest_cache"

        self._memory_cache: Dict[str, pd.DataFrame] = {}
        self._disk_cache: Dict[str, Path] = {}
        self._access_times: Dict[str, float] = {}
        self._sizes: Dict[str, float] = {}  # en MB

        # Cr√©er le r√©pertoire cache
        if spill_to_disk:
            self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _current_memory_mb(self) -> float:
        """Calcule la m√©moire utilis√©e par le cache."""
        return sum(self._sizes.get(k, 0) for k in self._memory_cache)

    def _evict_lru(self, needed_mb: float):
        """√âvince les entr√©es LRU pour lib√©rer de la m√©moire."""
        while self._memory_cache and self._current_memory_mb() + needed_mb > self.max_memory_gb * 1024:
            # Trouver l'entr√©e la moins r√©cemment utilis√©e
            lru_key = min(self._memory_cache.keys(), key=lambda k: self._access_times.get(k, 0))

            if self.spill_to_disk:
                # Spiller sur disque
                df = self._memory_cache[lru_key]
                disk_path = self.cache_dir / f"{lru_key}.parquet"
                df.to_parquet(disk_path)
                self._disk_cache[lru_key] = disk_path
                logger.debug(f"Spilled {lru_key} to disk ({self._sizes[lru_key]:.1f}MB)")

            del self._memory_cache[lru_key]

    def put(self, key: str, df: pd.DataFrame):
        """
        Ajoute un DataFrame au cache.

        Args:
            key: Cl√© unique
            df: DataFrame √† cacher
        """
        size_mb = get_object_size_mb(df)

        # √âviction si n√©cessaire
        if size_mb < self.max_memory_gb * 1024:
            self._evict_lru(size_mb)

        self._memory_cache[key] = df
        self._access_times[key] = time.time()
        self._sizes[key] = size_mb

        # Retirer du cache disque si pr√©sent
        if key in self._disk_cache:
            try:
                self._disk_cache[key].unlink()
            except Exception:
                pass
            del self._disk_cache[key]

    def get(self, key: str) -> Optional[pd.DataFrame]:
        """
        R√©cup√®re un DataFrame du cache.

        Args:
            key: Cl√© du DataFrame

        Returns:
            DataFrame ou None si non trouv√©
        """
        # V√©rifier cache m√©moire
        if key in self._memory_cache:
            self._access_times[key] = time.time()
            return self._memory_cache[key]

        # V√©rifier cache disque
        if key in self._disk_cache:
            disk_path = self._disk_cache[key]
            if disk_path.exists():
                df = pd.read_parquet(disk_path)

                # Remettre en m√©moire si possible
                size_mb = get_object_size_mb(df)
                if self._current_memory_mb() + size_mb <= self.max_memory_gb * 1024:
                    self._memory_cache[key] = df
                    self._access_times[key] = time.time()

                return df

        return None

    def contains(self, key: str) -> bool:
        """V√©rifie si une cl√© existe dans le cache."""
        return key in self._memory_cache or key in self._disk_cache

    def clear(self):
        """Vide le cache."""
        self._memory_cache.clear()
        self._access_times.clear()
        self._sizes.clear()

        # Supprimer fichiers disque
        for path in self._disk_cache.values():
            try:
                path.unlink()
            except Exception:
                pass
        self._disk_cache.clear()

    def stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache."""
        return {
            "memory_items": len(self._memory_cache),
            "disk_items": len(self._disk_cache),
            "memory_used_mb": self._current_memory_mb(),
            "memory_limit_mb": self.max_memory_gb * 1024,
            "keys": list(self._memory_cache.keys()) + list(self._disk_cache.keys()),
        }


# ======================== Fonctions utilitaires ========================

@contextmanager
def memory_efficient_mode():
    """
    Context manager pour mode √©conomie m√©moire.

    Active GC agressif et r√©duit les allocations.

    Example:
        >>> with memory_efficient_mode():
        ...     process_large_data()
    """
    # Sauvegarder les seuils GC
    old_thresholds = gc.get_threshold()

    try:
        # GC plus agressif
        gc.set_threshold(100, 5, 5)
        gc.collect()
        yield
    finally:
        # Restaurer
        gc.set_threshold(*old_thresholds)
        gc.collect()


def optimize_dataframe(df: pd.DataFrame, inplace: bool = False) -> pd.DataFrame:
    """
    Optimise la m√©moire d'un DataFrame en r√©duisant les types.

    Args:
        df: DataFrame √† optimiser
        inplace: Modifier en place

    Returns:
        DataFrame optimis√©
    """
    if not inplace:
        df = df.copy()

    for col in df.columns:
        col_type = df[col].dtype

        if col_type == "float64":
            # Essayer float32
            df[col] = pd.to_numeric(df[col], downcast="float")

        elif col_type == "int64":
            # R√©duire la taille des entiers
            df[col] = pd.to_numeric(df[col], downcast="integer")

        elif col_type == "object":
            # Convertir en category si peu de valeurs uniques
            n_unique = df[col].nunique()
            if n_unique / len(df) < 0.5:  # Moins de 50% de valeurs uniques
                df[col] = df[col].astype("category")

    return df


def estimate_memory_needed(
    n_rows: int,
    n_strategies: int,
    n_indicators: int = 5,
) -> float:
    """
    Estime la m√©moire n√©cessaire pour un backtest.

    Args:
        n_rows: Nombre de lignes de donn√©es
        n_strategies: Nombre de combinaisons de param√®tres
        n_indicators: Nombre d'indicateurs

    Returns:
        Estimation en GB
    """
    # Base: ~100 bytes par ligne pour OHLCV
    base_data_mb = n_rows * 100 / (1024**2)

    # Indicateurs: ~50 bytes par indicateur par ligne
    indicators_mb = n_rows * n_indicators * 50 / (1024**2)

    # R√©sultats: ~200 bytes par strat√©gie
    results_mb = n_strategies * 200 / (1024**2)

    # Overhead Python/Pandas: x2
    total_mb = (base_data_mb + indicators_mb + results_mb) * 2

    return total_mb / 1024  # En GB
```
<!-- MODULE-END: memory.py -->

<!-- MODULE-START: monitor.py -->
```json
{
  "name": "monitor.py",
  "path": "performance\\monitor.py",
  "ext": ".py",
  "anchor": "monitor_py"
}
```
## monitor_py
*Chemin* : `performance\monitor.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.monitor

Purpose: Monitoring temps r√©el syst√®me (CPU, m√©moire, I/O, GPU) pendant ex√©cution.

Role in pipeline: observability

Key components: PerformanceMonitor, ResourceTracker, psutil wrapper, Rich display

Inputs: None (reads system metrics)

Outputs: Stats {cpu_pct, mem_mb, io_r_mb, gpu_mem_mb}, timeline

Dependencies: psutil, threading, time, rich (optionnel)

Conventions: Background thread safe; thread-safe stats dict; 1s interval.

Read-if: Modification metrics collection ou refresh interval.

Skip-if: Vous appelez monitor.get_stats().
"""

from __future__ import annotations

import logging
import os
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

# psutil pour m√©triques syst√®me
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    logger.warning("psutil non disponible - monitoring limit√©")

# rich pour affichage console
try:
    from rich.console import Console
    from rich.live import Live
    from rich.panel import Panel
    from rich.progress import (
        BarColumn,
        Progress,
        SpinnerColumn,
        TaskProgressColumn,
        TextColumn,
        TimeElapsedColumn,
        TimeRemainingColumn,
    )
    from rich.table import Table
    HAS_RICH = True
except ImportError:
    HAS_RICH = False
    logger.warning("rich non disponible - affichage console basique")


@dataclass
class ResourceSnapshot:
    """Snapshot des ressources syst√®me √† un instant t."""
    timestamp: float
    cpu_percent: float
    memory_used_gb: float
    memory_available_gb: float
    memory_percent: float
    disk_read_mb: float = 0.0
    disk_write_mb: float = 0.0
    gpu_memory_used_gb: Optional[float] = None
    gpu_utilization: Optional[float] = None


@dataclass
class ResourceStats:
    """Statistiques agr√©g√©es des ressources."""
    duration_seconds: float
    cpu_avg: float
    cpu_max: float
    memory_avg_gb: float
    memory_max_gb: float
    memory_peak_percent: float
    samples_count: int
    gpu_memory_max_gb: Optional[float] = None
    gpu_utilization_avg: Optional[float] = None


class ResourceTracker:
    """
    Tracker de ressources en arri√®re-plan.

    Capture les m√©triques CPU/RAM/GPU √† intervalles r√©guliers.

    Example:
        >>> tracker = ResourceTracker(interval=0.5)
        >>> tracker.start()
        >>>
        >>> # ... ex√©cution du backtest ...
        >>>
        >>> stats = tracker.stop()
        >>> print(f"CPU max: {stats.cpu_max}%")
        >>> print(f"RAM max: {stats.memory_max_gb:.2f} GB")
    """

    def __init__(self, interval: float = 1.0):
        """
        Initialise le tracker.

        Args:
            interval: Intervalle de sampling en secondes
        """
        self.interval = interval
        self._snapshots: List[ResourceSnapshot] = []
        self._running = False
        self._thread: Optional[threading.Thread] = None
        self._start_time: float = 0.0

        # Compteurs IO disque de base
        self._disk_io_start = None
        if HAS_PSUTIL:
            try:
                self._disk_io_start = psutil.disk_io_counters()
            except Exception:
                pass

    def _take_snapshot(self) -> ResourceSnapshot:
        """Capture un snapshot des ressources."""
        timestamp = time.time()

        if HAS_PSUTIL:
            cpu_percent = psutil.cpu_percent(interval=0)
            mem = psutil.virtual_memory()

            # IO disque
            disk_read_mb = 0.0
            disk_write_mb = 0.0
            try:
                io = psutil.disk_io_counters()
                if self._disk_io_start:
                    disk_read_mb = (
                        io.read_bytes - self._disk_io_start.read_bytes
                    ) / (1024**2)
                    disk_write_mb = (
                        io.write_bytes - self._disk_io_start.write_bytes
                    ) / (1024**2)
            except Exception:
                pass

            return ResourceSnapshot(
                timestamp=timestamp,
                cpu_percent=cpu_percent,
                memory_used_gb=mem.used / (1024**3),
                memory_available_gb=mem.available / (1024**3),
                memory_percent=mem.percent,
                disk_read_mb=disk_read_mb,
                disk_write_mb=disk_write_mb,
            )
        else:
            # Fallback sans psutil
            return ResourceSnapshot(
                timestamp=timestamp,
                cpu_percent=0.0,
                memory_used_gb=0.0,
                memory_available_gb=0.0,
                memory_percent=0.0,
            )

    def _sampling_loop(self):
        """Boucle de sampling en arri√®re-plan."""
        while self._running:
            snapshot = self._take_snapshot()
            self._snapshots.append(snapshot)
            time.sleep(self.interval)

    def start(self):
        """D√©marre le tracking."""
        if self._running:
            return

        self._running = True
        self._start_time = time.time()
        self._snapshots = []

        self._thread = threading.Thread(
            target=self._sampling_loop,
            daemon=True,
        )
        self._thread.start()

        logger.debug("ResourceTracker d√©marr√©")

    def stop(self) -> ResourceStats:
        """
        Arr√™te le tracking et retourne les statistiques.

        Returns:
            ResourceStats avec m√©triques agr√©g√©es
        """
        self._running = False

        if self._thread:
            self._thread.join(timeout=2.0)

        # Calculer les stats
        duration = time.time() - self._start_time

        if not self._snapshots:
            return ResourceStats(
                duration_seconds=duration,
                cpu_avg=0.0,
                cpu_max=0.0,
                memory_avg_gb=0.0,
                memory_max_gb=0.0,
                memory_peak_percent=0.0,
                samples_count=0,
            )

        cpu_values = [s.cpu_percent for s in self._snapshots]
        mem_values = [s.memory_used_gb for s in self._snapshots]
        mem_pct_values = [s.memory_percent for s in self._snapshots]

        return ResourceStats(
            duration_seconds=duration,
            cpu_avg=sum(cpu_values) / len(cpu_values),
            cpu_max=max(cpu_values),
            memory_avg_gb=sum(mem_values) / len(mem_values),
            memory_max_gb=max(mem_values),
            memory_peak_percent=max(mem_pct_values),
            samples_count=len(self._snapshots),
        )

    def get_current(self) -> ResourceSnapshot:
        """Retourne le snapshot actuel."""
        return self._take_snapshot()

    def get_history(self) -> List[ResourceSnapshot]:
        """Retourne l'historique des snapshots."""
        return self._snapshots.copy()


class PerformanceMonitor:
    """
    Moniteur de performance avec affichage temps r√©el.

    Utilise rich pour afficher une interface console avec:
    - Barre de progression
    - M√©triques CPU/RAM en temps r√©el
    - Statistiques de performance

    Example:
        >>> with PerformanceMonitor("Backtest") as monitor:
        ...     for i, params in enumerate(param_grid):
        ...         run_backtest(params)
        ...         monitor.update(i + 1, len(param_grid))
    """

    def __init__(
        self,
        title: str = "Backtest",
        show_live: bool = True,
        refresh_rate: int = 4,
    ):
        """
        Initialise le moniteur.

        Args:
            title: Titre de l'op√©ration
            show_live: Afficher le dashboard live
            refresh_rate: Rafra√Æchissements par seconde
        """
        self.title = title
        self.show_live = show_live and HAS_RICH
        self.refresh_rate = refresh_rate

        self._tracker = ResourceTracker(interval=1.0 / refresh_rate)
        self._start_time: float = 0.0
        self._progress: int = 0
        self._total: int = 0
        self._status: str = "En attente..."
        self._live: Optional[Any] = None
        self._console: Optional[Any] = None

        if HAS_RICH:
            self._console = Console()

    def _build_display(self) -> Any:
        """Construit l'affichage rich."""
        if not HAS_RICH:
            return None

        # Stats actuelles
        snapshot = self._tracker.get_current()
        elapsed = time.time() - self._start_time

        # Table des m√©triques
        table = Table(title=f"üìä {self.title}", show_header=True)
        table.add_column("M√©trique", style="cyan")
        table.add_column("Valeur", style="green")

        table.add_row("‚è±Ô∏è  Temps √©coul√©", f"{elapsed:.1f}s")
        table.add_row("üìà Progression", f"{self._progress}/{self._total}")
        table.add_row("üíª CPU", f"{snapshot.cpu_percent:.1f}%")
        table.add_row("üß† RAM utilis√©e", f"{snapshot.memory_used_gb:.2f} GB")
        table.add_row("üìä RAM %", f"{snapshot.memory_percent:.1f}%")
        table.add_row("üìù Status", self._status)

        # Calcul ETA
        if self._progress > 0 and self._total > 0:
            avg_time = elapsed / self._progress
            remaining = (self._total - self._progress) * avg_time
            table.add_row("‚è≥ ETA", f"{remaining:.0f}s")

        return Panel(table, border_style="blue")

    def __enter__(self):
        """Context manager entry."""
        self._start_time = time.time()
        self._tracker.start()

        if self.show_live and HAS_RICH:
            self._live = Live(
                self._build_display(),
                console=self._console,
                refresh_per_second=self.refresh_rate,
            )
            self._live.__enter__()

        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        if self._live:
            self._live.__exit__(exc_type, exc_val, exc_tb)

        self._tracker.stop()
        return False

    def update(self, progress: int, total: int, status: str = ""):
        """
        Met √† jour la progression.

        Args:
            progress: Nombre de t√¢ches compl√©t√©es
            total: Nombre total de t√¢ches
            status: Message de status optionnel
        """
        self._progress = progress
        self._total = total
        if status:
            self._status = status
        else:
            self._status = f"Traitement {progress}/{total}..."

        if self._live:
            self._live.update(self._build_display())

    def set_status(self, status: str):
        """Met √† jour le message de status."""
        self._status = status
        if self._live:
            self._live.update(self._build_display())

    def get_stats(self) -> ResourceStats:
        """Retourne les statistiques de ressources."""
        return self._tracker.stop()


class ProgressBar:
    """
    Barre de progression simple avec rich.

    Example:
        >>> with ProgressBar("Running", total=100) as bar:
        ...     for _ in range(100):
        ...         bar.advance()
    """

    def __init__(self, description: str = "Processing", total: int = 100):
        self.description = description
        self.total = total
        self._progress: Optional[Any] = None
        self._task_id: Optional[int] = None

    def __enter__(self):
        if HAS_RICH:
            self._progress = Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                TimeElapsedColumn(),
                TimeRemainingColumn(),
            )
            self._progress.__enter__()
            self._task_id = self._progress.add_task(
                self.description, total=self.total
            )
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._progress:
            self._progress.__exit__(exc_type, exc_val, exc_tb)
        return False

    def advance(self, amount: int = 1):
        """Avance la progression."""
        if self._progress and self._task_id is not None:
            self._progress.update(self._task_id, advance=amount)

    def update(self, completed: int):
        """Met √† jour la progression √† une valeur sp√©cifique."""
        if self._progress and self._task_id is not None:
            self._progress.update(self._task_id, completed=completed)


# ======================== Fonctions utilitaires ========================

def print_system_info():
    """Affiche les informations syst√®me."""
    if HAS_RICH:
        console = Console()

        table = Table(title="üñ•Ô∏è Informations Syst√®me")
        table.add_column("Composant", style="cyan")
        table.add_column("Valeur", style="green")

        if HAS_PSUTIL:
            table.add_row("CPU (c≈ìurs)", str(psutil.cpu_count()))
            cpu_logical = psutil.cpu_count(logical=True)
            table.add_row("CPU (logiques)", str(cpu_logical))

            mem = psutil.virtual_memory()
            table.add_row("RAM totale", f"{mem.total / (1024**3):.1f} GB")
            mem_available_gb = mem.available / (1024**3)
            table.add_row("RAM disponible", f"{mem_available_gb:.1f} GB")

            # psutil.disk_usage("/") plante sur Windows (chemin sans drive).
            # Utiliser l'ancre du CWD.
            try:
                root_path = Path.cwd().anchor or os.path.abspath(os.sep)
                disk = psutil.disk_usage(root_path)
                disk_free_gb = disk.free / (1024**3)
                table.add_row("Disque disponible", f"{disk_free_gb:.1f} GB")
            except Exception:
                table.add_row("Disque disponible", "N/A")
        else:
            table.add_row("psutil", "Non disponible")

        console.print(table)
    else:
        print("=== Informations Syst√®me ===")
        if HAS_PSUTIL:
            print(f"CPU: {psutil.cpu_count()} c≈ìurs")
            mem = psutil.virtual_memory()
            ram_total_gb = mem.total / (1024**3)
            ram_available_gb = mem.available / (1024**3)
            print(
                f"RAM: {ram_total_gb:.1f} GB total, "
                f"{ram_available_gb:.1f} GB disponible"
            )


def get_system_resources() -> Dict[str, Any]:
    """Retourne un dict avec les ressources syst√®me."""
    resources = {
        "psutil_available": HAS_PSUTIL,
        "rich_available": HAS_RICH,
    }

    if HAS_PSUTIL:
        resources["cpu_count"] = psutil.cpu_count()
        resources["cpu_count_logical"] = psutil.cpu_count(logical=True)

        mem = psutil.virtual_memory()
        resources["memory_total_gb"] = mem.total / (1024**3)
        resources["memory_available_gb"] = mem.available / (1024**3)
        resources["memory_percent"] = mem.percent

        resources["cpu_percent"] = psutil.cpu_percent(interval=0.1)

    return resources
```
<!-- MODULE-END: monitor.py -->

<!-- MODULE-START: parallel.py -->
```json
{
  "name": "parallel.py",
  "path": "performance\\parallel.py",
  "ext": ".py",
  "anchor": "parallel_py"
}
```
## parallel_py
*Chemin* : `performance\parallel.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.parallel

Purpose: Parall√©lisation backtests - ProcessPoolExecutor/ThreadPoolExecutor + joblib.

Role in pipeline: performance optimization

Key components: ParallelRunner, parallel_sweep(), job chunking, progress tracking

Inputs: Function callable, param_grid, n_jobs (CPU count)

Outputs: List[results], timing stats, failure tracking

Dependencies: concurrent.futures, joblib (optionnel), numpy, pandas

Conventions: n_jobs=-1 (all CPUs); timeout protection; error aggregation.

Read-if: Modification parallelization strategy ou max_workers.

Skip-if: Vous appelez parallel_sweep(func, param_grid).
"""

from __future__ import annotations

import logging
import os
import time
from concurrent.futures import (
    ProcessPoolExecutor,
    ThreadPoolExecutor,
    as_completed,
    wait,
    FIRST_COMPLETED,
)
from dataclasses import dataclass
from typing import Any, Callable, Dict, Iterator, List, Optional

import numpy as np
import pandas as pd

# Joblib pour parall√©lisation simple (optionnel)
try:
    from joblib import Parallel, delayed
    HAS_JOBLIB = True
except ImportError:
    HAS_JOBLIB = False

# psutil pour monitoring ressources (optionnel)
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

logger = logging.getLogger(__name__)

# Shared worker state to avoid pickling large fixed kwargs per task.
_WORKER_FUNC: Optional[Callable[..., Any]] = None
_WORKER_KWARGS: Dict[str, Any] = {}


def _init_shared_worker(func: Callable[..., Any], fixed_kwargs: Dict[str, Any]) -> None:
    """Initialise un worker avec une fonction + kwargs partag√©s."""
    global _WORKER_FUNC, _WORKER_KWARGS
    _WORKER_FUNC = func
    _WORKER_KWARGS = fixed_kwargs


def _run_with_shared_kwargs(params: Dict[str, Any]) -> Any:
    """Ex√©cute la fonction partag√©e avec les kwargs stock√©s en worker."""
    if _WORKER_FUNC is None:
        raise RuntimeError("Worker non initialis√© (fonction manquante)")
    return _WORKER_FUNC(params, **_WORKER_KWARGS)


@dataclass
class ParallelConfig:
    """Configuration pour l'ex√©cution parall√®le."""
    max_workers: int = -1  # -1 = auto (nb CPU avec GPU multiplier)
    use_processes: bool = True  # True=multiprocessing, False=threading
    backend: str = "loky"  # Backend joblib: 'loky' (d√©faut, optimal), 'multiprocessing', 'threading'
    chunk_size: int = 10  # Taille des batches
    timeout: Optional[float] = None  # Timeout par t√¢che (secondes)
    memory_limit_gb: Optional[float] = None  # Limite m√©moire
    max_in_flight: Optional[int] = None  # Nombre max de t√¢ches en vol
    share_fixed_kwargs: bool = True  # Partager kwargs fixes via initializer
    continue_on_timeout: bool = False  # Continuer apr√®s un timeout

    # üöÄ NOUVEAUX PARAM√àTRES MULTI-GPU
    gpu_enabled: bool = True  # Activer optimisations GPU
    gpu_count: int = 2  # Nombre de GPUs disponibles
    gpu_memory_per_worker_mb: int = 2048  # M√©moire GPU par worker (MB)


@dataclass
class SweepResult:
    """R√©sultat d'un sweep parall√®le."""
    results: List[Dict[str, Any]]
    total_time: float
    n_completed: int
    n_failed: int
    avg_time_per_task: float
    memory_peak_gb: Optional[float] = None


def _get_cpu_count() -> int:
    """
    Retourne le nombre de CPUs optimis√© pour setup dual-GPU.

    Pour setup multi-GPU, utilise plus de threads pour alimenter les GPU
    et √©viter la sous-utilisation des cartes graphiques.
    """
    if HAS_PSUTIL:
        cpu_count = psutil.cpu_count(logical=False) or os.cpu_count() or 4
        # üöÄ OPTIMISATION DUAL-GPU: 1.5x plus de workers pour saturer les GPU
        gpu_multiplier = float(os.environ.get("BACKTEST_GPU_MULTIPLIER", "1.5"))
        optimized_count = int(cpu_count * gpu_multiplier)
        return max(cpu_count, optimized_count)
    return os.cpu_count() or 4


def _get_available_memory_gb() -> float:
    """Retourne la m√©moire disponible en GB."""
    if HAS_PSUTIL:
        try:
            return psutil.virtual_memory().available / (1024 ** 3)
        except Exception:
            pass
    return 8.0  # Valeur par d√©faut


def generate_param_grid(param_ranges: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    G√©n√®re toutes les combinaisons de param√®tres.

    Args:
        param_ranges: Dict avec {param_name: [values]} ou {param_name: value}

    Returns:
        Liste de dicts, chaque dict √©tant une combinaison de param√®tres

    Example:
        >>> grid = generate_param_grid({
        ...     "period": [10, 20, 30],
        ...     "threshold": [0.5, 1.0],
        ...     "leverage": 1  # Valeur fixe
        ... })
        >>> len(grid)  # 3 * 2 = 6 combinaisons
        6
    """
    import itertools

    # Normaliser: convertir valeurs scalaires en listes
    normalized = {}
    for key, value in param_ranges.items():
        if isinstance(value, (list, tuple, np.ndarray)):
            normalized[key] = list(value)
        else:
            normalized[key] = [value]

    # G√©n√©rer le produit cart√©sien
    keys = list(normalized.keys())
    values = list(normalized.values())

    combinations = []
    for combo in itertools.product(*values):
        combinations.append(dict(zip(keys, combo)))

    return combinations


def parallel_sweep(
    func: Callable,
    param_grid: List[Dict[str, Any]],
    n_jobs: int = -1,
    backend: str = "loky",
    verbose: int = 0,
    **fixed_kwargs
) -> List[Any]:
    """
    Ex√©cute une fonction sur une grille de param√®tres en parall√®le.

    Utilise joblib si disponible, sinon ProcessPoolExecutor.

    Args:
        func: Fonction √† appeler, signature: func(params, **fixed_kwargs)
        param_grid: Liste de dicts de param√®tres
        n_jobs: Nombre de workers (-1 = tous les CPUs)
        backend: Backend joblib ('loky', 'multiprocessing', 'threading')
        verbose: Niveau de verbosit√© (0-10)
        **fixed_kwargs: Arguments fixes pass√©s √† chaque appel

    Returns:
        Liste des r√©sultats dans le m√™me ordre que param_grid

    Example:
        >>> def run_backtest(params, data=None):
        ...     return {"params": params, "sharpe": 1.5}
        >>>
        >>> grid = [{"period": 10}, {"period": 20}]
        >>> results = parallel_sweep(run_backtest, grid, data=df)
    """
    if n_jobs == -1:
        n_jobs = _get_cpu_count()

    if HAS_JOBLIB:
        # Utiliser joblib (plus robuste et optimis√©)
        results = Parallel(n_jobs=n_jobs, backend=backend, verbose=verbose)(
            delayed(func)(params, **fixed_kwargs) for params in param_grid
        )
        return results
    else:
        # Fallback sur concurrent.futures
        logger.info("joblib non disponible, utilisation de ProcessPoolExecutor")
        results = [None] * len(param_grid)

        with ProcessPoolExecutor(max_workers=n_jobs) as executor:
            futures = {
                executor.submit(func, params, **fixed_kwargs): i
                for i, params in enumerate(param_grid)
            }

            for future in as_completed(futures):
                idx = futures[future]
                try:
                    results[idx] = future.result()
                except Exception as e:
                    logger.error(f"Erreur t√¢che {idx}: {e}")
                    results[idx] = {"error": str(e)}

        return results


class ParallelRunner:
    """
    Gestionnaire de backtests parall√®les avec monitoring et optimisation.

    Supporte:
    - Ex√©cution multi-processus ou multi-thread
    - Chunking automatique pour gestion m√©moire
    - Monitoring CPU/RAM en temps r√©el
    - Arr√™t anticip√© sur crit√®re

    Example:
        >>> runner = ParallelRunner(max_workers=8)
        >>>
        >>> param_grid = generate_param_grid({
        ...     "bb_period": range(15, 35, 5),
        ...     "atr_mult": [1.5, 2.0, 2.5]
        ... })
        >>>
        >>> results = runner.run_sweep(
        ...     strategy=my_strategy,
        ...     data=df,
        ...     param_grid=param_grid
        ... )
    """

    def __init__(
        self,
        max_workers: Optional[int] = None,
        use_processes: bool = True,
        backend: str = "loky",
        chunk_size: int = 50,
        memory_limit_gb: Optional[float] = None,
        max_in_flight: Optional[int] = None,
        share_fixed_kwargs: bool = True,
        task_timeout: Optional[float] = None,
        continue_on_timeout: bool = False,
    ):
        """
        Initialise le runner parall√®le.

        Args:
            max_workers: Nombre de workers (None = auto)
            use_processes: True=multiprocessing, False=threading
            backend: Backend joblib ('loky', 'multiprocessing', 'threading'). D√©faut='loky' (optimal)
            chunk_size: Taille des batches pour gestion m√©moire
            memory_limit_gb: Limite m√©moire (None = pas de limite)
            max_in_flight: Limite de t√¢ches simultan√©es soumises (None = auto)
            share_fixed_kwargs: Partager les kwargs fixes via initializer (processes)
            task_timeout: Timeout par t√¢che (secondes)
            continue_on_timeout: Continuer apr√®s timeout (sinon arr√™t)
        """
        self.max_workers = max_workers or self._calculate_optimal_workers()
        self.use_processes = use_processes
        self.backend = backend
        self.chunk_size = chunk_size
        self.memory_limit_gb = memory_limit_gb
        self.max_in_flight = max_in_flight
        self.share_fixed_kwargs = share_fixed_kwargs
        self.task_timeout = task_timeout
        self.continue_on_timeout = continue_on_timeout

        # √âtat
        self._stop_requested = False
        self._current_progress = 0
        self._total_tasks = 0

        # Callbacks
        self._progress_callback: Optional[Callable[[int, int], None]] = None

        # D√©terminer si on peut utiliser joblib
        self._use_joblib = HAS_JOBLIB and backend in ("loky", "multiprocessing", "threading")

        logger.info(
            f"ParallelRunner initialis√©: {self.max_workers} workers, "
            f"backend={'joblib-' + backend if self._use_joblib else ('processes' if use_processes else 'threads')}, "
            f"chunk_size={chunk_size}, max_in_flight={self.max_in_flight or 'auto'}"
        )

    def _calculate_optimal_workers(self) -> int:
        """Calcule le nombre optimal de workers."""
        cpu_count = _get_cpu_count()
        available_ram = _get_available_memory_gb()

        # Estimation: ~500MB par worker de backtest
        ram_limited_workers = int(available_ram / 0.5)

        optimal = min(cpu_count, ram_limited_workers)
        return max(1, optimal)

    def set_progress_callback(self, callback: Callable[[int, int], None]):
        """D√©finit un callback de progression: callback(completed, total)."""
        self._progress_callback = callback

    def request_stop(self):
        """Demande l'arr√™t du sweep en cours."""
        self._stop_requested = True
        logger.info("Arr√™t demand√© pour le sweep en cours")

    def _chunk_grid(self, param_grid: List[Dict]) -> Iterator[List[Dict]]:
        """Divise la grille en chunks pour gestion m√©moire."""
        for i in range(0, len(param_grid), self.chunk_size):
            yield param_grid[i:i + self.chunk_size]

    def run_sweep(
        self,
        run_func: Callable,
        param_grid: List[Dict[str, Any]],
        progress_callback: Optional[Callable[[int, int], None]] = None,
        **fixed_kwargs
    ) -> SweepResult:
        """
        Ex√©cute un sweep parall√®le complet (OPTIMIS√â avec joblib/loky par d√©faut).

        Args:
            run_func: Fonction de backtest, signature: run_func(params, **kwargs)
            param_grid: Liste des combinaisons de param√®tres
            progress_callback: Callback optionnel (completed, total)
            **fixed_kwargs: Arguments fixes (data, etc.)

        Returns:
            SweepResult avec tous les r√©sultats et m√©triques
        """
        self._stop_requested = False
        self._total_tasks = len(param_grid)
        self._current_progress = 0

        if progress_callback:
            self._progress_callback = progress_callback

        start_time = time.time()

        logger.info(
            f"D√©marrage sweep: {self._total_tasks} t√¢ches, "
            f"{self.max_workers} workers, backend={self.backend if self._use_joblib else 'executor'}"
        )

        if self._total_tasks == 0:
            return SweepResult(
                results=[],
                total_time=0.0,
                n_completed=0,
                n_failed=0,
                avg_time_per_task=0.0,
                memory_peak_gb=None,
            )

        # üöÄ PRIORIT√â: Utiliser joblib avec backend loky si disponible (meilleure gestion m√©moire)
        if self._use_joblib:
            return self._run_sweep_joblib(run_func, param_grid, **fixed_kwargs)
        else:
            return self._run_sweep_executor(run_func, param_grid, **fixed_kwargs)

    def _run_sweep_joblib(
        self,
        run_func: Callable,
        param_grid: List[Dict[str, Any]],
        **fixed_kwargs
    ) -> SweepResult:
        """
        Ex√©cution du sweep via joblib (loky/multiprocessing/threading).

        Avantages:
        - Pas de pickling r√©p√©titif du DataFrame (shared memory automatique avec loky)
        - Meilleure gestion des ressources
        - Plus stable pour gros volumes
        """
        start_time = time.time()
        all_results = []
        n_failed = 0
        memory_peak = 0.0

        logger.info(f"Utilisation de joblib backend={self.backend}")

        # Wrapper pour capturer les erreurs et faire le suivi de progression
        def _safe_run_with_progress(idx: int, params: Dict[str, Any]) -> Dict[str, Any]:
            try:
                result = run_func(params, **fixed_kwargs)
                return {
                    "idx": idx,
                    "params": params,
                    "result": result,
                    "success": True,
                }
            except Exception as e:
                logger.error(f"Erreur t√¢che {idx}: {e}")
                return {
                    "idx": idx,
                    "params": params,
                    "error": str(e),
                    "success": False,
                }

        # Ex√©cution parall√®le avec joblib en mode batch pour feedback temps r√©el
        try:
            # verbose=0 pour pas de sortie, 10+ pour debug
            verbose_level = int(os.environ.get("JOBLIB_VERBOSE", "0"))

            # Taille de batch pour callbacks p√©riodiques (trade-off overhead vs feedback)
            # Pour 1000+ t√¢ches: batch de 100, sinon batch de 50
            batch_size = 100 if self._total_tasks > 1000 else 50
            batch_size = min(batch_size, max(10, self._total_tasks // 10))

            logger.info(f"Joblib mode batch: {self._total_tasks} t√¢ches, batch_size={batch_size}")

            # Tracking temps pour logs p√©riodiques
            last_log_time = start_time
            batch_count = 0

            # Traiter par batch pour avoir des callbacks en temps r√©el
            for batch_start in range(0, self._total_tasks, batch_size):
                batch_end = min(batch_start + batch_size, self._total_tasks)
                batch_params = param_grid[batch_start:batch_end]

                # Ex√©cuter un batch
                batch_results = Parallel(
                    n_jobs=self.max_workers,
                    backend=self.backend,
                    verbose=verbose_level,
                )(
                    delayed(_safe_run_with_progress)(batch_start + i, params)
                    for i, params in enumerate(batch_params)
                )

                # Trier ce batch par index
                batch_results.sort(key=lambda x: x["idx"])

                # Traiter r√©sultats de ce batch imm√©diatement pour callbacks
                for r in batch_results:
                    if r["success"]:
                        all_results.append({
                            "params": r["params"],
                            "result": r["result"],
                            "success": True,
                        })
                    else:
                        all_results.append({
                            "params": r["params"],
                            "error": r.get("error", "Unknown error"),
                            "success": False,
                        })
                        n_failed += 1

                    # Callback de progression PENDANT l'ex√©cution
                    self._current_progress += 1
                    if self._progress_callback:
                        self._progress_callback(self._current_progress, self._total_tasks)

                # Logs p√©riodiques pour feedback (toutes les 5 batches ou 30s)
                batch_count += 1
                current_time = time.time()
                if batch_count % 5 == 0 or (current_time - last_log_time) >= 30.0:
                    elapsed = current_time - start_time
                    speed = self._current_progress / elapsed if elapsed > 0 else 0
                    logger.info(
                        f"Joblib progress: {self._current_progress}/{self._total_tasks} "
                        f"({self._current_progress/self._total_tasks*100:.1f}%) ‚Ä¢ "
                        f"{speed:.1f} tasks/s ‚Ä¢ batch {batch_count}"
                    )
                    last_log_time = current_time

                # Tracking m√©moire √† chaque batch
                if HAS_PSUTIL:
                    current_mem = psutil.virtual_memory().used / (1024 ** 3)
                    memory_peak = max(memory_peak, current_mem)

        except Exception as e:
            logger.error(f"Erreur fatale joblib: {e}")
            # Fallback sur executor
            logger.info("Repli sur ProcessPoolExecutor")
            return self._run_sweep_executor(run_func, param_grid, **fixed_kwargs)

        elapsed = time.time() - start_time
        n_completed = len([r for r in all_results if r.get("success")])

        logger.info(
            f"‚úÖ Sweep joblib termin√©: {n_completed}/{self._total_tasks} en {elapsed:.1f}s "
            f"({n_completed/elapsed:.1f} t√¢ches/s)"
        )

        return SweepResult(
            results=all_results,
            total_time=elapsed,
            n_completed=n_completed,
            n_failed=n_failed,
            avg_time_per_task=elapsed / self._total_tasks if self._total_tasks else 0.0,
            memory_peak_gb=memory_peak if memory_peak > 0 else None,
        )

    def _run_sweep_executor(
        self,
        run_func: Callable,
        param_grid: List[Dict[str, Any]],
        **fixed_kwargs
    ) -> SweepResult:
        """
        Ex√©cution du sweep via ProcessPoolExecutor/ThreadPoolExecutor (fallback).
        """
        start_time = time.time()
        all_results = []
        n_failed = 0
        memory_peak = 0.0

        # Choisir l'executor
        ExecutorClass = ProcessPoolExecutor if self.use_processes else ThreadPoolExecutor

        max_in_flight = self.max_in_flight
        if max_in_flight is None:
            max_in_flight = max(1, self.max_workers * 2)
        max_in_flight = min(max_in_flight, self._total_tasks)

        fixed_kwargs = dict(fixed_kwargs)
        use_shared_kwargs = (
            self.use_processes and self.share_fixed_kwargs and bool(fixed_kwargs)
        )

        executor_kwargs: Dict[str, Any] = {}
        submit_func = run_func
        submit_kwargs = fixed_kwargs
        if use_shared_kwargs:
            executor_kwargs = {
                "initializer": _init_shared_worker,
                "initargs": (run_func, fixed_kwargs),
            }
            submit_func = _run_with_shared_kwargs
            submit_kwargs = {}

        # ‚úÖ Executor unique + limite de t√¢ches en vol pour √©viter l'overhead m√©moire
        with ExecutorClass(max_workers=self.max_workers, **executor_kwargs) as executor:
            pending = {}
            submitted_at: Dict[Any, float] = {}
            param_iter = iter(param_grid)

            def submit_next() -> bool:
                try:
                    params = next(param_iter)
                except StopIteration:
                    return False
                future = executor.submit(submit_func, params, **submit_kwargs)
                pending[future] = params
                submitted_at[future] = time.time()
                return True

            for _ in range(max_in_flight):
                if not submit_next():
                    break

            while pending:
                if self._stop_requested:
                    logger.info("Sweep arr√™t√© par demande utilisateur")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break

                done, _ = wait(
                    pending,
                    timeout=0.2,
                    return_when=FIRST_COMPLETED,
                )

                if not done:
                    # Timeout par t√¢che si configur√©
                    if self.task_timeout is not None:
                        now = time.time()
                        timed_out = [
                            fut for fut, started in submitted_at.items()
                            if now - started > self.task_timeout
                        ]
                        for fut in timed_out:
                            params = pending.pop(fut, None)
                            submitted_at.pop(fut, None)
                            if params is None:
                                continue
                            fut.cancel()
                            all_results.append({
                                "params": params,
                                "error": f"timeout > {self.task_timeout}s",
                                "success": False,
                            })
                            n_failed += 1
                            self._current_progress += 1
                            if self._progress_callback:
                                self._progress_callback(self._current_progress, self._total_tasks)
                            if not self.continue_on_timeout:
                                self._stop_requested = True
                                break
                            if not self._stop_requested:
                                submit_next()
                    continue

                for future in done:
                    params = pending.pop(future)
                    submitted_at.pop(future, None)
                    try:
                        result = future.result()
                        all_results.append({
                            "params": params,
                            "result": result,
                            "success": True,
                        })
                    except Exception as e:
                        logger.error(f"Erreur: {params} -> {e}")
                        all_results.append({
                            "params": params,
                            "error": str(e),
                            "success": False,
                        })
                        n_failed += 1

                    self._current_progress += 1
                    if self._progress_callback:
                        self._progress_callback(self._current_progress, self._total_tasks)

                    # Tracking m√©moire p√©riodique (tous les 10 r√©sultats pour √©viter overhead)
                    if HAS_PSUTIL and self._current_progress % 10 == 0:
                        current_mem = psutil.virtual_memory().used / (1024 ** 3)
                        memory_peak = max(memory_peak, current_mem)

                        # V√©rifier limite m√©moire
                        if self.memory_limit_gb and current_mem > self.memory_limit_gb:
                            logger.warning(f"Limite m√©moire atteinte: {current_mem:.1f} GB")
                            executor.shutdown(wait=False, cancel_futures=True)
                            self._stop_requested = True
                            break

                    if not self._stop_requested:
                        submit_next()

        elapsed = time.time() - start_time
        n_completed = len([r for r in all_results if r.get("success")])

        logger.info(
            f"‚úÖ Sweep termin√©: {n_completed}/{self._total_tasks} en {elapsed:.1f}s "
            f"({n_completed/elapsed:.1f} t√¢ches/s)"
        )

        return SweepResult(
            results=all_results,
            total_time=elapsed,
            n_completed=n_completed,
            n_failed=n_failed,
            avg_time_per_task=elapsed / max(1, len(all_results)),
            memory_peak_gb=memory_peak if memory_peak > 0 else None
        )


def run_backtest_worker(
    params: Dict[str, Any],
    strategy_class: type,
    data: pd.DataFrame,
    indicators: Dict[str, Any],
) -> Dict[str, Any]:
    """
    Worker function pour ex√©cuter un backtest (picklable).

    Args:
        params: Param√®tres de la strat√©gie
        strategy_class: Classe de strat√©gie √† instancier
        data: DataFrame OHLCV
        indicators: Indicateurs pr√©calcul√©s

    Returns:
        Dict avec params et m√©triques de performance
    """
    try:
        strategy = strategy_class()
        result = strategy.run(data, indicators, params)

        # Calculer m√©triques simples
        signals = result.signals
        n_trades = int(np.sum(signals != 0))

        return {
            "params": params,
            "n_trades": n_trades,
            "success": True
        }
    except Exception as e:
        return {
            "params": params,
            "error": str(e),
            "success": False
        }


# ======================== Utilitaires de benchmark ========================

def benchmark_parallel_configs(
    func: Callable,
    sample_params: List[Dict],
    configs: Optional[List[ParallelConfig]] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    Benchmark diff√©rentes configurations parall√®les.

    Args:
        func: Fonction √† tester
        sample_params: √âchantillon de param√®tres
        configs: Liste de configurations √† tester (None = auto)
        **kwargs: Arguments fixes pour func

    Returns:
        Dict avec meilleure config et r√©sultats de benchmark
    """
    if configs is None:
        cpu_count = _get_cpu_count()
        configs = [
            ParallelConfig(max_workers=cpu_count // 2, use_processes=True),
            ParallelConfig(max_workers=cpu_count, use_processes=True),
            ParallelConfig(max_workers=cpu_count * 2, use_processes=True),
            ParallelConfig(max_workers=cpu_count, use_processes=False),  # threading
        ]

    results = []

    for config in configs:
        runner = ParallelRunner(
            max_workers=config.max_workers,
            use_processes=config.use_processes,
            backend=getattr(config, "backend", "loky"),  # Utilise backend de config ou loky par d√©faut
            chunk_size=config.chunk_size,
            memory_limit_gb=config.memory_limit_gb,
            max_in_flight=config.max_in_flight,
            share_fixed_kwargs=config.share_fixed_kwargs,
            task_timeout=config.timeout,
            continue_on_timeout=config.continue_on_timeout,
        )

        start = time.time()
        runner.run_sweep(func, sample_params[:min(20, len(sample_params))], **kwargs)
        elapsed = time.time() - start

        results.append({
            "config": config,
            "elapsed": elapsed,
            "throughput": len(sample_params) / elapsed if elapsed > 0 else 0
        })

        logger.info(
            f"Config: {config.max_workers} workers, "
            f"{'process' if config.use_processes else 'thread'} -> "
            f"{elapsed:.2f}s ({results[-1]['throughput']:.1f} t√¢ches/s)"
        )

    # Trouver la meilleure config
    best = max(results, key=lambda x: x["throughput"])

    return {
        "best_config": best["config"],
        "best_throughput": best["throughput"],
        "all_results": results
    }
```
<!-- MODULE-END: parallel.py -->

<!-- MODULE-START: profiler.py -->
```json
{
  "name": "profiler.py",
  "path": "performance\\profiler.py",
  "ext": ".py",
  "anchor": "profiler_py"
}
```
## profiler_py
*Chemin* : `performance\profiler.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.profiler

Purpose: Profiling cProfile/line_profiler - identifie goulots d'√©tranglement (CPU, ligne).

Role in pipeline: performance optimization

Key components: Profiler, ProfileStats, @profile_function decorator, save_report()

Inputs: Function/code block √† profiler

Outputs: Stats {duration_ms, top_functions[], line_stats}, text report

Dependencies: cProfile, pstats, functools, time, pathlib

Conventions: Context manager support; CSV export; @profile decorator.

Read-if: Modification profiling strategy ou report format.

Skip-if: Vous appelez Profiler.start() ‚Üí stop() ‚Üí print_stats().
"""

from __future__ import annotations

import cProfile
import functools
import io
import logging
import os
import pstats
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, TypeVar

logger = logging.getLogger(__name__)

# line_profiler (optionnel)
try:
    from line_profiler import LineProfiler
    HAS_LINE_PROFILER = True
except ImportError:
    HAS_LINE_PROFILER = False

# memory_profiler (optionnel)
try:
    from memory_profiler import memory_usage
    HAS_MEMORY_PROFILER = True
except ImportError:
    HAS_MEMORY_PROFILER = False

F = TypeVar("F", bound=Callable[..., Any])


@dataclass
class ProfileResult:
    """R√©sultat d'un profiling."""
    name: str
    total_time: float
    n_calls: int
    top_functions: List[Dict[str, Any]]
    memory_peak_mb: Optional[float] = None


class Profiler:
    """
    Profiler flexible avec support cProfile et line_profiler.

    Example:
        >>> profiler = Profiler("backtest_run")
        >>> profiler.start()
        >>>
        >>> result = engine.run(...)
        >>>
        >>> profiler.stop()
        >>> profiler.print_stats(top_n=20)
        >>> profiler.save_report("profile_output.txt")
    """

    def __init__(self, name: str = "profile", output_dir: Optional[str] = None):
        """
        Initialise le profiler.

        Args:
            name: Nom du profil (pour fichiers de sortie)
            output_dir: R√©pertoire de sortie (None = r√©pertoire courant)
        """
        self.name = name
        self.output_dir = Path(output_dir) if output_dir else Path(".")

        self._profiler: Optional[cProfile.Profile] = None
        self._stats: Optional[pstats.Stats] = None
        self._start_time: float = 0.0
        self._end_time: float = 0.0
        self._is_running = False

    def start(self):
        """D√©marre le profiling."""
        if self._is_running:
            logger.warning("Profiler d√©j√† en cours")
            return

        self._profiler = cProfile.Profile()
        self._profiler.enable()
        self._start_time = time.time()
        self._is_running = True

        logger.debug(f"Profiler '{self.name}' d√©marr√©")

    def stop(self) -> ProfileResult:
        """
        Arr√™te le profiling et retourne les r√©sultats.

        Returns:
            ProfileResult avec les statistiques
        """
        if not self._is_running:
            logger.warning("Profiler non d√©marr√©")
            return ProfileResult(
                name=self.name,
                total_time=0.0,
                n_calls=0,
                top_functions=[],
            )

        self._end_time = time.time()
        self._profiler.disable()
        self._is_running = False

        # Cr√©er les stats
        stream = io.StringIO()
        self._stats = pstats.Stats(self._profiler, stream=stream)

        # Extraire les top fonctions
        self._stats.sort_stats("cumulative")

        top_functions = []
        for func, (cc, nc, tt, ct, callers) in list(self._stats.stats.items())[:20]:
            filename, lineno, name = func
            top_functions.append({
                "function": name,
                "file": filename,
                "line": lineno,
                "calls": nc,
                "total_time": tt,
                "cumulative_time": ct,
            })

        total_time = self._end_time - self._start_time
        n_calls = sum(s[1] for s in self._stats.stats.values())

        logger.debug(f"Profiler '{self.name}' arr√™t√©: {total_time:.2f}s, {n_calls} appels")

        return ProfileResult(
            name=self.name,
            total_time=total_time,
            n_calls=n_calls,
            top_functions=top_functions,
        )

    def __enter__(self):
        """Context manager entry."""
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        self.stop()
        return False

    def print_stats(self, top_n: int = 20, sort_by: str = "cumulative"):
        """
        Affiche les statistiques de profiling.

        Args:
            top_n: Nombre de fonctions √† afficher
            sort_by: Crit√®re de tri ('cumulative', 'time', 'calls')
        """
        if not self._stats:
            logger.warning("Pas de stats disponibles - avez-vous appel√© stop()?")
            return

        print(f"\n{'='*60}")
        print(f"PROFILING REPORT: {self.name}")
        print(f"{'='*60}")
        print(f"Total time: {self._end_time - self._start_time:.3f}s")
        print(f"{'='*60}\n")

        self._stats.sort_stats(sort_by)
        self._stats.print_stats(top_n)

    def save_report(self, filename: Optional[str] = None):
        """
        Sauvegarde le rapport de profiling.

        Args:
            filename: Nom du fichier (None = auto-g√©n√©r√©)
        """
        if not self._stats:
            logger.warning("Pas de stats disponibles")
            return

        if filename is None:
            filename = f"{self.name}_{int(time.time())}.prof"

        filepath = self.output_dir / filename

        # Sauvegarder le fichier binaire .prof
        if filepath.suffix == ".prof":
            self._profiler.dump_stats(str(filepath))
            logger.info(f"Profil binaire sauv√©: {filepath}")

            # Aussi sauvegarder une version texte
            txt_path = filepath.with_suffix(".txt")
            with open(txt_path, "w") as f:
                stats = pstats.Stats(self._profiler, stream=f)
                stats.sort_stats("cumulative")
                stats.print_stats(50)
            logger.info(f"Rapport texte sauv√©: {txt_path}")
        else:
            # Sauvegarder uniquement le texte
            with open(filepath, "w") as f:
                stats = pstats.Stats(self._profiler, stream=f)
                stats.sort_stats("cumulative")
                stats.print_stats(50)
            logger.info(f"Rapport sauv√©: {filepath}")

    def get_slowest_functions(self, n: int = 10) -> List[Dict[str, Any]]:
        """
        Retourne les N fonctions les plus lentes.

        Args:
            n: Nombre de fonctions

        Returns:
            Liste de dicts avec infos sur chaque fonction
        """
        if not self._stats:
            return []

        self._stats.sort_stats("cumulative")

        slowest = []
        for func, (cc, nc, tt, ct, callers) in list(self._stats.stats.items())[:n]:
            filename, lineno, name = func
            slowest.append({
                "function": name,
                "file": os.path.basename(filename),
                "line": lineno,
                "calls": nc,
                "total_time_ms": tt * 1000,
                "cumulative_time_ms": ct * 1000,
                "time_per_call_ms": (ct / nc * 1000) if nc > 0 else 0,
            })

        return slowest


def profile_function(func: F) -> F:
    """
    D√©corateur pour profiler une fonction.

    Affiche les statistiques de temps apr√®s chaque appel.

    Example:
        >>> @profile_function
        >>> def slow_function():
        ...     time.sleep(1)
        ...     return 42
        >>>
        >>> result = slow_function()
        # Affiche: slow_function executed in 1.001s
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()

        start = time.time()
        try:
            result = func(*args, **kwargs)
        finally:
            profiler.disable()
            elapsed = time.time() - start

            # Afficher un r√©sum√©
            stats = pstats.Stats(profiler)
            stats.sort_stats("cumulative")

            print(f"\n‚è±Ô∏è  {func.__name__} executed in {elapsed:.3f}s")
            print("   Top 5 internal calls:")

            for i, (key, val) in enumerate(list(stats.stats.items())[:5]):
                filename, lineno, name = key
                _, nc, tt, ct, _ = val
                print(f"   {i+1}. {name}: {ct*1000:.1f}ms ({nc} calls)")

        return result

    return wrapper  # type: ignore


def profile_memory(func: F) -> F:
    """
    D√©corateur pour profiler la m√©moire d'une fonction.

    N√©cessite memory_profiler install√©.

    Example:
        >>> @profile_memory
        >>> def memory_hungry():
        ...     data = [i for i in range(1000000)]
        ...     return len(data)
    """
    if not HAS_MEMORY_PROFILER:
        logger.warning("memory_profiler non disponible - d√©corateur ignor√©")
        return func

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        # Mesurer usage m√©moire
        mem_before = memory_usage(-1, interval=0.1, timeout=1)[0]

        result = func(*args, **kwargs)

        mem_after = memory_usage(-1, interval=0.1, timeout=1)[0]
        mem_diff = mem_after - mem_before

        print(f"\nüß† {func.__name__} memory:")
        print(f"   Before: {mem_before:.1f} MB")
        print(f"   After:  {mem_after:.1f} MB")
        print(f"   Delta:  {mem_diff:+.1f} MB")

        return result

    return wrapper  # type: ignore


class TimingContext:
    """
    Context manager simple pour mesurer le temps.

    Example:
        >>> with TimingContext("data_loading"):
        ...     df = pd.read_csv("large_file.csv")
        # Affiche: data_loading: 2.345s
    """

    def __init__(self, name: str, verbose: bool = True):
        self.name = name
        self.verbose = verbose
        self.elapsed: float = 0.0

    def __enter__(self):
        self._start = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.elapsed = time.time() - self._start
        if self.verbose:
            print(f"‚è±Ô∏è  {self.name}: {self.elapsed:.3f}s")
        return False


class LineProfilerWrapper:
    """
    Wrapper pour line_profiler avec API simplifi√©e.

    N√©cessite line_profiler install√©.

    Example:
        >>> lp = LineProfilerWrapper()
        >>> lp.add_function(my_slow_function)
        >>>
        >>> lp.run(my_slow_function, arg1, arg2)
        >>> lp.print_stats()
    """

    def __init__(self):
        if not HAS_LINE_PROFILER:
            raise ImportError(
                "line_profiler non install√©. "
                "Installez avec: pip install line_profiler"
            )

        self._profiler = LineProfiler()
        self._functions: List[Callable] = []

    def add_function(self, func: Callable):
        """Ajoute une fonction √† profiler."""
        self._profiler.add_function(func)
        self._functions.append(func)

    def run(self, func: Callable, *args, **kwargs) -> Any:
        """
        Ex√©cute une fonction avec profiling ligne par ligne.

        Args:
            func: Fonction √† ex√©cuter
            *args, **kwargs: Arguments de la fonction

        Returns:
            R√©sultat de la fonction
        """
        if func not in self._functions:
            self.add_function(func)

        return self._profiler.runcall(func, *args, **kwargs)

    def print_stats(self):
        """Affiche les statistiques ligne par ligne."""
        self._profiler.print_stats()

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques sous forme de dict."""
        stats = {}

        for func, timings in self._profiler.get_stats().timings.items():
            filename, start_line, name = func

            lines = []
            for lineno, nhits, time_ns in timings:
                lines.append({
                    "line": lineno,
                    "hits": nhits,
                    "time_us": time_ns / 1000,  # ns -> us
                })

            stats[name] = {
                "file": filename,
                "start_line": start_line,
                "lines": lines,
            }

        return stats


# ======================== Fonctions utilitaires ========================

def run_with_profiling(
    func: Callable,
    *args,
    output_file: Optional[str] = None,
    **kwargs
) -> Any:
    """
    Ex√©cute une fonction avec profiling complet.

    Args:
        func: Fonction √† profiler
        *args: Arguments positionnels
        output_file: Fichier de sortie optionnel
        **kwargs: Arguments nomm√©s

    Returns:
        R√©sultat de la fonction
    """
    profiler = Profiler(func.__name__)
    profiler.start()

    try:
        result = func(*args, **kwargs)
    finally:
        profiler.stop()
        profiler.print_stats(top_n=15)

        if output_file:
            profiler.save_report(output_file)

    return result


def benchmark_function(
    func: Callable,
    *args,
    n_runs: int = 10,
    warmup: int = 2,
    **kwargs
) -> Dict[str, float]:
    """
    Benchmark une fonction avec statistiques.

    Args:
        func: Fonction √† benchmarker
        *args: Arguments positionnels
        n_runs: Nombre d'ex√©cutions
        warmup: Nombre d'ex√©cutions de warmup
        **kwargs: Arguments nomm√©s

    Returns:
        Dict avec min, max, mean, std des temps
    """
    import statistics

    # Warmup
    for _ in range(warmup):
        func(*args, **kwargs)

    # Benchmark
    times = []
    for _ in range(n_runs):
        start = time.time()
        func(*args, **kwargs)
        times.append(time.time() - start)

    return {
        "min_ms": min(times) * 1000,
        "max_ms": max(times) * 1000,
        "mean_ms": statistics.mean(times) * 1000,
        "std_ms": statistics.stdev(times) * 1000 if len(times) > 1 else 0,
        "n_runs": n_runs,
    }
```
<!-- MODULE-END: profiler.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "performance\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `performance\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: performance.__init__

Purpose: Package performance - exports profiler, parallel, monitor, GPU, benchmarks.

Role in pipeline: performance optimization & observability

Key components: Re-exports ParallelRunner, Profiler, PerformanceMonitor, GPUIndicatorCalculator

Inputs: None (module imports only)

Outputs: Public API via __all__

Dependencies: .profiler, .parallel, .monitor, .memory, .gpu, .device_backend, .benchmark

Conventions: __all__ d√©finit API publique; imports conditionnels pour optional deps.

Read-if: Modification exports ou module structure.

Skip-if: Vous importez directement depuis performance.profiler.
"""

from performance.gpu import (
    GPUIndicatorCalculator,
    benchmark_gpu_cpu,
    get_gpu_info,
    gpu_available,
    to_cpu,
    to_gpu,
)
from performance.memory import (
    ChunkedProcessor,
    DataFrameCache,
    MemoryManager,
    MemoryStats,
    estimate_memory_needed,
    get_available_ram_gb,
    get_memory_info,
    memory_efficient_mode,
    optimize_dataframe,
)
from performance.monitor import (
    PerformanceMonitor,
    ProgressBar,
    ResourceStats,
    ResourceTracker,
    get_system_resources,
    print_system_info,
)
from performance.parallel import (
    ParallelConfig,
    ParallelRunner,
    SweepResult,
    benchmark_parallel_configs,
    generate_param_grid,
    parallel_sweep,
)
from performance.profiler import (
    Profiler,
    ProfileResult,
    TimingContext,
    benchmark_function,
    profile_function,
    profile_memory,
    run_with_profiling,
)

__all__ = [
    # Parallel
    "ParallelRunner",
    "ParallelConfig",
    "SweepResult",
    "parallel_sweep",
    "generate_param_grid",
    "benchmark_parallel_configs",
    # Monitor
    "PerformanceMonitor",
    "ResourceTracker",
    "ResourceStats",
    "ProgressBar",
    "print_system_info",
    "get_system_resources",
    # Profiler
    "Profiler",
    "ProfileResult",
    "profile_function",
    "profile_memory",
    "TimingContext",
    "run_with_profiling",
    "benchmark_function",
    # Memory
    "ChunkedProcessor",
    "MemoryManager",
    "DataFrameCache",
    "MemoryStats",
    "get_memory_info",
    "get_available_ram_gb",
    "optimize_dataframe",
    "estimate_memory_needed",
    "memory_efficient_mode",
    # GPU
    "GPUIndicatorCalculator",
    "gpu_available",
    "get_gpu_info",
    "to_gpu",
    "to_cpu",
    "benchmark_gpu_cpu",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: base.py -->
```json
{
  "name": "base.py",
  "path": "strategies\\base.py",
  "ext": ".py",
  "anchor": "base_py"
}
```
## base_py
*Chemin* : `strategies\base.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.base

Purpose: Classe abstraite et contrat pour toutes les strat√©gies de trading.

Role in pipeline: core

Key components: StrategyBase (abstract), StrategyResult (dataclass), register_strategy (decorator)

Inputs: DataFrame OHLCV, param√®tres utilisateur, indicateurs pr√©-calcul√©s

Outputs: StrategyResult (signaux, prix, stop/target, metadata)

Dependencies: pandas, numpy, utils.parameters, dataclasses

Conventions: Signaux standardis√©s (1=long, -1=short, 0=flat); param√®tres clamp√©s aux bornes; indicateurs calcul√©s ou fournis; preset/granularit√© support.

Read-if: Cr√©ation nouvelle strat√©gie, modification interface ou patterns standards.

Skip-if: Vous ne changez qu'une strat√©gie sp√©cifique.
"""

import os
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Type

import numpy as np
import pandas as pd

from utils.parameters import ParameterSpec, Preset


@dataclass
class StrategyResult:
    """
    R√©sultat d'une ex√©cution de strat√©gie.

    Attributes:
        signals: S√©rie de signaux (1=long, -1=short, 0=flat)
        entry_prices: Prix d'entr√©e sugg√©r√©s (optionnel)
        stop_losses: Niveaux de stop-loss (optionnel)
        take_profits: Niveaux de take-profit (optionnel)
        indicators: Dict des indicateurs calcul√©s
        metadata: Informations additionnelles
        params_used: Param√®tres utilis√©s pour l'ex√©cution
    """
    signals: pd.Series
    entry_prices: Optional[np.ndarray] = None
    stop_losses: Optional[np.ndarray] = None
    take_profits: Optional[np.ndarray] = None
    indicators: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    params_used: Dict[str, Any] = field(default_factory=dict)


class StrategyBase(ABC):
    """
    Classe de base abstraite pour les strat√©gies de trading.

    Toute strat√©gie doit h√©riter de cette classe et impl√©menter:
    - required_indicators: liste des indicateurs n√©cessaires
    - generate_signals(): g√©n√©ration des signaux de trading

    Architecture con√ßue pour:
    1. √ätre utilis√©e de mani√®re autonome par le moteur de backtest
    2. Permettre une future int√©gration avec des agents LLM
    3. Supporter diff√©rents styles de trading (trend, mean-reversion, etc.)

    Example:
        class MyStrategy(StrategyBase):
            @property
            def required_indicators(self):
                return ["bollinger", "rsi"]

            def generate_signals(self, df, indicators, params):
                # Logique de g√©n√©ration de signaux
                ...
    """

    def __init__(self, name: str = "BaseStrategy"):
        """
        Initialise la strat√©gie.

        Args:
            name: Nom identifiant la strat√©gie
        """
        self.name = name
        self._last_result: Optional[StrategyResult] = None

    @property
    @abstractmethod
    def required_indicators(self) -> List[str]:
        """
        Liste des indicateurs techniques requis par la strat√©gie.

        Le moteur de backtest utilisera cette liste pour calculer
        automatiquement les indicateurs n√©cessaires avant d'appeler
        generate_signals().

        Returns:
            Liste de noms d'indicateurs (ex: ["bollinger", "atr"])
        """
        pass

    @property
    def default_params(self) -> Dict[str, Any]:
        """
        Param√®tres par d√©faut de la strat√©gie.

        Peut √™tre surcharg√© par les classes filles pour d√©finir
        des valeurs par d√©faut sp√©cifiques.
        """
        return {}

    @property
    def param_ranges(self) -> Dict[str, tuple]:
        """
        Plages de param√®tres pour l'optimisation.

        Format: {"param_name": (min_value, max_value)}
        G√©n√®re automatiquement depuis parameter_specs si disponible.
        Peut √™tre surcharg√© par les classes filles.
        """
        return self.get_param_ranges()

    def _should_include_optional_params(
        self,
        override: Optional[bool] = None,
    ) -> bool:
        """D√©termine si les param√®tres optionnels (ex: leverage) sont inclus."""
        if override is not None:
            return bool(override)

        if getattr(self, "_include_optional_params", False):
            return True

        env_flag = os.getenv("BACKTEST_INCLUDE_OPTIONAL_PARAMS", "").strip().lower()
        return env_flag in {"1", "true", "yes", "on"}

    def get_param_ranges(self, include_optional: Optional[bool] = None) -> Dict[str, tuple]:
        """Retourne les plages en excluant les param√®tres non optimisables par d√©faut."""
        include = self._should_include_optional_params(override=include_optional)

        if hasattr(self, 'parameter_specs') and self.parameter_specs:
            items = self.parameter_specs.items()
            if not include:
                items = (
                    (name, spec)
                    for name, spec in items
                    if getattr(spec, "optimize", True)
                )
            return {
                name: (spec.min_val, spec.max_val)
                for name, spec in items
            }
        return {}

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Retourne les parametres a passer a l'indicateur.

        Les strategies peuvent surcharger cette methode pour mapper leurs
        parametres internes vers ceux attendus par les indicateurs.
        """
        params = params or {}

        prefix_map = {
            "bollinger": "bb_",
            "atr": "atr_",
            "rsi": "rsi_",
            "ema": "ema_",
            "macd": "macd_",
        }

        prefix = prefix_map.get(indicator_name, f"{indicator_name}_")
        indicator_params: Dict[str, Any] = {}

        for key, value in params.items():
            if key.startswith(prefix):
                param_name = key[len(prefix):]
                indicator_params[param_name] = value

        if indicator_name == "bollinger" and "std" in indicator_params:
            indicator_params.setdefault("std_dev", indicator_params.pop("std"))

        direct_params = {
            "bollinger": ["period", "std_dev"],
            "atr": ["period", "method"],
            "rsi": ["period"],
            "ema": ["period"],
            "macd": ["fast_period", "slow_period", "signal_period"],
        }

        for param in direct_params.get(indicator_name, []):
            if param in params and param not in indicator_params:
                indicator_params[param] = params[param]

        return indicator_params

    @abstractmethod
    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re les signaux de trading.

        Args:
            df: DataFrame OHLCV avec colonnes (open, high, low, close, volume)
            indicators: Dict des indicateurs pr√©calcul√©s
                       Ex: {"bollinger": (upper, middle, lower), "atr": atr_array}
            params: Param√®tres de la strat√©gie
                   Ex: {"entry_z": 2.0, "k_sl": 1.5}

        Returns:
            pd.Series de signaux index√©e par le temps:
            - 1: Signal d'achat (entrer long)
            - -1: Signal de vente (entrer short)
            - 0: Aucun signal (rester flat ou maintenir position)

        Notes:
            - La s√©rie retourn√©e doit avoir le m√™me index que df
            - Les signaux repr√©sentent des intentions d'entr√©e/sortie
            - La gestion des positions est faite par le moteur de backtest
        """
        pass

    def run(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Optional[Dict[str, Any]] = None
    ) -> StrategyResult:
        """
        Ex√©cute la strat√©gie et retourne le r√©sultat complet.

        Cette m√©thode wrapper facilite l'utilisation et stocke
        le r√©sultat pour inspection ult√©rieure.

        Args:
            df: DataFrame OHLCV
            indicators: Dict des indicateurs calcul√©s
            params: Param√®tres (utilise default_params si None)

        Returns:
            StrategyResult avec signaux et m√©tadonn√©es
        """
        # Fusionner avec params par d√©faut
        final_params = {**self.default_params, **(params or {})}

        # G√©n√©rer les signaux
        signals = self.generate_signals(df, indicators, final_params)

        # Construire le r√©sultat
        result = StrategyResult(
            signals=signals,
            indicators=indicators,
            metadata={
                "strategy_name": self.name,
                "params": final_params,
                "n_signals_long": int((signals == 1).sum()),
                "n_signals_short": int((signals == -1).sum()),
                "period": f"{df.index[0]} ‚Üí {df.index[-1]}"
            }
        )

        self._last_result = result
        return result

    def validate_params(self, params: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        Valide les param√®tres fournis.

        Peut √™tre surcharg√© pour ajouter une validation sp√©cifique.

        Args:
            params: Param√®tres √† valider

        Returns:
            Tuple (is_valid, list_of_errors)
        """
        errors = []

        # Validation de base (√† surcharger)
        if params.get("leverage", 1) <= 0:
            errors.append("leverage doit √™tre > 0")
        if params.get("leverage", 1) > 10:
            errors.append("leverage doit √™tre <= 10")

        return len(errors) == 0, errors

    def describe(self) -> str:
        """
        Retourne une description de la strat√©gie.
        """
        return f"""
Strategy: {self.name}
Required Indicators: {', '.join(self.required_indicators)}
Default Parameters: {self.default_params}
"""

    def __repr__(self) -> str:
        return f"<{self.__class__.__name__}(name='{self.name}')>"

    # =========================================================================
    # HOOKS POUR INT√âGRATION FUTURE LLM
    # =========================================================================
    # Ces m√©thodes sont des points d'extension pour les agents LLM.
    # Elles ne font rien par d√©faut mais peuvent √™tre surcharg√©es
    # par des strat√©gies dynamiques g√©n√©r√©es par LLM.

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """
        Sp√©cifications d√©taill√©es des param√®tres pour UI et optimisation.

        Surchargez cette propri√©t√© pour d√©finir les bornes, types et
        descriptions de chaque param√®tre. Utilis√© par:
        - L'UI pour g√©n√©rer des sliders/inputs
        - L'optimiseur pour le sweep param√©trique
        - Les agents LLM pour proposer des modifications

        Returns:
            Dict[param_name, ParameterSpec]
        """
        return {}

    def get_preset(self) -> Optional[Preset]:
        """
        Retourne le preset associ√© √† cette strat√©gie (si disponible).

        Returns:
            Preset ou None
        """
        return None

    def on_backtest_start(self, context: Dict[str, Any]) -> None:
        """
        Hook appel√© au d√©but du backtest.

        Point d'extension pour les agents LLM qui veulent
        initialiser un √©tat ou modifier le contexte.

        Args:
            context: Contexte du backtest (symbol, timeframe, etc.)
        """
        pass

    def on_backtest_end(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        Hook appel√© √† la fin du backtest.

        Point d'extension pour les agents LLM qui veulent
        analyser les r√©sultats ou proposer des am√©liorations.

        Args:
            results: R√©sultats du backtest (m√©triques, trades, etc.)

        Returns:
            R√©sultats potentiellement enrichis avec des suggestions
        """
        return results

    def suggest_improvements(
        self,
        results: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        Sugg√®re des am√©liorations bas√©es sur les r√©sultats.

        Cette m√©thode sera utilis√©e par les agents LLM pour
        proposer des ajustements de param√®tres ou de logique.
        Par d√©faut retourne None (pas de suggestion).

        Args:
            results: R√©sultats du backtest

        Returns:
            Dict de suggestions ou None
            Format attendu: {"params": {...}, "rationale": "..."}
        """
        return None

    @classmethod
    def from_config(cls, config: Dict[str, Any]) -> "StrategyBase":
        """
        Factory method pour cr√©er une strat√©gie depuis une config.

        Permet aux agents LLM de g√©n√©rer des configurations JSON
        qui seront instanci√©es en strat√©gies.

        Args:
            config: Configuration dict avec 'name', 'params', etc.

        Returns:
            Instance de strat√©gie
        """
        # Par d√©faut, retourne une instance simple
        # Les sous-classes peuvent surcharger pour une logique plus complexe
        return cls()


# =============================================================================
# REGISTRE DES STRAT√âGIES
# =============================================================================

_STRATEGY_REGISTRY: Dict[str, Type[StrategyBase]] = {}


def register_strategy(name: str):
    """
    D√©corateur pour enregistrer une strat√©gie dans le registre.

    Usage:
        @register_strategy("bollinger_atr")
        class BollingerATRStrategy(StrategyBase):
            ...
    """
    def decorator(cls: Type[StrategyBase]):
        _STRATEGY_REGISTRY[name] = cls
        return cls
    return decorator


def get_strategy(name: str) -> Type[StrategyBase]:
    """R√©cup√®re une classe de strat√©gie par son nom."""
    if name not in _STRATEGY_REGISTRY:
        available = ", ".join(_STRATEGY_REGISTRY.keys())
        raise ValueError(f"Strat√©gie '{name}' non trouv√©e. Disponibles: {available}")
    return _STRATEGY_REGISTRY[name]


def list_strategies() -> List[str]:
    """Liste les strat√©gies enregistr√©es."""
    return list(_STRATEGY_REGISTRY.keys())


def create_strategy(name: str, **kwargs) -> StrategyBase:
    """Cr√©e une instance de strat√©gie par son nom."""
    strategy_cls = get_strategy(name)
    return strategy_cls(**kwargs)


def get_strategy_overview(name: str, max_chars: int = 1800) -> str:
    """
    Construit un r√©sum√© compact de la strat√©gie pour contexte LLM.

    Utilise describe() si disponible, puis docstring de classe et
    informations de base (indicateurs requis, param√®tres par d√©faut).
    """
    strategy_cls = get_strategy(name)

    parts: List[str] = []
    strategy = None
    try:
        strategy = strategy_cls()
    except Exception:
        strategy = None

    if strategy is not None:
        try:
            desc = strategy.describe()
            if desc:
                parts.append(str(desc).strip())
        except Exception:
            pass

        try:
            required = getattr(strategy, "required_indicators", [])
            if required:
                parts.append(f"Required Indicators: {', '.join(required)}")
        except Exception:
            pass

        try:
            defaults = getattr(strategy, "default_params", None)
            if defaults:
                parts.append(f"Default Params: {defaults}")
        except Exception:
            pass

    class_doc = (strategy_cls.__doc__ or "").strip()
    if class_doc and class_doc not in "\n".join(parts):
        parts.append(class_doc)

    overview = "\n\n".join([p for p in parts if p]).strip()
    if not overview:
        overview = f"Strategy: {strategy_cls.__name__}"

    if max_chars > 0 and len(overview) > max_chars:
        overview = overview[:max_chars].rstrip() + "\n...[truncated]"

    return overview


__all__ = [
    "StrategyBase",
    "StrategyResult",
    "register_strategy",
    "get_strategy",
    "list_strategies",
    "create_strategy",
    "get_strategy_overview",
]
```
<!-- MODULE-END: base.py -->

<!-- MODULE-START: bollinger_atr.py -->
```json
{
  "name": "bollinger_atr.py",
  "path": "strategies\\bollinger_atr.py",
  "ext": ".py",
  "anchor": "bollinger_atr_py"
}
```
## bollinger_atr_py
*Chemin* : `strategies\bollinger_atr.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.bollinger_atr

Purpose: Strat√©gie de breakout bas√©e sur les Bandes de Bollinger et ATR (volatilit√©).

Role in pipeline: core

Key components: BollingerATRStrategy, bb_window, bb_std, atr_period, atr_multiplier

Inputs: DataFrame OHLCV avec colonnes high, low, close

Outputs: StrategyResult (signaux 1/-1/0 sur breakouts bandes/ATR)

Dependencies: strategies.base, indicators.bollinger, indicators.atr, utils.parameters

Conventions: bb_window > atr_period recommand√©; bandes sup√©rieures/inf√©rieures + filtrage ATR; volume optionnel.

Read-if: Modification breakout logic, seuils volatilit√©, ou constraints.

Skip-if: Vous ne changez que d'autres strat√©gies.
"""

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from utils.parameters import SAFE_RANGES_PRESET, ParameterSpec, Preset

from .base import StrategyBase, register_strategy


@register_strategy("bollinger_atr")
class BollingerATRStrategy(StrategyBase):
    """
    Strat√©gie Bollinger Bands + ATR (Mean Reversion).

    Cette strat√©gie est le "moteur de Baptiste" - la strat√©gie de r√©f√©rence
    utilis√©e pour valider le nouveau moteur de backtest.

    Param√®tres:
        entry_z: Seuil d'entr√©e en Z-score (d√©faut: 2.0)
        k_sl: Multiplicateur ATR pour stop-loss (d√©faut: 1.5)
        atr_percentile: Percentile ATR pour filtre volatilit√© (d√©faut: 30)
        leverage: Levier de trading (d√©faut: 3)

    Signaux:
        +1 (Long): close <= lower_band ET ATR > seuil
        -1 (Short): close >= upper_band ET ATR > seuil
        0: Sinon
    """

    def __init__(self):
        super().__init__(name="BollingerATR")

    @property
    def required_indicators(self) -> List[str]:
        """Indicateurs requis: Bollinger Bands et ATR."""
        return ["bollinger", "atr"]

    @property
    def default_params(self) -> Dict[str, Any]:
        """Param√®tres par d√©faut de la strat√©gie."""
        return {
            # Bollinger
            "bb_period": 20,
            "bb_std": 2.0,
            # ATR
            "atr_period": 14,
            "atr_percentile": 30,  # Filtre: ATR doit √™tre > ce percentile
            # Trading
            "entry_z": 2.0,  # Z-score pour entr√©e (touch band = 2 std)
            "k_sl": 1.5,     # Stop loss = k_sl * ATR
            "leverage": 1,  # Fix√© √† 1 - ne pas optimiser
            # Frais (pour r√©f√©rence)
            "fees_bps": 10,
            "slippage_bps": 5
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications d√©taill√©es des param√®tres pour UI/optimisation."""
        return {
            "bb_period": ParameterSpec(
                name="bb_period",
                min_val=10, max_val=50, default=20,
                param_type="int",
                description="P√©riode des Bandes de Bollinger"
            ),
            "bb_std": ParameterSpec(
                name="bb_std",
                min_val=1.5, max_val=3.0, default=2.0,
                param_type="float",
                description="√âcarts-types pour les bandes"
            ),
            "entry_z": ParameterSpec(
                name="entry_z",
                min_val=1.0, max_val=3.0, default=2.0,
                param_type="float",
                description="Seuil z-score pour entree"
            ),
            "atr_period": ParameterSpec(
                name="atr_period",
                min_val=7, max_val=21, default=14,
                param_type="int",
                description="P√©riode de l'ATR"
            ),
            "atr_percentile": ParameterSpec(
                name="atr_percentile",
                min_val=0, max_val=60, default=30,
                param_type="int",
                description="Percentile volatilite minimum (ATR)"
            ),
            "k_sl": ParameterSpec(
                name="k_sl",
                min_val=1.0, max_val=3.0, default=1.5,
                param_type="float",
                description="Multiplicateur ATR pour stop-loss"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }

    def get_preset(self) -> Optional[Preset]:
        """Retourne le preset Safe Ranges associ√©."""
        return SAFE_RANGES_PRESET

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Mappe les parametres de la strategie vers les indicateurs."""
        if indicator_name == "bollinger":
            return {
                "period": int(params.get("bb_period", 20)),
                "std_dev": float(params.get("bb_std", 2.0)),
            }
        if indicator_name == "atr":
            return {"period": int(params.get("atr_period", 14))}
        return super().get_indicator_params(indicator_name, params)

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re les signaux de trading Bollinger + ATR.

        Args:
            df: DataFrame OHLCV
            indicators: {"bollinger": (upper, middle, lower), "atr": atr_array}
            params: Param√®tres de strat√©gie

        Returns:
            pd.Series de signaux (+1, -1, 0)
        """
        # Initialiser signaux √† 0 (hold)
        signals = pd.Series(0.0, index=df.index, dtype=np.float64, name="signals")

        # Extraire Bollinger Bands
        if "bollinger" not in indicators or indicators["bollinger"] is None:
            return signals

        bb_result = indicators["bollinger"]
        if not isinstance(bb_result, tuple) or len(bb_result) < 3:
            return signals

        upper, middle, lower = bb_result[:3]

        # Convertir en Series si n√©cessaire
        if not isinstance(upper, pd.Series):
            upper = pd.Series(np.asarray(upper), index=df.index)
        if not isinstance(lower, pd.Series):
            lower = pd.Series(np.asarray(lower), index=df.index)
        if not isinstance(middle, pd.Series):
            middle = pd.Series(np.asarray(middle), index=df.index)

        close = df["close"]

        # === Signaux Bollinger (Mean Reversion) ===
        bb_std = float(params.get("bb_std", 2.0))
        if bb_std <= 0:
            bb_std = 2.0
        entry_z = float(params.get("entry_z", bb_std))
        sigma = (upper - middle) / bb_std
        entry_upper = middle + (sigma * entry_z)
        entry_lower = middle - (sigma * entry_z)

        # Long: prix <= seuil bas (oversold)
        long_condition = close <= entry_lower

        # Short: prix >= seuil haut (overbought)
        short_condition = close >= entry_upper

        signals[long_condition] = 1.0
        signals[short_condition] = -1.0

        # === Filtre ATR (volatilit√©) ===
        if "atr" in indicators and indicators["atr"] is not None:
            atr_values = indicators["atr"]

            if not isinstance(atr_values, pd.Series):
                atr_values = pd.Series(np.asarray(atr_values), index=df.index)

            # Seuil de volatilit√© (percentile)
            atr_percentile = params.get("atr_percentile", 30)
            atr_threshold = atr_values.quantile(atr_percentile / 100.0)

            # Filtre: annuler signaux si volatilit√© trop faible
            low_volatility = atr_values <= atr_threshold
            signals[low_volatility] = 0.0

        # === Calculer stop-loss bas√©s sur Bollinger Bands ===
        # Pour LONG: stop = lower_band - 0.5 √ó (middle_band - lower_band)
        # Pour SHORT: stop = upper_band + 0.5 √ó (upper_band - middle_band)
        # Ces stop-loss sont stock√©s dans le DataFrame pour utilisation ult√©rieure
        bb_distance_lower = middle - lower  # Distance entre middle et lower
        bb_distance_upper = upper - middle  # Distance entre middle et upper

        # Calculer les prix de stop-loss pour chaque type de position
        stop_long = lower - 0.5 * bb_distance_lower   # En dessous de lower_band
        stop_short = upper + 0.5 * bb_distance_upper  # Au dessus de upper_band

        # Ajouter les colonnes au DataFrame (disponibles pour le backtest)
        df.loc[:, 'bb_stop_long'] = stop_long
        df.loc[:, 'bb_stop_short'] = stop_short
        df.loc[:, 'bb_upper'] = upper
        df.loc[:, 'bb_middle'] = middle
        df.loc[:, 'bb_lower'] = lower

        # === √âviter signaux cons√©cutifs identiques ===
        # Ne garder que les changements de signal
        signals_diff = signals.diff()
        # Premier signal conserv√©, ensuite seulement les changements
        signals_clean = signals.copy()
        signals_clean[1:] = np.where(signals_diff[1:] != 0, signals[1:], 0)

        return signals_clean

    def calculate_position_size(
        self,
        capital: float,
        entry_price: float,
        atr_value: float,
        params: Dict[str, Any]
    ) -> float:
        """
        Calcule la taille de position bas√©e sur le risque ATR.

        Position sizing: risk_amount / (k_sl * ATR)

        Args:
            capital: Capital disponible
            entry_price: Prix d'entr√©e
            atr_value: Valeur ATR actuelle
            params: Param√®tres de strat√©gie

        Returns:
            Quantit√© √† trader
        """
        leverage = params.get("leverage", 3)
        k_sl = params.get("k_sl", 1.5)
        risk_pct = params.get("risk_pct", 0.02)  # 2% du capital par trade

        # Risque en valeur absolue
        risk_amount = capital * risk_pct

        # Distance du stop en prix
        stop_distance = k_sl * atr_value

        # Quantit√© bas√©e sur le risque
        if stop_distance > 0:
            quantity = risk_amount / stop_distance
        else:
            quantity = 0

        # Limiter par le leverage disponible
        max_quantity = (capital * leverage) / entry_price

        return min(quantity, max_quantity)

    def get_stop_loss(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        bb_middle: Optional[float] = None,
        bb_upper: Optional[float] = None,
        bb_lower: Optional[float] = None
    ) -> float:
        """
        Calcule le niveau de stop-loss bas√© sur les bandes de Bollinger.

        Logique:
        - LONG: stop = lower_band - 0.5 √ó (middle_band - lower_band)
                (moiti√© de la distance entre middle et lower, EN DESSOUS de lower_band)
        - SHORT: stop = upper_band + 0.5 √ó (upper_band - middle_band)
                (moiti√© de la distance entre upper et middle, AU DESSUS de upper_band)

        Cette valeur est FIXE au moment de l'entr√©e (ne change pas avec les nouvelles bandes).

        Args:
            entry_price: Prix d'entr√©e
            atr_value: Valeur ATR (non utilis√© avec stop Bollinger)
            side: "long" ou "short"
            params: Param√®tres
            bb_middle: Bande de Bollinger m√©diane (au moment de l'entr√©e)
            bb_upper: Bande de Bollinger sup√©rieure (au moment de l'entr√©e)
            bb_lower: Bande de Bollinger inf√©rieure (au moment de l'entr√©e)

        Returns:
            Prix du stop-loss
        """
        # Si les bandes de Bollinger sont fournies, utiliser la logique Bollinger
        if bb_middle is not None and bb_upper is not None and bb_lower is not None:
            if side == "long":
                # Stop LONG: lower - 0.5 √ó (middle - lower)
                bb_distance = bb_middle - bb_lower
                return bb_lower - 0.5 * bb_distance
            else:  # SHORT
                # Stop SHORT: upper + 0.5 √ó (upper - middle)
                bb_distance = bb_upper - bb_middle
                return bb_upper + 0.5 * bb_distance
        else:
            # Fallback: logique ATR legacy (si les bandes ne sont pas disponibles)
            k_sl = params.get("k_sl", 1.5)
            distance = k_sl * atr_value

            if side == "long":
                return entry_price - distance
            else:
                return entry_price + distance


__all__ = ["BollingerATRStrategy"]
```
<!-- MODULE-END: bollinger_atr.py -->

<!-- MODULE-START: bollinger_atr_v2.py -->
```json
{
  "name": "bollinger_atr_v2.py",
  "path": "strategies\\bollinger_atr_v2.py",
  "ext": ".py",
  "anchor": "bollinger_atr_v2_py"
}
```
## bollinger_atr_v2_py
*Chemin* : `strategies\bollinger_atr_v2.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.bollinger_atr_v2

Purpose: Compatibility wrapper for Bollinger Best Longe 3i.

Role in pipeline: legacy import path.

Key components: BollingerBestLonge3iStrategy, register_strategy("bollinger_best_longe_3i")

Inputs: None

Outputs: Strategy class import.

Dependencies: strategies.bollinger_best_longe_3i

Conventions: None.

Read-if: You still import strategies.bollinger_atr_v2.

Skip-if: Use strategies.bollinger_best_longe_3i instead.
"""

from .bollinger_best_longe_3i import BollingerBestLonge3iStrategy

__all__ = ["BollingerBestLonge3iStrategy"]
```
<!-- MODULE-END: bollinger_atr_v2.py -->

<!-- MODULE-START: bollinger_atr_v3.py -->
```json
{
  "name": "bollinger_atr_v3.py",
  "path": "strategies\\bollinger_atr_v3.py",
  "ext": ".py",
  "anchor": "bollinger_atr_v3_py"
}
```
## bollinger_atr_v3_py
*Chemin* : `strategies\bollinger_atr_v3.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.bollinger_atr_v3

Purpose: Compatibility wrapper for Bollinger Best Short 3i.

Role in pipeline: legacy import path.

Key components: BollingerBestShort3iStrategy, register_strategy("bollinger_best_short_3i")

Inputs: None

Outputs: Strategy class import.

Dependencies: strategies.bollinger_best_short_3i

Conventions: None.

Read-if: You still import strategies.bollinger_atr_v3.

Skip-if: Use strategies.bollinger_best_short_3i instead.
"""

from .bollinger_best_short_3i import BollingerBestShort3iStrategy

__all__ = ["BollingerBestShort3iStrategy"]
```
<!-- MODULE-END: bollinger_atr_v3.py -->

<!-- MODULE-START: bollinger_best_longe_3i.py -->
```json
{
  "name": "bollinger_best_longe_3i.py",
  "path": "strategies\\bollinger_best_longe_3i.py",
  "ext": ".py",
  "anchor": "bollinger_best_longe_3i_py"
}
```
## bollinger_best_longe_3i_py
*Chemin* : `strategies\bollinger_best_longe_3i.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.bollinger_best_longe_3i

Purpose: Bollinger level-based LONG strategy with entry/SL/TP on band scale.

Role in pipeline: trading strategy

Key components: BollingerBestLonge3iStrategy, register_strategy("bollinger_best_longe_3i")

Inputs: DataFrame OHLCV, parameters (bb_period, bb_std, entry_level, sl_level, tp_level, leverage)

Outputs: StrategyResult signals (+1/0), Bollinger levels, metadata

Dependencies: pandas, numpy, utils.parameters, strategies.base

Conventions: Scale 0.0=lower band, 0.5=middle, 1.0=upper. Entry touches base band (0.0 to 0.2).
Stop-loss uses negative levels (below lower band). Take-profit uses upper band levels (0.5 to 2.0).

Read-if: Adjusting level ranges or entry logic.

Skip-if: Editing other strategies.
"""

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from utils.parameters import SAFE_RANGES_PRESET, ParameterSpec, Preset

from .base import StrategyBase, register_strategy


@register_strategy("bollinger_best_longe_3i")
class BollingerBestLonge3iStrategy(StrategyBase):
    """
    Bollinger level-based LONG strategy.

    Scale reference:
        0.0 = lower_band
        0.5 = middle_band
        1.0 = upper_band

    Parameters:
        entry_level: 0.0 to 0.2 (touching lower band)
        sl_level: -0.8 to -0.3 (below lower band)
        tp_level: 0.5 to 2.0 (toward upper band)
    """

    def __init__(self) -> None:
        super().__init__(name="Bollinger_best_longe_3i")

    @property
    def required_indicators(self) -> List[str]:
        return ["bollinger"]

    @property
    def default_params(self) -> Dict[str, Any]:
        return {
            "bb_period": 20,
            "bb_std": 2.1,
            "entry_level": 0.0,
            "sl_level": -0.5,
            "tp_level": 0.85,
            "leverage": 1,
            "fees_bps": 10,
            "slippage_bps": 5,
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        return {
            "bb_period": ParameterSpec(
                name="bb_period",
                min_val=10, max_val=50, default=20,
                param_type="int",
                description="Bollinger period",
            ),
            "bb_std": ParameterSpec(
                name="bb_std",
                min_val=1.0, max_val=4.0, step=0.1, default=2.1,
                param_type="float",
                description="Bollinger std dev",
            ),
            "entry_level": ParameterSpec(
                name="entry_level",
                min_val=0.0, max_val=0.2, step=0.05, default=0.0,
                param_type="float",
                description="Entry level on BB scale (0.0 to 0.2)",
            ),
            "sl_level": ParameterSpec(
                name="sl_level",
                min_val=-0.8, max_val=-0.3, step=0.05, default=-0.5,
                param_type="float",
                description="Stop-loss level below lower band",
            ),
            "tp_level": ParameterSpec(
                name="tp_level",
                min_val=0.5, max_val=2.0, step=0.05, default=0.85,
                param_type="float",
                description="Take-profit level toward upper band",
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Leverage (not optimized)",
                optimize=False,
            ),
        }

    def get_preset(self) -> Optional[Preset]:
        return SAFE_RANGES_PRESET

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        if indicator_name == "bollinger":
            return {
                "period": int(params.get("bb_period", 20)),
                "std_dev": float(params.get("bb_std", 2.1)),
            }
        return super().get_indicator_params(indicator_name, params)

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        signals = pd.Series(0.0, index=df.index, dtype=np.float64, name="signals")

        if "bollinger" not in indicators or indicators["bollinger"] is None:
            return signals

        bb_result = indicators["bollinger"]
        if not isinstance(bb_result, tuple) or len(bb_result) < 3:
            return signals

        upper, middle, lower = bb_result[:3]

        if not isinstance(upper, pd.Series):
            upper = pd.Series(np.asarray(upper), index=df.index)
        if not isinstance(lower, pd.Series):
            lower = pd.Series(np.asarray(lower), index=df.index)
        if not isinstance(middle, pd.Series):
            middle = pd.Series(np.asarray(middle), index=df.index)

        close = df["close"]

        entry_level = float(params.get("entry_level", 0.0))
        total_distance = upper - lower
        entry_price_level = lower + entry_level * total_distance

        long_condition = close <= entry_price_level
        signals[long_condition] = 1.0

        sl_level = float(params.get("sl_level", -0.5))
        tp_level = float(params.get("tp_level", 0.85))
        stop_long = lower + sl_level * total_distance
        tp_long = lower + tp_level * total_distance

        df.loc[:, "bb_entry_long"] = entry_price_level
        df.loc[:, "bb_stop_long"] = stop_long
        df.loc[:, "bb_tp_long"] = tp_long
        df.loc[:, "bb_upper"] = upper
        df.loc[:, "bb_middle"] = middle
        df.loc[:, "bb_lower"] = lower

        signals_diff = signals.diff()
        signals_clean = signals.copy()
        signals_clean[1:] = np.where(signals_diff[1:] != 0, signals[1:], 0)

        return signals_clean

    def _resolve_level_price(
        self,
        entry_price: float,
        atr_value: float,
        params: Dict[str, Any],
        level_key: str,
        bb_upper: Optional[float],
        bb_lower: Optional[float],
    ) -> float:
        entry_level = float(params.get("entry_level", 0.0))
        level = float(params.get(level_key, entry_level))

        if bb_upper is not None and bb_lower is not None:
            total_distance = bb_upper - bb_lower
            base = bb_lower
        else:
            total_distance = atr_value * 2.0 if atr_value else entry_price * 0.01
            base = entry_price - entry_level * total_distance

        if total_distance == 0:
            return entry_price

        return base + level * total_distance

    def get_stop_loss(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        bb_middle: Optional[float] = None,
        bb_upper: Optional[float] = None,
        bb_lower: Optional[float] = None,
    ) -> float:
        _ = side
        return self._resolve_level_price(
            entry_price,
            atr_value,
            params,
            "sl_level",
            bb_upper,
            bb_lower,
        )

    def get_take_profit(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        bb_middle: Optional[float] = None,
        bb_upper: Optional[float] = None,
        bb_lower: Optional[float] = None,
    ) -> float:
        _ = side
        return self._resolve_level_price(
            entry_price,
            atr_value,
            params,
            "tp_level",
            bb_upper,
            bb_lower,
        )


__all__ = ["BollingerBestLonge3iStrategy"]
```
<!-- MODULE-END: bollinger_best_longe_3i.py -->

<!-- MODULE-START: bollinger_best_short_3i.py -->
```json
{
  "name": "bollinger_best_short_3i.py",
  "path": "strategies\\bollinger_best_short_3i.py",
  "ext": ".py",
  "anchor": "bollinger_best_short_3i_py"
}
```
## bollinger_best_short_3i_py
*Chemin* : `strategies\bollinger_best_short_3i.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.bollinger_best_short_3i

Purpose: Bollinger level-based SHORT mirror strategy with entry/SL/TP on band scale.

Role in pipeline: trading strategy

Key components: BollingerBestShort3iStrategy, register_strategy("bollinger_best_short_3i")

Inputs: DataFrame OHLCV, parameters (bb_period, bb_std, entry_level, sl_level, tp_level, leverage)

Outputs: StrategyResult signals (-1/0), Bollinger levels, metadata

Dependencies: pandas, numpy, utils.parameters, strategies.base

Conventions: Scale 0.0=lower band, 0.5=middle, 1.0=upper. Entry near upper band (0.8 to 1.0).
Stop-loss above upper band (1.3 to 1.8). Take-profit toward lower band (0.0 to 0.3).

Read-if: Adjusting mirror ranges or entry logic.

Skip-if: Editing other strategies.
"""

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from utils.parameters import SAFE_RANGES_PRESET, ParameterSpec, Preset

from .base import StrategyBase, register_strategy


@register_strategy("bollinger_best_short_3i")
class BollingerBestShort3iStrategy(StrategyBase):
    """
    Bollinger level-based SHORT mirror strategy.

    Scale reference:
        0.0 = lower_band
        0.5 = middle_band
        1.0 = upper_band

    Parameters:
        entry_level: 0.8 to 1.0 (near upper band)
        sl_level: 1.3 to 1.8 (above upper band)
        tp_level: 0.0 to 0.3 (toward lower band)
    """

    def __init__(self) -> None:
        super().__init__(name="Bollinger_best_short_3i")

    @property
    def required_indicators(self) -> List[str]:
        return ["bollinger"]

    @property
    def default_params(self) -> Dict[str, Any]:
        return {
            "bb_period": 20,
            "bb_std": 2.1,
            "entry_level": 1.0,
            "sl_level": 1.5,
            "tp_level": 0.15,
            "leverage": 1,
            "fees_bps": 10,
            "slippage_bps": 5,
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        return {
            "bb_period": ParameterSpec(
                name="bb_period",
                min_val=10, max_val=50, default=20,
                param_type="int",
                description="Bollinger period",
            ),
            "bb_std": ParameterSpec(
                name="bb_std",
                min_val=1.0, max_val=4.0, step=0.1, default=2.1,
                param_type="float",
                description="Bollinger std dev",
            ),
            "entry_level": ParameterSpec(
                name="entry_level",
                min_val=0.8, max_val=1.0, step=0.05, default=1.0,
                param_type="float",
                description="Entry level near upper band (0.8 to 1.0)",
            ),
            "sl_level": ParameterSpec(
                name="sl_level",
                min_val=1.3, max_val=1.8, step=0.05, default=1.5,
                param_type="float",
                description="Stop-loss level above upper band",
            ),
            "tp_level": ParameterSpec(
                name="tp_level",
                min_val=0.0, max_val=0.3, step=0.05, default=0.15,
                param_type="float",
                description="Take-profit level toward lower band",
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Leverage (not optimized)",
                optimize=False,
            ),
        }

    def get_preset(self) -> Optional[Preset]:
        return SAFE_RANGES_PRESET

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        if indicator_name == "bollinger":
            return {
                "period": int(params.get("bb_period", 20)),
                "std_dev": float(params.get("bb_std", 2.1)),
            }
        return super().get_indicator_params(indicator_name, params)

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        signals = pd.Series(0.0, index=df.index, dtype=np.float64, name="signals")

        if "bollinger" not in indicators or indicators["bollinger"] is None:
            return signals

        bb_result = indicators["bollinger"]
        if not isinstance(bb_result, tuple) or len(bb_result) < 3:
            return signals

        upper, middle, lower = bb_result[:3]

        if not isinstance(upper, pd.Series):
            upper = pd.Series(np.asarray(upper), index=df.index)
        if not isinstance(lower, pd.Series):
            lower = pd.Series(np.asarray(lower), index=df.index)
        if not isinstance(middle, pd.Series):
            middle = pd.Series(np.asarray(middle), index=df.index)

        close = df["close"]

        entry_level = float(params.get("entry_level", 1.0))
        total_distance = upper - lower
        entry_price_level = lower + entry_level * total_distance

        short_condition = close >= entry_price_level
        signals[short_condition] = -1.0

        sl_level = float(params.get("sl_level", 1.5))
        tp_level = float(params.get("tp_level", 0.15))
        stop_short = lower + sl_level * total_distance
        tp_short = lower + tp_level * total_distance

        df.loc[:, "bb_entry_short"] = entry_price_level
        df.loc[:, "bb_stop_short"] = stop_short
        df.loc[:, "bb_tp_short"] = tp_short
        df.loc[:, "bb_upper"] = upper
        df.loc[:, "bb_middle"] = middle
        df.loc[:, "bb_lower"] = lower

        signals_diff = signals.diff()
        signals_clean = signals.copy()
        signals_clean[1:] = np.where(signals_diff[1:] != 0, signals[1:], 0)

        return signals_clean

    def _resolve_level_price(
        self,
        entry_price: float,
        atr_value: float,
        params: Dict[str, Any],
        level_key: str,
        bb_upper: Optional[float],
        bb_lower: Optional[float],
    ) -> float:
        entry_level = float(params.get("entry_level", 1.0))
        level = float(params.get(level_key, entry_level))

        if bb_upper is not None and bb_lower is not None:
            total_distance = bb_upper - bb_lower
            base = bb_lower
        else:
            total_distance = atr_value * 2.0 if atr_value else entry_price * 0.01
            base = entry_price - entry_level * total_distance

        if total_distance == 0:
            return entry_price

        return base + level * total_distance

    def get_stop_loss(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        bb_middle: Optional[float] = None,
        bb_upper: Optional[float] = None,
        bb_lower: Optional[float] = None,
    ) -> float:
        _ = side
        return self._resolve_level_price(
            entry_price,
            atr_value,
            params,
            "sl_level",
            bb_upper,
            bb_lower,
        )

    def get_take_profit(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        bb_middle: Optional[float] = None,
        bb_upper: Optional[float] = None,
        bb_lower: Optional[float] = None,
    ) -> float:
        _ = side
        return self._resolve_level_price(
            entry_price,
            atr_value,
            params,
            "tp_level",
            bb_upper,
            bb_lower,
        )


__all__ = ["BollingerBestShort3iStrategy"]
```
<!-- MODULE-END: bollinger_best_short_3i.py -->

<!-- MODULE-START: ema_cross.py -->
```json
{
  "name": "ema_cross.py",
  "path": "strategies\\ema_cross.py",
  "ext": ".py",
  "anchor": "ema_cross_py"
}
```
## ema_cross_py
*Chemin* : `strategies\ema_cross.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.ema_cross

Purpose: Strat√©gie de suivi de tendance par croisement de deux EMAs (Golden/Death Cross).

Role in pipeline: core

Key components: EMACrossStrategy, fast_period, slow_period, leverage

Inputs: DataFrame OHLCV avec colonnes close, optionnel volume

Outputs: StrategyResult (signaux 1/-1/0 sur croisements EMA)

Dependencies: strategies.base, utils.parameters, pandas, numpy

Conventions: fast_period < slow_period obligatoire; EMA calcul√©es internement; leverage appliqu√© apr√®s signaux.

Read-if: Modification logique croisement, seuils entr√©e, ou preset.

Skip-if: Vous ne changez que d'autres strat√©gies.
"""

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from utils.parameters import EMA_CROSS_PRESET, ParameterSpec, Preset

from .base import StrategyBase, register_strategy


@register_strategy("ema_cross")
class EMACrossStrategy(StrategyBase):
    """
    Strat√©gie EMA Crossover (Trend Following).

    Strat√©gie classique de suivi de tendance utilisant deux moyennes
    mobiles exponentielles de p√©riodes diff√©rentes.

    Param√®tres:
        fast_period: P√©riode de l'EMA rapide (d√©faut: 12)
        slow_period: P√©riode de l'EMA lente (d√©faut: 26)
        leverage: Levier de trading (d√©faut: 1)

    Signaux:
        +1 (Long): EMA fast croise EMA slow √† la hausse
        -1 (Short): EMA fast croise EMA slow √† la baisse
        0: Sinon
    """

    def __init__(self):
        super().__init__(name="EMACross")

    @property
    def required_indicators(self) -> List[str]:
        """Cette strat√©gie calcule ses propres EMAs."""
        return []

    @property
    def default_params(self) -> Dict[str, Any]:
        """Param√®tres par d√©faut."""
        return {
            "fast_period": 12,
            "slow_period": 26,
            "leverage": 1,  # Fix√© √† 1 - ne pas optimiser
            "k_sl": 2.0,  # Stop loss en % du prix
            "fees_bps": 10,
            "slippage_bps": 5
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications des param√®tres."""
        return {
            "fast_period": ParameterSpec(
                name="fast_period",
                min_val=5, max_val=20, default=12,
                param_type="int",
                description="P√©riode EMA rapide"
            ),
            "slow_period": ParameterSpec(
                name="slow_period",
                min_val=20, max_val=50, default=26,
                param_type="int",
                description="P√©riode EMA lente"
            ),
            "k_sl": ParameterSpec(
                name="k_sl",
                min_val=1.0, max_val=5.0, default=2.0,
                param_type="float",
                description="Stop-loss en %"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }

    def get_preset(self) -> Optional[Preset]:
        """Retourne le preset EMA Cross."""
        return EMA_CROSS_PRESET

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re les signaux de croisement EMA.

        Note: Cette strat√©gie calcule ses propres EMAs car elle a besoin
        de deux p√©riodes sp√©cifiques. Le registre d'indicateurs standard
        ne g√®re qu'une p√©riode √† la fois.
        """
        # Initialiser signaux
        signals = pd.Series(0.0, index=df.index, dtype=np.float64, name="signals")

        close = df["close"]
        fast_period = int(params.get("fast_period", 12))
        slow_period = int(params.get("slow_period", 26))

        # Calculer les EMAs
        ema_fast = close.ewm(span=fast_period, adjust=True, min_periods=fast_period).mean()
        ema_slow = close.ewm(span=slow_period, adjust=True, min_periods=slow_period).mean()

        # D√©tecter les croisements
        # Fast au-dessus de slow
        fast_above = ema_fast > ema_slow
        # Utiliser shift avec fill_value pour √©viter FutureWarning
        fast_above_prev = fast_above.shift(1, fill_value=False)

        # Golden Cross: fast passe au-dessus de slow
        golden_cross = fast_above & ~fast_above_prev

        # Death Cross: fast passe en dessous de slow
        death_cross = ~fast_above & fast_above_prev

        signals[golden_cross] = 1.0
        signals[death_cross] = -1.0

        return signals

    def describe(self) -> str:
        """Description de la strat√©gie."""
        return """
EMA Crossover Strategy (Trend Following)
========================================

Cette strat√©gie g√©n√®re des signaux bas√©s sur le croisement de deux EMAs:

LONG Signal:
  - L'EMA rapide croise l'EMA lente √† la hausse (Golden Cross)
  - Indique un potentiel d√©but de tendance haussi√®re

SHORT Signal:
  - L'EMA rapide croise l'EMA lente √† la baisse (Death Cross)
  - Indique un potentiel d√©but de tendance baissi√®re

Param√®tres optimaux typiques:
  - Crypto court terme: fast=9, slow=21
  - Crypto moyen terme: fast=12, slow=26 (MACD standard)
  - Crypto long terme: fast=20, slow=50

Notes:
  - Fonctionne bien en march√© tendanciel
  - G√©n√®re des faux signaux en march√© range (whipsaw)
  - Combine bien avec un filtre de tendance (ADX, ATR)
"""


__all__ = ["EMACrossStrategy"]
```
<!-- MODULE-END: ema_cross.py -->

<!-- MODULE-START: fvg_strategy.py -->
```json
{
  "name": "fvg_strategy.py",
  "path": "strategies\\fvg_strategy.py",
  "ext": ".py",
  "anchor": "fvg_strategy_py"
}
```
## fvg_strategy_py
*Chemin* : `strategies\fvg_strategy.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.fvg_strategy

Purpose: Strategie FairValOseille - Trading base sur FVG, FVA, swings et smart legs.

Role in pipeline: trading strategy

Key components: FVGStrategy, register_strategy("fvg_strategy")

Inputs: DataFrame OHLCV, parametres (leverage, scoring)

Outputs: StrategyResult (signaux LONG/SHORT, prix, stop-loss, metadata)

Dependencies: pandas, numpy, utils.parameters, strategies.base

Conventions: Signaux bases sur consensus patterns; stop-loss dynamiques; scoring multi-indicateurs.
"""

from typing import Any, Dict, List

import numpy as np
import pandas as pd

from utils.parameters import ParameterSpec

from .base import StrategyBase, register_strategy


@register_strategy("fvg_strategy")
class FVGStrategy(StrategyBase):
    """
    Strategie FairValOseille - Version simplifiee et corrigee.

    Logique de trading:
        LONG: Score bull > seuil ET (swing_low OU fvg_bullish)
        SHORT: Score bear > seuil ET (swing_high OU fvg_bearish)

    Indicateurs requis:
        - swing_high, swing_low (detection fractals)
        - fvg_bullish, fvg_bearish (fair value gaps)
        - fva (fair value areas)
        - smart_leg_bullish, smart_leg_bearish (validation directionnelle)
        - bull_score, bear_score (scoring)
        - atr (volatilite pour stops)
    """

    def __init__(self):
        super().__init__(name="FVG_Strategy")

    @property
    def required_indicators(self) -> List[str]:
        """Indicateurs requis par la strategie."""
        return [
            "swing_high",
            "swing_low",
            "fvg_bullish",
            "fvg_bearish",
            "fva",
            "smart_leg_bullish",
            "smart_leg_bearish",
            "bull_score",
            "bear_score",
            "atr"
        ]

    @property
    def default_params(self) -> Dict[str, Any]:
        """Parametres par defaut de la strategie."""
        return {
            # Scoring
            "min_bull_score": 0.6,   # Score minimum pour entree LONG
            "min_bear_score": 0.6,   # Score minimum pour entree SHORT
            # Stop-loss / Take-profit
            "stop_atr_mult": 1.5,    # Multiplicateur ATR pour stop-loss
            "tp_atr_mult": 3.0,      # Multiplicateur ATR pour take-profit
            # Trading
            "leverage": 1,  # Fix√© √† 1 - ne pas optimiser
            "risk_pct": 0.02,        # 2% du capital par trade
            # Frais
            "fees_bps": 10,
            "slippage_bps": 5
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Specifications des parametres pour UI/optimisation."""
        return {
            "min_bull_score": ParameterSpec(
                name="min_bull_score",
                min_val=0.3, max_val=0.9, step=0.05, default=0.6,
                param_type="float",
                description="Score minimum pour signal LONG"
            ),
            "min_bear_score": ParameterSpec(
                name="min_bear_score",
                min_val=0.3, max_val=0.9, step=0.05, default=0.6,
                param_type="float",
                description="Score minimum pour signal SHORT"
            ),
            "stop_atr_mult": ParameterSpec(
                name="stop_atr_mult",
                min_val=1.0, max_val=3.0, step=0.25, default=1.5,
                param_type="float",
                description="Multiplicateur ATR pour stop-loss"
            ),
            "tp_atr_mult": ParameterSpec(
                name="tp_atr_mult",
                min_val=2.0, max_val=5.0, step=0.5, default=3.0,
                param_type="float",
                description="Multiplicateur ATR pour take-profit"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1, max_val=10, default=1,
                param_type="int",
                description="Levier de trading (non optimis√©)",
                optimize=False,
            ),
        }

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        Genere les signaux de trading bases sur les patterns detectes.

        Args:
            df: DataFrame OHLCV
            indicators: Dict contenant tous les indicateurs requis
            params: Parametres de strategie

        Returns:
            pd.Series de signaux (+1 LONG, -1 SHORT, 0 HOLD)
        """
        # Initialiser signaux
        signals = pd.Series(0.0, index=df.index, dtype=np.float64, name="signals")

        # Verifier presence des indicateurs
        required = self.required_indicators
        if not all(ind in indicators for ind in required):
            return signals

        # Extraire les indicateurs
        swing_high = indicators["swing_high"]
        swing_low = indicators["swing_low"]
        fvg_bull = indicators["fvg_bullish"]
        fvg_bear = indicators["fvg_bearish"]
        bull_score = indicators["bull_score"]
        bear_score = indicators["bear_score"]

        # Convertir en Series si necessaire
        if not isinstance(swing_high, pd.Series):
            swing_high = pd.Series(swing_high, index=df.index)
        if not isinstance(swing_low, pd.Series):
            swing_low = pd.Series(swing_low, index=df.index)
        if not isinstance(fvg_bull, pd.Series):
            fvg_bull = pd.Series(fvg_bull, index=df.index)
        if not isinstance(fvg_bear, pd.Series):
            fvg_bear = pd.Series(fvg_bear, index=df.index)
        if not isinstance(bull_score, pd.Series):
            bull_score = pd.Series(bull_score, index=df.index)
        if not isinstance(bear_score, pd.Series):
            bear_score = pd.Series(bear_score, index=df.index)

        # Seuils de scoring
        min_bull_score = params.get("min_bull_score", 0.6)
        min_bear_score = params.get("min_bear_score", 0.6)

        # === CONDITIONS LONG ===
        # Score bull suffisant ET presence d'un pattern (swing_low OU fvg_bullish)
        long_condition = (
            (bull_score >= min_bull_score) &
            (swing_low | fvg_bull)
        )

        # === CONDITIONS SHORT ===
        # Score bear suffisant ET presence d'un pattern (swing_high OU fvg_bearish)
        short_condition = (
            (bear_score >= min_bear_score) &
            (swing_high | fvg_bear)
        )

        # Assigner signaux
        signals[long_condition] = 1.0
        signals[short_condition] = -1.0

        # Eviter signaux consecutifs identiques
        signals_diff = signals.diff()
        signals_clean = signals.copy()
        signals_clean[1:] = np.where(signals_diff[1:] != 0, signals[1:], 0)

        return signals_clean

    def get_stop_loss(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        **kwargs
    ) -> float:
        """
        Calcule le stop-loss base sur ATR.

        Args:
            entry_price: Prix d'entree
            atr_value: Valeur ATR actuelle
            side: "long" ou "short"
            params: Parametres (contient stop_atr_mult)

        Returns:
            Prix du stop-loss
        """
        stop_mult = params.get("stop_atr_mult", 1.5)
        distance = atr_value * stop_mult

        if side == "long":
            return entry_price - distance
        else:  # SHORT
            return entry_price + distance

    def get_take_profit(
        self,
        entry_price: float,
        atr_value: float,
        side: str,
        params: Dict[str, Any],
        **kwargs
    ) -> float:
        """
        Calcule le take-profit base sur ATR.

        Args:
            entry_price: Prix d'entree
            atr_value: Valeur ATR actuelle
            side: "long" ou "short"
            params: Parametres (contient tp_atr_mult)

        Returns:
            Prix du take-profit
        """
        tp_mult = params.get("tp_atr_mult", 3.0)
        distance = atr_value * tp_mult

        if side == "long":
            return entry_price + distance
        else:  # SHORT
            return entry_price - distance


__all__ = ["FVGStrategy"]
```
<!-- MODULE-END: fvg_strategy.py -->

<!-- MODULE-START: indicators_mapping.py -->
```json
{
  "name": "indicators_mapping.py",
  "path": "strategies\\indicators_mapping.py",
  "ext": ".py",
  "anchor": "indicators_mapping_py"
}
```
## indicators_mapping_py
*Chemin* : `strategies\indicators_mapping.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.indicators_mapping

Purpose: Mapping centralis√© strat√©gies ‚Üí indicateurs pour chargement automatique UI.

Role in pipeline: core / data

Key components: StrategyIndicatorsMapping, get_strategy_indicators, IndicatorRequirement

Inputs: Strategy name, configuration

Outputs: Dict[str, List[IndicatorRequirement]] (required + internal + all)

Dependencies: strategies.base, indicators.registry, dataclasses

Conventions: required_indicators charg√©s par moteur; internal_indicators calcul√©s par strat; all_indicators = union compl√®te.

Read-if: Ajout nouvelle strat√©gie/indicateur, modification deps.

Skip-if: Vous ne changez qu'une strat√©gie.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Set


@dataclass
class StrategyIndicators:
    """D√©finition des indicateurs pour une strat√©gie."""

    name: str
    required_indicators: List[str]  # Charg√©s par le moteur
    internal_indicators: List[str]  # Calcul√©s par la strat√©gie
    description: str
    ui_label: str = ""
    ui_indicators: List[str] = field(default_factory=list)

    @property
    def all_indicators(self) -> Set[str]:
        """Tous les indicateurs utilis√©s (requis + internes)."""
        return set(self.required_indicators + self.internal_indicators)

    def display_label(self) -> str:
        """Libelle d'affichage pour l'UI."""
        return self.ui_label or self.name

    def ui_indicator_list(self) -> List[str]:
        """Indicateurs affiches dans l'UI (ordre preserve)."""
        if self.ui_indicators:
            return list(self.ui_indicators)
        combined = self.required_indicators + self.internal_indicators
        return list(dict.fromkeys(combined))


# =============================================================================
# MAPPING COMPLET STRAT√âGIES ‚Üí INDICATEURS
# =============================================================================

STRATEGY_INDICATORS_MAP: Dict[str, StrategyIndicators] = {

    # 1. ATR Channel
    "atr_channel": StrategyIndicators(
        name="ATR Channel",
        ui_label="üìè ATR Channel (Breakout)",
        required_indicators=["atr", "ema"],
        # ATR pour canal, EMA fournie en externe
        internal_indicators=[],  # Canal calcul√© √† partir de l'EMA + ATR
        description="Breakout sur canal ATR avec filtre EMA",
        ui_indicators=["atr_channel", "atr"],
    ),

    # 2. EMA Cross
    "ema_cross": StrategyIndicators(
        name="EMA Cross",
        ui_label="üìà EMA Crossover (Trend Following)",
        required_indicators=[],
        internal_indicators=["ema"],  # EMA rapide/lente calcul√©es internement
        description="Croisement EMA simple (Golden/Death Cross)",
        ui_indicators=["ema"],
    ),

    # 3. Bollinger ATR
    "bollinger_atr": StrategyIndicators(
        name="Bollinger ATR",
        ui_label="üìâ Bollinger + ATR (Mean Reversion)",
        required_indicators=["bollinger", "atr"],
        internal_indicators=[],
        description="Mean-reversion Bollinger avec filtre volatilit√© ATR",
        ui_indicators=["bollinger", "atr"],
    ),

    # 3b. Bollinger Best Longe 3i (levels on band scale)
    "bollinger_best_longe_3i": StrategyIndicators(
        name="Bollinger Best Longe 3i",
        ui_label="üìâ Bollinger Best Longe 3i (Levels)",
        required_indicators=["bollinger", "atr"],
        internal_indicators=[],
        description="Long-only Bollinger levels: entry 0.0-0.2, SL -0.8 to -0.3, TP 0.7-2.0",
        ui_indicators=["bollinger", "atr"],
    ),

    # 3c. Bollinger Best Short 3i (mirror levels)
    "bollinger_best_short_3i": StrategyIndicators(
        name="Bollinger Best Short 3i",
        ui_label="üìâ Bollinger Best Short 3i (Mirror Levels)",
        required_indicators=["bollinger", "atr"],
        internal_indicators=[],
        description="Short-only Bollinger levels: entry 0.8-1.0, SL 1.3-1.8, TP 0.0-0.3",
        ui_indicators=["bollinger", "atr"],
    ),

    # 4. MACD Cross
    "macd_cross": StrategyIndicators(
        name="MACD Cross",
        ui_label="üìä MACD Crossover (Momentum)",
        required_indicators=["macd"],
        internal_indicators=[],
        description="Croisement MACD avec ligne signal",
        ui_indicators=["macd"],
    ),

    # 5. RSI Reversal
    "rsi_reversal": StrategyIndicators(
        name="RSI Reversal",
        ui_label="üîÑ RSI Reversal (Mean Reversion)",
        required_indicators=["rsi"],
        internal_indicators=[],
        description="Mean-reversion sur niveaux RSI (survente/surachat)",
        ui_indicators=["rsi"],
    ),

    # 6. MA Crossover
    "ma_crossover": StrategyIndicators(
        name="MA Crossover",
        ui_label="üìê MA Crossover (SMA Trend)",
        required_indicators=[],
        internal_indicators=["sma"],
        description="Croisement SMA rapide/lente",
        ui_indicators=["ma"],
    ),

    # 7. EMA Stochastic Scalp
    "ema_stochastic_scalp": StrategyIndicators(
        name="EMA Stochastic Scalp",
        ui_label="‚ö° EMA + Stochastic (Scalping)",
        required_indicators=["stochastic"],
        internal_indicators=["ema"],
        description="Scalping avec filtre EMA et timing Stochastic",
        ui_indicators=["ema", "stochastic"],
    ),

    # 8. Bollinger Dual
    "bollinger_dual": StrategyIndicators(
        name="Bollinger Dual",
        ui_label="üìä Bollinger Dual (Mean Reversion)",
        required_indicators=["bollinger"],
        internal_indicators=["sma", "ema"],
        description="Bollinger + franchissement MA",
        ui_indicators=["bollinger", "ma"],
    ),

    # 9. RSI Trend Filtered
    "rsi_trend_filtered": StrategyIndicators(
        name="RSI Trend Filtered",
        ui_label="üîÑ RSI Trend Filtered (Mean Rev.)",
        required_indicators=["rsi"],
        internal_indicators=["ema"],
        description="RSI filtre par tendance EMA",
        ui_indicators=["rsi", "ema"],
    ),
}


# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

def get_required_indicators(strategy_name: str) -> List[str]:
    """
    Retourne la liste des indicateurs requis pour une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie (ex: "bollinger_atr")

    Returns:
        Liste des indicateurs requis (ex: ["bollinger", "atr"])

    Raises:
        KeyError: Si la strat√©gie n'existe pas
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        raise KeyError(
            f"Strat√©gie '{strategy_name}' inconnue. "
            f"Disponibles: {list(STRATEGY_INDICATORS_MAP.keys())}"
        )

    return STRATEGY_INDICATORS_MAP[strategy_name].required_indicators


def get_all_indicators(strategy_name: str) -> Set[str]:
    """
    Retourne tous les indicateurs utilis√©s par une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        Set de tous les indicateurs (requis + internes)
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        raise KeyError(f"Strat√©gie '{strategy_name}' inconnue")

    return STRATEGY_INDICATORS_MAP[strategy_name].all_indicators


def get_internal_indicators(strategy_name: str) -> List[str]:
    """
    Retourne les indicateurs calcul√©s internement par une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        Liste des indicateurs internes
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        raise KeyError(f"Strat√©gie '{strategy_name}' inconnue")

    return STRATEGY_INDICATORS_MAP[strategy_name].internal_indicators


def get_ui_indicators(strategy_name: str) -> List[str]:
    """
    Retourne la liste des indicateurs a afficher dans l'UI.
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        raise KeyError(f"Strat√©gie '{strategy_name}' inconnue")

    return STRATEGY_INDICATORS_MAP[strategy_name].ui_indicator_list()


def list_strategies() -> List[str]:
    """Liste toutes les strat√©gies disponibles."""
    return list(STRATEGY_INDICATORS_MAP.keys())


def get_strategy_info(strategy_name: str) -> StrategyIndicators:
    """
    Retourne les informations compl√®tes sur une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        StrategyIndicators avec toutes les infos
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        raise KeyError(f"Strat√©gie '{strategy_name}' inconnue")

    return STRATEGY_INDICATORS_MAP[strategy_name]


def format_strategy_summary() -> str:
    """
    G√©n√®re un r√©sum√© format√© de toutes les strat√©gies et leurs indicateurs.

    Returns:
        R√©sum√© en format texte
    """
    lines = ["=" * 80]
    lines.append("R√âF√âRENCE STRAT√âGIES ‚Üí INDICATEURS")
    lines.append("=" * 80)
    lines.append("")

    for strategy_name, info in STRATEGY_INDICATORS_MAP.items():
        lines.append(f"üìä {info.name} ({strategy_name})")
        lines.append(f"   Description: {info.description}")
        required = ", ".join(info.required_indicators) or "Aucun"
        internal = ", ".join(info.internal_indicators) or "Aucun"
        lines.append(f"   Requis:      {required}")
        lines.append(f"   Internes:    {internal}")
        lines.append("")

    lines.append("=" * 80)
    return "\n".join(lines)


# =============================================================================
# VALIDATION
# =============================================================================

def validate_strategy_indicators(
    strategy_name: str,
    strategy_instance
) -> bool:
    """
    Valide que les indicateurs d√©clar√©s dans le mapping correspondent
    aux indicateurs requis de la strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie
        strategy_instance: Instance de la strat√©gie

    Returns:
        True si coh√©rent, False sinon
    """
    if strategy_name not in STRATEGY_INDICATORS_MAP:
        return False

    expected = set(STRATEGY_INDICATORS_MAP[strategy_name].required_indicators)
    actual = set(strategy_instance.required_indicators)

    return expected == actual


__all__ = [
    "StrategyIndicators",
    "STRATEGY_INDICATORS_MAP",
    "get_required_indicators",
    "get_all_indicators",
    "get_internal_indicators",
    "get_ui_indicators",
    "list_strategies",
    "get_strategy_info",
    "format_strategy_summary",
    "validate_strategy_indicators",
]
```
<!-- MODULE-END: indicators_mapping.py -->

<!-- MODULE-START: macd_cross.py -->
```json
{
  "name": "macd_cross.py",
  "path": "strategies\\macd_cross.py",
  "ext": ".py",
  "anchor": "macd_cross_py"
}
```
## macd_cross_py
*Chemin* : `strategies\macd_cross.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.macd_cross

Purpose: Strat√©gie momentum bas√©e sur croisement de MACD et signal line.

Role in pipeline: core

Key components: MACDCrossStrategy, fast_period, slow_period, signal_period

Inputs: DataFrame OHLCV avec colonne close

Outputs: StrategyResult (signaux 1/-1/0 sur croisements MACD/signal)

Dependencies: strategies.base, indicators.macd, utils.parameters, pandas, numpy

Conventions: fast < slow < signal obligatoires; histogram comme filtre optionnel; momentum valid√©.

Read-if: Modification logique croisement MACD, seuils, ou signal.

Skip-if: Vous ne changez que d'autres strat√©gies.
"""

from typing import Any, Dict, List

import numpy as np
import pandas as pd

from strategies.base import StrategyBase, StrategyResult, register_strategy
from utils.parameters import ParameterSpec


@register_strategy("macd_cross")
class MACDCrossStrategy(StrategyBase):
    """
    Strat√©gie de croisement MACD.

    Signaux:
        - LONG (+1): MACD croise Signal vers le haut (golden cross)
        - SHORT (-1): MACD croise Signal vers le bas (death cross)

    Param√®tres:
        - fast_period: P√©riode EMA rapide (d√©faut: 12)
        - slow_period: P√©riode EMA lente (d√©faut: 26)
        - signal_period: P√©riode ligne signal (d√©faut: 9)
        - leverage: Multiplicateur de position (d√©faut: 1)
    """

    def __init__(self, name: str = "macd_cross"):
        super().__init__(name)

    @property
    def required_indicators(self) -> List[str]:
        """Indicateurs requis par la strat√©gie."""
        return ["macd"]

    @property
    def default_params(self) -> Dict[str, Any]:
        """Param√®tres par d√©faut."""
        return {
            "fast_period": 12,
            "slow_period": 26,
            "signal_period": 9,
            "leverage": 1,
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications des param√®tres pour l'UI et l'optimisation."""
        return {
            "fast_period": ParameterSpec(
                name="fast_period",
                min_val=5,
                max_val=30,
                default=12,
                param_type="int",
                description="P√©riode EMA rapide"
            ),
            "slow_period": ParameterSpec(
                name="slow_period",
                min_val=15,
                max_val=50,
                default=26,
                param_type="int",
                description="P√©riode EMA lente"
            ),
            "signal_period": ParameterSpec(
                name="signal_period",
                min_val=5,
                max_val=20,
                default=9,
                param_type="int",
                description="P√©riode ligne signal"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1,
                max_val=10,
                default=1,
                param_type="int",
                description="Levier de trading",
                optimize=False,
            ),
        }

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Mappe les parametres de la strategie vers les indicateurs."""
        if indicator_name == "macd":
            return {
                "fast_period": int(params.get("fast_period", 12)),
                "slow_period": int(params.get("slow_period", 26)),
                "signal_period": int(params.get("signal_period", 9)),
            }
        return super().get_indicator_params(indicator_name, params)

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re les signaux de trading bas√©s sur les croisements MACD.

        Args:
            df: DataFrame OHLCV
            indicators: Dictionnaire contenant 'macd' avec
                {macd, signal, histogram}
            params: Param√®tres de la strat√©gie

        Returns:
            Series de signaux (-1, 0, +1)
        """
        signals = pd.Series(0.0, index=df.index)

        # R√©cup√©rer les donn√©es MACD
        if "macd" not in indicators or indicators["macd"] is None:
            return signals

        macd_data = indicators["macd"]

        # macd_data peut √™tre un dict ou un tuple selon la version
        if isinstance(macd_data, dict):
            macd_line = macd_data.get("macd")
            signal_line = macd_data.get("signal")
        elif isinstance(macd_data, tuple) and len(macd_data) >= 2:
            macd_line = macd_data[0]
            signal_line = macd_data[1]
        else:
            return signals

        if macd_line is None or signal_line is None:
            return signals

        # BUGFIX CRITIQUE: V√©rifier que les donn√©es ne sont pas toutes NaN
        if isinstance(macd_line, np.ndarray) and np.isnan(macd_line).all():
            return signals
        if isinstance(signal_line, np.ndarray) and np.isnan(signal_line).all():
            return signals

        # BUGFIX CRITIQUE: V√©rifier que les donn√©es ne sont pas toutes NaN
        if isinstance(macd_line, np.ndarray) and np.isnan(macd_line).all():
            return signals
        if isinstance(signal_line, np.ndarray) and np.isnan(signal_line).all():
            return signals

        # Convertir en Series si n√©cessaire
        if isinstance(macd_line, np.ndarray):
            macd_line = pd.Series(macd_line, index=df.index)
        if isinstance(signal_line, np.ndarray):
            signal_line = pd.Series(signal_line, index=df.index)

        # Nettoyer les NaN qui peuvent causer des probl√®mes
        macd_line = macd_line.fillna(0.0)
        signal_line = signal_line.fillna(0.0)

        # D√©tecter les croisements
        # MACD au-dessus de Signal
        macd_above = macd_line > signal_line
        # Utiliser shift avec fill_value pour √©viter FutureWarning
        macd_above_prev = macd_above.shift(1, fill_value=False)

        # Golden Cross: MACD passe au-dessus de Signal
        golden_cross = macd_above & ~macd_above_prev

        # Death Cross: MACD passe en dessous de Signal
        death_cross = ~macd_above & macd_above_prev

        signals[golden_cross] = 1.0
        signals[death_cross] = -1.0

        return signals

    def describe(self) -> str:
        """Description de la strat√©gie."""
        return (
            "MACD Cross Strategy: G√©n√®re des signaux sur les croisements "
            "entre la ligne MACD et la ligne Signal. "
            "Achat sur golden cross, vente sur death cross."
        )

    def run(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any] = None
    ) -> StrategyResult:
        """
        Ex√©cute la strat√©gie.

        Args:
            df: DataFrame OHLCV
            indicators: Dictionnaire d'indicateurs pr√©-calcul√©s
            params: Param√®tres (optionnel, utilise default_params sinon)

        Returns:
            StrategyResult avec signaux et m√©tadonn√©es
        """
        if params is None:
            params = self.default_params

        signals = self.generate_signals(df, indicators, params)

        # Compter les signaux
        n_long = (signals == 1).sum()
        n_short = (signals == -1).sum()

        self._last_result = StrategyResult(
            signals=signals,
            params_used=params,
            metadata={
                "strategy": self.name,
                "total_signals": n_long + n_short,
                "long_signals": int(n_long),
                "short_signals": int(n_short),
                "fast_period": params.get("fast_period", 12),
                "slow_period": params.get("slow_period", 26),
                "signal_period": params.get("signal_period", 9),
            }
        )

        return self._last_result
```
<!-- MODULE-END: macd_cross.py -->

<!-- MODULE-START: rsi_reversal.py -->
```json
{
  "name": "rsi_reversal.py",
  "path": "strategies\\rsi_reversal.py",
  "ext": ".py",
  "anchor": "rsi_reversal_py"
}
```
## rsi_reversal_py
*Chemin* : `strategies\rsi_reversal.py`  
*Type* : `.py`  

```python
"""
Module-ID: strategies.rsi_reversal

Purpose: Strat√©gie mean-reversion bas√©e sur seuils sur√©dapte/survente RSI.

Role in pipeline: core

Key components: RSIReversalStrategy, rsi_period, overbought_threshold, oversold_threshold

Inputs: DataFrame OHLCV avec colonne close

Outputs: StrategyResult (signaux 1/-1/0 sur seuils RSI)

Dependencies: strategies.base, indicators.rsi, utils.parameters, pandas, numpy

Conventions: oversold < 50 < overbought; RSI p√©riode standard 14; signaux confirm√©s.

Read-if: Modification seuils RSI, p√©riode, ou logique renversement.

Skip-if: Vous ne changez que d'autres strat√©gies.
"""

from typing import Any, Dict, List

import numpy as np
import pandas as pd

from strategies.base import StrategyBase, StrategyResult, register_strategy
from utils.parameters import ParameterSpec


@register_strategy("rsi_reversal")
class RSIReversalStrategy(StrategyBase):
    """
    Strat√©gie RSI de renversement.

    Signaux:
        - LONG (+1): RSI < oversold_level (survente ‚Üí achat)
        - SHORT (-1): RSI > overbought_level (surachat ‚Üí vente)

    Param√®tres:
        - rsi_period: P√©riode du RSI (d√©faut: 14)
        - oversold_level: Seuil de survente (d√©faut: 30)
        - overbought_level: Seuil de surachat (d√©faut: 70)
        - leverage: Multiplicateur de position (d√©faut: 1)
    """

    def __init__(self, name: str = "rsi_reversal"):
        super().__init__(name)

    @property
    def required_indicators(self) -> List[str]:
        """Indicateurs requis par la strat√©gie."""
        return ["rsi"]

    @property
    def default_params(self) -> Dict[str, Any]:
        """Param√®tres par d√©faut."""
        return {
            "rsi_period": 14,
            "oversold_level": 30,
            "overbought_level": 70,
            "leverage": 1,
        }

    @property
    def parameter_specs(self) -> Dict[str, ParameterSpec]:
        """Sp√©cifications des param√®tres pour l'UI et l'optimisation."""
        return {
            "rsi_period": ParameterSpec(
                name="rsi_period",
                min_val=5,
                max_val=30,
                default=14,
                param_type="int",
                description="P√©riode du RSI"
            ),
            "oversold_level": ParameterSpec(
                name="oversold_level",
                min_val=10,
                max_val=40,
                default=30,
                param_type="int",
                description="Seuil de survente"
            ),
            "overbought_level": ParameterSpec(
                name="overbought_level",
                min_val=60,
                max_val=90,
                default=70,
                param_type="int",
                description="Seuil de surachat"
            ),
            "leverage": ParameterSpec(
                name="leverage",
                min_val=1,
                max_val=10,
                default=1,
                param_type="int",
                description="Levier de trading",
                optimize=False,
            ),
        }

    def get_indicator_params(
        self,
        indicator_name: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Mappe les parametres de la strategie vers les indicateurs."""
        if indicator_name == "rsi":
            return {"period": int(params.get("rsi_period", 14))}
        return super().get_indicator_params(indicator_name, params)

    def generate_signals(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re les signaux de trading bas√©s sur les niveaux RSI.

        Args:
            df: DataFrame OHLCV
            indicators: Dictionnaire contenant 'rsi'
            params: Param√®tres de la strat√©gie

        Returns:
            Series de signaux (-1, 0, +1)
        """
        signals = pd.Series(0.0, index=df.index)

        # R√©cup√©rer le RSI
        if "rsi" not in indicators or indicators["rsi"] is None:
            return signals

        rsi_values = indicators["rsi"]

        # Convertir en Series si n√©cessaire
        if isinstance(rsi_values, np.ndarray):
            rsi_values = pd.Series(rsi_values, index=df.index)

        oversold = params.get("oversold_level", 30)
        overbought = params.get("overbought_level", 70)

        # Signaux
        # LONG quand RSI passe sous le niveau de survente
        # Utiliser fill_value=50 (neutre) pour √©viter les NaN au d√©but
        rsi_prev = rsi_values.shift(1, fill_value=50.0)
        long_signal = (rsi_values < oversold) & (rsi_prev >= oversold)

        # SHORT quand RSI passe au-dessus du niveau de surachat
        short_signal = (rsi_values > overbought) & (rsi_prev <= overbought)

        signals[long_signal] = 1.0
        signals[short_signal] = -1.0

        return signals

    def describe(self) -> str:
        """Description de la strat√©gie."""
        return (
            "RSI Reversal Strategy: G√©n√®re des signaux bas√©s sur les "
            "niveaux de surachat/survente du RSI. "
            "Achat en survente, vente en surachat."
        )

    def run(
        self,
        df: pd.DataFrame,
        indicators: Dict[str, Any],
        params: Dict[str, Any] = None
    ) -> StrategyResult:
        """
        Ex√©cute la strat√©gie.

        Args:
            df: DataFrame OHLCV
            indicators: Dictionnaire d'indicateurs pr√©-calcul√©s
            params: Param√®tres (optionnel, utilise default_params sinon)

        Returns:
            StrategyResult avec signaux et m√©tadonn√©es
        """
        if params is None:
            params = self.default_params

        signals = self.generate_signals(df, indicators, params)

        # Compter les signaux
        n_long = (signals == 1).sum()
        n_short = (signals == -1).sum()

        self._last_result = StrategyResult(
            signals=signals,
            params_used=params,
            metadata={
                "strategy": self.name,
                "total_signals": n_long + n_short,
                "long_signals": int(n_long),
                "short_signals": int(n_short),
                "rsi_period": params.get("rsi_period", 14),
                "oversold_level": params.get("oversold_level", 30),
                "overbought_level": params.get("overbought_level", 70),
            }
        )

        return self._last_result
```
<!-- MODULE-END: rsi_reversal.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "strategies\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `strategies\__init__.py`  
*Type* : `.py`  

```python
"""
Backtest Core - Strategies Package
==================================

Strat√©gies de trading modulaires.
"""

from .base import StrategyBase, StrategyResult, get_strategy, list_strategies
from .bollinger_atr import BollingerATRStrategy
from .bollinger_best_longe_3i import BollingerBestLonge3iStrategy
from .bollinger_best_short_3i import BollingerBestShort3iStrategy
from .ema_cross import EMACrossStrategy
from .indicators_mapping import (
    STRATEGY_INDICATORS_MAP,
    get_all_indicators,
    get_required_indicators,
    get_strategy_info,
)
from .macd_cross import MACDCrossStrategy
from .rsi_reversal import RSIReversalStrategy

__all__ = [
    "StrategyBase",
    "StrategyResult",
    "get_strategy",
    "list_strategies",
    "BollingerATRStrategy",
    "BollingerBestLonge3iStrategy",
    "BollingerBestShort3iStrategy",
    "EMACrossStrategy",
    "MACDCrossStrategy",
    "RSIReversalStrategy",
    "get_required_indicators",
    "get_all_indicators",
    "get_strategy_info",
    "STRATEGY_INDICATORS_MAP",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: app.py -->
```json
{
  "name": "app.py",
  "path": "ui\\app.py",
  "ext": ".py",
  "anchor": "app_py"
}
```
## app_py
*Chemin* : `ui\app.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.app

Purpose: Application Streamlit principale - UI orchestration, page config, sidebar/main/results.

Role in pipeline: user interface

Key components: configure_page(), install_best_pnl_tracker(), main()

Inputs: Streamlit state, user interactions

Outputs: Rendered UI pages (setup, backtest, results, analysis)

Dependencies: streamlit, ui.*, backtest.*, utils.observability

Conventions: PYTHONPATH setup; init_logging() first; st.set_page_config() before sidebar.

Read-if: Modification page layout ou flow control.

Skip-if: Vous lancez juste `streamlit run ui/app.py`.
"""

import sys
from pathlib import Path

# pylint: disable=wrong-import-position

# Ajouter le r√©pertoire racine au PYTHONPATH pour les imports
ROOT_DIR = Path(__file__).parent.parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

# Charger les variables d'environnement depuis .env
try:
    from dotenv import load_dotenv
    env_path = ROOT_DIR / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass  # python-dotenv non install√©, ignorer

import streamlit as st  # noqa: E402

from ui.context import BACKEND_AVAILABLE, IMPORT_ERROR, LLM_AVAILABLE  # noqa: E402
from ui.log_taps import install_best_pnl_tracker  # noqa: E402
from ui.main import render_controls, render_main, render_setup_previews  # noqa: E402
from ui.results import render_results  # noqa: E402
from ui.sidebar import render_sidebar  # noqa: E402
from utils.observability import init_logging  # noqa: E402

init_logging()


def configure_page() -> None:
    st.set_page_config(
        page_title="Backtest Core",
        page_icon="üìà",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    st.markdown(
        """
<style>
div[style*="border-left: 4px solid rgba(0,0,0,0.2)"] code,
div[style*="border-left: 4px solid #666"] code {
    color: #111827 !important;
    background-color: rgba(255,255,255,0.65) !important;
    border: 1px solid rgba(15,23,42,0.25) !important;
}
</style>
""",
        unsafe_allow_html=True,
    )


def render_footer() -> None:
    st.sidebar.markdown("---")
    st.sidebar.markdown("**Backtest Core v2.1**")
    optimization_mode = st.session_state.get("optimization_mode", "Backtest Simple")
    if optimization_mode == "ü§ñ Optimisation LLM":
        llm_status = "‚úÖ LLM" if LLM_AVAILABLE else "‚ùå LLM"
        st.sidebar.caption(f"Architecture d√©coupl√©e UI/Moteur | {llm_status}")
    else:
        st.sidebar.caption("Architecture d√©coupl√©e UI/Moteur")


def main() -> None:
    configure_page()

    best_pnl_tracker = install_best_pnl_tracker()

    if not BACKEND_AVAILABLE:
        st.error("‚ùå Backend non disponible")
        st.code(IMPORT_ERROR)
        st.stop()

    run_button, status_container = render_controls()

    try:
        sidebar_state = render_sidebar()
    except Exception as e:
        import traceback
        st.error(f"‚ùå Exception sidebar: {e}")
        st.code(traceback.format_exc())
        st.stop()

    if sidebar_state is None:
        st.error("‚ùå Erreur sidebar - rechargez la page")
        st.stop()

    render_setup_previews(sidebar_state)
    render_main(sidebar_state, run_button, status_container)
    render_results(sidebar_state, best_pnl_tracker)
    render_footer()


if __name__ == "__main__":
    main()
```
<!-- MODULE-END: app.py -->

<!-- MODULE-START: cache_integration.py -->
```json
{
  "name": "cache_integration.py",
  "path": "ui\\cache_integration.py",
  "ext": ".py",
  "anchor": "cache_integration_py"
}
```
## cache_integration_py
*Chemin* : `ui\cache_integration.py`  
*Type* : `.py`  

```python
"""
Module d'int√©gration du cache am√©lior√© dans helpers.py

Ajoute les fonctions de cache TTL intelligent pour remplacer le cache session state basique.
"""

def integrate_cache_manager_into_load_selected_data():
    """
    Code d'int√©gration pour load_selected_data avec cache manager.

    Cette fonction montre comment modifier load_selected_data pour utiliser
    le cache manager au lieu du cache session state basique.
    """

    # Code √† int√©grer dans load_selected_data de helpers.py :
    integration_code = """
def load_selected_data(
    symbol: str,
    timeframe: str,
    start_date: Optional[object],
    end_date: Optional[object],
) -> Tuple[Optional[pd.DataFrame], str]:
    from .cache_manager import get_cached_data, cache_data

    # V√©rifier cache d'abord
    cached_df = get_cached_data(symbol, timeframe, start_date, end_date)
    if cached_df is not None:
        # Mise √† jour session state avec donn√©es cached
        st.session_state["ohlcv_df"] = cached_df
        st.session_state["ohlcv_cache_key"] = _data_cache_key(
            symbol, timeframe, start_date, end_date
        )
        st.session_state["ohlcv_status_msg"] = "üìã Donn√©es du cache (5min TTL)"
        return cached_df, "üìã Donn√©es du cache (5min TTL)"

    # Charger depuis source si pas en cache
    start_str = str(start_date) if start_date else None
    end_str = str(end_date) if end_date else None
    df, msg = safe_load_data(symbol, timeframe, start_str, end_str)
    if df is not None:
        # Mettre en cache les nouvelles donn√©es
        cache_data(symbol, timeframe, start_date, end_date, df)
        st.session_state["ohlcv_df"] = df
        st.session_state["ohlcv_cache_key"] = _data_cache_key(
            symbol, timeframe, start_date, end_date
        )
        st.session_state["ohlcv_status_msg"] = msg
    return df, msg
    """

    return integration_code


def add_cache_cleanup_to_sidebar():
    """
    Code d'ajout d'un bouton de nettoyage cache dans la sidebar.
    """

    cleanup_code = """
    # Ajout dans sidebar.py - section debug
    if st.sidebar.button("üóëÔ∏è Nettoyer cache donn√©es"):
        from ui.cache_manager import clear_data_cache, get_cache_stats
        stats_before = get_cache_stats()
        clear_data_cache()
        st.sidebar.success(f"Cache nettoy√©! ({stats_before['total_entries']} entr√©es supprim√©es)")

    # Optionnel : afficher stats cache
    if st.sidebar.checkbox("üìä Stats cache", value=False):
        from ui.cache_manager import get_cache_stats
        stats = get_cache_stats()
        st.sidebar.json(stats)
    """

    return cleanup_code
```
<!-- MODULE-END: cache_integration.py -->

<!-- MODULE-START: cache_manager.py -->
```json
{
  "name": "cache_manager.py",
  "path": "ui\\cache_manager.py",
  "ext": ".py",
  "anchor": "cache_manager_py"
}
```
## cache_manager_py
*Chemin* : `ui\cache_manager.py`  
*Type* : `.py`  

```python
"""
Module de gestion du cache pour l'interface utilisateur.

Fournit un cache intelligent avec TTL pour √©viter les rechargements r√©p√©t√©s
des donn√©es OHLCV.
"""
from __future__ import annotations

import gc
import time
from typing import Optional

import pandas as pd

# Cache global pour √©viter rechargements r√©p√©t√©s
_DATA_CACHE = {}
_CACHE_MAX_SIZE = 10  # Nombre max d'entr√©es en cache
_CACHE_TTL = 300  # TTL en secondes (5 minutes)


def get_cached_data(symbol: str, timeframe: str, start_date, end_date) -> Optional[pd.DataFrame]:
    """
    R√©cup√®re les donn√©es du cache si disponibles et valides.

    Args:
        symbol: Symbole du token (ex: BTCUSDC)
        timeframe: Timeframe (ex: 1h)
        start_date: Date de d√©but
        end_date: Date de fin

    Returns:
        DataFrame des donn√©es ou None si pas en cache/expir√©
    """
    cache_key = f"{symbol}_{timeframe}_{start_date}_{end_date}"

    if cache_key in _DATA_CACHE:
        cached_entry = _DATA_CACHE[cache_key]
        # V√©rifier TTL
        if time.time() - cached_entry["timestamp"] < _CACHE_TTL:
            return cached_entry["data"].copy()  # Copie d√©fensive
        else:
            # Nettoyer entr√©e expir√©e
            del _DATA_CACHE[cache_key]

    return None


def cache_data(symbol: str, timeframe: str, start_date, end_date, df: pd.DataFrame) -> None:
    """
    Stocke les donn√©es en cache avec nettoyage automatique.

    Args:
        symbol: Symbole du token
        timeframe: Timeframe
        start_date: Date de d√©but
        end_date: Date de fin
        df: DataFrame √† mettre en cache
    """
    cache_key = f"{symbol}_{timeframe}_{start_date}_{end_date}"

    # Nettoyer le cache si trop plein
    if len(_DATA_CACHE) >= _CACHE_MAX_SIZE:
        # Supprimer l'entr√©e la plus ancienne
        oldest_key = min(_DATA_CACHE.keys(),
                         key=lambda k: _DATA_CACHE[k]["timestamp"])
        del _DATA_CACHE[oldest_key]
        gc.collect()  # Forcer nettoyage m√©moire

    _DATA_CACHE[cache_key] = {
        "data": df.copy(),
        "timestamp": time.time()
    }


def clear_data_cache() -> None:
    """Nettoie compl√®tement le cache de donn√©es."""
    global _DATA_CACHE
    _DATA_CACHE.clear()
    gc.collect()


def get_cache_stats() -> dict:
    """Retourne les statistiques du cache."""
    current_time = time.time()
    valid_entries = 0
    expired_entries = 0

    for entry in _DATA_CACHE.values():
        if current_time - entry["timestamp"] < _CACHE_TTL:
            valid_entries += 1
        else:
            expired_entries += 1

    return {
        "total_entries": len(_DATA_CACHE),
        "valid_entries": valid_entries,
        "expired_entries": expired_entries,
        "max_size": _CACHE_MAX_SIZE,
        "ttl_seconds": _CACHE_TTL,
    }
```
<!-- MODULE-END: cache_manager.py -->

<!-- MODULE-START: constants.py -->
```json
{
  "name": "constants.py",
  "path": "ui\\constants.py",
  "ext": ".py",
  "anchor": "constants_py"
}
```
## constants_py
*Chemin* : `ui\constants.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.constants

Purpose: Constantes UI - limites param√®tres, descriptions strat√©gies, options modes, styles.

Role in pipeline: configuration

Key components: PARAM_CONSTRAINTS dict, get_strategy_description(), MODE_OPTIONS, CSS

Inputs: None (static definitions)

Outputs: Constants exported

Dependencies: strategies.indicators_mapping

Conventions: Min/max/step pour chaque param; descriptions UI-friendly; CSS button inline.

Read-if: Modification ranges params ou descriptions strat√©gies.

Skip-if: Vous appelez get_strategy_description(strategy_name).
"""

from __future__ import annotations

import re
from typing import Dict, List, Tuple

from strategies.indicators_mapping import STRATEGY_INDICATORS_MAP, get_ui_indicators

# Contraintes des parametres (min, max, step, description)
# Plages etendues pour permettre plus de combinaisons de test
PARAM_CONSTRAINTS: Dict[str, Dict[str, object]] = {
    # Bollinger ATR Strategy
    "bb_period": {
        "min": 2, "max": 200, "step": 1, "default": 20,
        "description": "P√©riode des Bollinger Bands (2-200)",
    },
    "bb_std": {
        "min": 0.5, "max": 5.0, "step": 0.1, "default": 2.0,
        "description": "√âcart-type des bandes (0.5-5.0)",
    },
    "bb_window": {
        "min": 10, "max": 50, "step": 1, "default": 20,
        "description": "Periode Bollinger (10-50)",
    },
    "ma_window": {
        "min": 5, "max": 30, "step": 1, "default": 10,
        "description": "Periode MA (5-30)",
    },
    "trailing_pct": {
        "min": 0.5, "max": 1.0, "step": 0.05, "default": 0.8,
        "description": "Trailing stop (0.5-1.0)",
    },
    "short_stop_pct": {
        "min": 0.1, "max": 0.5, "step": 0.01, "default": 0.37,
        "description": "Stop loss short (0.1-0.5)",
    },
    "atr_period": {
        "min": 2, "max": 100, "step": 1, "default": 14,
        "description": "Periode ATR (2-100)",
    },
    "atr_percentile": {
        "min": 0, "max": 60, "step": 1, "default": 30,
        "description": "Percentile ATR (0-60)",
    },
    "entry_z": {
        "min": 0.5, "max": 5.0, "step": 0.1, "default": 2.0,
        "description": "Z-score d'entr√©e (0.5-5.0)",
    },
    "k_sl": {
        "min": 0.1, "max": 10.0, "step": 0.1, "default": 1.5,
        "description": "Multiplicateur stop-loss (0.1-10.0)",
    },
    # Commun
    "leverage": {
        "min": 1, "max": 10, "step": 1, "default": 1,
        "description": "Levier de trading (1-10) - d√©faut: 1 pour √©viter ruine du compte",
    },
    # EMA Cross / MA Crossover Strategy
    "fast_period": {
        "min": 2, "max": 200, "step": 1, "default": 12,
        "description": "P√©riode MA rapide (2-200)",
    },
    "slow_period": {
        "min": 2, "max": 500, "step": 1, "default": 26,
        "description": "P√©riode MA lente (2-500)",
    },
    "ema_fast": {
        "min": 10, "max": 50, "step": 1, "default": 20,
        "description": "P√©riode EMA rapide (10-50)",
    },
    "ema_slow": {
        "min": 30, "max": 100, "step": 1, "default": 50,
        "description": "P√©riode EMA lente (30-100)",
    },
    # MACD Cross Strategy
    "signal_period": {
        "min": 2, "max": 50, "step": 1, "default": 9,
        "description": "P√©riode ligne signal MACD (2-50)",
    },
    # RSI Reversal Strategy
    "rsi_period": {
        "min": 2, "max": 100, "step": 1, "default": 14,
        "description": "P√©riode RSI (2-100)",
    },
    "oversold_level": {
        "min": 1, "max": 49, "step": 1, "default": 30,
        "description": "Seuil survente RSI (1-49)",
    },
    "overbought_level": {
        "min": 51, "max": 99, "step": 1, "default": 70,
        "description": "Seuil surachat RSI (51-99)",
    },
    # ATR Channel Strategy
    "atr_mult": {
        "min": 0.1, "max": 10.0, "step": 0.1, "default": 2.0,
        "description": "Multiplicateur ATR pour canal (0.1-10.0)",
    },
    # EMA Stochastic Scalp Strategy
    "fast_ema": {
        "min": 2, "max": 200, "step": 1, "default": 50,
        "description": "P√©riode EMA rapide scalp (2-200)",
    },
    "slow_ema": {
        "min": 2, "max": 500, "step": 1, "default": 100,
        "description": "P√©riode EMA lente scalp (2-500)",
    },
    "stoch_k": {
        "min": 2, "max": 100, "step": 1, "default": 14,
        "description": "P√©riode Stochastic %K (2-100)",
    },
    "stoch_d": {
        "min": 1, "max": 50, "step": 1, "default": 3,
        "description": "P√©riode Stochastic %D (1-50)",
    },
    "stoch_oversold": {
        "min": 1, "max": 49, "step": 1, "default": 20,
        "description": "Seuil survente Stochastic (1-49)",
    },
    "stoch_overbought": {
        "min": 51, "max": 99, "step": 1, "default": 80,
        "description": "Seuil surachat Stochastic (51-99)",
    },
}

_STRATEGY_TYPE_RE = re.compile(r"\(([^)]+)\)\s*$")
_LEADING_NONWORD_RE = re.compile(r"^\W+\s*")


def get_strategy_ui_label(strategy_key: str) -> str:
    info = STRATEGY_INDICATORS_MAP.get(strategy_key)
    if not info:
        return strategy_key
    return info.display_label()


def get_strategy_display_name(strategy_key: str) -> str:
    label = get_strategy_ui_label(strategy_key)
    label = _LEADING_NONWORD_RE.sub("", label).strip()
    label = _STRATEGY_TYPE_RE.sub("", label).strip()
    return label or strategy_key


def get_strategy_type(strategy_key: str) -> str:
    label = get_strategy_ui_label(strategy_key)
    match = _STRATEGY_TYPE_RE.search(label)
    if not match:
        return "Autre"
    return match.group(1).strip()


def get_strategy_description(strategy_key: str) -> str:
    info = STRATEGY_INDICATORS_MAP.get(strategy_key)
    if not info:
        return ""
    return info.description or ""


def get_strategy_ui_indicators(strategy_key: str) -> List[str]:
    try:
        return get_ui_indicators(strategy_key)
    except KeyError:
        return []


MODE_BUTTON_CSS = """
<style>
    .mode-button {
        width: 100%;
        padding: 12px 16px;
        margin: 6px 0;
        border: 2px solid transparent;
        border-radius: 8px;
        font-size: 14px;
        font-weight: 600;
        cursor: pointer;
        text-align: center;
        transition: all 0.3s ease;
    }
    .mode-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .mode-inactive {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        opacity: 0.6;
    }
    .mode-active {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        opacity: 1;
        border-color: #ffd700;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
</style>
"""

MODE_OPTIONS: List[Tuple[str, str, str]] = [
    ("Backtest Simple", "üìä", "1 combinaison de param√®tres"),
    ("Grille de Param√®tres", "üî¢", "Exploration min/max/step"),
    ("ü§ñ Optimisation LLM", "üß†", "Agents IA + Deep Trace int√©gr√©"),
]


def build_strategy_options(available_strategies: List[str]) -> Dict[str, str]:
    return {get_strategy_ui_label(k): k for k in available_strategies}
```
<!-- MODULE-END: constants.py -->

<!-- MODULE-START: context.py -->
```json
{
  "name": "context.py",
  "path": "ui\\context.py",
  "ext": ".py",
  "anchor": "context_py"
}
```
## context_py
*Chemin* : `ui\context.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.context

Purpose: Context loaders - chargement imports backend avec error handling, fallbacks gracieux.

Role in pipeline: configuration/initialization

Key components: BACKEND_AVAILABLE flag, lazy imports BacktestEngine/RunResult/data/strategies/agents

Inputs: None (dynamic imports)

Outputs: Modules import√©s (ou None + IMPORT_ERROR si echec)

Dependencies: backtest.*, data.*, indicators.*, strategies.*, agents.*

Conventions: sys.path injection; try/except gracieux; fallback lazy loading.

Read-if: Modification imports ou gestion errors.

Skip-if: Vous checked juste BACKEND_AVAILABLE flag.
"""

from __future__ import annotations

# pylint: disable=invalid-name
import sys
from pathlib import Path

# Ensure project root is on sys.path when running via streamlit.
sys.path.insert(0, str(Path(__file__).parent.parent))

BACKEND_AVAILABLE = False
IMPORT_ERROR = ""

BacktestEngine = None
RunResult = None
get_storage = None

# Data/strategy/indicators
load_ohlcv = None
discover_available_data = None
get_data_date_range = None
calculate_indicator = None
get_strategy = None
list_strategies = None
get_strategy_info = None

# Parameters/presets
ParameterSpec = None
compute_search_space_stats = None
list_strategy_versions = None
load_strategy_version = None
resolve_latest_version = None
save_versioned_preset = None

try:
    from backtest.engine import BacktestEngine, RunResult  # noqa: F401
    from backtest.storage import get_storage  # noqa: F401
    from data.loader import discover_available_data, load_ohlcv, get_data_date_range  # noqa: F401
    from indicators.registry import calculate_indicator  # noqa: F401
    from strategies.base import get_strategy, list_strategies  # noqa: F401
    from strategies.indicators_mapping import get_strategy_info  # noqa: F401
    from utils.parameters import (  # noqa: F401
        ParameterSpec,
        compute_search_space_stats,
        list_strategy_versions,
        load_strategy_version,
        resolve_latest_version,
        save_versioned_preset,
    )
    BACKEND_AVAILABLE = True
except ImportError as exc:
    IMPORT_ERROR = str(exc)
    BACKEND_AVAILABLE = False

LLM_AVAILABLE = False
LLM_IMPORT_ERROR = ""

AutonomousStrategist = None
create_optimizer_from_engine = None
create_orchestrator_with_backtest = None
get_strategy_param_bounds = None
get_strategy_param_space = None
LLMConfig = None
LLMProvider = None
create_llm_client = None

KNOWN_MODELS = None
ModelCategory = None
ModelInfo = None
RoleModelConfig = None
get_global_model_config = None
get_models_by_category = None
list_available_models = None
set_global_model_config = None

ensure_ollama_running = None
is_ollama_available = None

OrchestrationLogger = None
generate_session_id = None

ActivityType = None
AgentActivity = None
AgentActivityTimeline = None
AgentType = None
render_agent_timeline = None
render_mini_timeline = None

RECOMMENDED_FOR_STRATEGY = None
get_available_models_for_ui = None
get_model_info = None

render_mini_monitor = None
render_deep_trace_viewer = None

LiveOrchestrationViewer = None
render_full_orchestration_viewer = None
render_live_orchestration_panel = None
render_orchestration_logs = None
render_orchestration_summary_table = None

BUILTIN_PRESETS = None
apply_preset_to_config = None
delete_model_preset = None
get_current_config_as_dict = None
list_model_presets = None
load_model_preset = None
save_model_preset = None

try:
    from agents.autonomous_strategist import AutonomousStrategist  # noqa: F401
    from agents.integration import (  # noqa: F401
        create_optimizer_from_engine,
        create_orchestrator_with_backtest,
        get_strategy_param_bounds,
        get_strategy_param_space,
    )
    from agents.llm_client import LLMConfig, LLMProvider, create_llm_client  # noqa: F401
    from agents.model_config import (  # noqa: F401
        KNOWN_MODELS,
        ModelCategory,
        ModelInfo,
        RoleModelConfig,
        get_global_model_config,
        get_models_by_category,
        list_available_models,
        set_global_model_config,
    )
    from agents.ollama_manager import ensure_ollama_running, is_ollama_available  # noqa: F401
    from agents.orchestration_logger import OrchestrationLogger, generate_session_id  # noqa: F401
    from ui.components.agent_timeline import (  # noqa: F401
        ActivityType,
        AgentActivity,
        AgentActivityTimeline,
        AgentType,
        render_agent_timeline,
        render_mini_timeline,
    )
    from ui.components.model_selector import (  # noqa: F401
        OPTIMAL_CONFIG_BY_ROLE,
        OPTIMAL_CONFIG_FALLBACK,
        RECOMMENDED_FOR_STRATEGY,
        get_available_models_for_ui,
        get_model_info,
        get_optimal_config_for_role,
    )
    from ui.components.monitor import render_mini_monitor  # noqa: F401
    from ui.deep_trace_viewer import render_deep_trace_viewer  # noqa: F401
    from ui.model_presets import (  # noqa: F401
        BUILTIN_PRESETS,
        apply_preset_to_config,
        delete_model_preset,
        get_current_config_as_dict,
        list_model_presets,
        load_model_preset,
        save_model_preset,
    )
    from ui.orchestration_viewer import (  # noqa: F401
        LiveOrchestrationViewer,
        render_full_orchestration_viewer,
        render_live_orchestration_panel,
        render_orchestration_logs,
        render_orchestration_summary_table,
    )
    LLM_AVAILABLE = True
except ImportError as exc:
    LLM_IMPORT_ERROR = str(exc)
    LLM_AVAILABLE = False
```
<!-- MODULE-END: context.py -->

<!-- MODULE-START: deep_trace_viewer.py -->
```json
{
  "name": "deep_trace_viewer.py",
  "path": "ui\\deep_trace_viewer.py",
  "ext": ".py",
  "anchor": "deep_trace_viewer_py"
}
```
## deep_trace_viewer_py
*Chemin* : `ui\deep_trace_viewer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.deep_trace_viewer

Purpose: Visualiseur Deep Trace d√©taill√© pour orchestration LLM - timeline, inspecteur, propositions, state machine, m√©triques.

Role in pipeline: visualization / debugging

Key components: render_deep_trace(), timeline, metrics, state inspector

Inputs: OrchestrationLogger instance

Outputs: Interface Streamlit multi-onglets (timeline, inspector, metrics, etc.)

Dependencies: streamlit, agents.orchestration_logger

Conventions: Onglets: Timeline, Inspector, Proposals, State Machine, Metrics

Read-if: Deep debugging orchestration LLM ou inspection √©tats.

Skip-if: Pas d'agents LLM ou monitoring minimal suffisant.
"""

import math
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd
import streamlit as st

from agents.orchestration_logger import (
    OrchestrationActionType,
    OrchestrationLogEntry,
    OrchestrationLogger,
    OrchestrationStatus,
)

# ============================================================================
# UTILITAIRES
# ============================================================================


def _format_float(value: Any, precision: int) -> Optional[str]:
    """Formate un float de facon sure (retourne None si invalide)."""
    if value is None:
        return None
    try:
        parsed = float(value)
    except (TypeError, ValueError):
        return None
    if not math.isfinite(parsed):
        return None
    return f"{parsed:.{precision}f}"


def _format_percent(value: Any, precision: int = 2) -> Optional[str]:
    """Formate un pourcentage de facon sure (retourne None si invalide)."""
    if value is None:
        return None
    try:
        parsed = float(value)
    except (TypeError, ValueError):
        return None
    if not math.isfinite(parsed):
        return None
    return f"{parsed:.{precision}%}"


def _get_event_emoji(action_type: OrchestrationActionType) -> str:
    """Retourne l'emoji appropri√© pour un type d'√©v√©nement."""
    emoji_map = {
        OrchestrationActionType.RUN_START: "üöÄ",
        OrchestrationActionType.RUN_END: "üèÅ",
        OrchestrationActionType.PHASE_START: "üìç",
        OrchestrationActionType.STATE_ENTER: "‚û°Ô∏è",
        OrchestrationActionType.STATE_CHANGE: "üîÑ",
        OrchestrationActionType.AGENT_EXECUTE_START: "ü§ñ",
        OrchestrationActionType.AGENT_EXECUTE_END: "‚úÖ",
        OrchestrationActionType.PROPOSALS_GENERATED: "üí°",
        OrchestrationActionType.PROPOSAL_TEST_STARTED: "üß™",
        OrchestrationActionType.PROPOSAL_TEST_ENDED: "üìä",
        OrchestrationActionType.VALIDATOR_DECISION: "‚öñÔ∏è",
        OrchestrationActionType.BACKTEST_START: "‚ñ∂Ô∏è",
        OrchestrationActionType.BACKTEST_END: "‚èπÔ∏è",
        OrchestrationActionType.WARNING: "‚ö†Ô∏è",
        OrchestrationActionType.ERROR: "‚ùå",
        OrchestrationActionType.CONFIG_VALID: "‚úîÔ∏è",
        OrchestrationActionType.CONFIG_INVALID: "‚ùå",
    }
    return emoji_map.get(action_type, "‚Ä¢")


def _get_event_color(action_type: OrchestrationActionType, status: OrchestrationStatus) -> str:
    """Retourne la couleur de fond pour un √©v√©nement."""
    # Priorit√© au statut
    if status == OrchestrationStatus.FAILED:
        return "#f8d7da"  # Rouge clair
    elif status == OrchestrationStatus.COMPLETED:
        return "#d4edda"  # Vert clair

    # Sinon, couleur par type
    color_map = {
        OrchestrationActionType.RUN_START: "#e0f7fa",
        OrchestrationActionType.RUN_END: "#c8e6c9",
        OrchestrationActionType.ERROR: "#f8d7da",
        OrchestrationActionType.WARNING: "#fff3cd",
        OrchestrationActionType.AGENT_EXECUTE_START: "#e3f2fd",
        OrchestrationActionType.AGENT_EXECUTE_END: "#c8e6c9",
        OrchestrationActionType.VALIDATOR_DECISION: "#fff9c4",
        OrchestrationActionType.BACKTEST_END: "#f3e5f5",
    }
    return color_map.get(action_type, "#f5f5f5")


def _format_timestamp(ts_str: str) -> str:
    """Formate un timestamp ISO en HH:MM:SS."""
    try:
        dt = datetime.fromisoformat(ts_str)
        return dt.strftime("%H:%M:%S.%f")[:-3]  # Millisecondes
    except Exception:
        return ts_str[:12] if len(ts_str) > 12 else ts_str


def _get_role_badge_color(role: Optional[str]) -> str:
    """Retourne la couleur du badge de r√¥le."""
    if not role:
        return "#9e9e9e"
    role_colors = {
        "analyst": "#2196f3",
        "strategist": "#4caf50",
        "critic": "#ff9800",
        "validator": "#9c27b0",
    }
    return role_colors.get(role.lower(), "#9e9e9e")


# ============================================================================
# TIMELINE COMPL√àTE
# ============================================================================

def render_timeline_panel(logger: OrchestrationLogger, filters: Dict[str, Any]):
    """
    Affiche la timeline compl√®te des √©v√©nements avec filtres.

    Args:
        logger: OrchestrationLogger instance
        filters: Dict avec 'iteration', 'agent', 'event_type', 'level'
    """
    st.markdown("### üìã Timeline des √âv√©nements")

    # Appliquer les filtres
    filtered_logs = logger.logs

    if filters.get("iteration") and "Toutes" not in filters["iteration"]:
        iterations = [int(x.split()[1]) for x in filters["iteration"] if x != "Toutes"]
        filtered_logs = [log for log in filtered_logs if log.iteration in iterations]

    if filters.get("agent") and "Tous" not in filters["agent"]:
        filtered_logs = [log for log in filtered_logs if log.agent in filters["agent"]]

    if filters.get("event_type") and "Tous" not in filters["event_type"]:
        event_types = [OrchestrationActionType(et) for et in filters["event_type"]]
        filtered_logs = [log for log in filtered_logs if log.action_type in event_types]

    if filters.get("level"):
        level = filters["level"]
        if level == "ERROR":
            filtered_logs = [
                log
                for log in filtered_logs
                if log.action_type == OrchestrationActionType.ERROR
                or log.status == OrchestrationStatus.FAILED
            ]
        elif level == "WARNING":
            filtered_logs = [
                log
                for log in filtered_logs
                if log.action_type == OrchestrationActionType.WARNING
            ]

    if not filtered_logs:
        st.info("Aucun √©v√©nement ne correspond aux filtres s√©lectionn√©s")
        return

    st.caption(f"Affichage de {len(filtered_logs)} √©v√©nements sur {len(logger.logs)} total")

    # Grouper par it√©ration
    logs_by_iteration = {}
    for log in filtered_logs:
        iteration = log.iteration
        if iteration not in logs_by_iteration:
            logs_by_iteration[iteration] = []
        logs_by_iteration[iteration].append(log)

    # Afficher par it√©ration (ordre inverse)
    for iteration in sorted(logs_by_iteration.keys(), reverse=True):
        iteration_logs = logs_by_iteration[iteration]

        with st.expander(
            f"üîÑ **It√©ration {iteration}** ({len(iteration_logs)} √©v√©nements)",
            expanded=(iteration == max(logs_by_iteration.keys()))
        ):
            for log in iteration_logs:
                _render_timeline_entry(log)


def _render_timeline_entry(log: OrchestrationLogEntry):
    """Affiche une entr√©e de timeline."""
    emoji = _get_event_emoji(log.action_type)
    color = _get_event_color(log.action_type, log.status)
    timestamp = _format_timestamp(log.timestamp)

    # Badge de r√¥le
    role_badge = ""
    if log.agent:
        role_color = _get_role_badge_color(log.agent)
        role_badge = f'<span style="background-color: {role_color}; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.75em; margin-left: 8px;"><strong>{log.agent.upper()}</strong></span>'

    # Type d'√©v√©nement
    event_type = log.action_type.value.replace("_", " ").title()

    # Ligne principale
    main_html = f"""
    <div style="background-color: {color}; padding: 8px 12px; border-radius: 5px; margin: 5px 0; border-left: 4px solid #666;">
        <span style="font-size: 1.2em;">{emoji}</span>
        <code style="background-color: rgba(0,0,0,0.1); padding: 2px 6px; border-radius: 3px; margin: 0 8px;">{timestamp}</code>
        <strong>{event_type}</strong>
        {role_badge}
    </div>
    """
    st.markdown(main_html, unsafe_allow_html=True)

    # D√©tails si disponibles
    if log.details:
        _render_event_details(log)


def _render_event_details(log: OrchestrationLogEntry):
    """Affiche les d√©tails d'un √©v√©nement."""
    details = log.details

    # Extraire les champs importants
    important_fields = []

    # Mod√®le LLM
    if "model" in details:
        important_fields.append(f"üì¶ Mod√®le: `{details['model']}`")

    # Latence
    if "latency_ms" in details:
        latency = details["latency_ms"]
        latency_str = _format_float(latency, 0) or str(latency)
        important_fields.append(f"‚è±Ô∏è Latence: {latency_str}ms")

    # M√©triques
    if "sharpe" in details or "sharpe_ratio" in details:
        sharpe = details.get("sharpe") or details.get("sharpe_ratio")
        sharpe_str = _format_float(sharpe, 3) or "N/A"
        important_fields.append(f"üìä Sharpe: {sharpe_str}")

    if "total_return" in details:
        ret = details["total_return"]
        ret_str = _format_percent(ret, 2)
        if ret_str is None:
            ret_str = str(ret) if ret is not None else "N/A"
        important_fields.append(f"üí∞ Return: {ret_str}")

    if "max_drawdown" in details:
        dd = details["max_drawdown"]
        dd_str = _format_percent(dd, 2)
        if dd_str is None:
            dd_str = str(dd) if dd is not None else "N/A"
        important_fields.append(f"üìâ Drawdown: {dd_str}")

    # D√©cision
    if "decision" in details:
        important_fields.append(f"‚öñÔ∏è D√©cision: **{details['decision']}**")

    # Propositions
    if "count" in details:
        important_fields.append(f"üí° Nombre: {details['count']}")

    # Message/Erreur
    if "message" in details:
        msg = details["message"]
        if log.action_type == OrchestrationActionType.ERROR:
            important_fields.append(f"‚ùå {msg}")
        elif log.action_type == OrchestrationActionType.WARNING:
            important_fields.append(f"‚ö†Ô∏è {msg}")
        else:
            important_fields.append(f"üìù {msg}")

    # Afficher les champs importants
    if important_fields:
        for field in important_fields:
            st.caption(f"   {field}")

    # Bouton pour afficher le JSON complet
    with st.expander("üîç D√©tails complets (JSON)", expanded=False):
        st.json(details, expanded=False)


# ============================================================================
# INSPECTEUR LLM
# ============================================================================

def render_llm_inspector_panel(logger: OrchestrationLogger):
    """
    Affiche l'inspecteur des √©changes LLM par r√¥le.
    """
    st.markdown("### ü§ñ Inspecteur LLM")

    # R√©cup√©rer tous les √©v√©nements d'agents
    agent_events = [
        log for log in logger.logs
        if log.action_type in [
            OrchestrationActionType.AGENT_EXECUTE_START,
            OrchestrationActionType.AGENT_EXECUTE_END,
        ]
    ]

    if not agent_events:
        st.info("Aucun √©v√©nement LLM enregistr√©")
        return

    # Grouper par r√¥le
    events_by_role = {}
    for log in agent_events:
        role = log.agent or "unknown"
        if role not in events_by_role:
            events_by_role[role] = []
        events_by_role[role].append(log)

    # Onglets par r√¥le
    roles = sorted(events_by_role.keys())
    if len(roles) == 1:
        _render_llm_role_details(roles[0], events_by_role[roles[0]])
    else:
        tabs = st.tabs([f"üé≠ {role.capitalize()}" for role in roles])
        for tab, role in zip(tabs, roles):
            with tab:
                _render_llm_role_details(role, events_by_role[role])


def _render_llm_role_details(role: str, events: List[OrchestrationLogEntry]):
    """Affiche les d√©tails LLM pour un r√¥le."""
    # Statistiques globales
    total_calls = len([e for e in events if e.action_type == OrchestrationActionType.AGENT_EXECUTE_END])
    successful = len([e for e in events if e.action_type == OrchestrationActionType.AGENT_EXECUTE_END and e.details.get("success")])

    total_latency = sum([
        e.details.get("latency_ms", 0)
        for e in events
        if e.action_type == OrchestrationActionType.AGENT_EXECUTE_END
    ])
    avg_latency = total_latency / total_calls if total_calls > 0 else 0

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Appels", total_calls)
    with col2:
        st.metric("R√©ussis", successful)
    with col3:
        st.metric("Latence Moyenne", f"{avg_latency:.0f}ms")

    st.markdown("---")

    # Liste des appels
    st.markdown("#### üìû Historique des Appels")

    # Filtrer uniquement les √©v√©nements END (qui contiennent le r√©sum√©)
    end_events = [e for e in events if e.action_type == OrchestrationActionType.AGENT_EXECUTE_END]

    for i, event in enumerate(reversed(end_events), 1):
        details = event.details
        timestamp = _format_timestamp(event.timestamp)
        model = details.get("model", "inconnu")
        latency = details.get("latency_ms", 0)
        success = details.get("success", False)
        iteration = event.iteration

        status_emoji = "‚úÖ" if success else "‚ùå"

        with st.expander(
            f"{status_emoji} **Appel #{i}** - It√©ration {iteration} - {timestamp} ({latency}ms)",
            expanded=False
        ):
            st.markdown(f"**Mod√®le:** `{model}`")
            st.markdown(f"**It√©ration:** {iteration}")
            st.markdown(f"**Timestamp:** {timestamp}")
            st.markdown(f"**Latence:** {latency}ms")
            st.markdown(f"**Statut:** {'R√©ussi ‚úÖ' if success else '√âchou√© ‚ùå'}")

            # D√©tails complets
            st.markdown("**M√©tadonn√©es compl√®tes:**")
            st.json(details, expanded=False)


# ============================================================================
# PROPOSITIONS & TESTS
# ============================================================================

def render_proposals_panel(logger: OrchestrationLogger):
    """
    Affiche le panneau Propositions & Tests.
    """
    st.markdown("### üí° Propositions & Tests")

    # R√©cup√©rer les √©v√©nements de propositions
    proposal_events = [
        log for log in logger.logs
        if log.action_type in [
            OrchestrationActionType.PROPOSALS_GENERATED,
            OrchestrationActionType.PROPOSAL_TEST_STARTED,
            OrchestrationActionType.PROPOSAL_TEST_ENDED,
        ]
    ]

    if not proposal_events:
        st.info("Aucune proposition enregistr√©e")
        return

    # Compter les propositions g√©n√©r√©es vs test√©es
    generated_events = [e for e in proposal_events if e.action_type == OrchestrationActionType.PROPOSALS_GENERATED]
    test_ended_events = [e for e in proposal_events if e.action_type == OrchestrationActionType.PROPOSAL_TEST_ENDED]

    total_generated = sum([e.details.get("count", 0) for e in generated_events])
    total_tested = len(test_ended_events)
    tested_successful = len([e for e in test_ended_events if e.details.get("tested", False)])

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Propositions G√©n√©r√©es", total_generated)
    with col2:
        st.metric("Propositions Test√©es", total_tested)
    with col3:
        st.metric("Tests R√©ussis", tested_successful)

    st.markdown("---")

    # Tableau des tests
    if test_ended_events:
        st.markdown("#### üìä R√©sultats des Tests")

        test_data = []
        for event in test_ended_events:
            details = event.details
            # R√©cup√©rer les valeurs (0.0 est une valeur valide, ne pas afficher "N/A")
            sharpe = details.get("sharpe")
            total_return = details.get("total_return")

            test_data.append({
                "ID": details.get("proposal_id", "N/A"),
                "It√©ration": event.iteration,
                "Test√©": "‚úÖ" if details.get("tested") else "‚ùå",
                "Sharpe": f"{sharpe:.3f}" if sharpe is not None else "N/A",
                "Return": f"{total_return:.2%}" if total_return is not None else "N/A",
                "Timestamp": _format_timestamp(event.timestamp),
            })

        df = pd.DataFrame(test_data)
        st.dataframe(df, width="stretch", hide_index=True)
    else:
        st.info("Aucun test de proposition enregistr√©")


# ============================================================================
# STATE MACHINE
# ============================================================================

def render_state_machine_panel(logger: OrchestrationLogger):
    """
    Affiche le panneau State Machine.
    """
    st.markdown("### üîÑ State Machine")

    # R√©cup√©rer les √©v√©nements d'√©tats
    state_events = [
        log for log in logger.logs
        if log.action_type in [
            OrchestrationActionType.STATE_ENTER,
            OrchestrationActionType.STATE_CHANGE,
        ]
    ]

    if not state_events:
        st.info("Aucun √©v√©nement d'√©tat enregistr√©")
        return

    # √âtat actuel (dernier STATE_ENTER)
    current_state = "UNKNOWN"
    if state_events:
        last_enter = next((e for e in reversed(logger.logs) if e.action_type == OrchestrationActionType.STATE_ENTER), None)
        if last_enter:
            current_state = last_enter.details.get("state", "UNKNOWN")

    # Nombre de transitions
    state_changes = [e for e in state_events if e.action_type == OrchestrationActionType.STATE_CHANGE]
    total_transitions = len(state_changes)

    # It√©ration courante
    current_iteration = logger.current_iteration

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("√âtat Actuel", current_state)
    with col2:
        st.metric("It√©ration Courante", current_iteration)
    with col3:
        st.metric("Total Transitions", total_transitions)

    st.markdown("---")

    # Historique des transitions
    st.markdown("#### üìú Historique des Transitions")

    if state_changes:
        transitions_data = []
        for event in reversed(state_changes):
            details = event.details
            transitions_data.append({
                "It√©ration": event.iteration,
                "De": details.get("state_from", "?"),
                "Vers": details.get("state_to", "?"),
                "Timestamp": _format_timestamp(event.timestamp),
            })

        df = pd.DataFrame(transitions_data)
        st.dataframe(df, width="stretch", hide_index=True)
    else:
        st.info("Aucune transition enregistr√©e")


# ============================================================================
# M√âTRIQUES GLOBALES
# ============================================================================

def render_metrics_panel(logger: OrchestrationLogger):
    """
    Affiche le panneau M√©triques Globales de la session.
    """
    st.markdown("### üìà M√©triques Globales Session")

    # Compter les diff√©rents types d'√©v√©nements
    llm_calls = len([
        e for e in logger.logs
        if e.action_type == OrchestrationActionType.AGENT_EXECUTE_END
    ])

    backtests_done = len([
        e for e in logger.logs
        if e.action_type == OrchestrationActionType.BACKTEST_END
        and e.details.get("success")
    ])

    errors_count = len([
        e for e in logger.logs
        if e.action_type == OrchestrationActionType.ERROR
        or e.status == OrchestrationStatus.FAILED
    ])

    warnings_count = len([
        e for e in logger.logs
        if e.action_type == OrchestrationActionType.WARNING
    ])

    # Temps total (si disponible)
    next((e for e in logger.logs if e.action_type == OrchestrationActionType.RUN_START), None)
    run_end = next((e for e in reversed(logger.logs) if e.action_type == OrchestrationActionType.RUN_END), None)

    total_time_s = 0
    if run_end and "total_time_s" in run_end.details:
        total_time_s = run_end.details["total_time_s"]

    # M√©triques principales
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("Total LLM Calls", llm_calls)
    with col2:
        st.metric("Total Backtests", backtests_done)
    with col3:
        st.metric("Temps Total", f"{total_time_s:.1f}s" if total_time_s > 0 else "N/A")
    with col4:
        st.metric("‚ö†Ô∏è Warnings", warnings_count)
    with col5:
        st.metric("‚ùå Errors", errors_count)

    st.markdown("---")

    # Meilleur r√©sultat (si disponible)
    st.markdown("#### üèÜ Meilleur R√©sultat")

    # Chercher dans les √©v√©nements iteration_recorded
    iteration_events = [
        e for e in logger.logs
        if e.action_type == OrchestrationActionType.ITERATION_RECORDED
    ]

    if iteration_events:
        best_sharpe = max([e.details.get("sharpe", -999) for e in iteration_events if e.details.get("sharpe") is not None], default=None)

        if best_sharpe is not None and best_sharpe > -999:
            best_event = next((e for e in iteration_events if e.details.get("sharpe") == best_sharpe), None)
            if best_event:
                details = best_event.details
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Best Sharpe", f"{best_sharpe:.3f}")
                with col2:
                    ret = details.get("total_return", 0)
                    st.metric("Return", f"{ret:.2%}" if ret else "N/A")
                with col3:
                    dd = details.get("max_drawdown", 0)
                    st.metric("Max Drawdown", f"{dd:.2%}" if dd else "N/A")
            else:
                st.info("Donn√©es de meilleur r√©sultat non disponibles")
        else:
            st.info("Aucune m√©trique Sharpe enregistr√©e")
    else:
        st.info("Aucune it√©ration enregistr√©e")


# ============================================================================
# FILTRES
# ============================================================================

def render_filters_sidebar(logger: OrchestrationLogger) -> Dict[str, Any]:
    """
    Affiche les filtres dans la sidebar et retourne les valeurs s√©lectionn√©es.

    Returns:
        Dict avec les filtres s√©lectionn√©s
    """
    st.sidebar.markdown("### üîç Filtres")

    # Filtre par it√©ration
    iterations = sorted(set(log.iteration for log in logger.logs))
    iteration_filter = st.sidebar.multiselect(
        "It√©ration",
        ["Toutes"] + [f"It√©ration {i}" for i in iterations],
        default=["Toutes"]
    )

    # Filtre par agent
    agents = sorted(set(log.agent for log in logger.logs if log.agent))
    agent_filter = st.sidebar.multiselect(
        "Agent",
        ["Tous"] + agents,
        default=["Tous"]
    )

    # Filtre par type d'√©v√©nement
    event_types = sorted(set(log.action_type.value for log in logger.logs))
    event_type_filter = st.sidebar.multiselect(
        "Type d'√©v√©nement",
        ["Tous"] + event_types,
        default=["Tous"]
    )

    # Filtre par niveau (INFO/WARNING/ERROR)
    level_filter = st.sidebar.selectbox(
        "Niveau",
        ["TOUS", "ERROR", "WARNING"],
        index=0
    )

    return {
        "iteration": iteration_filter,
        "agent": agent_filter,
        "event_type": event_type_filter,
        "level": level_filter if level_filter != "TOUS" else None,
    }


# ============================================================================
# SESSION SELECTOR & LOADER
# ============================================================================

def render_session_selector() -> Optional[OrchestrationLogger]:
    """
    Affiche un s√©lecteur de session et permet de charger des traces.

    Returns:
        OrchestrationLogger charg√© ou None
    """
    st.sidebar.markdown("### üìÇ Chargement de Session")

    # D√©couvrir les sessions disponibles dans runs/
    runs_dir = Path("runs")
    if not runs_dir.exists():
        st.sidebar.info("Aucune session disponible (r√©pertoire runs/ inexistant)")
        return None

    # Lister les sessions (dossiers avec trace.jsonl)
    available_sessions = []
    for session_dir in runs_dir.iterdir():
        if session_dir.is_dir():
            trace_file = session_dir / "trace.jsonl"
            if trace_file.exists():
                available_sessions.append(session_dir.name)

    if not available_sessions:
        st.sidebar.info("Aucune session disponible")

        # Option d'upload manuel
        uploaded_file = st.sidebar.file_uploader(
            "Charger un fichier trace (JSON/JSONL)",
            type=["json", "jsonl"],
            key="trace_uploader"
        )

        if uploaded_file:
            try:
                # Sauvegarder temporairement
                temp_path = Path(f"/tmp/{uploaded_file.name}")
                temp_path.write_bytes(uploaded_file.read())

                # Charger
                logger = OrchestrationLogger.load_from_file(temp_path)
                st.sidebar.success(f"‚úÖ Session {logger.session_id} charg√©e")
                return logger
            except Exception as e:
                st.sidebar.error(f"‚ùå Erreur de chargement: {e}")
                return None

        return None

    # S√©lecteur de session
    selected_session = st.sidebar.selectbox(
        "S√©lectionner une session",
        ["-- S√©lectionnez --"] + sorted(available_sessions, reverse=True),
        index=0
    )

    if selected_session == "-- S√©lectionnez --":
        return None

    # Charger la session
    trace_file = runs_dir / selected_session / "trace.jsonl"
    try:
        logger = OrchestrationLogger.load_from_file(trace_file)
        st.sidebar.success(f"‚úÖ Session charg√©e: {selected_session}")
        return logger
    except Exception as e:
        st.sidebar.error(f"‚ùå Erreur de chargement: {e}")
        return None


# ============================================================================
# EXPORT
# ============================================================================

def render_export_panel(logger: OrchestrationLogger, filters: Dict[str, Any]):
    """
    Affiche un panneau d'export des logs filtr√©s.
    """
    st.markdown("### üíæ Export")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("üì• Exporter JSON complet"):
            export_path = Path(f"orchestration_export_{logger.session_id}.json")
            logger.save_to_file(export_path)
            st.success(f"‚úÖ Export√© vers {export_path}")

    with col2:
        if st.button("üì• Exporter JSONL"):
            export_path = Path(f"orchestration_export_{logger.session_id}.jsonl")
            logger.save_to_jsonl(export_path)
            st.success(f"‚úÖ Export√© vers {export_path}")


# ============================================================================
# VIEWER PRINCIPAL
# ============================================================================

def render_deep_trace_viewer(logger: Optional[OrchestrationLogger] = None):
    """
    Point d'entr√©e principal pour le Deep Trace Viewer.

    Args:
        logger: Instance OrchestrationLogger (peut √™tre None, auquel cas on charge depuis s√©lecteur)
    """
    st.markdown("## üîç Orchestration Deep Trace")

    # Si pas de logger fourni, essayer de charger depuis s√©lecteur
    if logger is None:
        logger = render_session_selector()

    if logger is None:
        st.info("üëà S√©lectionnez une session dans la sidebar pour commencer")
        return

    # Informations de session
    st.markdown(f"**Session:** `{logger.session_id}`")
    st.markdown(f"**Total √©v√©nements:** {len(logger.logs)}")
    st.markdown(f"**It√©rations:** {logger.current_iteration}")

    st.markdown("---")

    # Filtres dans la sidebar
    filters = render_filters_sidebar(logger)

    # Onglets principaux
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìã Timeline",
        "ü§ñ Inspecteur LLM",
        "üí° Propositions",
        "üîÑ State Machine",
        "üìà M√©triques",
        "üíæ Export"
    ])

    with tab1:
        render_timeline_panel(logger, filters)

    with tab2:
        render_llm_inspector_panel(logger)

    with tab3:
        render_proposals_panel(logger)

    with tab4:
        render_state_machine_panel(logger)

    with tab5:
        render_metrics_panel(logger)

    with tab6:
        render_export_panel(logger, filters)


__all__ = [
    "render_deep_trace_viewer",
]
```
<!-- MODULE-END: deep_trace_viewer.py -->

<!-- MODULE-START: emergency_stop.py -->
```json
{
  "name": "emergency_stop.py",
  "path": "ui\\emergency_stop.py",
  "ext": ".py",
  "anchor": "emergency_stop_py"
}
```
## emergency_stop_py
*Chemin* : `ui\emergency_stop.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.emergency_stop

Purpose: Syst√®me d'arr√™t d'urgence et nettoyage m√©moire complet.

Role in pipeline: ui / cleanup

Key components: EmergencyStopHandler, full_memory_cleanup

Inputs: Session state, logger

Outputs: RAM/VRAM lib√©r√©e, processus arr√™t√©s

Dependencies: gc, psutil, torch, cupy, MemoryManager, GPUMemoryManager

Conventions: Nettoyage agressif tous composants; logs d√©taill√©s; fallback sur erreurs.

Read-if: Modification logique arr√™t d'urgence

Skip-if: Utilisation normale du bouton stop
"""

from __future__ import annotations

import gc
import logging
import threading
import time
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


class EmergencyStopHandler:
    """
    Gestionnaire d'arr√™t d'urgence avec nettoyage m√©moire complet.

    Responsabilit√©s:
    - Arr√™ter tous les threads/processus en cours
    - Vider les caches (indicateurs, LLM, GPU)
    - Lib√©rer RAM et VRAM
    - R√©initialiser les √©tats Streamlit
    """

    def __init__(self):
        self._stop_event = threading.Event()
        self._cleanup_stats: Dict[str, Any] = {}

    def request_stop(self) -> None:
        """Demande l'arr√™t de tous les processus en cours."""
        self._stop_event.set()
        logger.warning("üõë ARR√äT D'URGENCE DEMAND√â")

    def is_stop_requested(self) -> bool:
        """V√©rifie si un arr√™t a √©t√© demand√©."""
        return self._stop_event.is_set()

    def reset_stop(self) -> None:
        """R√©initialise le flag d'arr√™t."""
        self._stop_event.clear()

    def full_cleanup(self, session_state: Optional[Any] = None) -> Dict[str, Any]:
        """
        Effectue un nettoyage m√©moire complet de tous les composants.

        Args:
            session_state: √âtat de session Streamlit (optionnel)

        Returns:
            Dict avec statistiques de nettoyage
        """
        stats = {
            "timestamp": time.time(),
            "components_cleaned": [],
            "errors": [],
            "ram_freed_mb": 0.0,
            "vram_freed_mb": 0.0,
        }

        # 1. Arr√™ter les op√©rations en cours
        self._stop_running_operations(session_state, stats)

        # 2. Nettoyer les LLM (d√©charger de la VRAM)
        self._cleanup_llm_models(stats)

        # 3. Nettoyer le cache d'indicateurs
        self._cleanup_indicator_cache(stats)

        # 4. Nettoyer CuPy (GPU arrays)
        self._cleanup_cupy(stats)

        # 5. Nettoyer PyTorch (si utilis√©)
        self._cleanup_pytorch(stats)

        # 6. Nettoyer le MemoryManager
        self._cleanup_memory_manager(stats)

        # 7. Garbage collection agressif
        self._aggressive_gc(stats)

        # 8. R√©initialiser les √©tats Streamlit
        if session_state is not None:
            self._reset_session_state(session_state, stats)

        # 9. Mesurer la m√©moire lib√©r√©e
        self._measure_freed_memory(stats)

        self._cleanup_stats = stats
        return stats

    def _stop_running_operations(
        self,
        session_state: Optional[Any],
        stats: Dict[str, Any]
    ) -> None:
        """Arr√™te toutes les op√©rations en cours."""
        try:
            # Signaler l'arr√™t via le flag global
            self.request_stop()

            # Arr√™ter SweepEngine si en cours
            # Note: On ne peut pas acc√©der √† l'instance en cours directement,
            # mais le flag _stop_requested sera v√©rifi√© dans la boucle
            stats["components_cleaned"].append("sweep_engine_signal")

            # Arr√™ter les agents LLM en cours
            if session_state is not None:
                if hasattr(session_state, "is_running"):
                    session_state.is_running = False
                if hasattr(session_state, "stop_requested"):
                    session_state.stop_requested = True
                stats["components_cleaned"].append("session_flags")

            logger.info("‚úÖ Op√©rations arr√™t√©es")

        except Exception as e:
            logger.error(f"‚ùå Erreur arr√™t op√©rations: {e}")
            stats["errors"].append(f"stop_operations: {e}")

    def _cleanup_llm_models(self, stats: Dict[str, Any]) -> None:
        """D√©charge tous les mod√®les LLM de la VRAM avec v√©rification compl√®te."""
        try:
            import httpx

            from agents.ollama_manager import unload_model

            # R√©cup√©rer la liste de TOUS les mod√®les charg√©s
            try:
                response = httpx.get("http://127.0.0.1:11434/api/ps", timeout=5.0)
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])

                    if not models:
                        logger.debug("Aucun mod√®le LLM charg√©")
                        stats["components_cleaned"].append("llm_none_loaded")
                        return

                    # D√©charger chaque mod√®le avec v√©rification
                    n_unloaded = 0
                    for model_info in models:
                        model_name = model_info.get("name", "")
                        if model_name:
                            try:
                                success = unload_model(model_name)
                                if success:
                                    n_unloaded += 1
                                    logger.info(f"üóëÔ∏è LLM d√©charg√©: {model_name}")
                                    stats["components_cleaned"].append(f"llm_{model_name}")
                                else:
                                    logger.warning(f"‚ö†Ô∏è √âchec d√©chargement: {model_name}")
                                    stats["errors"].append(f"llm_unload_{model_name}_failed")
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è Erreur d√©chargement {model_name}: {e}")
                                stats["errors"].append(f"llm_{model_name}: {e}")

                    # V√©rification finale : aucun mod√®le ne devrait rester
                    response_check = httpx.get("http://127.0.0.1:11434/api/ps", timeout=3.0)
                    if response_check.status_code == 200:
                        remaining = response_check.json().get("models", [])
                        if remaining:
                            logger.warning(f"‚ö†Ô∏è {len(remaining)} mod√®le(s) encore en m√©moire apr√®s cleanup")
                            stats["errors"].append(f"llm_remaining_{len(remaining)}_models")
                        else:
                            logger.info(f"‚úÖ Tous les LLM d√©charg√©s ({n_unloaded} mod√®les)")

                else:
                    logger.debug(f"Ollama API non accessible (status {response.status_code})")
                    stats["errors"].append(f"ollama_api_status_{response.status_code}")

            except httpx.TimeoutException:
                logger.warning("‚ö†Ô∏è Timeout connexion Ollama API")
                stats["errors"].append("ollama_api_timeout")
            except Exception as e:
                logger.debug(f"Impossible de d√©charger LLM via API: {e}")
                stats["errors"].append(f"llm_api_error: {e}")

        except ImportError:
            logger.debug("Module agents.ollama_manager non disponible")
            # Pas d'erreur si module non install√©
        except Exception as e:
            stats["errors"].append(f"llm_cleanup: {e}")

    def _cleanup_indicator_cache(self, stats: Dict[str, Any]) -> None:
        """Vide le cache d'indicateurs."""
        try:
            from data.indicator_bank import IndicatorBank

            bank = IndicatorBank()

            # D'abord nettoyer les entr√©es expir√©es
            n_expired = bank.cleanup_expired()
            if n_expired > 0:
                stats["components_cleaned"].append(f"indicator_expired_{n_expired}")

            # Ensuite vider compl√®tement le cache si n√©cessaire
            # Note: Garder comment√© par d√©faut pour ne pas perdre le cache
            # D√©commenter si vous voulez un nettoyage vraiment complet
            # bank.clear()
            # stats["components_cleaned"].append("indicator_bank_full_clear")

            # Vider le cache m√©moire interne
            if hasattr(bank, "_memory_cache"):
                bank._memory_cache.clear()
                stats["components_cleaned"].append("indicator_memory_cache")

            logger.info(f"üóëÔ∏è Cache indicateurs nettoy√© ({n_expired} expir√©s)")

        except Exception as e:
            stats["errors"].append(f"indicator_cache: {e}")

    def _cleanup_cupy(self, stats: Dict[str, Any]) -> None:
        """Lib√®re toute la m√©moire CuPy."""
        try:
            import cupy as cp

            # Vider tous les memory pools
            if hasattr(cp, "get_default_memory_pool"):
                mempool = cp.get_default_memory_pool()
                mempool.free_all_blocks()
                stats["components_cleaned"].append("cupy_memory_pool")

            if hasattr(cp, "get_default_pinned_memory_pool"):
                pinned = cp.get_default_pinned_memory_pool()
                pinned.free_all_blocks()
                stats["components_cleaned"].append("cupy_pinned_pool")

            # Synchroniser tous les devices
            if hasattr(cp.cuda, "Device"):
                n_devices = cp.cuda.runtime.getDeviceCount()
                for i in range(n_devices):
                    with cp.cuda.Device(i):
                        cp.cuda.Stream.null.synchronize()

            logger.info("üóëÔ∏è CuPy VRAM vid√©e")

        except ImportError:
            pass  # CuPy non install√©
        except Exception as e:
            stats["errors"].append(f"cupy: {e}")

    def _cleanup_pytorch(self, stats: Dict[str, Any]) -> None:
        """Lib√®re le cache PyTorch CUDA."""
        try:
            import torch

            if torch.cuda.is_available():
                # Vider le cache pour tous les devices
                n_devices = torch.cuda.device_count()
                for i in range(n_devices):
                    with torch.cuda.device(i):
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()

                stats["components_cleaned"].append("pytorch_cuda")
                logger.info("üóëÔ∏è PyTorch VRAM vid√©e")

        except ImportError:
            pass  # PyTorch non install√©
        except Exception as e:
            stats["errors"].append(f"pytorch: {e}")

    def _cleanup_memory_manager(self, stats: Dict[str, Any]) -> None:
        """Nettoie le MemoryManager central."""
        try:
            from utils.memory import MemoryManager

            # Cr√©er une instance pour forcer le cleanup
            manager = MemoryManager()
            n_freed = manager.cleanup(aggressive=True)

            if n_freed > 0:
                stats["ram_freed_mb"] += n_freed / (1024**2)
                stats["components_cleaned"].append(f"memory_manager_{n_freed}_bytes")

            # Vider tous les caches manag√©s
            for cache_name in list(manager._caches.keys()):
                cache = manager._caches[cache_name]
                freed = cache.clear()
                if freed > 0:
                    stats["ram_freed_mb"] += freed / (1024**2)
                    stats["components_cleaned"].append(f"managed_cache_{cache_name}")

            logger.info("üóëÔ∏è MemoryManager nettoy√©")

        except Exception as e:
            stats["errors"].append(f"memory_manager: {e}")

    def _aggressive_gc(self, stats: Dict[str, Any]) -> None:
        """Garbage collection agressif multi-passes."""
        try:
            # 3 passes de GC pour collecter les r√©f√©rences cycliques
            for i in range(3):
                collected = gc.collect(generation=2)  # Full collection
                if i == 0:
                    stats["gc_collected_objects"] = collected

            stats["components_cleaned"].append("garbage_collector")
            logger.info(f"üóëÔ∏è GC: {stats.get('gc_collected_objects', 0)} objets collect√©s")

        except Exception as e:
            stats["errors"].append(f"gc: {e}")

    def _reset_session_state(
        self,
        session_state: Any,
        stats: Dict[str, Any]
    ) -> None:
        """R√©initialise les √©tats Streamlit pertinents et nettoie le contexte LLM."""
        try:
            # Flags de contr√¥le
            if hasattr(session_state, "is_running"):
                session_state.is_running = False
            if hasattr(session_state, "stop_requested"):
                session_state.stop_requested = False

            # Nettoyer TOUS les r√©sultats et contextes pr√©c√©dents
            llm_keys_to_clean = [
                "last_run_result",
                "last_winner_params",
                "last_winner_metrics",
                "last_winner_origin",
                "last_winner_meta",
                "orchestration_logs",
                "llm_optimizer",
                "llm_session",
                "current_optimization",
            ]

            n_cleaned = 0
            for key in llm_keys_to_clean:
                if hasattr(session_state, key):
                    delattr(session_state, key)
                    n_cleaned += 1

            if n_cleaned > 0:
                stats["components_cleaned"].append(f"session_llm_context_{n_cleaned}_keys")
                logger.info(f"üóëÔ∏è Contexte LLM nettoy√© ({n_cleaned} cl√©s)")

            stats["components_cleaned"].append("session_state")
            logger.info("‚úÖ Session state r√©initialis√©")

        except Exception as e:
            stats["errors"].append(f"session_state: {e}")

    def _measure_freed_memory(self, stats: Dict[str, Any]) -> None:
        """Mesure approximative de la m√©moire lib√©r√©e."""
        try:
            import psutil

            process = psutil.Process()
            mem_info = process.memory_info()

            # Note: On ne peut pas mesurer directement la RAM lib√©r√©e
            # car le GC ne rend pas forc√©ment la m√©moire au syst√®me
            # On indique juste l'usage actuel
            stats["current_ram_mb"] = mem_info.rss / (1024**2)

        except ImportError:
            pass
        except Exception as e:
            stats["errors"].append(f"measure_memory: {e}")

    def get_last_cleanup_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du dernier nettoyage."""
        return self._cleanup_stats.copy()


# Instance singleton
_emergency_handler: Optional[EmergencyStopHandler] = None


def get_emergency_handler() -> EmergencyStopHandler:
    """Retourne le gestionnaire d'arr√™t d'urgence singleton."""
    global _emergency_handler
    if _emergency_handler is None:
        _emergency_handler = EmergencyStopHandler()
    return _emergency_handler


def execute_emergency_stop(session_state: Optional[Any] = None) -> Dict[str, Any]:
    """
    Raccourci pour ex√©cuter un arr√™t d'urgence complet.

    Args:
        session_state: √âtat de session Streamlit

    Returns:
        Dict avec statistiques de nettoyage

    Example:
        >>> stats = execute_emergency_stop(st.session_state)
        >>> st.success(f"‚úÖ {len(stats['components_cleaned'])} composants nettoy√©s")
    """
    handler = get_emergency_handler()
    return handler.full_cleanup(session_state)
```
<!-- MODULE-END: emergency_stop.py -->

<!-- MODULE-START: helpers.py -->
```json
{
  "name": "helpers.py",
  "path": "ui\\helpers.py",
  "ext": ".py",
  "anchor": "helpers_py"
}
```
## helpers_py
*Chemin* : `ui\helpers.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.helpers

Purpose: Utilitaires UI - tables strat√©gies markdown, stat calcs, cache streamlit helpers.

Role in pipeline: user interface utilities

Key components: generate_strategies_table(), format_metric(), st_cache wrappers

Inputs: Strategies registry, metric values

Outputs: Markdown tables, formatted strings, cached dataframes

Dependencies: streamlit, pandas, ui.constants, ui.context

Conventions: Cache streamlit TTL; markdown tables sync auto; metric formatting pr√©cision.

Read-if: Modification format output ou stat calculations.

Skip-if: Vous appelez generate_strategies_table().
"""

from __future__ import annotations

# pylint: disable=too-many-lines
import math
import statistics
import time
import traceback
from collections import deque
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

from ui.constants import (
    PARAM_CONSTRAINTS,
    get_strategy_description,
    get_strategy_display_name,
    get_strategy_type,
)
from ui.context import (
    BACKEND_AVAILABLE,
    ParameterSpec,
    calculate_indicator,
    get_storage,
    get_strategy,
    list_strategies,
    load_ohlcv,
)
from utils.observability import generate_run_id, get_obs_logger


def compute_period_days(start_ts: pd.Timestamp, end_ts: pd.Timestamp) -> int:
    """
    Calcule le nombre de jours entre deux timestamps.

    Args:
        start_ts: Timestamp de d√©but
        end_ts: Timestamp de fin

    Returns:
        Nombre de jours (entier)
    """
    if pd.isna(start_ts) or pd.isna(end_ts):
        return 0
    delta = end_ts - start_ts
    return max(1, int(delta.total_seconds() / 86400))


def compute_period_days_from_df(df: pd.DataFrame) -> int:
    """
    Calcule le nombre de jours couverts par un DataFrame OHLCV.

    Args:
        df: DataFrame avec index datetime

    Returns:
        Nombre de jours (entier)
    """
    if df is None or df.empty:
        return 0
    return compute_period_days(df.index[0], df.index[-1])


def format_pnl_with_daily(
    pnl: float,
    period_days: int,
    show_plus: bool = False,
    escape_markdown: bool = False,
) -> str:
    """
    Formate un PnL avec son √©quivalent journalier.

    Args:
        pnl: PnL total
        period_days: Nombre de jours de la p√©riode
        show_plus: Si True, affiche un + devant les valeurs positives

    Returns:
        Cha√Æne format√©e "PnL (PnL/jour/day)"
    """
    if period_days <= 0:
        prefix = "+" if show_plus and pnl > 0 else ""
        result = f"{prefix}${pnl:,.2f}"
        return result.replace("$", "\\$") if escape_markdown else result

    pnl_per_day = pnl / period_days
    prefix = "+" if show_plus and pnl > 0 else ""
    result = f"{prefix}${pnl:,.2f} ({prefix}${pnl_per_day:,.2f}/jour)"
    return result.replace("$", "\\$") if escape_markdown else result


def generate_strategies_table() -> str:
    """
    G√©n√®re dynamiquement le tableau markdown des strat√©gies disponibles.

    Synchronise automatiquement avec le registre des strat√©gies pour √©viter
    toute divergence entre la sidebar et la page principale.
    """
    available = list_strategies()

    table_lines = [
        "### Strat√©gies Disponibles",
        "",
        "| Strat√©gie | Type | Description |",
        "|-----------|------|-------------|",
    ]

    for strat_key in sorted(available):
        name = get_strategy_display_name(strat_key)
        stype = get_strategy_type(strat_key)
        desc = get_strategy_description(strat_key) or "Strat√©gie personnalis√©e"
        table_lines.append(f"| **{name}** | {stype} | {desc} |")

    return "\n".join(table_lines)


class ProgressMonitor:
    """
    Moniteur de progression en temps r√©el pour les backtests.

    Calcule la vitesse d'ex√©cution et estime le temps restant en utilisant
    une moyenne glissante sur les 3 derni√®res secondes.
    """

    def __init__(self, total_runs: int):
        self.total_runs = total_runs
        self.runs_completed = 0
        self.start_time = time.perf_counter()
        self.history = deque(maxlen=3)
        self.last_update_time = self.start_time

    def update(self, runs_completed: int) -> Dict[str, Any]:
        self.runs_completed = runs_completed
        current_time = time.perf_counter()

        self.history.append((current_time, runs_completed))

        if len(self.history) >= 2:
            time_span = self.history[-1][0] - self.history[0][0]
            runs_in_span = self.history[-1][1] - self.history[0][1]

            if time_span > 0 and runs_in_span > 0:
                iteration_speed_per_sec = runs_in_span / time_span
                iteration_speed_per_2sec = iteration_speed_per_sec * 2
            else:
                iteration_speed_per_sec = 0
                iteration_speed_per_2sec = 0
        else:
            iteration_speed_per_sec = 0
            iteration_speed_per_2sec = 0

        elapsed_time = current_time - self.start_time

        remaining_runs = self.total_runs - runs_completed
        if iteration_speed_per_sec > 0 and remaining_runs > 0:
            time_remaining_sec = remaining_runs / iteration_speed_per_sec
        else:
            time_remaining_sec = 0

        progress = runs_completed / self.total_runs if self.total_runs > 0 else 0

        self.last_update_time = current_time

        return {
            "progress": progress,
            "runs_completed": runs_completed,
            "total_runs": self.total_runs,
            "speed_per_2sec": iteration_speed_per_2sec,
            "speed_per_sec": iteration_speed_per_sec,
            "elapsed_time_sec": elapsed_time,
            "time_remaining_sec": time_remaining_sec,
        }

    def format_time(self, seconds: float) -> str:
        if seconds <= 0:
            return "0s"

        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)

        parts = []
        if hours > 0:
            parts.append(f"{hours}h")
        if minutes > 0:
            parts.append(f"{minutes}m")
        if secs > 0 or not parts:
            parts.append(f"{secs}s")

        return " ".join(parts)


def render_progress_monitor(monitor: ProgressMonitor, placeholder) -> None:
    metrics = monitor.update(monitor.runs_completed)

    with placeholder.container():
        st.progress(metrics["progress"])

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Progression",
                f"{metrics['runs_completed']}/{metrics['total_runs']}",
                f"{metrics['progress']*100:.1f}%",
            )

        with col2:
            st.metric(
                "Vitesse",
                f"{metrics['speed_per_sec']:.2f} runs/s",
                f"{metrics['speed_per_2sec']:.1f} runs/2s",
            )

        with col3:
            elapsed_str = monitor.format_time(metrics["elapsed_time_sec"])
            st.metric("Temps √©coul√©", elapsed_str)

        with col4:
            remaining_str = monitor.format_time(metrics["time_remaining_sec"])
            st.metric("Temps restant", remaining_str)


def show_status(status_type: str, message: str, details: Optional[str] = None):
    if status_type == "success":
        st.success(f"‚úÖ {message}")
    elif status_type == "error":
        st.error(f"‚ùå {message}")
        if details:
            with st.expander("D√©tails de l'erreur"):
                st.code(details)
    elif status_type == "warning":
        st.warning(f"‚ö†Ô∏è {message}")
    elif status_type == "info":
        st.info(f"‚ÑπÔ∏è {message}")


def validate_param(name: str, value: Any) -> Tuple[bool, str]:
    if name not in PARAM_CONSTRAINTS:
        return True, ""

    constraints = PARAM_CONSTRAINTS[name]

    if value < constraints["min"]:
        return False, f"{name} doit √™tre ‚â• {constraints['min']}"

    if value > constraints["max"]:
        return False, f"{name} doit √™tre ‚â§ {constraints['max']}"

    return True, ""


def validate_all_params(params: Dict[str, Any]) -> Tuple[bool, List[str]]:
    errors = []

    for name, value in params.items():
        is_valid, error = validate_param(name, value)
        if not is_valid:
            errors.append(error)

    if "fast_period" in params and "slow_period" in params:
        if params["fast_period"] >= params["slow_period"]:
            errors.append("fast_period doit √™tre < slow_period")

    return len(errors) == 0, errors


def apply_versioned_preset(preset: Any, strategy_key: str) -> None:
    try:
        values = preset.get_default_values()
    except Exception:
        values = {}

    for name, value in values.items():
        st.session_state[f"{strategy_key}_{name}"] = value

    if "leverage" in values:
        st.session_state["trading_leverage"] = values["leverage"]


def create_param_range_selector(
    name: str,
    key_prefix: str = "",
    mode: str = "single",
    spec: Optional[ParameterSpec] = None,
    label: Optional[str] = None,
) -> Any:
    constraints: Dict[str, Any] = {}
    is_int = False
    display_name = label or name

    if spec is not None:
        spec_type = spec.param_type
        is_int = spec_type == "int" or spec_type is int
        step = spec.step
        if step is None:
            range_size = float(spec.max_val) - float(spec.min_val)
            if is_int:
                step = max(1, int(range_size / 10))
            else:
                step = range_size / 10 if range_size > 0 else 0.1
        if is_int:
            step = max(1, int(round(step)))
        constraints = {
            "min": spec.min_val,
            "max": spec.max_val,
            "step": step,
            "default": spec.default,
            "description": spec.description,
            "type": "int" if is_int else "float",
        }
    else:
        if name not in PARAM_CONSTRAINTS:
            st.sidebar.warning(f"Param√®tre {name} sans contraintes d√©finies")
            return None
        constraints = PARAM_CONSTRAINTS[name]
        step = constraints.get("step", 1)
        is_int = constraints.get("type") == "int"
        if not is_int:
            try:
                is_int = float(step).is_integer()
            except (TypeError, ValueError):
                is_int = False

    unique_key = f"{key_prefix}_{name}"

    if mode == "single":
        if is_int:
            return st.sidebar.slider(
                display_name,
                min_value=int(constraints["min"]),
                max_value=int(constraints["max"]),
                value=int(constraints["default"]),
                step=int(constraints["step"]),
                help=constraints["description"],
                key=unique_key,
            )
        return st.sidebar.slider(
            display_name,
            min_value=float(constraints["min"]),
            max_value=float(constraints["max"]),
            value=float(constraints["default"]),
            step=float(constraints["step"]),
            help=constraints["description"],
            key=unique_key,
        )

    with st.sidebar.expander(f"üìä {display_name}", expanded=False):
        st.caption(constraints["description"])

        col1, col2 = st.columns(2)

        if is_int:
            with col1:
                param_min = st.number_input(
                    "Min",
                    min_value=int(constraints["min"]),
                    max_value=int(constraints["max"]),
                    value=int(constraints["min"]),
                    step=1,
                    key=f"{unique_key}_min",
                )
            with col2:
                param_max = st.number_input(
                    "Max",
                    min_value=int(constraints["min"]),
                    max_value=int(constraints["max"]),
                    value=int(constraints["max"]),
                    step=1,
                    key=f"{unique_key}_max",
                )
            param_step = st.number_input(
                "Step",
                min_value=1,
                max_value=max(1, (int(constraints["max"]) - int(constraints["min"])) // 2),
                value=int(constraints["step"]),
                step=1,
                key=f"{unique_key}_step",
            )
        else:
            with col1:
                param_min = st.number_input(
                    "Min",
                    min_value=float(constraints["min"]),
                    max_value=float(constraints["max"]),
                    value=float(constraints["min"]),
                    step=0.1,
                    format="%.2f",
                    key=f"{unique_key}_min",
                )
            with col2:
                param_max = st.number_input(
                    "Max",
                    min_value=float(constraints["min"]),
                    max_value=float(constraints["max"]),
                    value=float(constraints["max"]),
                    step=0.1,
                    format="%.2f",
                    key=f"{unique_key}_max",
                )
            param_step = st.number_input(
                "Step",
                min_value=0.01,
                max_value=max(0.1, (float(constraints["max"]) - float(constraints["min"])) / 2),
                value=float(constraints["step"]),
                step=0.01,
                format="%.2f",
                key=f"{unique_key}_step",
            )

        if param_max > param_min and param_step > 0:
            nb_values = int((param_max - param_min) / param_step) + 1
            st.caption(f"‚Üí {nb_values} valeurs √† tester")
        else:
            nb_values = 1
            st.warning("‚ö†Ô∏è Plage invalide")

        return {
            "min": param_min,
            "max": param_max,
            "step": param_step,
            "count": nb_values,
        }


def create_constrained_slider(name: str, granularity: float, key_prefix: str = "") -> Any:
    _ = granularity
    return create_param_range_selector(name, key_prefix, mode="single")


def safe_load_data(
    symbol: str,
    timeframe: str,
    start: Optional[str] = None,
    end: Optional[str] = None,
) -> Tuple[Optional[pd.DataFrame], str]:
    try:
        df = load_ohlcv(symbol, timeframe, start=start, end=end)

        if df is None or df.empty:
            return None, "‚ùå Donn√©es vides ou fichier non trouv√©"

        required_cols = ["open", "high", "low", "close", "volume"]
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            return None, f"‚ùå Colonnes manquantes: {missing}"

        if not isinstance(df.index, pd.DatetimeIndex):
            return None, "‚ùå L'index n'est pas un DatetimeIndex"

        # Validation plus d√©taill√©e des donn√©es
        nan_count = df.isna().sum().sum()
        total_values = len(df) * len(df.columns)
        nan_pct = (nan_count / total_values) * 100 if total_values > 0 else 0

        if nan_pct > 10:
            return None, f"‚ùå Trop de valeurs NaN ({nan_pct:.1f}%, {nan_count}/{total_values})"

        # Validation coh√©rence OHLC
        invalid_ohlc = ((df['high'] < df['low']) |
                       (df['open'] < df['low']) | (df['open'] > df['high']) |
                       (df['close'] < df['low']) | (df['close'] > df['high'])).sum()

        if invalid_ohlc > 0:
            return None, f"‚ùå Donn√©es OHLC incoh√©rentes ({invalid_ohlc} barres)"

        start_fmt = df.index[0].strftime("%Y-%m-%d %H:%M")
        end_fmt = df.index[-1].strftime("%Y-%m-%d %H:%M")
        quality_msg = f"NaN: {nan_pct:.1f}%" if nan_pct > 0 else "‚úì Propre"
        return df, f"‚úÖ {len(df)} barres ({start_fmt} ‚Üí {end_fmt}) - {quality_msg}"

    except FileNotFoundError as e:
        from data.loader import _get_data_dir
        data_dir = _get_data_dir()
        return None, f"üìÅ Fichier non trouv√©: {symbol}_{timeframe} dans {data_dir}"
    except ValueError as e:
        return None, f"üìä Erreur de donn√©es: {str(e)}"
    except pd.errors.EmptyDataError:
        return None, f"üìÑ Fichier vide: {symbol}_{timeframe}"
    except pd.errors.ParserError as e:
        return None, f"üîß Erreur format fichier: {str(e)}"
    except Exception as exc:
        import traceback
        tb_summary = traceback.format_exc().split('\n')[-3] if len(traceback.format_exc().split('\n')) > 2 else str(exc)
        return None, f"‚ö†Ô∏è Erreur inattendue: {tb_summary}"


def _data_cache_key(
    symbol: str,
    timeframe: str,
    start_date: Optional[object],
    end_date: Optional[object],
) -> Tuple[str, str, Optional[str], Optional[str]]:
    start_str = str(start_date) if start_date else None
    end_str = str(end_date) if end_date else None
    return (symbol, timeframe, start_str, end_str)


def load_selected_data(
    symbol: str,
    timeframe: str,
    start_date: Optional[object],
    end_date: Optional[object],
) -> Tuple[Optional[pd.DataFrame], str]:
    from .cache_manager import get_cached_data, cache_data

    # V√©rifier cache d'abord
    cached_df = get_cached_data(symbol, timeframe, start_date, end_date)
    if cached_df is not None:
        # Mise √† jour session state avec donn√©es cached
        st.session_state["ohlcv_df"] = cached_df
        st.session_state["ohlcv_cache_key"] = _data_cache_key(
            symbol, timeframe, start_date, end_date
        )
        st.session_state["ohlcv_status_msg"] = "üìã Donn√©es du cache (5min TTL)"
        return cached_df, "üìã Donn√©es du cache (5min TTL)"

    # Charger depuis source si pas en cache
    start_str = str(start_date) if start_date else None
    end_str = str(end_date) if end_date else None
    df, msg = safe_load_data(symbol, timeframe, start_str, end_str)
    if df is not None:
        # Mettre en cache les nouvelles donn√©es
        cache_data(symbol, timeframe, start_date, end_date, df)
        st.session_state["ohlcv_df"] = df
        st.session_state["ohlcv_cache_key"] = _data_cache_key(
            symbol, timeframe, start_date, end_date
        )
        st.session_state["ohlcv_status_msg"] = msg
    return df, msg


def _parse_run_timestamp(value: Optional[str]) -> Optional[pd.Timestamp]:
    if not value:
        return None
    try:
        return pd.Timestamp(value)
    except Exception:
        return None


def _format_run_timestamp(value: Optional[str]) -> str:
    ts = _parse_run_timestamp(value)
    if ts is None:
        return value or "n/a"
    if ts.tzinfo is not None:
        ts = ts.tz_convert("UTC")
    if ts.hour == 0 and ts.minute == 0 and ts.second == 0:
        return ts.strftime("%Y-%m-%d")
    return ts.strftime("%Y-%m-%d %H:%M")


def _format_run_period(start: Optional[str], end: Optional[str]) -> str:
    start_fmt = _format_run_timestamp(start)
    end_fmt = _format_run_timestamp(end)
    if start_fmt == "n/a" and end_fmt == "n/a":
        return "n/a"
    return f"{start_fmt} -> {end_fmt}"


def _find_saved_run_meta(storage: Any, run_id: str) -> Optional[Any]:
    for meta in storage.list_results():
        if meta.run_id == run_id:
            return meta
    return None


def _build_saved_run_label(meta: Any) -> str:
    period = _format_run_period(meta.period_start, meta.period_end)
    return (
        f"{meta.strategy} | {meta.symbol}/{meta.timeframe} | {period} | {meta.run_id}"
    )


def _save_result_to_storage(storage: Any, result: Optional[Any]) -> Tuple[bool, str]:
    if result is None:
        return False, "No result to save."
    run_id = result.meta.get("run_id") or generate_run_id()
    existing_ids = {meta.run_id for meta in storage.list_results()}
    if run_id in existing_ids:
        return False, f"Run already saved: {run_id}"
    try:
        saved_id = storage.save_result(result, run_id=run_id)
    except Exception as exc:
        return False, f"Save failed: {exc}"
    return True, f"Saved run: {saved_id}"


def _maybe_auto_save_run(result: Optional[Any]) -> None:
    if result is None:
        return
    if not st.session_state.get("auto_save_final_run", False):
        return
    if result.meta.get("loaded_from_storage"):
        return
    if not BACKEND_AVAILABLE:
        return
    try:
        storage = get_storage()
    except Exception as exc:
        st.session_state["saved_runs_status"] = f"Auto-save failed: {exc}"
        return
    saved, msg = _save_result_to_storage(storage, result)
    if msg:
        st.session_state["saved_runs_status"] = msg


def render_saved_runs_panel(
    result: Optional[Any],
    strategy_key: str,
    symbol: str,
    timeframe: str,
) -> None:
    st.sidebar.subheader("Saved runs")
    if not BACKEND_AVAILABLE:
        st.sidebar.info("Saved runs unavailable (backend not available).")
        return
    try:
        storage = get_storage()
    except Exception as exc:
        st.sidebar.error(f"Storage error: {exc}")
        return

    status_msg = st.session_state.pop("saved_runs_status", None)
    if status_msg:
        st.sidebar.info(status_msg)

    if "auto_save_final_run" not in st.session_state:
        st.session_state["auto_save_final_run"] = True

    st.sidebar.checkbox(
        "Auto-save final run",
        key="auto_save_final_run",
    )

    if result is not None:
        if st.sidebar.button("Save current run", key="save_current_run"):
            saved, msg = _save_result_to_storage(storage, result)
            if saved:
                st.sidebar.success(msg)
            else:
                st.sidebar.warning(msg)

    filter_current = st.sidebar.checkbox(
        "Filter to current selection",
        value=True,
        key="saved_runs_filter_current",
    )
    filter_text = st.sidebar.text_input(
        "Filter text",
        value="",
        key="saved_runs_filter_text",
    )

    runs = storage.list_results()
    if filter_current:
        runs = [
            r
            for r in runs
            if r.strategy == strategy_key
            and r.symbol == symbol
            and r.timeframe == timeframe
        ]
    if filter_text:
        filter_l = filter_text.lower()
        runs = [
            r
            for r in runs
            if filter_l in _build_saved_run_label(r).lower()
            or filter_l in r.run_id.lower()
        ]

    if not runs:
        st.sidebar.info("No saved runs.")
        return

    run_ids = [r.run_id for r in runs]
    label_map = {r.run_id: _build_saved_run_label(r) for r in runs}
    if st.session_state.get("saved_runs_selected") not in run_ids:
        st.session_state["saved_runs_selected"] = run_ids[0]
    selected_run_id = st.sidebar.selectbox(
        "Select run",
        options=run_ids,
        format_func=lambda rid: label_map.get(rid, rid),
        key="saved_runs_selected",
    )
    selected_meta = next((r for r in runs if r.run_id == selected_run_id), None)
    if selected_meta is not None:
        period_label = _format_run_period(
            selected_meta.period_start,
            selected_meta.period_end,
        )
        st.sidebar.caption(f"Period: {period_label}")
        st.sidebar.caption(
            f"Trades: {selected_meta.n_trades} | Bars: {selected_meta.n_bars}"
        )
        sharpe = selected_meta.metrics.get("sharpe_ratio", 0)
        ret_pct = selected_meta.metrics.get("total_return_pct", 0)
        max_dd = selected_meta.metrics.get("max_drawdown", 0)
        st.sidebar.caption(
            f"Sharpe: {sharpe:.2f} | Return: {ret_pct:.1f}% | MaxDD: {max_dd:.1f}%"
        )

    load_data = st.sidebar.checkbox(
        "Load data for charts",
        value=True,
        key="saved_runs_load_data",
    )
    if st.sidebar.button("Load selected run", key="load_selected_run"):
        st.session_state["pending_run_load_id"] = selected_run_id
        st.session_state["pending_run_load_data"] = load_data
        st.rerun()


def safe_run_backtest(
    engine: Any,
    df: pd.DataFrame,
    strategy: str,
    params: Dict[str, Any],
    symbol: str,
    timeframe: str,
    run_id: Optional[str] = None,
    silent_mode: bool = False,
    fast_metrics: bool = False,
) -> Tuple[Optional[Any], str]:
    run_id = run_id or generate_run_id(
        strategy=strategy,
        symbol=symbol,
        timeframe=timeframe,
    )
    logger = get_obs_logger("ui.app", run_id=run_id, strategy=strategy, symbol=symbol)

    if not silent_mode:
        logger.info("ui_backtest_start params=%s", params)

    try:
        engine.run_id = run_id
        engine.logger = get_obs_logger("backtest.engine", run_id=run_id)

        result = engine.run(
            df=df,
            strategy=strategy,
            params=params,
            symbol=symbol,
            timeframe=timeframe,
            silent_mode=silent_mode,
            fast_metrics=fast_metrics,
        )

        pnl = result.metrics.get("total_pnl", 0)
        sharpe = result.metrics.get("sharpe_ratio", 0)

        if not silent_mode:
            logger.info("ui_backtest_end pnl=%.2f sharpe=%.2f", pnl, sharpe)
        return result, f"Termin√© | P&L: ${pnl:,.2f} | Sharpe: {sharpe:.2f}"

    except ValueError as exc:
        logger.warning("ui_backtest_validation_error error=%s", str(exc))
        return None, f"Param√®tres invalides: {str(exc)}"
    except Exception as exc:
        logger.error("ui_backtest_error error=%s", str(exc))
        return None, f"Erreur: {str(exc)}\n{traceback.format_exc()}"


def _strip_global_params(params: Dict[str, Any]) -> Dict[str, Any]:
    for key in ("fees_bps", "slippage_bps", "initial_capital"):
        params.pop(key, None)
    return params


def build_strategy_params_for_comparison(
    strategy_key: str,
    use_preset: bool = True,
) -> Dict[str, Any]:
    try:
        strategy_class = get_strategy(strategy_key)
    except Exception:
        return {}
    if not strategy_class:
        return {}
    strategy_instance = strategy_class()
    params = dict(strategy_instance.default_params)
    if use_preset:
        preset = strategy_instance.get_preset()
        if preset is not None:
            params.update(preset.get_default_values())
    return _strip_global_params(params)


def _aggregate_metric(values: List[Any], method: str, higher_is_better: bool) -> float:
    cleaned: List[float] = []
    for value in values:
        try:
            val = float(value)
        except (TypeError, ValueError):
            continue
        if math.isnan(val):
            continue
        cleaned.append(val)

    if not cleaned:
        return float("nan")

    if method == "median":
        return float(statistics.median(cleaned))
    if method == "worst":
        return float(min(cleaned) if higher_is_better else max(cleaned))
    return float(sum(cleaned) / len(cleaned))


def summarize_comparison_results(
    results: List[Dict[str, Any]],
    aggregate: str,
    primary_metric: str,
    expected_runs: int,
) -> List[Dict[str, Any]]:
    metric_directions = {
        "sharpe_ratio": 1,
        "total_return_pct": 1,
        "win_rate": 1,
        "total_pnl": 1,
        "trades": 1,
        "max_drawdown": -1,
    }
    metrics = [
        "sharpe_ratio",
        "total_return_pct",
        "max_drawdown",
        "win_rate",
        "total_pnl",
        "trades",
    ]
    by_strategy: Dict[str, List[Dict[str, Any]]] = {}
    for item in results:
        by_strategy.setdefault(item["strategy"], []).append(item)

    summary: List[Dict[str, Any]] = []
    for strategy_key, runs in by_strategy.items():
        row: Dict[str, Any] = {
            "strategy": strategy_key,
            "runs": len(runs),
        }
        if expected_runs > 0:
            row["coverage_pct"] = (len(runs) / expected_runs) * 100
        for metric in metrics:
            values = []
            for run in runs:
                if metric == "trades":
                    values.append(run.get("trades"))
                else:
                    values.append(run.get("metrics", {}).get(metric))
            row[metric] = _aggregate_metric(
                values,
                aggregate,
                metric_directions.get(metric, 1) >= 0,
            )
        summary.append(row)

    direction = metric_directions.get(primary_metric, 1)
    reverse = direction >= 0

    def _sort_key(item: Dict[str, Any]) -> float:
        value = item.get(primary_metric)
        if value is None or (isinstance(value, float) and math.isnan(value)):
            return float("-inf") if reverse else float("inf")
        return float(value)

    summary.sort(key=_sort_key, reverse=reverse)
    return summary


def build_indicator_overlays(
    strategy_key: str,
    df: pd.DataFrame,
    params: Dict[str, Any],
) -> Dict[str, Any]:
    overlays: Dict[str, Any] = {}
    if df is None or df.empty:
        return overlays

    params = _strip_global_params(dict(params))

    try:
        if strategy_key == "bollinger_atr":
            bb_period = int(params.get("bb_period", 20))
            bb_std = float(params.get("bb_std", 2.0))
            entry_z = float(params.get("entry_z", bb_std))
            atr_period = int(params.get("atr_period", 14))
            atr_percentile = float(params.get("atr_percentile", 30))

            bb_upper, bb_mid, bb_lower = calculate_indicator(
                "bollinger",
                df,
                {"period": bb_period, "std_dev": bb_std},
            )
            atr_values = calculate_indicator(
                "atr",
                df,
                {"period": atr_period},
            )
            atr_series = pd.Series(atr_values, index=df.index)
            overlays["bollinger"] = {
                "upper": pd.Series(bb_upper, index=df.index),
                "lower": pd.Series(bb_lower, index=df.index),
                "mid": pd.Series(bb_mid, index=df.index),
                "entry_z": entry_z,
            }
            overlays["atr"] = {
                "atr": atr_series,
                "atr_percentile": atr_percentile,
            }

        elif strategy_key == "bollinger_best_longe_3i":
            bb_period = int(params.get("bb_period", 20))
            bb_std = float(params.get("bb_std", 2.0))
            entry_level = float(params.get("entry_level", 0.0))
            sl_level = float(params.get("sl_level", -0.5))
            tp_level = float(params.get("tp_level", 0.85))
            atr_period = int(params.get("atr_period", 14))
            atr_percentile = float(params.get("atr_percentile", 30))

            bb_upper, bb_mid, bb_lower = calculate_indicator(
                "bollinger",
                df,
                {"period": bb_period, "std_dev": bb_std},
            )
            atr_values = calculate_indicator(
                "atr",
                df,
                {"period": atr_period},
            )
            upper = pd.Series(bb_upper, index=df.index)
            lower = pd.Series(bb_lower, index=df.index)
            mid = pd.Series(bb_mid, index=df.index)
            entry_line = lower + entry_level * (upper - lower)
            atr_series = pd.Series(atr_values, index=df.index)
            overlays["bollinger"] = {
                "upper": upper,
                "lower": lower,
                "mid": mid,
                "entry_lower": entry_line,
                "sl_level": sl_level,
                "tp_level": tp_level,
            }
            overlays["atr"] = {
                "atr": atr_series,
                "atr_percentile": atr_percentile,
            }

        elif strategy_key == "bollinger_best_short_3i":
            bb_period = int(params.get("bb_period", 20))
            bb_std = float(params.get("bb_std", 2.0))
            entry_level = float(params.get("entry_level", 1.0))
            sl_level = float(params.get("sl_level", 1.5))
            tp_level = float(params.get("tp_level", 0.15))
            atr_period = int(params.get("atr_period", 14))
            atr_percentile = float(params.get("atr_percentile", 30))

            bb_upper, bb_mid, bb_lower = calculate_indicator(
                "bollinger",
                df,
                {"period": bb_period, "std_dev": bb_std},
            )
            atr_values = calculate_indicator(
                "atr",
                df,
                {"period": atr_period},
            )
            upper = pd.Series(bb_upper, index=df.index)
            lower = pd.Series(bb_lower, index=df.index)
            mid = pd.Series(bb_mid, index=df.index)
            entry_line = lower + entry_level * (upper - lower)
            atr_series = pd.Series(atr_values, index=df.index)
            overlays["bollinger"] = {
                "upper": upper,
                "lower": lower,
                "mid": mid,
                "entry_upper": entry_line,
                "sl_level": sl_level,
                "tp_level": tp_level,
            }
            overlays["atr"] = {
                "atr": atr_series,
                "atr_percentile": atr_percentile,
            }

        elif strategy_key == "ema_cross":
            fast_period = int(params.get("fast_period", 12))
            slow_period = int(params.get("slow_period", 26))
            close = df["close"]
            overlays["ema"] = {
                "fast": close.ewm(span=fast_period, adjust=False).mean(),
                "slow": close.ewm(span=slow_period, adjust=False).mean(),
            }

        elif strategy_key == "macd_cross":
            fast_period = int(params.get("fast_period", 12))
            slow_period = int(params.get("slow_period", 26))
            signal_period = int(params.get("signal_period", 9))
            macd_line, signal_line, hist = calculate_indicator(
                "macd",
                df,
                {
                    "fast": fast_period,
                    "slow": slow_period,
                    "signal": signal_period,
                },
            )
            overlays["macd"] = {
                "macd": pd.Series(macd_line, index=df.index),
                "signal": pd.Series(signal_line, index=df.index),
                "hist": pd.Series(hist, index=df.index),
            }

        elif strategy_key == "rsi_reversal":
            rsi_period = int(params.get("rsi_period", 14))
            oversold = float(params.get("oversold_level", 30))
            overbought = float(params.get("overbought_level", 70))
            rsi_values = calculate_indicator(
                "rsi",
                df,
                {"period": rsi_period},
            )
            overlays["rsi"] = {
                "rsi": pd.Series(rsi_values, index=df.index),
                "oversold": oversold,
                "overbought": overbought,
            }

        elif strategy_key == "ma_crossover":
            fast_period = int(params.get("fast_period", 10))
            slow_period = int(params.get("slow_period", 30))
            close = df["close"]
            overlays["ma"] = {
                "fast": close.rolling(window=fast_period).mean(),
                "slow": close.rolling(window=slow_period).mean(),
            }

        elif strategy_key == "ema_stochastic_scalp":
            fast_ema = int(params.get("fast_ema", 50))
            slow_ema = int(params.get("slow_ema", 100))
            stoch_k = int(params.get("stoch_k", 14))
            stoch_d = int(params.get("stoch_d", 3))
            oversold = float(params.get("stoch_oversold", 20))
            overbought = float(params.get("stoch_overbought", 80))
            close = df["close"]
            overlays["ema"] = {
                "fast": close.ewm(span=fast_ema, adjust=False).mean(),
                "slow": close.ewm(span=slow_ema, adjust=False).mean(),
            }
            stoch_values = calculate_indicator(
                "stochastic",
                df,
                {"k_period": stoch_k, "d_period": stoch_d, "smooth_k": 3},
            )
            if isinstance(stoch_values, tuple) and len(stoch_values) >= 2:
                overlays["stochastic"] = {
                    "k": pd.Series(stoch_values[0], index=df.index),
                    "d": pd.Series(stoch_values[1], index=df.index),
                    "oversold": oversold,
                    "overbought": overbought,
                }

        elif strategy_key == "bollinger_dual":
            bb_window = int(params.get("bb_window", 20))
            bb_std = float(params.get("bb_std", 2.0))
            ma_window = int(params.get("ma_window", 10))
            ma_type = str(params.get("ma_type", "sma")).lower()
            upper, middle, lower = calculate_indicator(
                "bollinger",
                df,
                {"period": bb_window, "std_dev": bb_std},
            )
            overlays["bollinger"] = {
                "upper": pd.Series(upper, index=df.index),
                "lower": pd.Series(lower, index=df.index),
                "mid": pd.Series(middle, index=df.index),
            }
            close = df["close"]
            if ma_type == "ema":
                ma_series = close.ewm(span=ma_window, adjust=False).mean()
            else:
                ma_series = close.rolling(
                    window=ma_window, min_periods=ma_window
                ).mean()
            overlays["ma"] = {"center": ma_series}

        elif strategy_key == "atr_channel":
            atr_period = int(params.get("atr_period", 14))
            atr_mult = float(params.get("atr_mult", 2.0))
            close = df["close"]
            ema_center = close.ewm(span=atr_period, adjust=False).mean()
            atr_values = calculate_indicator("atr", df, {"period": atr_period})
            atr_series = pd.Series(atr_values, index=df.index)
            overlays["atr_channel"] = {
                "upper": ema_center + atr_series * atr_mult,
                "lower": ema_center - atr_series * atr_mult,
                "center": ema_center,
            }
            overlays["atr"] = {"atr": atr_series}
    except Exception:
        return {}

    return overlays


def safe_copy_cleanup(logger=None) -> None:
    try:
        import cupy as cp  # noqa: F401
    except Exception as exc:
        if logger:
            logger.debug("CuPy import failed (ignored): %s", exc)
        return

    has_pool = hasattr(cp, "get_default_memory_pool") and hasattr(
        cp, "get_default_pinned_memory_pool"
    )
    if not has_pool:
        if logger:
            logger.warning(
                "CuPy cleanup skipped: missing memory pool API. cupy_file=%s",
                getattr(cp, "__file__", None),
            )
        return

    try:
        mempool = cp.get_default_memory_pool()
        pinned_mempool = cp.get_default_pinned_memory_pool()
        mempool.free_all_blocks()
        pinned_mempool.free_all_blocks()
        if logger:
            logger.debug("CuPy cleanup done: freed default pools.")
    except Exception as exc:
        if logger:
            logger.warning("CuPy cleanup failed (ignored): %s", exc)


def run_sweep_parallel_with_callback(
    df,
    strategy_name,
    param_combinations,
    param_names,
    base_params,
    symbol,
    timeframe,
    initial_capital,
    n_workers,
    period_days,
    fast_metrics,
    silent_mode=True,
    callback=None
):
    """Version du sweep parall√®le avec callback pour affichage temps r√©el."""
    from performance.parallel import ParallelRunner
    import os

    # Configuration parall√©lisation
    config_dict = {
        "n_workers": n_workers,
        "max_in_flight": n_workers * 3,
        "timeout_per_task": 300.0,
        "continue_on_timeout": True,
        "shared_kwargs": {
            "strategy_name": strategy_name,
            "symbol": symbol,
            "timeframe": timeframe,
            "initial_capital": initial_capital,
            "period_days": period_days,
            "fast_metrics": fast_metrics,
            "silent_mode": silent_mode
        }
    }

    runner = ParallelRunner(config_dict)

    # Pr√©parer les t√¢ches
    tasks = []
    for i, combo in enumerate(param_combinations):
        params = base_params.copy()
        for j, param_name in enumerate(param_names):
            params[param_name] = combo[j]

        tasks.append({
            "df": df,
            "params": params,
            "combo_id": i
        })

    # Fonction de traitement des r√©sultats avec callback
    results = []
    completed = 0
    total = len(tasks)

    def process_result(result):
        nonlocal completed, results
        completed += 1
        if result and "error" not in result:
            results.append(result)

        # Callback pour affichage temps r√©el
        if callback:
            callback(completed, total, result)

    # Ex√©cuter avec callback
    from backtest.worker import run_backtest_worker
    try:
        for task in tasks:
            result = run_backtest_worker(task)
            process_result(result)
    except Exception as e:
        print(f"Erreur sweep parall√®le: {e}")

    return results


def run_sweep_sequential_with_callback(
    df,
    strategy_name,
    param_combinations,
    param_names,
    base_params,
    symbol,
    timeframe,
    initial_capital,
    period_days,
    fast_metrics,
    silent_mode=True,
    callback=None
):
    """Version du sweep s√©quentiel avec callback pour affichage temps r√©el."""
    from ui.context import get_strategy
    from backtest.engine import BacktestEngine
    import time

    results = []
    total = len(param_combinations)

    for i, combo in enumerate(param_combinations):
        # Construire param√®tres
        params = base_params.copy()
        for j, param_name in enumerate(param_names):
            params[param_name] = combo[j]

        try:
            # Ex√©cuter backtest
            engine = BacktestEngine(initial_capital=initial_capital)
            strategy = get_strategy(strategy_name)()
            result = engine.run(
                df=df,
                strategy=strategy,
                params=params,
                symbol=symbol,
                timeframe=timeframe,
                silent_mode=silent_mode
            )

            # Formater pour compatibilit√© avec worker
            result_dict = {
                "params": params,
                "metrics": result.metrics,
                "meta": result.meta,
                "period_days": period_days,
                "combo_id": i
            }
            results.append(result_dict)

            # Callback pour affichage temps r√©el
            if callback:
                callback(i + 1, total, result_dict)

        except Exception as e:
            error_result = {
                "params": params,
                "error": str(e),
                "combo_id": i
            }
            # Callback m√™me en cas d'erreur
            if callback:
                callback(i + 1, total, error_result)

    return results


def run_sweep_parallel_with_callback(
    df, strategy, param_grid, initial_capital, n_workers=None, callback=None,
    silent_mode=True, fast_metrics=False, symbol="unknown", timeframe="unknown"
):
    """
    Ex√©cute un sweep en parall√®le avec callback de progression temps r√©el.

    Utilise une fen√™tre glissante pour limiter les futures en m√©moire
    et supporter des millions de combinaisons sans saturation RAM.
    """
    from backtest.worker import run_backtest_worker, init_worker_with_dataframe
    from concurrent.futures import ProcessPoolExecutor, as_completed
    import os

    if n_workers is None:
        n_workers = max(1, os.cpu_count() // 2)

    # D√©tecter si param_grid supporte len() (liste/tuple) ou non (g√©n√©rateur)
    try:
        total_combos = len(param_grid)
        param_iter = iter(param_grid)
    except TypeError:
        # C'est un g√©n√©rateur ou it√©rateur sans taille
        param_iter = param_grid
        total_combos = None

    results = []
    completed = 0
    best_result = None

    # Configuration worker avec initializer (charge DataFrame une seule fois par worker)
    worker_thread_limit = int(os.getenv("BACKTEST_WORKER_THREADS", "1"))
    debug_enabled = os.getenv("DEBUG", "").lower() in ("1", "true", "yes")

    # Convertir g√©n√©rateur en liste pour √©viter probl√®mes de pickling
    if hasattr(param_grid, '__next__'):
        param_list = list(param_iter)
        total_combos = len(param_list)
    else:
        param_list = list(param_iter) if total_combos else param_grid

    # SOLUTION SIMPLE : passer DataFrame directement
    # Le pickling est lent MAIS il se fait UNE FOIS par worker au d√©marrage
    # Apr√®s, chaque worker a sa copie en m√©moire, pas de contention I/O
    with ProcessPoolExecutor(
        max_workers=n_workers,
        initializer=init_worker_with_dataframe,
        initargs=(
            df,
            strategy,
            symbol,
            timeframe,
            initial_capital,
            debug_enabled,
            worker_thread_limit,
            fast_metrics,
            False,  # is_path=False : passer DataFrame directement
        ),
    ) as executor:
        # Soumettre TOUTES les t√¢ches d'un coup (approche simple, sans deadlock)
        futures = {executor.submit(run_backtest_worker, params): params for params in param_list}

        # Collecter les r√©sultats au fur et √† mesure
        for future in as_completed(futures):
            try:
                raw_result = future.result(timeout=120)  # Timeout de 2 min par backtest

                # Reformater pour correspondre au format attendu par main.py
                if raw_result and "error" not in raw_result:
                    formatted_result = {
                        "params": raw_result.get("params_dict", {}),
                        "metrics": {
                            "total_pnl": raw_result.get("total_pnl", 0.0),
                            "sharpe_ratio": raw_result.get("sharpe", 0.0),
                            "win_rate_pct": raw_result.get("win_rate", 0.0),
                            "max_drawdown_pct": raw_result.get("max_dd", 0.0),
                            "total_trades": raw_result.get("total_trades", 0),
                            "profit_factor": raw_result.get("profit_factor", 0.0),
                            "total_return_pct": raw_result.get("liquidation_total_return_pct", 0.0),
                        }
                    }
                    results.append(formatted_result)

                    # Mettre √† jour le meilleur r√©sultat
                    pnl = raw_result.get("total_pnl", 0.0)
                    if best_result is None or pnl > best_result.get("best_pnl", float("-inf")):
                        best_result = {"result": formatted_result, "best_pnl": pnl}
                else:
                    results.append(None)

            except Exception:
                # Worker a plant√©, on ajoute None
                results.append(None)

            completed += 1

            # Callback de progression
            if callback:
                callback(completed, total_combos, best_result)

    return results


def run_sweep_sequential_with_callback(
    df, strategy, param_grid, initial_capital, callback=None,
    silent_mode=True, fast_metrics=False
):
    """Ex√©cute un sweep en s√©quentiel avec callback de progression."""
    from utils.config import Config
    from backtest.engine import BacktestEngine

    config = Config(initial_capital=initial_capital)
    engine = BacktestEngine(config=config)

    results = []
    total_combos = len(param_grid)
    best_result = None

    for i, params in enumerate(param_grid):
        try:
            result, _ = safe_run_backtest(
                engine, df, strategy, params,
                "unknown", "unknown",  # Pas besoin de symbol/timeframe ici
                silent_mode=silent_mode,
                fast_metrics=fast_metrics
            )

            if result:
                results.append({"metrics": result.metrics, "params": params})
                pnl = result.metrics.get("total_pnl", 0.0)
                if best_result is None or pnl > best_result.get("best_pnl", float("-inf")):
                    best_result = {"result": result, "best_pnl": pnl}
            else:
                results.append(None)

        except Exception:
            results.append(None)

        # Callback de progression
        if callback:
            callback(i + 1, total_combos, best_result)

    return results
```
<!-- MODULE-END: helpers.py -->

<!-- MODULE-START: indicators_panel.py -->
```json
{
  "name": "indicators_panel.py",
  "path": "ui\\indicators_panel.py",
  "ext": ".py",
  "anchor": "indicators_panel_py"
}
```
## indicators_panel_py
*Chemin* : `ui\indicators_panel.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.indicators_panel

Purpose: Panel d'indicateurs dynamique Streamlit - grouper et afficher indicateurs par cat√©gorie (tendance, momentum, volatilite).

Role in pipeline: visualization / input

Key components: group_indicators_by_category(), render_indicator_panel(), selecteur interactif

Inputs: Registry indicateurs

Outputs: Interface s√©lection indicateurs avec cat√©gories

Dependencies: streamlit, indicators.registry

Conventions: Cat√©gories: üìà Tendance, üìç Momentum, üéä Volatilit√©, üíà Volume

Read-if: Modification UI s√©lection indicateurs ou cat√©gorisation.

Skip-if: Interface indicateurs d√©j√† d√©finie.
"""

from typing import Dict, List

import streamlit as st

from indicators.registry import get_indicator, list_indicators


def group_indicators_by_category() -> Dict[str, List[str]]:
    """
    Groupe les indicateurs par cat√©gorie fonctionnelle.

    Returns:
        Dict avec cat√©gories comme cl√©s et listes d'indicateurs comme valeurs
    """
    # R√©cup√©rer tous les indicateurs
    all_indicators = list_indicators()

    # D√©finir les cat√©gories
    categories = {
        "üìà Tendance": [
            "ema",
            "sma",
            "adx",
            "macd",
            "aroon",
            "supertrend",
            "ichimoku",
            "psar",
            "vortex",
            "pi_cycle",
            "onchain_smoothing",
        ],
        "üìä Volatilit√©": [
            "atr",
            "bollinger",
            "keltner",
            "donchian",
            "standard_deviation",
            "amplitude_hunter",
        ],
        "‚ö° Momentum": [
            "rsi", "stochastic", "cci", "momentum", "roc", "williams_r"
        ],
        "üì¶ Volume": [
            "vwap", "obv", "mfi", "volume_oscillator"
        ],
    }

    # Filtrer pour ne garder que les indicateurs existants
    filtered_categories = {}
    for category, indicators in categories.items():
        existing = [ind for ind in indicators if ind in all_indicators]
        if existing:
            filtered_categories[category] = existing

    # Ajouter une cat√©gorie "Autres" pour les indicateurs non cat√©goris√©s
    categorized = set()
    for indicators in filtered_categories.values():
        categorized.update(indicators)

    uncategorized = [ind for ind in all_indicators if ind not in categorized]
    if uncategorized:
        filtered_categories["üîß Autres"] = uncategorized

    return filtered_categories


def render_indicators_panel(expanded: bool = False):
    """
    Affiche le panel complet des indicateurs disponibles.

    Args:
        expanded: Si True, affiche toutes les cat√©gories ouvertes
    """
    st.markdown("### üìä Indicateurs Disponibles")

    # R√©cup√©rer les indicateurs group√©s
    categories = group_indicators_by_category()

    # Compter le total
    total_indicators = sum(len(inds) for inds in categories.values())
    st.caption(f"**{total_indicators} indicateurs techniques** pr√™ts √† l'emploi")

    # Afficher par cat√©gorie
    for category, indicator_names in categories.items():
        with st.expander(f"{category} ({len(indicator_names)})", expanded=expanded):
            for ind_name in sorted(indicator_names):
                info = get_indicator(ind_name)
                if info and info.description:
                    st.markdown(f"- **{ind_name.upper()}** : {info.description}")
                else:
                    st.markdown(f"- **{ind_name.upper()}**")


def render_indicators_summary():
    """
    Affiche un r√©sum√© compact des indicateurs disponibles.
    """
    categories = group_indicators_by_category()
    total = sum(len(inds) for inds in categories.values())

    st.markdown(f"""
    ### üìä Indicateurs Int√©gr√©s

    **{total} indicateurs techniques** r√©partis en {len(categories)} cat√©gories :
    """)

    for category, indicators in categories.items():
        # Formater la liste des indicateurs
        ind_list = ", ".join([ind.upper() for ind in sorted(indicators)])
        st.markdown(f"**{category}** : {ind_list}")

    st.info("üí° Les indicateurs sont charg√©s **automatiquement** selon la strat√©gie s√©lectionn√©e")


def render_indicators_table():
    """
    Affiche un tableau complet des indicateurs avec leurs m√©tadonn√©es.
    """
    import pandas as pd

    st.markdown("### üìã Table Compl√®te des Indicateurs")

    all_indicators = list_indicators()

    # Cr√©er les donn√©es du tableau
    data = []
    for ind_name in sorted(all_indicators):
        info = get_indicator(ind_name)
        if info:
            data.append({
                "Nom": ind_name.upper(),
                "Colonnes Requises": ", ".join(info.required_columns),
                "Description": info.description or "N/A"
            })

    # Afficher le DataFrame
    df = pd.DataFrame(data)
    st.dataframe(df, width="stretch", hide_index=True)


def get_category_for_indicator(indicator_name: str) -> str:
    """
    Retourne la cat√©gorie d'un indicateur.

    Args:
        indicator_name: Nom de l'indicateur

    Returns:
        Nom de la cat√©gorie (sans emoji)
    """
    categories = group_indicators_by_category()

    for category, indicators in categories.items():
        if indicator_name in indicators:
            # Retirer l'emoji
            return category.split(" ", 1)[1] if " " in category else category

    return "Autres"


def format_indicator_name(indicator_name: str, with_description: bool = True) -> str:
    """
    Formate le nom d'un indicateur pour l'affichage.

    Args:
        indicator_name: Nom de l'indicateur
        with_description: Si True, inclut la description

    Returns:
        Nom format√©
    """
    info = get_indicator(indicator_name)

    if not info:
        return indicator_name.upper()

    if with_description and info.description:
        return f"**{indicator_name.upper()}** : {info.description}"
    else:
        return f"**{indicator_name.upper()}**"


__all__ = [
    "group_indicators_by_category",
    "render_indicators_panel",
    "render_indicators_summary",
    "render_indicators_table",
    "get_category_for_indicator",
    "format_indicator_name",
]
```
<!-- MODULE-END: indicators_panel.py -->

<!-- MODULE-START: llm_handlers.py -->
```json
{
  "name": "llm_handlers.py",
  "path": "ui\\llm_handlers.py",
  "ext": ".py",
  "anchor": "llm_handlers_py"
}
```
## llm_handlers_py
*Chemin* : `ui\llm_handlers.py`  
*Type* : `.py`  

```python
"""
Handlers LLM pour l'optimisation par agents.

Ce module contient toute la logique d'optimisation LLM, incluant:
- Mode single-agent vs multi-agent
- Mode single-optimization vs multi-sweep LLM
- Gestion des erreurs et logging d'orchestration
- Configuration et initialisation des agents LLM
"""
from __future__ import annotations

import gc
import logging
import time
from typing import Any, Dict, List, Optional

import pandas as pd
import streamlit as st

from ui.cache_manager import get_cached_data
from ui.helpers import (
    compute_period_days_from_df,
    format_pnl_with_daily,
    safe_load_data,
    show_status,
)
from ui.state import SidebarState
from ui.components.charts import (
    render_multi_sweep_heatmap,
    render_multi_sweep_ranking,
)
from utils.run_tracker import RunSignature, get_global_tracker
from agents.integration import create_comparison_context
from backtest.storage import get_storage
from ui.context import (
    LLM_AVAILABLE,
    LLM_IMPORT_ERROR,
    OrchestrationLogger,
    BacktestEngine,
    create_llm_client,
    create_optimizer_from_engine,
    create_orchestrator_with_backtest,
    generate_session_id,
    render_deep_trace_viewer,
    render_full_orchestration_viewer,
    LiveOrchestrationViewer,
)


def handle_llm_optimization(
    state: SidebarState,
    df: pd.DataFrame,
    engine: BacktestEngine,
    status_container: Any,
) -> None:
    """
    Gestionnaire principal pour l'optimisation LLM.

    G√®re √† la fois le mode simple et le mode multi-sweep LLM.
    """
    if not LLM_AVAILABLE:
        with status_container:
            show_status("error", f"LLM non disponible: {LLM_IMPORT_ERROR}")
        st.session_state.is_running = False
        return

    if state.llm_config is None:
        with status_container:
            show_status("error", "Configuration LLM manquante")
        st.session_state.is_running = False
        return

    # Multi-sweep: r√©cup√©rer les listes
    strategy_keys = state.strategy_keys
    symbols = state.symbols
    timeframes = state.timeframes
    is_multi_sweep = (len(strategy_keys) > 1 or len(symbols) > 1 or len(timeframes) > 1)

    session_id = generate_session_id()
    orchestration_logger = OrchestrationLogger(session_id=session_id)

    try:
        comparison_context = create_comparison_context(
            mode="llm_optimization",
            symbols=symbols,
            timeframes=timeframes,
            strategies=strategy_keys,
        )
    except Exception as exc:
        logging.getLogger(__name__).warning(
            f"Impossible de cr√©er le contexte de comparaison: {exc}"
        )
        comparison_context = None

    try:
        llm_client = create_llm_client(state.llm_config)
    except Exception:
        comparison_context = None

    max_iterations = min(state.llm_max_iterations, state.max_combos)

    # Gestion de la comparaison (section complexe pr√©serv√©e)
    comparison_summary: List[Dict[str, Any]] = []
    should_run_comparison = state.llm_compare_enabled and (
        state.llm_compare_auto_run or st.session_state.get("llm_compare_run_now", False)
    )
    if should_run_comparison:
        _handle_llm_comparison(state, comparison_summary, comparison_context)

    st.subheader("ü§ñ Optimisation par Agents LLM")

    col_info, col_timeline = st.columns([1, 2])

    with col_info:
        st.info(f"""
**Configuration LLM:**
- Provider: {state.llm_config.provider.value}
- Model: {state.llm_config.model}
- Mode: {"Multi-Agent" if state.llm_use_multi_agent else "Single Agent"}
- Max iterations: {max_iterations}
- Walk forward: {"‚úÖ" if state.llm_use_walk_forward else "‚ùå"}
- GPU unload: {"‚úÖ" if state.llm_unload_during_backtest else "‚ùå"}

**Donn√©es:**
- Symbol: {state.symbol}
- Timeframe: {state.timeframe}
- Period: {compute_period_days_from_df(df)} jours
- Bars: {len(df):,}

**Comparaison:**
- Enabled: {"‚úÖ" if state.llm_compare_enabled else "‚ùå"}
- Auto-run: {"‚úÖ" if state.llm_compare_auto_run else "‚ùå"}
""")

    col_timeline.empty()

    # Enregistrement du run
    run_tracker = get_global_tracker()
    data_identifier = (
        f"df_{len(df)}rows_{df.index[0]}_{df.index[-1]}"
        if len(df) > 0
        else "empty_df"
    )
    run_signature = RunSignature(
        strategy_name=state.strategy_key,
        data_path=data_identifier,
        initial_params=state.params,
        llm_model=state.llm_model,
        mode="multi_agents" if state.llm_use_multi_agent else "autonomous",
        session_id=session_id,
    )
    run_tracker.register(run_signature)

    # === D√âTECTION MODE MULTI-SWEEP LLM ===
    if is_multi_sweep:
        run_multi_sweep_llm(
            state=state,
            strategy_keys=strategy_keys,
            symbols=symbols,
            timeframes=timeframes,
            session_id=session_id,
            orchestration_logger=orchestration_logger,
            comparison_context=comparison_context,
            max_iterations=max_iterations,
            status_container=status_container,
        )
    else:
        # === MODE LLM SIMPLE (UNE SEULE COMBINAISON) ===
        run_single_llm_optimization(
            state=state,
            df=df,
            engine=engine,
            session_id=session_id,
            orchestration_logger=orchestration_logger,
            comparison_context=comparison_context,
            max_iterations=max_iterations,
            status_container=status_container,
        )


def run_multi_sweep_llm(
    state: SidebarState,
    strategy_keys: List[str],
    symbols: List[str],
    timeframes: List[str],
    session_id: str,
    orchestration_logger: OrchestrationLogger,
    comparison_context: Optional[Dict],
    max_iterations: int,
    status_container: Any,
) -> None:
    """Ex√©cution du mode Multi-Sweep LLM."""
    total_combinations = len(strategy_keys) * len(symbols) * len(timeframes)

    st.info(
        f"ü§ñ **Mode Multi-Sweep LLM activ√©**\n\n"
        f"- {len(strategy_keys)} strat√©gie(s): {', '.join(strategy_keys)}\n"
        f"- {len(symbols)} token(s): {', '.join(symbols)}\n"
        f"- {len(timeframes)} timeframe(s): {', '.join(timeframes)}\n\n"
        f"‚û°Ô∏è **{total_combinations} optimisations LLM** seront ex√©cut√©es en s√©rie"
    )

    # Barre de progression et accumulateur de r√©sultats
    progress_bar = st.progress(0)
    status_placeholder = st.empty()
    multi_llm_results = []

    # Affichage optionnel des logs d√©taill√©s en temps r√©el
    show_detailed_logs = st.checkbox(
        "üìù Afficher logs LLM d√©taill√©s en temps r√©el",
        value=False,
        help="Active l'affichage des r√©flexions compl√®tes des agents (peut ralentir l'interface)"
    )

    if show_detailed_logs:
        st.markdown("#### üß† Journal d'Orchestration LLM en Temps R√©el")
        logs_container = st.container()
        recent_logs = []

        def on_orchestration_event(event_data):
            """Callback enrichi pour afficher les logs LLM en temps r√©el."""
            nonlocal recent_logs

            # Extraire informations d√©taill√©es
            event_type = event_data.get("action", "unknown")
            agent_role = event_data.get("agent_role", "unknown")

            # Textes d√©taill√©s selon le type d'√©v√©nement
            details = ""
            if "agent_analysis" in event_data:
                details = f"**Analyse**: {event_data['agent_analysis'][:1000]}..."
            elif "agent_proposal" in event_data:
                details = f"**Proposition**: {event_data['agent_proposal'][:1000]}..."
            elif "agent_critique" in event_data:
                details = f"**Critique**: {event_data['agent_critique'][:1000]}..."
            elif "validator_decision" in event_data:
                details = f"**D√©cision**: {event_data['validator_decision']}"
            elif "backtest_metrics" in event_data:
                metrics = event_data["backtest_metrics"]
                pnl = metrics.get("total_pnl", 0)
                sharpe = metrics.get("sharpe_ratio", 0)
                details = f"**R√©sultat backtest**: PnL={pnl:.2f}, Sharpe={sharpe:.3f}"

            # Ajouter √† la liste des logs r√©cents (limite √† 3)
            timestamp = time.strftime("%H:%M:%S")
            log_entry = {
                "timestamp": timestamp,
                "agent": agent_role,
                "type": event_type,
                "details": details
            }
            recent_logs.append(log_entry)

            # Garder seulement les 3 derniers logs
            if len(recent_logs) > 3:
                recent_logs.pop(0)

            # Afficher dans le container
            with logs_container:
                for i, log in enumerate(recent_logs):
                    color = "üîµ" if "analyst" in log["agent"].lower() else \
                           "üü¢" if "strategist" in log["agent"].lower() else \
                           "üü°" if "critic" in log["agent"].lower() else \
                           "üî¥" if "validator" in log["agent"].lower() else "‚ö´"

                    with st.expander(f"{color} {log['timestamp']} - {log['agent']} - {log['type']}", expanded=False):
                        if log["details"]:
                            st.write(log["details"])
    else:
        on_orchestration_event = None

    idx = 0
    all_params = getattr(state, 'all_params', {state.strategy_key: state.params})

    for sk in strategy_keys:
        for sym in symbols:
            for tf in timeframes:
                idx += 1

                # V√©rifier arr√™t utilisateur
                if st.session_state.get("stop_requested", False):
                    st.warning("üõë Arr√™t demand√© par l'utilisateur")
                    break

                progress_bar.progress(idx / total_combinations)
                status_placeholder.info(f"ü§ñ Optimisation LLM {idx}/{total_combinations}: {sk} √ó {sym} √ó {tf}")

                try:
                    # Charger donn√©es pour cette combinaison
                    combo_df = safe_load_data(sym, tf, state.start_date, state.end_date)
                    if combo_df is None:
                        st.warning(f"‚ùå Donn√©es indisponibles pour {sym}/{tf}")
                        continue

                    # Cr√©er engine isol√© pour cette combinaison
                    combo_engine = BacktestEngine(initial_capital=state.initial_capital)
                    combo_session_id = f"{session_id}_{sk}_{sym}_{tf}"
                    combo_orchestration_logger = OrchestrationLogger(session_id=combo_session_id)

                    # Utiliser les param√®tres de cette strat√©gie
                    combo_params = all_params.get(sk, state.params)

                    # Ex√©cuter optimisation LLM pour cette combinaison
                    combo_best_result = _run_single_llm_combo(
                        state=state,
                        strategy_key=sk,
                        symbol=sym,
                        timeframe=tf,
                        df=combo_df,
                        engine=combo_engine,
                        params=combo_params,
                        session_id=combo_session_id,
                        orchestration_logger=combo_orchestration_logger,
                        comparison_context=comparison_context,
                        max_iterations=max_iterations,
                        on_event_callback=on_orchestration_event,
                    )

                    if combo_best_result:
                        # Enrichir avec m√©tadonn√©es
                        combo_result = {
                            "strategy": sk,
                            "symbol": sym,
                            "timeframe": tf,
                            "combination": f"{sk}_{sym}_{tf}",
                            "session_id": combo_session_id,
                            "pnl": combo_best_result.get("total_pnl", 0),
                            "pnl_daily": format_pnl_with_daily(
                                combo_best_result.get("total_pnl", 0),
                                compute_period_days_from_df(combo_df)
                            ),
                            "sharpe": combo_best_result.get("sharpe_ratio", 0),
                            "max_dd": combo_best_result.get("max_drawdown_pct", 0),
                            "trades": combo_best_result.get("total_trades", 0),
                            "win_rate": combo_best_result.get("win_rate_pct", 0),
                            "profit_factor": combo_best_result.get("profit_factor", 0),
                            "best_params": combo_best_result.get("best_params", {}),
                            "iteration_count": combo_best_result.get("iteration_count", 0),
                            "llm_config": f"{state.llm_config.provider.value}/{state.llm_config.model}",
                        }
                        multi_llm_results.append(combo_result)

                        # Sauvegarde individuelle imm√©diate
                        storage = get_storage()
                        sweep_id = f"llm_multi_sweep_{session_id}_{idx:03d}_{sk}_{sym}_{tf}"
                        extra_metadata = {
                            "strategy_name": sk,
                            "symbol": sym,
                            "timeframe": tf,
                            "llm_config": f"{state.llm_config.provider.value}/{state.llm_config.model}",
                            "iteration_count": combo_result["iteration_count"],
                            "best_sharpe": combo_result["sharpe"],
                            "final_pnl": combo_result["pnl"],
                            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                        }
                        try:
                            storage.save_individual_result(
                                sweep_id=sweep_id,
                                result=combo_best_result,
                                metadata=extra_metadata,
                                mode="llm_individual"
                            )
                        except Exception as save_exc:
                            st.warning(f"‚ö†Ô∏è √âchec sauvegarde {sweep_id}: {save_exc}")

                    # Nettoyage m√©moire entre optimisations
                    del combo_df, combo_engine, combo_orchestration_logger
                    gc.collect()

                except Exception as exc:
                    st.error(f"‚ùå Erreur optimisation {sk} √ó {sym} √ó {tf}: {exc}")

                    # Sauvegarder l'erreur aussi
                    storage = get_storage()
                    error_sweep_id = f"llm_multi_sweep_error_{session_id}_{idx:03d}_{sk}_{sym}_{tf}"
                    error_result = {
                        "strategy": sk,
                        "symbol": sym,
                        "timeframe": tf,
                        "error": str(exc),
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    }
                    error_metadata = {
                        "strategy_name": sk,
                        "symbol": sym,
                        "timeframe": tf,
                        "error_type": type(exc).__name__,
                        "llm_config": f"{state.llm_config.provider.value}/{state.llm_config.model}",
                    }
                    try:
                        storage.save_error_result(
                            sweep_id=error_sweep_id,
                            error_info=error_result,
                            metadata=error_metadata
                        )
                    except Exception:
                        pass  # √âchec de sauvegarde d'erreur : pas critique

                    continue

    # === AFFICHAGE R√âSUM√â FINAL MULTI-SWEEP LLM ===
    progress_bar.progress(1.0)
    status_placeholder.success(f"‚úÖ Multi-Sweep LLM termin√©: {len(multi_llm_results)}/{total_combinations} r√©ussites")

    if multi_llm_results:
        st.markdown("---\n### üéØ R√©sum√© Multi-Sweep LLM")

        # Cr√©er DataFrame pour visualisations
        results_df = pd.DataFrame(multi_llm_results)

        # Trouver le meilleur r√©sultat global
        best_overall = results_df.loc[results_df["pnl"].idxmax()]

        st.success(
            f"üèÜ **Meilleur r√©sultat global**: {best_overall['strategy']} √ó {best_overall['symbol']} √ó {best_overall['timeframe']}\n\n"
            f"üí∞ PnL: ${best_overall['pnl']:.2f} | ‚ö° Sharpe: {best_overall['sharpe']:.3f} | üìä MaxDD: {best_overall['max_dd']:.1f}%"
        )

        # Onglets pour les diff√©rentes vues
        tab_table, tab_heatmap, tab_ranking = st.tabs(["üìä Tableau", "üî• Heatmap", "üèÜ Classement"])

        with tab_table:
            # Configuration des colonnes num√©riques pour tri correct
            column_config = {
                "pnl": st.column_config.NumberColumn("PnL", format="$%.2f"),
                "sharpe": st.column_config.NumberColumn("Sharpe", format="%.3f"),
                "max_dd": st.column_config.NumberColumn("Max DD", format="%.1f%%"),
                "trades": st.column_config.NumberColumn("Trades", format="%d"),
                "win_rate": st.column_config.NumberColumn("Win Rate", format="%.1f%%"),
                "profit_factor": st.column_config.NumberColumn("Profit Factor", format="%.2f"),
                "iteration_count": st.column_config.NumberColumn("It√©rations", format="%d"),
            }
            st.dataframe(
                results_df[["strategy", "symbol", "timeframe", "pnl", "pnl_daily", "sharpe", "max_dd", "trades", "win_rate", "iteration_count"]].sort_values("pnl", ascending=False),
                column_config=column_config,
                width="stretch",
            )

            # Param√®tres gagnants dans un expander
            with st.expander(f"üéØ Param√®tres gagnants ({best_overall['strategy']} √ó {best_overall['symbol']} √ó {best_overall['timeframe']})"):
                st.json(best_overall["best_params"])

        with tab_heatmap:
            render_multi_sweep_heatmap(results_df, metric="pnl")

        with tab_ranking:
            render_multi_sweep_ranking(results_df, metric="pnl", top_n=min(10, len(results_df)))

        # Sauvegarde finale compl√®te
        storage = get_storage()
        final_metadata = {
            "session_id": session_id,
            "total_optimizations": total_combinations,
            "successful_optimizations": len(multi_llm_results),
            "failed_optimizations": total_combinations - len(multi_llm_results),
            "best_overall_pnl": float(best_overall["pnl"]),
            "best_overall_sharpe": float(best_overall["sharpe"]),
            "best_combination": f"{best_overall['strategy']}_{best_overall['symbol']}_{best_overall['timeframe']}",
            "llm_config": f"{state.llm_config.provider.value}/{state.llm_config.model}",
            "strategies_tested": strategy_keys,
            "symbols_tested": symbols,
            "timeframes_tested": timeframes,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
        try:
            storage.save_summary_result(
                sweep_id=f"llm_multi_sweep_summary_{session_id}",
                metadata=final_metadata
            )
        except Exception as save_exc:
            st.warning(f"‚ö†Ô∏è √âchec sauvegarde r√©sum√© final: {save_exc}")

    else:
        st.error("‚ùå Aucune optimisation LLM n'a r√©ussi")

    with status_container:
        show_status("success", f"Multi-Sweep LLM termin√©: {len(multi_llm_results)} optimisations")


def run_single_llm_optimization(
    state: SidebarState,
    df: pd.DataFrame,
    engine: BacktestEngine,
    session_id: str,
    orchestration_logger: OrchestrationLogger,
    comparison_context: Optional[Dict],
    max_iterations: int,
    status_container: Any,
) -> None:
    """Ex√©cution d'une optimisation LLM simple (une seule combinaison)."""
    st.subheader(f"ü§ñ Optimisation LLM: {state.strategy_key} √ó {state.symbol} √ó {state.timeframe}")

    with st.spinner("üîå Connexion au LLM..."):
        try:
            llm_client = create_llm_client(state.llm_config)
            st.success("‚úÖ LLM connect√©")
        except Exception as exc:
            with status_container:
                show_status("error", f"√âchec connexion LLM: {exc}")
            st.session_state.is_running = False
            return

    result = _run_single_llm_combo(
        state=state,
        strategy_key=state.strategy_key,
        symbol=state.symbol,
        timeframe=state.timeframe,
        df=df,
        engine=engine,
        params=state.params,
        session_id=session_id,
        orchestration_logger=orchestration_logger,
        comparison_context=comparison_context,
        max_iterations=max_iterations,
        on_event_callback=None,
    )

    if result:
        st.success("üéØ Optimisation LLM termin√©e avec succ√®s!")

        # Stocker les r√©sultats dans la session
        st.session_state["last_run_result"] = result.get("full_result")
        st.session_state["last_winner_params"] = result.get("best_params", state.params)
        st.session_state["last_winner_metrics"] = result
        st.session_state["last_winner_origin"] = "llm"
        st.session_state["last_winner_meta"] = {
            "strategy": state.strategy_key,
            "symbol": state.symbol,
            "timeframe": state.timeframe,
            "session_id": session_id,
            "iteration_count": result.get("iteration_count", 0),
            "llm_config": f"{state.llm_config.provider.value}/{state.llm_config.model}",
        }

        with status_container:
            pnl_daily = format_pnl_with_daily(
                result.get("total_pnl", 0),
                compute_period_days_from_df(df),
                escape_markdown=True,
            )
            show_status("success", f"PnL: {pnl_daily} | Sharpe: {result.get('sharpe_ratio', 0):.3f}")
    else:
        with status_container:
            show_status("error", "√âchec de l'optimisation LLM")


def _run_single_llm_combo(
    state: SidebarState,
    strategy_key: str,
    symbol: str,
    timeframe: str,
    df: pd.DataFrame,
    engine: BacktestEngine,
    params: Dict[str, Any],
    session_id: str,
    orchestration_logger: OrchestrationLogger,
    comparison_context: Optional[Dict],
    max_iterations: int,
    on_event_callback: Optional[callable] = None,
) -> Optional[Dict[str, Any]]:
    """
    Ex√©cute une optimisation LLM pour une seule combinaison strat√©gie √ó symbol √ó timeframe.

    Returns:
        Dict avec les m√©triques du meilleur r√©sultat, ou None en cas d'√©chec.
    """
    try:
        if state.llm_use_multi_agent:
            # Mode multi-agent avec orchestrateur
            orchestrator = create_orchestrator_with_backtest(
                llm_config=state.llm_config,
                strategy_name=strategy_key,
                data=df,
                comparison_context=comparison_context,
                use_walk_forward=state.llm_use_walk_forward,
                unload_llm_during_backtest=state.llm_unload_during_backtest,
            )

            if on_event_callback:
                orchestrator.set_event_callback(on_event_callback)

            # Lancer l'optimisation
            session = orchestrator.run_optimization(
                initial_params=params,
                max_iterations=max_iterations,
                session_id=session_id,
            )

            if session and session.best_result:
                best_metrics = session.best_result.metrics
                return {
                    **best_metrics,
                    "best_params": session.best_result.params,
                    "iteration_count": len(session.iteration_history),
                    "full_result": session.best_result,
                }

        else:
            # Mode single-agent (strategist autonome)
            strategist, executor = create_optimizer_from_engine(
                llm_config=state.llm_config,
                strategy_name=strategy_key,
                data=df,
                use_walk_forward=state.llm_use_walk_forward,
                unload_llm_during_backtest=state.llm_unload_during_backtest,
                comparison_context=comparison_context,
            )

            # Lancer l'optimisation
            session = strategist.optimize(
                executor=executor,
                initial_params=params,
                max_iterations=max_iterations,
            )

            if session and session.best_result:
                best_metrics = session.best_result.metrics
                return {
                    **best_metrics,
                    "best_params": session.best_result.params,
                    "iteration_count": len(session.experiment_history),
                    "full_result": session.best_result,
                }

    except Exception as exc:
        logging.getLogger(__name__).error(f"Erreur optimisation LLM {strategy_key}√ó{symbol}√ó{timeframe}: {exc}")
        raise

    return None


def _handle_llm_comparison(
    state: SidebarState,
    comparison_summary: List[Dict[str, Any]],
    comparison_context: Optional[Dict],
) -> None:
    """
    G√®re la section complexe de comparaison LLM.

    Cette fonction est pr√©serv√©e telle quelle pour maintenir la compatibilit√©.
    """
    # Code de comparaison complexe pr√©serv√©
    # (Cette section peut √™tre extraite plus tard si n√©cessaire)
    pass
```
<!-- MODULE-END: llm_handlers.py -->

<!-- MODULE-START: log_taps.py -->
```json
{
  "name": "log_taps.py",
  "path": "ui\\log_taps.py",
  "ext": ".py",
  "anchor": "log_taps_py"
}
```
## log_taps_py
*Chemin* : `ui\log_taps.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.log_taps

Purpose: Capture et suit le meilleur PnL des logs de backtest.

Role in pipeline: monitoring / metrics

Key components: BestPnlTracker

Inputs: Logs de backtest

Outputs: Meilleur PnL track√©

Dependencies: logging

Conventions: PnL en devise de base

Read-if: Tracking PnL en temps r√©el

Skip-if: Pas besoin de monitoring PnL
"""

from __future__ import annotations

import logging
import re
import threading
from typing import Optional, Tuple

_BEST_PNL_TRACKER = None


class BestPnlTracker(logging.Handler):
    """
    Tracker du meilleur PnL de backtest (PnL total du meilleur run).
    Note: Capture le PnL TOTAL du backtest, pas le meilleur trade individuel.
    """

    def __init__(self) -> None:
        super().__init__(level=logging.INFO)
        self.best_backtest_pnl: Optional[float] = None
        self.best_run_id: Optional[str] = None
        self._lock = threading.Lock()
        self._pnl_pattern = re.compile(
            r"\bpnl\s*=\s*[^0-9-+]*([-+]?\d+(?:\.\d+)?)",
            re.IGNORECASE,
        )

    def emit(self, record: logging.LogRecord) -> None:
        if record.name != "backtest.engine":
            return
        msg = record.getMessage()

        # Ignorer les logs qui ne sont pas des r√©sultats de backtest complets
        if "pnl" not in msg.lower():
            return

        # Capturer uniquement le log final du backtest (pipeline_end)
        # qui contient le PnL TOTAL du backtest
        if "pipeline_end" not in msg and "duration_ms" not in msg:
            return

        match = self._pnl_pattern.search(msg)
        if not match:
            return
        try:
            pnl = float(match.group(1))
        except ValueError:
            return
        with self._lock:
            if self.best_backtest_pnl is None or pnl > self.best_backtest_pnl:
                self.best_backtest_pnl = pnl
                self.best_run_id = getattr(record, "run_id", None)

    def get_best(self) -> Tuple[Optional[float], Optional[str]]:
        with self._lock:
            return self.best_backtest_pnl, self.best_run_id


def install_best_pnl_tracker() -> BestPnlTracker:
    global _BEST_PNL_TRACKER
    if _BEST_PNL_TRACKER is not None:
        return _BEST_PNL_TRACKER
    logger = logging.getLogger("backtest")
    for handler in logger.handlers:
        if isinstance(handler, BestPnlTracker):
            _BEST_PNL_TRACKER = handler
            return handler
    tracker = BestPnlTracker()
    logger.addHandler(tracker)
    _BEST_PNL_TRACKER = tracker
    return tracker
```
<!-- MODULE-END: log_taps.py -->

<!-- MODULE-START: main.py -->
```json
{
  "name": "main.py",
  "path": "ui\\main.py",
  "ext": ".py",
  "anchor": "main_py"
}
```
## main_py
*Chemin* : `ui\main.py`  
*Type* : `.py`  

```python
"""
UI Streamlit principale pour le moteur de backtest.

PROTECTION WINDOWS SPAWN:
Ce module cr√©e des ProcessPoolExecutor pour les sweeps grille.
Sous Windows, multiprocessing utilise 'spawn' qui r√©-ex√©cute le module.
Les workers IMPORTENT ce fichier mais NE DOIVENT PAS ex√©cuter Streamlit.
Protection: Tout code Streamlit est dans main() appel√© uniquement par __main__.
"""
from __future__ import annotations

# pylint: disable=import-outside-toplevel,too-many-lines

import gc
import logging
import math
import os
import time
import traceback
from itertools import chain, islice, product
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import streamlit as st

from ui.constants import PARAM_CONSTRAINTS
from ui.context import (
    LLM_AVAILABLE,
    LLM_IMPORT_ERROR,
    OrchestrationLogger,
    BacktestEngine,
    compute_search_space_stats,
    create_llm_client,
    create_optimizer_from_engine,
    create_orchestrator_with_backtest,
    get_strategy_param_bounds,
    get_strategy_param_space,
    generate_session_id,
    render_deep_trace_viewer,
    render_full_orchestration_viewer,
    LiveOrchestrationViewer,
)
from ui.helpers import (
    ProgressMonitor,
    build_strategy_params_for_comparison,
    render_progress_monitor,
    safe_load_data,
    load_selected_data,
    safe_run_backtest,
    safe_copy_cleanup,
    show_status,
    summarize_comparison_results,
    validate_all_params,
    _maybe_auto_save_run,
)
from ui.state import SidebarState
from ui.components.charts import (
    render_comparison_chart,
    render_strategy_param_diagram,
    render_ohlcv_with_trades_and_indicators,
)
from ui.components.sweep_monitor import (
    SweepMonitor,
    render_sweep_progress,
    render_sweep_summary,
)
from ui.helpers import build_indicator_overlays
from utils.run_tracker import RunSignature, get_global_tracker

# Import du worker isol√© pour √©viter les probl√®mes de pickling avec hot-reload Streamlit
from backtest.worker import run_backtest_worker as _isolated_worker


def _run_backtest_multiprocess(args):
    """
    Wrapper picklable pour ProcessPoolExecutor.

    Args:
        args: tuple (param_combo, initial_capital, df, strategy_key, symbol, timeframe, debug_enabled)

    Returns:
        Dict avec r√©sultats du backtest ou erreur
    """
    param_combo, initial_capital, df, strategy_key, symbol, timeframe, debug_enabled = args

    try:
        # Cr√©er l'engine localement (pas picklable donc recr√©√© dans chaque process)
        engine = BacktestEngine(initial_capital=initial_capital)

        result_i, msg_i = safe_run_backtest(
            engine,
            df,
            strategy_key,
            param_combo,
            symbol,
            timeframe,
            silent_mode=not debug_enabled,
        )

        params_native = {
            k: float(v) if hasattr(v, "item") else v for k, v in param_combo.items()
        }
        params_str = str(params_native)

        if result_i:
            m = result_i.metrics
            return {
                "params": params_str,
                "params_dict": param_combo,
                "total_pnl": m.get("total_pnl", 0.0),
                "theoretical_pnl": m.get("theoretical_pnl", 0.0),
                "sharpe": m.get("sharpe_ratio", 0.0),
                "max_dd": m.get("max_drawdown_pct", m.get("max_drawdown", 0.0)),
                "win_rate": m.get("win_rate", 0.0),
                "trades": m.get("total_trades", 0),
                "profit_factor": m.get("profit_factor", 0.0),
            }
        return {
            "params": params_str,
            "params_dict": param_combo,
            "error": msg_i,
        }
    except Exception as exc:
        params_str = str(param_combo)
        return {
            "params": params_str,
            "params_dict": param_combo,
            "error": str(exc),
        }


def _apply_thread_limit(thread_limit: int, label: str = "") -> None:
    if thread_limit <= 0:
        return

    os.environ["BACKTEST_WORKER_THREADS"] = str(thread_limit)
    for var in (
        "OMP_NUM_THREADS",
        "MKL_NUM_THREADS",
        "OPENBLAS_NUM_THREADS",
        "NUMEXPR_NUM_THREADS",
        "VECLIB_MAXIMUM_THREADS",
        "BLIS_NUM_THREADS",
    ):
        os.environ[var] = str(thread_limit)

    try:
        from threadpoolctl import threadpool_limits

        threadpool_limits(thread_limit)
    except Exception:
        pass

    try:
        import torch

        torch.set_num_threads(thread_limit)
        torch.set_num_interop_threads(max(1, thread_limit // 2))
    except Exception:
        pass

    if label:
        logger = logging.getLogger(__name__)
        logger.info("Thread limit %s appliqu√©: %s", label, thread_limit)


def _init_sweep_worker(thread_limit: int) -> None:
    """Initializer ProcessPoolExecutor - applique limites threads AVANT tout calcul."""
    _apply_thread_limit(thread_limit, label="worker")

    # Forcer avec threadpoolctl (plus efficace que les env vars seules)
    try:
        import threadpoolctl
        info_before = threadpoolctl.threadpool_info()
        threadpoolctl.threadpool_limits(limits=max(1, thread_limit), user_api="blas")
        info_after = threadpoolctl.threadpool_info()

        # Log pour debug
        import logging
        logger = logging.getLogger(__name__)
        num_threads_before = sum(pool.get("num_threads", 0) for pool in info_before)
        num_threads_after = sum(pool.get("num_threads", 0) for pool in info_after)
        logger.debug(f"Worker threads BLAS: {num_threads_before} ‚Üí {num_threads_after}")
    except ImportError:
        pass  # threadpoolctl non install√© - les env vars suffiront


def render_controls() -> tuple[bool, Any]:
    st.title("üìà Backtest Core - Moteur Simplifi√©")

    status_container = st.container()

    st.markdown(
        """
Interface avec validation des param√®tres et feedback utilisateur.
Le syst√®me de granularit√© limite le nombre de valeurs testables.
"""
    )

    if "is_running" not in st.session_state:
        st.session_state.is_running = False
    if "stop_requested" not in st.session_state:
        st.session_state.stop_requested = False

    st.markdown("---")
    col_btn1, col_btn2, col_spacer = st.columns([2, 2, 6])

    with col_btn1:
        run_button = st.button(
            "üöÄ Lancer le Backtest",
            type="primary",
            disabled=st.session_state.is_running,
            use_container_width=True,
            key="btn_run_backtest",
        )

    with col_btn2:
        stop_button = st.button(
            "‚õî Arr√™t d'urgence",
            type="secondary",
            disabled=not st.session_state.is_running,
            use_container_width=True,
            key="btn_stop_backtest",
        )

    if stop_button:
        st.session_state.stop_requested = True
        st.session_state.is_running = False

        gc.collect()

        try:
            import torch

            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                st.success("‚úÖ VRAM GPU vid√©e")
        except ImportError:
            pass

        logger = logging.getLogger(__name__)
        safe_copy_cleanup(logger)

        st.success("‚úÖ RAM syst√®me vid√©e")
        st.info("üí° Syst√®me pr√™t pour un nouveau test")
        st.session_state.stop_requested = False
        st.rerun()

    st.markdown("---")

    return run_button, status_container


def render_setup_previews(state: SidebarState) -> None:
    st.markdown("---")
    st.subheader("Schema indicateurs & parametres")
    if state.strategy_instance is None:
        st.info("Selectionnez une strategie pour afficher le schema.")
    else:
        diagram_params = {
            **state.strategy_instance.default_params,
            **state.params,
        }
        render_strategy_param_diagram(
            state.strategy_key,
            diagram_params,
            key=f"diagram_{state.strategy_key}",
        )

    st.markdown("---")
    st.subheader("Apercu OHLCV + indicateurs")
    preview_df = st.session_state.get("ohlcv_df")
    if preview_df is None:
        st.info("Chargez les donnees pour afficher l'apercu.")
    else:
        preview_overlays = build_indicator_overlays(
            state.strategy_key,
            preview_df,
            state.params,
        )
        render_ohlcv_with_trades_and_indicators(
            df=preview_df,
            trades_df=pd.DataFrame(),
            overlays=preview_overlays,
            active_indicators=state.active_indicators,
            title="OHLCV + indicateurs (apercu)",
            key="ohlcv_indicator_preview",
            height=650,
        )


def render_main(
    state: SidebarState,
    run_button: bool,
    status_container: Any,
) -> None:
    result = st.session_state.get("last_run_result")
    winner_params = st.session_state.get("last_winner_params")
    winner_metrics = st.session_state.get("last_winner_metrics")
    winner_origin = st.session_state.get("last_winner_origin")
    winner_meta = st.session_state.get("last_winner_meta")

    params = state.params
    param_ranges = state.param_ranges
    strategy_key = state.strategy_key
    symbol = state.symbol
    timeframe = state.timeframe
    optimization_mode = state.optimization_mode
    debug_enabled = state.debug_enabled
    max_combos = state.max_combos
    n_workers = state.n_workers

    llm_config = state.llm_config
    llm_model = state.llm_model
    llm_use_multi_agent = state.llm_use_multi_agent
    llm_max_iterations = state.llm_max_iterations
    llm_use_walk_forward = state.llm_use_walk_forward
    llm_unload_during_backtest = state.llm_unload_during_backtest
    llm_compare_enabled = state.llm_compare_enabled
    llm_compare_auto_run = state.llm_compare_auto_run
    llm_compare_strategies = state.llm_compare_strategies
    llm_compare_tokens = state.llm_compare_tokens
    llm_compare_timeframes = state.llm_compare_timeframes
    llm_compare_metric = state.llm_compare_metric
    llm_compare_aggregate = state.llm_compare_aggregate
    llm_compare_max_runs = state.llm_compare_max_runs
    llm_compare_use_preset = state.llm_compare_use_preset
    llm_compare_generate_report = state.llm_compare_generate_report

    if run_button:
        st.session_state.is_running = True
        st.session_state.stop_requested = False
        winner_params = None
        winner_metrics = None
        winner_origin = None
        winner_meta = None

        is_valid, errors = validate_all_params(params)

        if not is_valid:
            with status_container:
                show_status("error", "Param√®tres invalides")
                for err in errors:
                    st.error(f"  ‚Ä¢ {err}")
            st.session_state.is_running = False
            st.stop()

        with st.spinner("üì• Chargement des donn√©es..."):
            df = st.session_state.get("ohlcv_df")
            data_msg = st.session_state.get("ohlcv_status_msg", "")

            if df is None:
                df, data_msg = load_selected_data(
                    symbol,
                    timeframe,
                    state.start_date,
                    state.end_date,
                )

            if df is None:
                with status_container:
                    show_status("error", f"√âchec chargement: {data_msg}")
                    st.info(
                        "üí° V√©rifiez les fichiers dans "
                        "`D:\\ThreadX_big\\data\\crypto\\processed\\parquet\\`"
                    )
                st.session_state.is_running = False
                st.stop()

            if df is not None:
                with status_container:
                    show_status("success", f"Donn√©es charg√©es: {data_msg}")

        engine = BacktestEngine(initial_capital=state.initial_capital)

        if optimization_mode == "Backtest Simple":
            with st.spinner("‚öôÔ∏è Ex√©cution du backtest..."):
                result, result_msg = safe_run_backtest(
                    engine,
                    df,
                    strategy_key,
                    params,
                    symbol,
                    timeframe,
                    silent_mode=not debug_enabled,
                )

            if result is None:
                with status_container:
                    show_status("error", f"√âchec backtest: {result_msg}")
                st.session_state.is_running = False
                st.stop()

            with status_container:
                show_status("success", f"Backtest termin√©: {result_msg}")
            winner_params = result.meta.get("params", params)
            winner_metrics = result.metrics
            winner_origin = "backtest"
            winner_meta = result.meta
            st.session_state["last_run_result"] = result
            st.session_state["last_winner_params"] = winner_params
            st.session_state["last_winner_metrics"] = winner_metrics
            st.session_state["last_winner_origin"] = winner_origin
            st.session_state["last_winner_meta"] = winner_meta
            _maybe_auto_save_run(result)

        elif optimization_mode == "Grille de Param√®tres":
            try:
                n_workers_effective = max(1, int(n_workers))
            except (TypeError, ValueError):
                n_workers_effective = 1
            # Lire threads depuis UI ou fallback env
            try:
                worker_thread_limit = int(st.session_state.get("grid_worker_threads",
                                                                 int(os.environ.get("BACKTEST_WORKER_THREADS", "1"))))
            except (TypeError, ValueError):
                worker_thread_limit = 1
            worker_thread_limit = max(1, worker_thread_limit)
            _apply_thread_limit(worker_thread_limit, label="main")

            with st.spinner("üìä G√©n√©ration de la grille..."):
                try:
                    param_names = list(param_ranges.keys())
                    param_values_lists = []

                    if param_names:
                        for pname in param_names:
                            r = param_ranges[pname]
                            pmin, pmax, step = r["min"], r["max"], r["step"]

                            if isinstance(pmin, int) and isinstance(step, int):
                                values = list(range(int(pmin), int(pmax) + 1, int(step)))
                            else:
                                values = list(
                                    np.arange(float(pmin), float(pmax) + float(step) / 2, float(step))
                                )
                                values = [round(v, 2) for v in values if v <= pmax]

                            if not values:
                                values = [pmin]

                            param_values_lists.append(values)

                        total_combinations = max(
                            1, math.prod(len(values) for values in param_values_lists)
                        )
                        combo_iter = (
                            {**params, **dict(zip(param_names, combo))}
                            for combo in product(*param_values_lists)
                        )
                    else:
                        total_combinations = 1
                        combo_iter = iter([params.copy()])

                    # Appliquer limite uniquement si max_combos < 100M (consid√©r√© comme illimit√© au-del√†)
                    if max_combos and max_combos < 100_000_000 and total_combinations > max_combos:
                        st.warning(
                            f"‚ö†Ô∏è Grille limit√©e: {total_combinations:,} ‚Üí {max_combos:,}"
                        )
                        total_runs = max_combos
                        combo_iter = islice(combo_iter, max_combos)
                    else:
                        total_runs = total_combinations

                    if total_runs < total_combinations:
                        show_status(
                            "info",
                            f"Grille: {total_runs:,} / {total_combinations:,} combinaisons ({n_workers_effective} workers √ó {worker_thread_limit} threads)",
                        )
                    else:
                        show_status("info", f"Grille: {total_runs:,} combinaisons ({n_workers_effective} workers √ó {worker_thread_limit} threads)")

                except Exception as exc:
                    show_status("error", f"√âchec g√©n√©ration grille: {exc}")
                    st.session_state.is_running = False
                    st.stop()

            results_list = []
            param_combos_map = {}

            monitor = ProgressMonitor(total_runs=total_runs)
            monitor_placeholder = st.empty()

            sweep_monitor = SweepMonitor(
                total_combinations=total_runs,
                objectives=["total_pnl", "theoretical_pnl", "sharpe_ratio", "total_return_pct", "max_drawdown"],
                top_k=15,
            )
            sweep_monitor.start()
            sweep_placeholder = st.empty()

            logger = logging.getLogger(__name__)
            error_counts: Dict[str, int] = {}
            error_logged: set[str] = set()
            try:
                error_log_limit = int(os.environ.get("BACKTEST_SWEEP_ERROR_LOG_LIMIT", "3"))
            except (TypeError, ValueError):
                error_log_limit = 3

            st.markdown("### üìä Progression en temps r√©el")
            render_progress_monitor(monitor, monitor_placeholder)


            def _normalize_param_combo(param_combo: Dict[str, Any]) -> Dict[str, Any]:
                return {
                    k: float(v) if hasattr(v, "item") else v for k, v in param_combo.items()
                }

            def _params_to_str(param_combo: Dict[str, Any]) -> str:
                return str(_normalize_param_combo(param_combo))

            def run_single_backtest(param_combo: Dict[str, Any]):
                try:
                    result_i, msg_i = safe_run_backtest(
                        engine,
                        df,
                        strategy_key,
                        param_combo,
                        symbol,
                        timeframe,
                        silent_mode=not debug_enabled,
                    )

                    params_str = _params_to_str(param_combo)

                    if result_i:
                        m = result_i.metrics
                        # Log des cl√©s disponibles si debug activ√©
                        if debug_enabled and not m:
                            logger.warning("Metrics vides pour params=%s", params_str)
                        return {
                            "params": params_str,
                            "params_dict": param_combo,
                            "total_pnl": m.get("total_pnl", 0.0),
                            "theoretical_pnl": m.get("theoretical_pnl", 0.0),
                            "sharpe": m.get("sharpe_ratio", 0.0),
                            "max_dd": m.get("max_drawdown_pct", m.get("max_drawdown", 0.0)),
                            "win_rate": m.get("win_rate", 0.0),
                            "trades": m.get("total_trades", 0),
                            "profit_factor": m.get("profit_factor", 0.0),
                        }
                    return {
                        "params": params_str,
                        "params_dict": param_combo,
                        "error": msg_i,
                    }
                except Exception as exc:
                    params_str = _params_to_str(param_combo)
                    # Log complet de l'erreur avec traceback
                    if debug_enabled:
                        logger.error("Backtest error params=%s: %s", params_str, traceback.format_exc())
                    return {
                        "params": params_str,
                        "params_dict": param_combo,
                        "error": f"{type(exc).__name__}: {exc}",
                    }

            def record_sweep_result(
                result: Dict[str, Any],
                fallback_params: Dict[str, Any],
            ) -> str:
                param_combo_result = result.get("params_dict") or fallback_params
                params_str = result.get("params") or _params_to_str(param_combo_result)
                result["params"] = params_str
                param_combos_map[params_str] = param_combo_result

                if "error" not in result:
                    metrics = {
                        "sharpe_ratio": result.get("sharpe", 0.0),
                        "total_pnl": result.get("total_pnl", 0.0),
                        "theoretical_pnl": result.get("theoretical_pnl", 0.0),
                        "total_return_pct": result.get("total_pnl", 0.0) / state.initial_capital * 100 if state.initial_capital else 0.0,
                        "max_drawdown": abs(result.get("max_dd", 0.0)),
                        "win_rate": result.get("win_rate", 0.0),
                        "total_trades": result.get("trades", 0),
                        "profit_factor": result.get("profit_factor", 0.0),
                        "consecutive_losses_max": result.get("consecutive_losses_max", 0),
                        "avg_win_loss_ratio": result.get("avg_win_loss_ratio", 0.0),
                        "robustness_score": result.get("robustness_score", 0.0),
                    }
                    sweep_monitor.update(params=param_combo_result, metrics=metrics)
                else:
                    error_msg = str(result.get("error") or "Erreur inconnue")
                    error_counts[error_msg] = error_counts.get(error_msg, 0) + 1
                    if len(error_logged) < error_log_limit and error_msg not in error_logged:
                        logger.error("Sweep error sample: %s", error_msg)
                        error_logged.add(error_msg)
                    sweep_monitor.update(params=param_combo_result, metrics={}, error=True)

                result_clean = {k: v for k, v in result.items() if k != "params_dict"}
                results_list.append(result_clean)
                return params_str

            completed_params = set()
            completed = 0
            last_render_time = time.perf_counter()

            def run_sequential_combos(combo_source, key_prefix: str) -> None:
                nonlocal completed, last_render_time
                for param_combo in combo_source:
                    params_str = _params_to_str(param_combo)
                    if params_str in completed_params:
                        continue

                    completed += 1
                    monitor.runs_completed = completed

                    result = run_single_backtest(param_combo)
                    params_str = record_sweep_result(result, param_combo)
                    completed_params.add(params_str)

                    current_time = time.perf_counter()
                    # üöÄ FIX FREEZE EDGE: Throttling ULTRA lent pour garder les graphiques sans freeze
                    # Update tous les 1000 runs OU toutes les 30 secondes (au lieu de 50/2s initialement)
                    # Cela r√©duit les messages WebSocket de 300+ √† ~10-15 en 10 minutes
                    if completed % 1000 == 0 or current_time - last_render_time >= 30.0:
                        render_progress_monitor(monitor, monitor_placeholder)
                        # R√©activer graphiques avec throttling ultra lent + mode statique
                        from ui.components.sweep_monitor import render_sweep_progress
                        with sweep_placeholder.container():
                            progress_pct = (completed / total_runs * 100) if total_runs > 0 else 0
                            st.info(f"‚ö° {completed}/{total_runs} runs compl√©t√©s ({progress_pct:.1f}%)")

                            # Afficher le meilleur PnL actuel + m√©triques critiques
                            if hasattr(sweep_monitor, '_results') and sweep_monitor._results:
                                # Extraire m√©triques - optimis√© avec un seul parcours
                                best_pnl = float("-inf")
                                best_sharpe = float("-inf")
                                best_pf = 0.0
                                best_robustness = 0.0
                                best_run = None

                                for r in sweep_monitor._results:
                                    pnl = r.metrics.get("total_pnl", float("-inf"))
                                    sharpe = r.metrics.get("sharpe_ratio", float("-inf"))
                                    pf = r.metrics.get("profit_factor", 0.0)
                                    rob = r.metrics.get("robustness_score", 0.0)

                                    if pnl > best_pnl:
                                        best_pnl = pnl
                                    if sharpe > best_sharpe:
                                        best_sharpe = sharpe
                                    if pf > best_pf:
                                        best_pf = pf
                                    if rob > best_robustness:
                                        best_robustness = rob
                                        best_run = r

                                # Fallback sur PnL si aucun robustness valide
                                if best_run is None:
                                    best_run = max(sweep_monitor._results, key=lambda r: r.metrics.get("total_pnl", float("-inf")))

                                best_wl_ratio = best_run.metrics.get("avg_win_loss_ratio", 0.0)
                                best_consec_losses = best_run.metrics.get("consecutive_losses_max", 0)

                                pnl_color = "green" if best_pnl > 0 else "red"

                                # Affichage compact des m√©triques critiques
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.markdown(f"üí∞ **Meilleur PnL**: :{pnl_color}[**${best_pnl:+,.2f}**]")
                                    st.caption(f"üìä Sharpe: **{best_sharpe:.2f}** | PF: **{best_pf:.2f}**")
                                with col2:
                                    robustness_color = "green" if best_robustness > 2.0 else "orange" if best_robustness > 1.0 else "red"
                                    st.markdown(f"üéØ **Robustesse**: :{robustness_color}[**{best_robustness:.2f}**]")
                                    st.caption(f"üìà Sharpe √ó PF (id√©al >3.0)")
                                with col3:
                                    wl_color = "green" if best_wl_ratio > 2.0 else "orange" if best_wl_ratio > 1.5 else "red"
                                    st.markdown(f"‚öñÔ∏è **W/L Ratio**: :{wl_color}[**{best_wl_ratio:.2f}**]")
                                    st.caption(f"üíî Max pertes: **{best_consec_losses}** cons√©cutives")

                            # Graphiques avec mode statique (pas d'interactivit√© = moins de donn√©es WebSocket)
                            render_sweep_progress(
                                sweep_monitor,
                                key=f"sweep_progress_seq_{completed}",
                                static_plots=True  # D√©sactiver interactivit√© Plotly
                            )
                            st.caption(f"üîÑ Rafra√Æchissement: tous les 1000 runs ou 30s (throttling anti-freeze)")
                        last_render_time = current_time
                        time.sleep(0.01)

            if n_workers_effective > 1 and total_runs > 1:
                from concurrent.futures import FIRST_COMPLETED, ProcessPoolExecutor, TimeoutError as FutureTimeoutError, wait
                try:
                    from concurrent.futures import BrokenProcessPool
                except ImportError:  # pragma: no cover - fallback for older runtimes
                    BrokenProcessPool = RuntimeError

                # Syst√®me de diagnostic
                from utils.sweep_diagnostics import SweepDiagnostics
                diag = SweepDiagnostics(run_id=f"grid_{strategy_key}")
                diag.log_pool_start(n_workers_effective, worker_thread_limit, total_runs)

                logger = logging.getLogger(__name__)
                stall_timeout_sec = float(os.getenv("BACKTEST_SWEEP_STALL_SEC", "60"))
                max_inflight = max(1, min(total_runs, n_workers_effective * 2))
                pending = {}
                failed_pending = []
                pool_failed = False
                pool_fail_reason = None
                pool_error: Exception | None = None
                last_completion_time = time.perf_counter()
                pickle_error_count = 0  # Compteur d'erreurs de pickling
                combo_counter = 0  # Compteur pour diagnostics

                def submit_next() -> bool:
                    nonlocal combo_counter
                    try:
                        param_combo = next(combo_iter)
                    except StopIteration:
                        return False
                    combo_counter += 1
                    diag.log_submit(combo_counter, param_combo)
                    # Soumettre UNIQUEMENT param_combo - le DataFrame est d√©j√† dans le worker
                    # Cela √©vite la s√©rialisation pickle r√©p√©t√©e du DataFrame (√©conomie CPU + m√©moire)
                    future = executor.submit(
                        _isolated_worker,
                        param_combo  # Seul param√®tre : dict des param√®tres de strat√©gie
                    )
                    pending[future] = param_combo
                    return True

                # Import de l'initializer optimis√© qui charge le DataFrame une seule fois par worker
                from backtest.worker import init_worker_with_dataframe

                executor = ProcessPoolExecutor(
                    max_workers=n_workers_effective,
                    initializer=init_worker_with_dataframe,
                    initargs=(
                        df,  # DataFrame charg√© UNE SEULE FOIS par worker
                        strategy_key,
                        symbol,
                        timeframe,
                        state.initial_capital,
                        debug_enabled,
                        worker_thread_limit,
                    ),
                )
                try:
                    for _ in range(max_inflight):
                        if not submit_next():
                            break

                    while pending:
                        done, _ = wait(pending, timeout=0.5, return_when=FIRST_COMPLETED)
                        if not done:
                            if time.perf_counter() - last_completion_time >= stall_timeout_sec:
                                pool_failed = True
                                pool_fail_reason = "stall"
                                pool_error = TimeoutError(
                                    f"Aucune completion depuis {stall_timeout_sec:.0f}s"
                                )
                                diag.log_stall(stall_timeout_sec, list(pending.values()))
                                logger.error(
                                    "Sweep multiprocess bloque depuis %ss, bascule sequentielle.",
                                    int(stall_timeout_sec),
                                )
                                break
                            continue

                        for future in done:
                            param_combo = pending.pop(future)
                            future_start = time.perf_counter()
                            result = None
                            should_record = True

                            try:
                                # Timeout 300s pour √©viter freeze si Windows interrupt (Task Manager, focus change, etc.)
                                result = future.result(timeout=300)
                                duration_ms = (time.perf_counter() - future_start) * 1000

                                # Log completion
                                combo_idx = combo_counter - len(pending) - len(failed_pending)
                                diag.log_completion(combo_idx, param_combo, result, duration_ms)

                                # D√©tecter erreur de pickling dans le r√©sultat
                                if isinstance(result, dict) and result.get("error", ""):
                                    error_msg = str(result.get("error", ""))
                                    if "pickle" in error_msg.lower() or "not the same object" in error_msg:
                                        pickle_error_count += 1
                                        if pickle_error_count >= 10:
                                            pool_failed = True
                                            pool_fail_reason = "pickle"
                                            pool_error = RuntimeError(
                                                "Erreur de pickling d√©tect√©e - Streamlit a recharg√© le module. "
                                                "Relancez le sweep apr√®s le rechargement."
                                            )
                                            logger.error(
                                                "Erreur de pickling r√©p√©t√©e (%d fois), arr√™t du sweep.",
                                                pickle_error_count,
                                            )
                                            failed_pending.append(param_combo)
                                            should_record = False
                                            break

                            except BrokenProcessPool as exc:
                                combo_idx = combo_counter - len(pending) - len(failed_pending)
                                diag.log_pool_broken("BrokenProcessPool", exc)
                                pool_failed = True
                                pool_fail_reason = "broken"
                                pool_error = exc
                                failed_pending.append(param_combo)
                                should_record = False

                                break

                            except FutureTimeoutError:
                                # Worker timeout (>300s) - probablement bloqu√© par interruption Windows
                                combo_idx = combo_counter - len(pending) - len(failed_pending)
                                diag.log_timeout(combo_idx, param_combo, 300)
                                logger.warning("Worker timeout (>300s) combo: %s", param_combo)
                                result = {
                                    "params": _params_to_str(param_combo),
                                    "params_dict": param_combo,
                                    "error": "Worker timeout (>300s, probablement bloqu√© par interruption Windows)",
                                }
                                # should_record reste True - on enregistre le timeout comme erreur

                            except Exception as exc:
                                combo_idx = combo_counter - len(pending) - len(failed_pending)
                                diag.log_future_exception(combo_idx, param_combo, exc)
                                error_str = f"{type(exc).__name__}: {exc}"
                                # D√©tecter erreur de pickling dans l'exception
                                if "pickle" in error_str.lower() or "not the same object" in error_str:
                                    pickle_error_count += 1
                                    if pickle_error_count >= 10:
                                        pool_failed = True
                                        pool_fail_reason = "pickle"
                                        pool_error = RuntimeError(
                                            "Erreur de pickling - le module a √©t√© recharg√© pendant le sweep."
                                        )
                                        failed_pending.append(param_combo)
                                        should_record = False
                                        break
                                result = {
                                    "params": _params_to_str(param_combo),
                                    "params_dict": param_combo,
                                    "error": error_str,
                                }
                                # should_record reste True - on enregistre l'erreur

                            # Enregistrer le r√©sultat (sauf si break anticip√©)
                            if should_record and result is not None:
                                completed += 1
                                monitor.runs_completed = completed
                                params_str = record_sweep_result(result, param_combo)
                                completed_params.add(params_str)
                                last_completion_time = time.perf_counter()

                            # ‚ö° CRITIQUE: Soumettre la combinaison suivante UNE SEULE FOIS apr√®s traitement complet
                            # (sauf si pool_failed ou break - dans ce cas on sort de la boucle de toute fa√ßon)
                            if not pool_failed:
                                submit_next()

                            current_time = time.perf_counter()
                            # üöÄ FIX FREEZE EDGE: Throttling ULTRA lent pour garder les graphiques sans freeze
                            # Update tous les 1000 runs OU toutes les 30 secondes
                            if completed % 1000 == 0 or current_time - last_render_time >= 30.0:
                                render_progress_monitor(monitor, monitor_placeholder)
                                # R√©activer graphiques avec throttling ultra lent + mode statique
                                from ui.components.sweep_monitor import render_sweep_progress
                                with sweep_placeholder.container():
                                    progress_pct = (completed / total_runs * 100) if total_runs > 0 else 0
                                    st.info(f"‚ö° {completed}/{total_runs} runs ({progress_pct:.1f}%)")

                                    # Afficher le meilleur PnL actuel + m√©triques critiques
                                    if hasattr(sweep_monitor, '_results') and sweep_monitor._results:
                                        # Extraire m√©triques - optimis√© avec un seul parcours
                                        best_pnl = float("-inf")
                                        best_sharpe = float("-inf")
                                        best_pf = 0.0
                                        best_robustness = 0.0
                                        best_run = None

                                        for r in sweep_monitor._results:
                                            pnl = r.metrics.get("total_pnl", float("-inf"))
                                            sharpe = r.metrics.get("sharpe_ratio", float("-inf"))
                                            pf = r.metrics.get("profit_factor", 0.0)
                                            rob = r.metrics.get("robustness_score", 0.0)

                                            if pnl > best_pnl:
                                                best_pnl = pnl
                                            if sharpe > best_sharpe:
                                                best_sharpe = sharpe
                                            if pf > best_pf:
                                                best_pf = pf
                                            if rob > best_robustness:
                                                best_robustness = rob
                                                best_run = r

                                        # Fallback sur PnL si aucun robustness valide
                                        if best_run is None:
                                            best_run = max(sweep_monitor._results, key=lambda r: r.metrics.get("total_pnl", float("-inf")))

                                        best_wl_ratio = best_run.metrics.get("avg_win_loss_ratio", 0.0)
                                        best_consec_losses = best_run.metrics.get("consecutive_losses_max", 0)

                                        pnl_color = "green" if best_pnl > 0 else "red"

                                        # Affichage compact des m√©triques critiques
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.markdown(f"üí∞ **Meilleur PnL**: :{pnl_color}[**${best_pnl:+,.2f}**]")
                                            st.caption(f"üìä Sharpe: **{best_sharpe:.2f}** | PF: **{best_pf:.2f}**")
                                        with col2:
                                            robustness_color = "green" if best_robustness > 2.0 else "orange" if best_robustness > 1.0 else "red"
                                            st.markdown(f"üéØ **Robustesse**: :{robustness_color}[**{best_robustness:.2f}**]")
                                            st.caption(f"üìà Sharpe √ó PF (id√©al >3.0)")
                                        with col3:
                                            wl_color = "green" if best_wl_ratio > 2.0 else "orange" if best_wl_ratio > 1.5 else "red"
                                            st.markdown(f"‚öñÔ∏è **W/L Ratio**: :{wl_color}[**{best_wl_ratio:.2f}**]")
                                            st.caption(f"üíî Max pertes: **{best_consec_losses}** cons√©cutives")

                                    # Graphiques avec mode statique
                                    render_sweep_progress(
                                        sweep_monitor,
                                        key=f"sweep_progress_multi_{completed}",
                                        static_plots=True
                                    )
                                    st.caption(f"üîÑ Rafra√Æchissement: tous les 1000 runs ou 30s (throttling anti-freeze)")
                                last_render_time = current_time
                                time.sleep(0.01)

                        if pool_failed:
                            diag.log_pool_broken(pool_fail_reason or "unknown", pool_error)
                            break
                finally:
                    diag.log_pool_shutdown(success=not pool_failed)
                    try:
                        executor.shutdown(
                            wait=not pool_failed,
                            cancel_futures=pool_failed,
                        )
                    except Exception:
                        logger.exception("Erreur shutdown ProcessPoolExecutor")

                if pool_failed:
                    with status_container:
                        if pool_fail_reason == "pickle":
                            show_status(
                                "error",
                                "‚ö†Ô∏è Erreur de pickling: le module a √©t√© recharg√© par Streamlit pendant le sweep. "
                                "Relancez le sweep - il reprendra depuis les combinaisons non test√©es.",
                            )
                        else:
                            show_status(
                                "warning",
                                "Pool multiprocess interrompu, reprise en mode s√©quentiel.",
                            )
                        if pool_error:
                            st.caption(f"D√©tails: {pool_error}")

                    pending_combos = failed_pending + list(pending.values())
                    if pool_fail_reason == "stall" and pending_combos:
                        for param_combo in pending_combos:
                            completed += 1
                            monitor.runs_completed = completed
                            params_str = record_sweep_result(
                                {"params_dict": param_combo, "error": "worker_stall"},
                                param_combo,
                            )
                            completed_params.add(params_str)
                        pending_combos = []

                    diag.log_sequential_fallback(pool_fail_reason, len(pending_combos))
                    fallback_iter = chain(pending_combos, combo_iter)
                    run_sequential_combos(fallback_iter, "sweep_fallback")
            else:
                run_sequential_combos(combo_iter, "sweep_sequential")

            render_progress_monitor(monitor, monitor_placeholder)
            sweep_placeholder.empty()
            with sweep_placeholder.container():
                render_sweep_progress(
                    sweep_monitor,
                    key="sweep_final",
                    show_top_results=True,
                    show_evolution=True,
                )

            st.markdown("---")
            st.markdown("### üéØ R√©sum√© de l'Optimisation")
            render_sweep_summary(sweep_monitor, key="sweep_summary")

            # Finalize diagnostics
            diag.log_final_summary()
            st.caption(f"üìã Logs diagnostiques: `{diag.log_file}`")

            monitor_placeholder.empty()
            sweep_placeholder.empty()

            with status_container:
                show_status("success", f"Optimisation: {len(results_list)} tests")

            results_df = pd.DataFrame(results_list)

            if "trades" in results_df.columns:
                logger = logging.getLogger(__name__)
                logger.info("=" * 80)
                logger.info("üîç DEBUG GRID SEARCH - Analyse de la colonne 'trades'")
                logger.info("   Type: %s", results_df["trades"].dtype)
                logger.info("   Shape: %s", results_df["trades"].shape)
                logger.info(
                    "   Premi√®res valeurs: %s",
                    results_df["trades"].head(10).tolist(),
                )
                logger.info(
                    "   Stats: min=%s, max=%s, mean=%.2f",
                    results_df["trades"].min(),
                    results_df["trades"].max(),
                    results_df["trades"].mean(),
                )

                trades_values = results_df["trades"].values
                fractional = [
                    x for x in trades_values if isinstance(x, float) and not x.is_integer()
                ]
                if fractional:
                    logger.warning(
                        "   ‚ö†Ô∏è  %s valeurs fractionnaires d√©tect√©es: %s",
                        len(fractional),
                        fractional[:5],
                    )
                else:
                    logger.info("   ‚úÖ Toutes les valeurs sont des entiers")
                logger.info("=" * 80)

            error_items = []
            if error_counts:
                total_errors = sum(error_counts.values())
                with st.expander("‚ùå Erreurs (extraits)", expanded=True):
                    st.caption(
                        f"{total_errors} erreurs detectees. "
                        "Consultez le terminal pour les premiers messages."
                    )
                    error_items = sorted(
                        error_counts.items(), key=lambda item: item[1], reverse=True
                    )
                    error_df = pd.DataFrame(
                        [
                            {"error": msg, "count": count}
                            for msg, count in error_items[:10]
                        ]
                    )
                    st.dataframe(error_df, use_container_width=True)

            error_column = results_df.get("error")
            if error_column is not None:
                valid_results = results_df[error_column.isna()]
            else:
                valid_results = results_df

            if not valid_results.empty:
                valid_results = valid_results.sort_values("sharpe", ascending=False)

                st.subheader("üèÜ Top 10 Combinaisons")

                with st.expander("üîç Debug Info - Types de donn√©es"):
                    st.text(f"Nombre de r√©sultats: {len(valid_results)}")
                    st.text("Types des colonnes:")
                    st.text(str(valid_results.dtypes))
                    if "trades" in valid_results.columns:
                        st.text("\nStatistiques 'trades':")
                        st.text(f"  Type: {valid_results['trades'].dtype}")
                        st.text(f"  Min: {valid_results['trades'].min()}")
                        st.text(f"  Max: {valid_results['trades'].max()}")
                        st.text(
                            f"  Mean: {valid_results['trades'].mean():.2f}"
                        )

                st.dataframe(valid_results.head(10), use_container_width=True)

                best = valid_results.iloc[0]
                st.info(f"ü•á Meilleure: {best['params']}")

                best_params = param_combos_map.get(best["params"], {})
                result, _ = safe_run_backtest(
                    engine,
                    df,
                    strategy_key,
                    best_params,
                    symbol,
                    timeframe,
                    silent_mode=not debug_enabled,
                )
                if result is not None:
                    winner_params = best_params
                    winner_metrics = result.metrics
                    winner_origin = "grid"
                    winner_meta = result.meta
                    st.session_state["last_run_result"] = result
                    st.session_state["last_winner_params"] = winner_params
                    st.session_state["last_winner_metrics"] = winner_metrics
                    st.session_state["last_winner_origin"] = winner_origin
                    st.session_state["last_winner_meta"] = winner_meta
                    _maybe_auto_save_run(result)
            else:
                show_status("error", "Aucun r√©sultat valide")
                # Afficher diagnostic d√©taill√©
                st.markdown("### üîç Diagnostic")
                st.warning(
                    f"Sur {len(results_list)} combinaisons √©valu√©es, "
                    f"toutes ont √©chou√©."
                )
                if error_items:
                    top_error, top_count = error_items[0]
                    st.error(
                        f"**Erreur principale** ({top_count} occurrences sur {sum(error_counts.values())} erreurs):"
                    )
                    st.code(top_error, language="text")
                elif results_list:
                    # Extraire les erreurs du DataFrame si error_counts vide
                    errors_in_results = [
                        r.get("error") for r in results_list if r.get("error")
                    ]
                    if errors_in_results:
                        st.error(f"**Premi√®re erreur d√©tect√©e:**")
                        st.code(errors_in_results[0], language="text")
                        if len(errors_in_results) > 1:
                            st.caption(f"+ {len(errors_in_results)-1} autres erreurs similaires")
                    else:
                        st.info(
                            "Aucune erreur explicite, mais les r√©sultats sont invalides. "
                            "V√©rifiez que les donn√©es OHLCV sont charg√©es et valides."
                        )
                st.session_state.is_running = False
                st.stop()

        elif optimization_mode == "ü§ñ Optimisation LLM":
            if not LLM_AVAILABLE:
                show_status("error", "Module agents LLM non disponible")
                st.code(LLM_IMPORT_ERROR)
                st.session_state.is_running = False
                st.stop()

            if llm_config is None:
                show_status("error", "Configuration LLM incompl√®te")
                st.info("Configurez le provider LLM dans la sidebar")
                st.session_state.is_running = False
                st.stop()

            session_id = generate_session_id()
            orchestration_logger = OrchestrationLogger(session_id=session_id)

            try:
                param_bounds = get_strategy_param_bounds(strategy_key)
                if not param_bounds:
                    param_bounds = {}
                    for pname in params.keys():
                        if pname in PARAM_CONSTRAINTS:
                            c = PARAM_CONSTRAINTS[pname]
                            param_bounds[pname] = (c["min"], c["max"])
            except Exception as exc:
                show_status("warning", f"Bornes par d√©faut utilis√©es: {exc}")
                param_bounds = {}
                for pname in params.keys():
                    if pname in PARAM_CONSTRAINTS:
                        c = PARAM_CONSTRAINTS[pname]
                        param_bounds[pname] = (c["min"], c["max"])

            try:
                full_param_space = get_strategy_param_space(strategy_key, include_step=True)
                llm_space_stats = compute_search_space_stats(full_param_space)
            except Exception:
                llm_space_stats = None

            max_iterations = min(llm_max_iterations, max_combos)

            comparison_summary: List[Dict[str, Any]] = []
            should_run_comparison = llm_compare_enabled and (
                llm_compare_auto_run or st.session_state.get("llm_compare_run_now", False)
            )
            if should_run_comparison:
                st.subheader("Comparaison multi-strategies")
                if not llm_compare_strategies:
                    st.warning("Aucune strategie selectionnee pour la comparaison.")
                elif not llm_compare_tokens or not llm_compare_timeframes:
                    st.warning("Selectionnez au moins un token et un timeframe.")
                else:
                    start_str = str(state.start_date) if state.start_date else None
                    end_str = str(state.end_date) if state.end_date else None
                    progress_bar = st.progress(0)
                    comparison_results: List[Dict[str, Any]] = []
                    comparison_errors: List[str] = []
                    data_cache: Dict[tuple[str, str], pd.DataFrame] = {}

                    for token in llm_compare_tokens:
                        for tf in llm_compare_timeframes:
                            df_cmp, msg = safe_load_data(token, tf, start_str, end_str)
                            if df_cmp is None:
                                comparison_errors.append(f"{token}/{tf}: {msg}")
                            else:
                                data_cache[(token, tf)] = df_cmp

                    valid_pairs = list(data_cache.keys())
                    total_runs = len(valid_pairs) * len(llm_compare_strategies)
                    total_runs = max(0, min(total_runs, llm_compare_max_runs))
                    run_index = 0

                    with st.spinner("Comparaison en cours..."):
                        for strategy_name_cmp in llm_compare_strategies:
                            params_cmp = build_strategy_params_for_comparison(
                                strategy_name_cmp,
                                use_preset=llm_compare_use_preset,
                            )
                            for token, tf in valid_pairs:
                                if run_index >= total_runs:
                                    break
                                df_cmp = data_cache[(token, tf)]
                                result_cmp, status = safe_run_backtest(
                                    engine,
                                    df_cmp,
                                    strategy_name_cmp,
                                    params_cmp,
                                    token,
                                    tf,
                                    silent_mode=not debug_enabled,
                                )
                                if result_cmp is None:
                                    comparison_errors.append(
                                        f"{strategy_name_cmp} {token}/{tf}: {status}"
                                    )
                                else:
                                    comparison_results.append(
                                        {
                                            "strategy": strategy_name_cmp,
                                            "symbol": token,
                                            "timeframe": tf,
                                            "metrics": result_cmp.metrics,
                                            "trades": len(result_cmp.trades),
                                        }
                                    )
                                run_index += 1
                                if total_runs > 0:
                                    progress_bar.progress(run_index / total_runs)
                            if run_index >= total_runs:
                                break

                    if comparison_errors:
                        st.warning(
                            "Comparaison: "
                            + "; ".join(comparison_errors[:8])
                            + (" ..." if len(comparison_errors) > 8 else "")
                        )

                    if comparison_results:
                        comparison_summary = summarize_comparison_results(
                            comparison_results,
                            aggregate=llm_compare_aggregate,
                            primary_metric=llm_compare_metric,
                            expected_runs=len(valid_pairs),
                        )
                        st.caption(
                            f"Runs effectues: {len(comparison_results)} / {total_runs}"
                        )
                        st.dataframe(pd.DataFrame(comparison_summary), use_container_width=True)

                        chart_rows = []
                        for row in comparison_summary:
                            chart_rows.append(
                                {
                                    "name": row["strategy"],
                                    "metrics": {
                                        llm_compare_metric: row.get(llm_compare_metric)
                                    },
                                }
                            )
                        render_comparison_chart(
                            chart_rows,
                            metric=llm_compare_metric,
                            title="Comparaison agregree",
                            key="llm_strategy_comparison",
                        )

                        if llm_compare_generate_report:
                            try:
                                llm_client = create_llm_client(llm_config)
                                if not llm_client.is_available():
                                    st.warning("LLM indisponible pour la justification.")
                                else:
                                    summary_lines = [
                                        "strategy | runs | sharpe | return_pct | max_drawdown | win_rate"
                                    ]
                                    for row in comparison_summary:
                                        summary_lines.append(
                                            f"{row.get('strategy')} | "
                                            f"{row.get('runs')} | "
                                            f"{row.get('sharpe_ratio', float('nan')):.2f} | "
                                            f"{row.get('total_return_pct', float('nan')):.2f} | "
                                            f"{row.get('max_drawdown', float('nan')):.2f} | "
                                            f"{row.get('win_rate', float('nan')):.1f}"
                                        )

                                    system_prompt = (
                                        "You are a senior quantitative strategist. "
                                        "Compare strategy robustness across assets and timeframes."
                                    )
                                    user_message = (
                                        "Comparison scope:\n"
                                        f"- tokens: {', '.join(llm_compare_tokens)}\n"
                                        f"- timeframes: {', '.join(llm_compare_timeframes)}\n"
                                        f"- aggregation: {llm_compare_aggregate}\n"
                                        f"- primary metric: {llm_compare_metric}\n\n"
                                        "Summary table (metrics are percent where applicable):\n"
                                        + "\n".join(summary_lines)
                                        + "\n\n"
                                        "Provide:\n"
                                        "1) Ranking with short justification.\n"
                                        "2) Notes on robustness and risk.\n"
                                        "3) Which strategies deserve further optimization."
                                    )

                                    response = llm_client.simple_chat(
                                        user_message=user_message,
                                        system_prompt=system_prompt,
                                        temperature=0.3,
                                    )
                                    st.markdown("**Justification LLM**")
                                    st.write(response.content)
                            except Exception as exc:
                                st.warning(f"Justification LLM indisponible: {exc}")
                    st.session_state["llm_compare_run_now"] = False

            st.subheader("ü§ñ Optimisation par Agents LLM")

            col_info, col_timeline = st.columns([1, 2])

            with col_info:
                st.markdown(
                    f"""
            **Strat√©gie:** `{strategy_key}`
            **Param√®tres initiaux:** `{params}`
            **Max it√©rations:** {llm_max_iterations}
            **Walk-Forward:** {'‚úÖ' if llm_use_walk_forward else '‚ùå'}
            """
                )

                st.markdown("**Bornes des param√®tres:**")
                for pname, (pmin, pmax) in param_bounds.items():
                    st.caption(f"‚Ä¢ {pname}: [{pmin}, {pmax}]")

                if llm_space_stats:
                    st.markdown("---")
                    if llm_space_stats.is_continuous:
                        st.info("‚ÑπÔ∏è **Espace continu** : exploration adaptative par LLM")
                    else:
                        st.caption(
                            "üìä Espace discret estim√©: "
                            f"~{llm_space_stats.total_combinations:,} combinaisons"
                        )
                        st.caption("_(Le LLM explore de fa√ßon intelligente sans √©num√©rer)_")

            col_timeline.empty()

            strategist = None
            executor = None
            orchestrator = None

            run_tracker = get_global_tracker()
            data_identifier = (
                f"df_{len(df)}rows_{df.index[0]}_{df.index[-1]}"
                if len(df) > 0
                else "empty_df"
            )
            run_signature = RunSignature(
                strategy_name=strategy_key,
                data_path=data_identifier,
                initial_params=params,
                llm_model=llm_model,
                mode="multi_agents" if llm_use_multi_agent else "autonomous",
                session_id=session_id,
            )

            # Enregistrer le run (pour statistiques) sans bloquer l'ex√©cution
            # Note: Le tracking des duplications durant la session est g√©r√© par session_param_tracker
            run_tracker.register(run_signature)

            with st.spinner("üîå Connexion au LLM..."):
                try:
                    if llm_use_multi_agent:
                        live_events_placeholder = st.empty()
                        live_viewer = LiveOrchestrationViewer(
                            container_key="live_orch_viewer_multi"
                        )

                        def on_orchestration_event(entry):
                            live_viewer.add_event(entry)
                            live_viewer.render(live_events_placeholder, show_header=True)

                        orchestration_logger.set_on_event_callback(on_orchestration_event)

                        orchestrator = create_orchestrator_with_backtest(
                            llm_config=llm_config,
                            strategy_name=strategy_key,
                            data=df,
                            initial_params=params,
                            data_symbol=symbol,
                            data_timeframe=timeframe,
                            role_model_config=state.role_model_config,
                            use_walk_forward=llm_use_walk_forward,
                            orchestration_logger=orchestration_logger,
                            session_id=session_id,
                            n_workers=n_workers,
                            max_iterations=max_iterations,
                            initial_capital=state.initial_capital,
                            config=engine.config,
                        )
                        show_status(
                            "success",
                            "Connexion LLM √©tablie (mode multi-agents)",
                        )
                    else:
                        strategist, executor = create_optimizer_from_engine(
                            llm_config=llm_config,
                            strategy_name=strategy_key,
                            data=df,
                            initial_capital=state.initial_capital,
                            use_walk_forward=llm_use_walk_forward,
                            verbose=True,
                            unload_llm_during_backtest=llm_unload_during_backtest,
                            orchestration_logger=orchestration_logger,
                        )
                        show_status("success", "Connexion LLM √©tablie")
                except Exception as exc:
                    show_status("error", f"Echec connexion LLM: {exc}")
                    st.code(traceback.format_exc())
                    st.session_state.is_running = False
                    st.stop()

            if llm_use_multi_agent:
                st.markdown("---")
                st.markdown("### Progression multi-agents")
                st.caption(
                    f"Limite: {max_combos:,} backtests max, "
                    f"{n_workers} workers, {max_iterations} iterations max"
                )

                if orchestrator is None:
                    show_status("error", "Orchestrator non initialise")
                    st.session_state.is_running = False
                    st.stop()

                try:
                    with st.spinner("Optimisation multi-agents en cours..."):
                        orchestrator_result = orchestrator.run()

                    try:
                        orchestration_logger.save_to_jsonl()
                    except Exception:
                        pass

                    if orchestrator_result.errors:
                        st.warning(
                            f"Orchestration errors: {len(orchestrator_result.errors)}"
                        )
                    if orchestrator_result.warnings:
                        st.warning(
                            f"Orchestration warnings: {len(orchestrator_result.warnings)}"
                        )

                    if orchestrator_result.success:
                        st.success("Optimisation multi-agents terminee")
                    else:
                        st.warning(
                            "Optimisation multi-agents terminee "
                            f"(decision: {orchestrator_result.decision})"
                        )

                    if orchestrator_result.final_params:
                        st.subheader("Resultat multi-agents")
                        st.json(orchestrator_result.final_params)
                    else:
                        st.warning("Aucun parametre final retourne")

                    if orchestrator_result.final_metrics:
                        metrics = orchestrator_result.final_metrics
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Sharpe", f"{metrics.sharpe_ratio:.3f}")
                        with col_b:
                            st.metric("Return", f"{metrics.total_return:.2%}")
                        with col_c:
                            st.metric("Max Drawdown", f"{metrics.max_drawdown:.2%}")

                    if orchestrator_result.iteration_history:
                        st.markdown("---")
                        st.dataframe(
                            pd.DataFrame(orchestrator_result.iteration_history),
                            use_container_width=True,
                        )

                    best_params = orchestrator_result.final_params or {}
                    if best_params:
                        result, _ = safe_run_backtest(
                            engine,
                            df,
                            strategy_key,
                            best_params,
                            symbol,
                            timeframe,
                            silent_mode=not debug_enabled,
                        )
                        if result is not None:
                            winner_params = best_params
                            winner_metrics = result.metrics
                            winner_origin = "llm"
                            winner_meta = result.meta
                            st.session_state["last_run_result"] = result
                            st.session_state["last_winner_params"] = winner_params
                            st.session_state["last_winner_metrics"] = winner_metrics
                            st.session_state["last_winner_origin"] = winner_origin
                            st.session_state["last_winner_meta"] = winner_meta
                            _maybe_auto_save_run(result)
                except Exception as exc:
                    show_status("error", f"Erreur optimisation multi-agents: {exc}")
                    st.code(traceback.format_exc())
                    st.session_state.is_running = False
                    st.stop()
            else:
                st.markdown("---")
                st.markdown("### üìä Progression de l'optimisation LLM")

                live_status = st.status(
                    "üöÄ D√©marrage de l'optimisation...",
                    expanded=True,
                )
                live_events_placeholder = st.empty()
                orchestration_placeholder = st.empty()

                max_iterations = min(llm_max_iterations, max_combos)

                live_viewer = LiveOrchestrationViewer(
                    container_key="live_orch_viewer"
                )

                def on_orchestration_event(entry):
                    live_viewer.add_event(entry)
                    live_viewer.render(live_events_placeholder, show_header=True)

                orchestration_logger.set_on_event_callback(on_orchestration_event)

                st.caption(
                    "üîß Limite: "
                    f"{max_combos:,} backtests max, {n_workers} workers, "
                    f"{max_iterations} it√©rations max"
                )

                try:
                    with live_status:
                        st.write("ü§ñ **Agent LLM actif** - Optimisation autonome")
                        st.write(
                            f"üìä Strat√©gie: `{strategy_key}` | Mod√®le: `{llm_model}`"
                        )

                        session = strategist.optimize(
                            executor=executor,
                            initial_params=params,
                            param_bounds=param_bounds,
                            max_iterations=max_iterations,
                            min_sharpe=-5.0,
                            max_drawdown=0.50,
                        )

                        live_status.update(
                            label=(
                                "‚úÖ Optimisation termin√©e en "
                                f"{session.current_iteration} it√©rations"
                            ),
                            state="complete",
                            expanded=False,
                        )

                    st.success(
                        f"‚úÖ Optimisation termin√©e en {session.current_iteration} it√©rations"
                    )

                    with st.expander("üìù Historique des it√©rations", expanded=True):
                        for i, exp in enumerate(session.all_results):
                            icon = "üü¢" if exp.sharpe_ratio > 0 else "üî¥"
                            col_it1, col_it2, col_it3 = st.columns([2, 1, 1])
                            with col_it1:
                                st.markdown(f"**It√©ration {i+1}** {icon}")
                                st.caption(
                                    f"Params: `{exp.request.parameters}`"
                                )
                            with col_it2:
                                st.metric("Sharpe", f"{exp.sharpe_ratio:.3f}")
                            with col_it3:
                                st.metric("Return", f"{exp.total_return:.2%}")

                    try:
                        orchestration_logger.save_to_jsonl()
                    except Exception:
                        pass

                    with orchestration_placeholder:
                        st.markdown("---")

                        tab_simple, tab_deep = st.tabs(
                            ["üìã Logs d'orchestration", "üîç Deep Trace (avanc√©)"]
                        )

                        with tab_simple:
                            render_full_orchestration_viewer(
                                orchestration_logger=orchestration_logger,
                                max_entries=50,
                            )

                        with tab_deep:
                            if LLM_AVAILABLE:
                                render_deep_trace_viewer(
                                    logger=orchestration_logger
                                )
                            else:
                                st.warning(
                                    "Module LLM non disponible pour Deep Trace avanc√©"
                                )

                    st.markdown("---")
                    st.subheader("üèÜ R√©sultat de l'optimisation LLM")

                    col_best, col_improve = st.columns(2)

                    with col_best:
                        st.markdown("**Meilleurs param√®tres trouv√©s:**")
                        st.json(session.best_result.request.parameters)

                        st.metric(
                            "Meilleur Sharpe",
                            f"{session.best_result.sharpe_ratio:.3f}",
                        )
                        st.metric(
                            "Return",
                            f"{session.best_result.total_return:.2%}",
                        )

                    with col_improve:
                        if session.all_results:
                            initial_sharpe = session.all_results[0].sharpe_ratio
                            best_sharpe = session.best_result.sharpe_ratio
                            improvement = (
                                (best_sharpe - initial_sharpe) / abs(initial_sharpe) * 100
                            ) if initial_sharpe != 0 else 0

                            st.metric(
                                "Am√©lioration Sharpe",
                                f"{improvement:+.1f}%",
                                delta=f"{best_sharpe - initial_sharpe:+.3f}",
                            )
                            st.metric("It√©rations utilis√©es", session.current_iteration)

                            if session.final_reasoning:
                                st.info(f"üõë Arr√™t: {session.final_reasoning}")

                    best_params = session.best_result.request.parameters
                    result, _ = safe_run_backtest(
                        engine,
                        df,
                        strategy_key,
                        best_params,
                        symbol,
                        timeframe,
                        silent_mode=not debug_enabled,
                    )
                    if result is not None:
                        winner_params = best_params
                        winner_metrics = result.metrics
                        winner_origin = "llm"
                        winner_meta = result.meta
                        st.session_state["last_run_result"] = result
                        st.session_state["last_winner_params"] = winner_params
                        st.session_state["last_winner_metrics"] = winner_metrics
                        st.session_state["last_winner_origin"] = winner_origin
                        st.session_state["last_winner_meta"] = winner_meta
                        _maybe_auto_save_run(result)

                except Exception as exc:
                    live_status.update(label=f"‚ùå Erreur: {exc}", state="error")
                    show_status("error", f"Erreur optimisation LLM: {exc}")
                    st.code(traceback.format_exc())
                    st.session_state.is_running = False
                    st.stop()

        else:
            show_status("error", f"Mode non reconnu: {optimization_mode}")
            st.session_state.is_running = False
            st.stop()

    st.session_state.is_running = False
```
<!-- MODULE-END: main.py -->

<!-- MODULE-START: model_presets.py -->
```json
{
  "name": "model_presets.py",
  "path": "ui\\model_presets.py",
  "ext": ".py",
  "anchor": "model_presets_py"
}
```
## model_presets_py
*Chemin* : `ui\model_presets.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.model_presets

Purpose: Gestion des presets de configuration de mod√®les LLM pour les agents.

Role in pipeline: configuration UI

Key components: BUILTIN_PRESETS, save/load/delete presets, apply preset

Inputs: Nom de preset, RoleModelConfig

Outputs: Presets JSON, config modifi√©e

Dependencies: pathlib, json, datetime, agents.model_config

Conventions: Presets builtin non modifiables, fichiers JSON dans data/model_presets/

Read-if: Modification des presets builtin ou logique de sauvegarde

Skip-if: Vous utilisez juste list_model_presets() ou load_model_preset()
"""

from __future__ import annotations

import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

from utils.log import get_logger

logger = get_logger(__name__)

# R√©pertoire de sauvegarde des presets utilisateur
MODEL_PRESETS_DIR = Path("data") / "model_presets"

# ===== PRESETS PR√âD√âFINIS (NON MODIFIABLES) =====

BUILTIN_PRESETS: Dict[str, Dict[str, Any]] = {
    "Optimal": {
        "name": "Optimal",
        "description": "Configuration optimale bas√©e sur benchmarks Dec 2025",
        "models": {
            "analyst": ["qwen2.5:14b"],
            "strategist": ["gemma3:27b"],
            "critic": ["llama3.3-70b-optimized"],
            "validator": ["llama3.3-70b-optimized"]
        },
        "builtin": True
    },
    "Rapide": {
        "name": "Rapide",
        "description": "Mod√®les l√©gers pour exploration rapide",
        "models": {
            "analyst": ["gemma3:12b"],
            "strategist": ["mistral:22b"],
            "critic": ["deepseek-r1:32b"],
            "validator": ["deepseek-r1:32b"]
        },
        "builtin": True
    },
    "√âquilibr√©": {
        "name": "√âquilibr√©",
        "description": "Mix light/medium/heavy pour compromis performance/vitesse",
        "models": {
            "analyst": ["qwen2.5:14b"],
            "strategist": ["gemma3:27b"],
            "critic": ["deepseek-r1:32b"],
            "validator": ["qwq:32b"]
        },
        "builtin": True
    },
    "Puissant": {
        "name": "Puissant",
        "description": "Heavy models pour analyses complexes et ajustements fins",
        "models": {
            "analyst": ["qwen2.5:32b"],
            "strategist": ["deepseek-r1:32b"],
            "critic": ["llama3.3-70b-optimized"],
            "validator": ["llama3.3-70b-optimized"]
        },
        "builtin": True
    }
}

# ===== FONCTIONS PRINCIPALES =====


def get_presets_dir() -> Path:
    """Retourne le r√©pertoire de sauvegarde des presets."""
    MODEL_PRESETS_DIR.mkdir(parents=True, exist_ok=True)
    return MODEL_PRESETS_DIR


def list_model_presets() -> List[Dict[str, Any]]:
    """
    Liste tous les presets disponibles (builtin + utilisateur).

    Returns:
        Liste de dicts avec cl√©s: name, description, models, builtin
    """
    # Presets builtin
    presets = list(BUILTIN_PRESETS.values())

    # Presets utilisateur sur disque
    presets_dir = get_presets_dir()
    for filepath in presets_dir.glob("*.json"):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                preset = json.load(f)
                preset["builtin"] = False
                presets.append(preset)
        except Exception as e:
            logger.warning(f"Erreur chargement preset {filepath}: {e}")

    return presets


def load_model_preset(name: str) -> Dict[str, Any]:
    """
    Charge un preset par son nom.

    Args:
        name: Nom du preset

    Returns:
        Dict avec cl√©s: name, description, models, builtin

    Raises:
        ValueError: Si le preset n'existe pas
    """
    # V√©rifier dans les builtin
    if name in BUILTIN_PRESETS:
        return BUILTIN_PRESETS[name].copy()

    # V√©rifier sur disque
    presets_dir = get_presets_dir()
    filepath = presets_dir / f"{name}.json"

    if not filepath.exists():
        raise ValueError(f"Preset '{name}' introuvable")

    with open(filepath, "r", encoding="utf-8") as f:
        preset = json.load(f)
        preset["builtin"] = False
        return preset


def save_model_preset(name: str, models: Dict[str, List[str]]) -> None:
    """
    Sauvegarde un preset utilisateur.

    Args:
        name: Nom du preset
        models: Dict {role: [model_names]}

    Raises:
        ValueError: Si le nom est invalide ou si c'est un builtin
    """
    name = name.strip()
    if not name:
        raise ValueError("Nom de preset requis")

    if name in BUILTIN_PRESETS:
        raise ValueError(f"Impossible de modifier le preset builtin '{name}'")

    preset = {
        "name": name,
        "description": "",
        "models": models,
        "created_at": datetime.utcnow().isoformat() + "Z"
    }

    presets_dir = get_presets_dir()
    filepath = presets_dir / f"{name}.json"

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(preset, f, indent=2, ensure_ascii=False)

    logger.info(f"Preset '{name}' sauvegard√©: {filepath}")


def delete_model_preset(name: str) -> bool:
    """
    Supprime un preset utilisateur.

    Args:
        name: Nom du preset

    Returns:
        True si supprim√©, False sinon

    Raises:
        ValueError: Si c'est un preset builtin
    """
    if name in BUILTIN_PRESETS:
        raise ValueError(f"Impossible de supprimer le preset builtin '{name}'")

    presets_dir = get_presets_dir()
    filepath = presets_dir / f"{name}.json"

    if filepath.exists():
        filepath.unlink()
        logger.info(f"Preset '{name}' supprim√©")
        return True

    return False


def get_current_config_as_dict(role_model_config) -> Dict[str, Any]:
    """
    Convertit la config actuelle en dict pour sauvegarde.

    Args:
        role_model_config: Instance de RoleModelConfig

    Returns:
        Dict avec cl√© 'models' contenant la config de chaque r√¥le
    """
    return {
        "models": {
            "analyst": role_model_config.analyst.models,
            "strategist": role_model_config.strategist.models,
            "critic": role_model_config.critic.models,
            "validator": role_model_config.validator.models,
        }
    }


def apply_preset_to_config(preset: Dict[str, Any], role_model_config) -> None:
    """
    Applique un preset √† la config globale.

    Args:
        preset: Dict du preset
        role_model_config: Instance de RoleModelConfig √† modifier
    """
    models = preset.get("models", {})

    role_model_config.analyst.models = models.get("analyst", [])
    role_model_config.strategist.models = models.get("strategist", [])
    role_model_config.critic.models = models.get("critic", [])
    role_model_config.validator.models = models.get("validator", [])

    logger.info(f"Preset '{preset.get('name')}' appliqu√© √† la config")


__all__ = [
    "BUILTIN_PRESETS",
    "get_presets_dir",
    "list_model_presets",
    "load_model_preset",
    "save_model_preset",
    "delete_model_preset",
    "get_current_config_as_dict",
    "apply_preset_to_config",
]
```
<!-- MODULE-END: model_presets.py -->

<!-- MODULE-START: orchestration_viewer.py -->
```json
{
  "name": "orchestration_viewer.py",
  "path": "ui\\orchestration_viewer.py",
  "ext": ".py",
  "anchor": "orchestration_viewer_py"
}
```
## orchestration_viewer_py
*Chemin* : `ui\orchestration_viewer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.orchestration_viewer

Purpose: Affiche les logs d'orchestration des agents LLM de mani√®re interactive dans l'UI Streamlit.

Role in pipeline: reporting / orchestration

Key components: render_orchestration_logs

Inputs: OrchestrationLogger instance

Outputs: Interface Streamlit avec logs et m√©triques

Dependencies: agents.orchestration_logger, streamlit

Conventions: Logs structur√©s avec timestamps et actions

Read-if: Besoin d'afficher les logs d'orchestration LLM

Skip-if: Pas d'utilisation d'agents LLM ou pas besoin de visualisation des logs
"""

from datetime import datetime
from html import escape
from typing import List, Optional

import pandas as pd
import streamlit as st

from agents.orchestration_logger import (
    OrchestrationActionType,
    OrchestrationLogEntry,
    OrchestrationLogger,
    OrchestrationStatus,
)


def render_orchestration_logs(
    orchestration_logger: OrchestrationLogger,
    show_filters: bool = True,
    max_entries: int = 50
):
    """
    Affiche les logs d'orchestration avec filtres et visualisation.

    Args:
        orchestration_logger: Instance du logger d'orchestration
        show_filters: Si True, affiche les filtres interactifs
        max_entries: Nombre maximum d'entr√©es √† afficher
    """
    st.markdown("### ü§ñ Journal d'Orchestration LLM")

    if len(orchestration_logger.logs) == 0:
        st.info("Aucun log d'orchestration disponible")
        return

    # M√©triques rapides
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Session ID", orchestration_logger.session_id[-8:])

    with col2:
        st.metric("It√©rations", orchestration_logger.current_iteration)

    with col3:
        st.metric("Total Logs", len(orchestration_logger.logs))

    with col4:
        # Compter les actions compl√©t√©es
        completed = sum(
            1 for log in orchestration_logger.logs
            if log.status == OrchestrationStatus.COMPLETED
        )
        st.metric("Compl√©t√©s", completed)

    # Filtres
    if show_filters:
        st.markdown("---")
        col_f1, col_f2, col_f3 = st.columns(3)

        with col_f1:
            # Filtre par agent
            agents = list(set(log.agent for log in orchestration_logger.logs if log.agent))
            agents_filter = st.multiselect(
                "Filtrer par Agent",
                ["Tous"] + agents,
                default=["Tous"]
            )

        with col_f2:
            # Filtre par type d'action
            action_types = list(set(log.action_type for log in orchestration_logger.logs))
            action_filter = st.multiselect(
                "Filtrer par Action",
                ["Tous"] + [at.value for at in action_types],
                default=["Tous"]
            )

        with col_f3:
            # Filtre par it√©ration
            iterations = list(set(log.iteration for log in orchestration_logger.logs))
            iteration_filter = st.multiselect(
                "Filtrer par It√©ration",
                ["Toutes"] + [f"It√©ration {i}" for i in sorted(iterations)],
                default=["Toutes"]
            )

        # Appliquer les filtres
        filtered_logs = orchestration_logger.logs

        if "Tous" not in agents_filter:
            filtered_logs = [log for log in filtered_logs if log.agent in agents_filter]

        if "Tous" not in action_filter:
            action_values = [at.value for at in action_types if at.value in action_filter]
            filtered_logs = [log for log in filtered_logs if log.action_type.value in action_values]

        if "Toutes" not in iteration_filter:
            selected_iterations = [
                int(it.split(" ")[1]) for it in iteration_filter if it != "Toutes"
            ]
            filtered_logs = [log for log in filtered_logs if log.iteration in selected_iterations]

    else:
        filtered_logs = orchestration_logger.logs

    st.markdown("---")

    # Affichage des logs
    _render_logs_timeline(filtered_logs, max_entries)


def _render_logs_timeline(logs: List[OrchestrationLogEntry], max_entries: int):
    """Affiche les logs sous forme de timeline."""
    st.markdown("#### üìã Timeline des Actions")

    # Limiter le nombre de logs
    display_logs = logs[-max_entries:] if len(logs) > max_entries else logs

    if len(logs) > max_entries:
        st.caption(f"Affichage des {max_entries} derniers logs sur {len(logs)} total")

    # Grouper par it√©ration
    logs_by_iteration = {}
    for log in display_logs:
        iteration = log.iteration
        if iteration not in logs_by_iteration:
            logs_by_iteration[iteration] = []
        logs_by_iteration[iteration].append(log)

    # Afficher par it√©ration
    for iteration in sorted(logs_by_iteration.keys(), reverse=True):
        iteration_logs = logs_by_iteration[iteration]

        with st.expander(f"üîÑ **It√©ration {iteration}** ({len(iteration_logs)} actions)", expanded=(iteration == max(logs_by_iteration.keys()))):
            for log in iteration_logs:
                _render_log_entry(log)


def _render_log_entry(log: OrchestrationLogEntry):
    """Affiche une entr√©e de log individuelle."""
    # Emoji et couleur selon le statut
    emoji = log._get_emoji()
    status_color = _get_status_color(log.status)
    text_color = _get_contrast_text_color(status_color)

    # Timestamp
    try:
        timestamp = datetime.fromisoformat(log.timestamp).strftime("%H:%M:%S")
    except Exception:
        timestamp = log.timestamp[:8]  # Fallback

    # Agent badge
    model_name = ""
    if isinstance(log.details, dict):
        model_name = log.details.get("model") or ""
    agent_label = log.agent or ""
    if model_name:
        agent_label = f"{agent_label} ¬∑ {model_name}" if agent_label else model_name
    agent_badge = (
        f"<strong style='color: {text_color};'>[{escape(agent_label)}]</strong>"
        if agent_label
        else ""
    )

    # Action type
    action_type = escape(log.action_type.value.replace("_", " ").title())

    # Construire la ligne principale
    timestamp_bg, timestamp_border = _get_timestamp_chip_colors(text_color)
    timestamp_html = (
        "<code style='color: {text_color}; background-color: {timestamp_bg}; "
        "border: 1px solid {timestamp_border}; padding: 1px 4px; "
        "border-radius: 3px;'>"
        "{timestamp}</code>"
    ).format(
        text_color=text_color,
        timestamp_bg=timestamp_bg,
        timestamp_border=timestamp_border,
        timestamp=escape(timestamp),
    )
    parts = [emoji, timestamp_html, agent_badge, action_type]
    main_line = " ".join(part for part in parts if part)

    # Afficher
    st.markdown(
        "<div style='background-color: {status_color}; color: {text_color}; "
        "padding: 8px; border-radius: 5px; margin: 5px 0;'>"
        "{main_line}</div>".format(
            status_color=status_color,
            text_color=text_color,
            main_line=main_line,
        ),
        unsafe_allow_html=True,
    )

    # D√©tails si disponibles
    if log.details:
        with st.container():
            _render_log_details(log)


def _render_log_details(log: OrchestrationLogEntry):
    """Affiche les d√©tails d'un log."""
    details = log.details

    # Strat√©gie
    if "strategy" in details:
        st.caption(f"   Strat√©gie: `{details['strategy']}`")

    if "old_strategy" in details and "new_strategy" in details:
        st.caption(f"   `{details['old_strategy']}` ‚Üí `{details['new_strategy']}`")

    # Indicateur
    if "indicator" in details:
        st.caption(f"   Indicateur: `{details['indicator']}`")

    if "old_values" in details and "new_values" in details:
        st.caption(f"   Anciens: {details['old_values']}")
        st.caption(f"   Nouveaux: {details['new_values']}")

    # Param√®tres
    if "params" in details:
        params = details['params']
        if isinstance(params, dict):
            param_str = ", ".join([f"{k}={v}" for k, v in list(params.items())[:3]])
            st.caption(f"   Param√®tres: {param_str}...")

    # R√©sultats
    if "results" in details:
        results = details['results']
        if isinstance(results, dict):
            if "sharpe" in results:
                st.caption(f"   üìä Sharpe: {results['sharpe']:.3f}")
            if "pnl" in results:
                st.caption(f"   üí∞ PnL: {results['pnl']:.2f}")

    # Raison
    if "reason" in details:
        st.caption(f"   Raison: _{details['reason']}_")

    # Message / Erreur
    if "message" in details:
        st.caption(f"   üìù {details['message']}")

    if "error" in details:
        st.error(f"   ‚ùå Erreur: {details['error']}")


def _get_status_color(status: OrchestrationStatus) -> str:
    """Retourne la couleur de fond selon le statut."""
    colors = {
        OrchestrationStatus.COMPLETED: "#d4edda",  # Vert clair
        OrchestrationStatus.FAILED: "#f8d7da",     # Rouge clair
        OrchestrationStatus.VALIDATED: "#d1ecf1",   # Bleu clair
        OrchestrationStatus.REJECTED: "#f8d7da",    # Rouge clair
        OrchestrationStatus.IN_PROGRESS: "#fff3cd",  # Jaune clair
        OrchestrationStatus.PENDING: "#e7e7e7",     # Gris clair
    }
    return colors.get(status, "#ffffff")


def _get_contrast_text_color(background_hex: str) -> str:
    """Retourne une couleur de texte lisible selon la luminance du fond."""
    hex_color = background_hex.lstrip("#")
    if len(hex_color) != 6:
        return "#1f2933"
    try:
        r = int(hex_color[0:2], 16)
        g = int(hex_color[2:4], 16)
        b = int(hex_color[4:6], 16)
    except ValueError:
        return "#1f2933"
    luminance = (0.299 * r) + (0.587 * g) + (0.114 * b)
    return "#111827" if luminance > 140 else "#f9fafb"


def _get_timestamp_chip_colors(text_color: str) -> tuple[str, str]:
    """Retourne fond/bordure pour le timestamp selon la couleur du texte."""
    if text_color.lower() == "#f9fafb":
        return ("rgba(255,255,255,0.18)", "rgba(255,255,255,0.35)")
    return ("rgba(15,23,42,0.12)", "rgba(15,23,42,0.25)")


def render_orchestration_summary_table(orchestration_logger: OrchestrationLogger):
    """Affiche un tableau r√©capitulatif des actions par agent."""
    st.markdown("#### üìä R√©capitulatif par Agent")

    # Compter les actions par agent
    agent_actions = {}
    for log in orchestration_logger.logs:
        if log.agent:
            if log.agent not in agent_actions:
                agent_actions[log.agent] = {
                    "total": 0,
                    "completed": 0,
                    "failed": 0,
                    "pending": 0
                }

            agent_actions[log.agent]["total"] += 1

            if log.status == OrchestrationStatus.COMPLETED:
                agent_actions[log.agent]["completed"] += 1
            elif log.status == OrchestrationStatus.FAILED:
                agent_actions[log.agent]["failed"] += 1
            elif log.status == OrchestrationStatus.PENDING:
                agent_actions[log.agent]["pending"] += 1

    # Cr√©er le DataFrame
    if agent_actions:
        df = pd.DataFrame.from_dict(agent_actions, orient="index")
        df = df.reset_index()
        df.columns = ["Agent", "Total", "Compl√©t√©s", "√âchou√©s", "En Attente"]

        st.dataframe(df, width="stretch", hide_index=True)
    else:
        st.info("Aucune action d'agent enregistr√©e")


def render_orchestration_metrics(orchestration_logger: OrchestrationLogger):
    """Affiche les m√©triques cl√©s de l'orchestration."""
    st.markdown("#### üìà M√©triques d'Orchestration")

    # Compter les backtests
    backtests_launched = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.BACKTEST_LAUNCH)
    )
    backtests_completed = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.BACKTEST_COMPLETE)
    )
    backtests_failed = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.BACKTEST_FAILED)
    )

    # Compter les changements de strat√©gie
    strategy_changes = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.STRATEGY_MODIFICATION)
    )

    # Compter les changements d'indicateurs
    indicator_changes = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.INDICATOR_VALUES_CHANGE)
    )
    indicator_adds = len(
        orchestration_logger.get_logs_by_type(OrchestrationActionType.INDICATOR_ADD)
    )

    # Afficher
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("Backtests Lanc√©s", backtests_launched)

    with col2:
        st.metric("Backtests R√©ussis", backtests_completed)

    with col3:
        st.metric("Backtests √âchou√©s", backtests_failed)

    with col4:
        st.metric("Changements Strat√©gie", strategy_changes)

    with col5:
        st.metric("Modifications Indicateurs", indicator_changes + indicator_adds)


def render_full_orchestration_viewer(
    orchestration_logger: OrchestrationLogger,
    max_entries: int = 50,
    show_filters: bool = True,
):
    """Affiche le visualiseur complet d'orchestration."""
    # Onglets
    tab1, tab2, tab3 = st.tabs(["üìã Timeline", "üìä R√©sum√©", "üìà M√©triques"])

    with tab1:
        render_orchestration_logs(
            orchestration_logger,
            show_filters=show_filters,
            max_entries=max_entries,
        )

    with tab2:
        render_orchestration_summary_table(orchestration_logger)

    with tab3:
        render_orchestration_metrics(orchestration_logger)


# =============================================================================
# LIVE ORCHESTRATION VIEWER - Affichage temps r√©el
# =============================================================================

class LiveOrchestrationViewer:
    """
    Composant pour afficher les logs d'orchestration en temps r√©el.

    Utilise un callback pour se mettre √† jour √† chaque nouvel √©v√©nement.
    """

    def __init__(self, container_key: str = "live_orch"):
        """
        Initialise le viewer live.

        Args:
            container_key: Cl√© unique pour le conteneur Streamlit
        """
        self.container_key = container_key
        self._events: List[OrchestrationLogEntry] = []
        self._max_display = 20  # Derniers √©v√©nements affich√©s

    def add_event(self, entry: OrchestrationLogEntry) -> None:
        """Ajoute un √©v√©nement √† la liste."""
        self._events.append(entry)

    def get_callback(self):
        """Retourne le callback pour OrchestrationLogger."""
        return self.add_event

    def render(self, placeholder, show_header: bool = True) -> None:
        """
        Affiche les √©v√©nements dans le placeholder donn√©.

        Args:
            placeholder: st.empty() ou conteneur Streamlit
            show_header: Si True, affiche un header avec stats
        """
        with placeholder.container():
            if show_header:
                self._render_header()
            self._render_events()

    def _render_header(self) -> None:
        """Affiche le header avec statistiques."""
        col1, col2, col3, col4 = st.columns(4)

        # Compter par type
        agents = set(e.agent for e in self._events if e.agent)
        iterations = set(e.iteration for e in self._events)
        completed = sum(1 for e in self._events if e.status == OrchestrationStatus.COMPLETED)

        with col1:
            st.metric("üéØ √âv√©nements", len(self._events))
        with col2:
            st.metric("ü§ñ Agents actifs", len(agents))
        with col3:
            st.metric("üîÑ It√©rations", max(iterations) if iterations else 0)
        with col4:
            st.metric("‚úÖ Compl√©t√©s", completed)

    def _render_events(self) -> None:
        """Affiche les derniers √©v√©nements."""
        if not self._events:
            st.info("‚è≥ En attente des √©v√©nements...")
            return

        # Afficher les derniers √©v√©nements (plus r√©cents en haut)
        recent = self._events[-self._max_display:][::-1]

        for event in recent:
            self._render_single_event(event)

    def _render_single_event(self, event: OrchestrationLogEntry) -> None:
        """Affiche un √©v√©nement unique avec style."""
        emoji = event._get_emoji()
        status_color = _get_status_color(event.status)
        text_color = _get_contrast_text_color(status_color)
        timestamp_bg, timestamp_border = _get_timestamp_chip_colors(text_color)

        # Timestamp
        try:
            timestamp = datetime.fromisoformat(event.timestamp).strftime("%H:%M:%S.%f")[:-3]
        except Exception:
            timestamp = event.timestamp[:12]

        # Agent et mod√®le
        agent = event.agent or ""
        model = ""
        if isinstance(event.details, dict):
            model = event.details.get("model", "")
        agent_info = f"{agent}" + (f" ({model})" if model else "")

        # Action
        action = event.action_type.value.replace("_", " ").title()

        # D√©tails r√©sum√©s
        detail_summary = ""
        if isinstance(event.details, dict):
            if "params" in event.details:
                params = event.details["params"]
                if isinstance(params, dict):
                    detail_summary = " | ".join(f"{k}={v}" for k, v in list(params.items())[:3])
            elif "results" in event.details:
                results = event.details["results"]
                if isinstance(results, dict):
                    if "sharpe" in results:
                        detail_summary = f"Sharpe: {results['sharpe']:.3f}"
                    elif "sharpe_ratio" in results:
                        detail_summary = f"Sharpe: {results['sharpe_ratio']:.3f}"
            elif "reason" in event.details:
                detail_summary = str(event.details["reason"])[:60]

        # HTML
        html = f"""
        <div style="background: {status_color}; color: {text_color};
                    padding: 8px 12px; border-radius: 6px; margin: 4px 0;
                    border-left: 4px solid rgba(0,0,0,0.2);">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <span>
                    {emoji} <code style="color: {text_color}; background: {timestamp_bg}; border: 1px solid {timestamp_border}; padding: 2px 5px; border-radius: 4px;">{escape(timestamp)}</code>
                    <strong>[{escape(agent_info)}]</strong> {escape(action)}
                </span>
                <span style="font-size: 0.85em; opacity: 0.8;">Iter {event.iteration}</span>
            </div>
            {f'<div style="font-size: 0.85em; margin-top: 4px; opacity: 0.9;">{escape(detail_summary)}</div>' if detail_summary else ''}
        </div>
        """
        st.markdown(html, unsafe_allow_html=True)

    def clear(self) -> None:
        """Efface tous les √©v√©nements."""
        self._events.clear()


def render_live_orchestration_panel(
    orchestration_logger: OrchestrationLogger,
    placeholder,
    iteration_info: Optional[dict] = None
) -> None:
    """
    Affiche un panneau de suivi live de l'orchestration.

    Args:
        orchestration_logger: Logger d'orchestration avec les √©v√©nements
        placeholder: st.empty() pour les mises √† jour
        iteration_info: Optionnel, dict avec current/total pour la progress bar
    """
    with placeholder.container():
        # Progress bar si info disponible
        if iteration_info:
            current = iteration_info.get("current", 0)
            total = iteration_info.get("total", 1)
            progress = min(current / max(total, 1), 1.0)
            st.progress(progress, text=f"It√©ration {current}/{total}")

        # Stats rapides
        col1, col2, col3 = st.columns(3)

        logs = orchestration_logger.logs
        with col1:
            st.metric("üìä √âv√©nements", len(logs))
        with col2:
            st.metric("üîÑ It√©ration", orchestration_logger.current_iteration)
        with col3:
            # Dernier agent actif
            last_agent = logs[-1].agent if logs else "‚Äî"
            st.metric("ü§ñ Dernier agent", last_agent or "‚Äî")

        # Afficher les 10 derniers √©v√©nements
        st.markdown("**üìã Derniers √©v√©nements:**")
        recent = logs[-10:][::-1] if logs else []

        for event in recent:
            emoji = event._get_emoji()
            agent = event.agent or "System"
            action = event.action_type.value.replace("_", " ").title()

            # Couleur selon statut
            if event.status == OrchestrationStatus.COMPLETED:
                color = "#28a745"
            elif event.status == OrchestrationStatus.FAILED:
                color = "#dc3545"
            elif event.status == OrchestrationStatus.IN_PROGRESS:
                color = "#ffc107"
            else:
                color = "#6c757d"

            st.markdown(
                f"<span style='color:{color}'>{emoji}</span> "
                f"**[{escape(agent)}]** {escape(action)}",
                unsafe_allow_html=True
            )


__all__ = [
    "render_orchestration_logs",
    "render_orchestration_summary_table",
    "render_orchestration_metrics",
    "render_full_orchestration_viewer",
    "LiveOrchestrationViewer",
    "render_live_orchestration_panel",
]
```
<!-- MODULE-END: orchestration_viewer.py -->

<!-- MODULE-START: results.py -->
```json
{
  "name": "results.py",
  "path": "ui\\results.py",
  "ext": ".py",
  "anchor": "results_py"
}
```
## results_py
*Chemin* : `ui\results.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.results

Purpose: Affiche les r√©sultats d√©taill√©s des backtests avec m√©triques et graphiques.

Role in pipeline: reporting

Key components: render_results, m√©triques, graphiques

Inputs: SidebarState, r√©sultats de backtest

Outputs: Interface Streamlit avec m√©triques et visualisations

Dependencies: ui.state, ui.components.charts

Conventions: M√©triques financi√®res standardis√©es

Read-if: Affichage des r√©sultats de backtest

Skip-if: Pas de r√©sultats √† afficher
"""

from __future__ import annotations

from typing import Optional

import pandas as pd
import streamlit as st

from ui.components.charts import (
    render_equity_and_drawdown,
    render_ohlcv_with_trades,
    render_ohlcv_with_trades_and_indicators,
    render_returns_distribution,
    render_trade_pnl_distribution,
)
from ui.context import resolve_latest_version, save_versioned_preset
from ui.helpers import build_indicator_overlays, generate_strategies_table
from ui.log_taps import BestPnlTracker
from ui.state import SidebarState


def render_results(state: SidebarState, best_pnl_tracker: Optional[BestPnlTracker]) -> None:
    result = st.session_state.get("last_run_result")
    winner_params = st.session_state.get("last_winner_params")
    winner_metrics = st.session_state.get("last_winner_metrics")
    winner_origin = st.session_state.get("last_winner_origin")
    winner_meta = st.session_state.get("last_winner_meta")

    if result is not None:
        st.header("üìä R√©sultats du Backtest")

        col1, col2, col3, col4, col5 = st.columns(5)

        if result is not None:
            with col1:
                pnl = result.metrics["total_pnl"]
                pnl_color: str = "normal" if pnl >= 0 else "inverse"
                ret_pct = result.metrics["total_return_pct"]
                st.metric(
                    "P&L Total",
                    f"${pnl:,.2f}",
                    delta=f"{ret_pct:.1f}%",
                    delta_color=pnl_color,  # type: ignore[arg-type]
                )

            with col2:
                sharpe = result.metrics["sharpe_ratio"]
                st.metric("Sharpe Ratio", f"{sharpe:.2f}")

            with col3:
                # Compatibilit√©: engine restaur√© retourne "max_drawdown", UI r√©cent cherche "max_drawdown_pct"
                max_dd = result.metrics.get("max_drawdown_pct", result.metrics.get("max_drawdown", 0))
                st.metric("Max Drawdown", f"{max_dd:.1f}%")

            with col4:
                trades = result.metrics["total_trades"]
                # Compatibilit√©: engine restaur√© retourne "win_rate", UI r√©cent cherche "win_rate_pct"
                win_rate = result.metrics.get("win_rate_pct", result.metrics.get("win_rate", 0))
                st.metric("Trades", f"{trades}", delta=f"{win_rate:.0f}% wins")

            with col5:
                if best_pnl_tracker is None:
                    st.metric("Backtest PnL (best run)", "n/a")
                else:
                    best_pnl, best_run_id = best_pnl_tracker.get_best()
                    if best_pnl is None:
                        st.metric("Backtest PnL (best run)", "n/a")
                    else:
                        st.metric(
                            "Backtest PnL (best run)",
                            f"${best_pnl:,.2f}",
                        )
                        if best_run_id:
                            st.caption(f"run {best_run_id}")

        liquidation_pnl = result.metrics.get("liquidation_total_pnl")
        if liquidation_pnl is not None:
            if result.metrics.get("liquidation_triggered"):
                liquidation_time = result.metrics.get("liquidation_time")
                time_note = f" √† {liquidation_time}" if liquidation_time else ""
                st.warning(
                    f"üí• Liquidation d√©tect√©e{time_note}. "
                    "Le mode liquidation coupe les trades d√®s que le capital atteint 0."
                )

            with st.expander("üßØ Liquidation vs cr√©dit infini", expanded=False):
                credit_col, liq_col = st.columns(2)
                with credit_col:
                    st.markdown("**Cr√©dit infini**")
                    st.metric("P&L", f"${result.metrics.get('total_pnl', 0):,.2f}")
                    st.metric("Sharpe", f"{result.metrics.get('sharpe_ratio', 0):.2f}")
                    st.metric("Max DD", f"{result.metrics.get('max_drawdown_pct', 0):.1f}%")
                    st.metric("Trades", f"{result.metrics.get('total_trades', 0)}")
                with liq_col:
                    st.markdown("**Liquidation**")
                    st.metric("P&L", f"${result.metrics.get('liquidation_total_pnl', 0):,.2f}")
                    st.metric(
                        "Sharpe",
                        f"{result.metrics.get('liquidation_sharpe_ratio', 0):.2f}",
                    )
                    st.metric(
                        "Max DD",
                        f"{result.metrics.get('liquidation_max_drawdown_pct', 0):.1f}%",
                    )
                    st.metric(
                        "Trades",
                        f"{result.metrics.get('liquidation_total_trades', result.metrics.get('total_trades', 0))}",
                    )

        if result is not None and winner_params is not None:
            st.subheader("Versioned preset")
            col_save_a, col_save_b = st.columns(2)

            with col_save_a:
                default_version = resolve_latest_version(state.strategy_key)
                preset_version = st.text_input(
                    "Preset version",
                    value=default_version,
                    key="winner_preset_version",
                )
                preset_name = st.text_input(
                    "Preset name",
                    value="winner",
                    key="winner_preset_name",
                )

            with col_save_b:
                description_default = (
                    f"{state.strategy_key} winner {state.symbol}/{state.timeframe}"
                )
                preset_description = st.text_input(
                    "Description",
                    value=description_default,
                    key="winner_preset_description",
                )

            if st.button("Save winner preset", key="save_winner_preset"):
                extra_meta = {}
                if winner_meta:
                    for key in [
                        "symbol",
                        "timeframe",
                        "period_start",
                        "period_end",
                    ]:
                        if key in winner_meta:
                            extra_meta[key] = winner_meta[key]

                origin_run_id = None
                if winner_meta and "run_id" in winner_meta:
                    origin_run_id = winner_meta["run_id"]

                try:
                    saved = save_versioned_preset(
                        strategy_name=state.strategy_key,
                        version=preset_version,
                        preset_name=preset_name,
                        params_values=winner_params,
                        indicators=state.strategy_info.required_indicators
                        if state.strategy_info is not None
                        else None,
                        description=preset_description,
                        metrics=winner_metrics,
                        origin=winner_origin,
                        origin_run_id=origin_run_id,
                        extra_metadata=extra_meta,
                    )
                    st.session_state["_sync_preset_version"] = preset_version
                    st.session_state["_sync_preset_name"] = saved.name
                    st.session_state["versioned_preset_last_saved"] = saved.name
                    st.rerun()
                except Exception as exc:
                    st.error(f"Save failed: {exc}")

        st.subheader("üí∞ Courbe d'√âquit√©")

        if result is not None and hasattr(result, "equity") and result.equity is not None:
            initial_capital = state.params.get("initial_capital", 10000.0)
            render_equity_and_drawdown(
                equity=result.equity,
                initial_capital=initial_capital,
                key="equity_drawdown_main",
                height=550,
            )
        elif result is not None:
            st.info("Courbe d'√©quit√© non disponible pour cette strat√©gie")

        st.subheader("üìà Prix et Trades")

        if result is not None:
            chart_df = st.session_state.get("ohlcv_df")
            if chart_df is None:
                st.info("Donnees non chargees. Cliquez sur 'Charger donnees'.")
            else:
                chart_params = result.meta.get("params", state.params)
                indicator_overlays = build_indicator_overlays(
                    state.strategy_key, chart_df, chart_params
                )

                if indicator_overlays:
                    render_ohlcv_with_trades_and_indicators(
                        df=chart_df,
                        trades_df=result.trades,
                        overlays=indicator_overlays,
                        active_indicators=state.active_indicators,
                        title="üìä OHLCV + Indicateurs + Entrees/Sorties",
                        key="ohlcv_trades_indicators_main",
                        height=700,
                    )
                elif not result.trades.empty:
                    render_ohlcv_with_trades(
                        df=chart_df,
                        trades_df=result.trades,
                        title="üìä Graphique OHLCV avec Points d'Entree/Sortie",
                        key="ohlcv_trades_main",
                        height=600,
                    )
                else:
                    st.info(
                        "Aucun trade execute, affichage du graphique de prix uniquement"
                    )
                    render_ohlcv_with_trades(
                        df=chart_df,
                        trades_df=pd.DataFrame(),
                        title="üìä Graphique OHLCV",
                        key="ohlcv_main_notrades",
                        height=600,
                    )

        st.subheader("üìà M√©triques D√©taill√©es")

        if result is not None:
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("**üí∞ Rendement**")
                st.text(f"P&L Total: ${result.metrics['total_pnl']:,.2f}")
                st.text(f"Rendement: {result.metrics['total_return_pct']:.2f}%")
                st.text(f"Ann. Return: {result.metrics['annualized_return']:.2f}%")
                st.text(f"Volatilit√©: {result.metrics['volatility_annual']:.2f}%")

            with col2:
                st.markdown("**üìä Risque**")
                st.text(f"Sharpe: {result.metrics['sharpe_ratio']:.2f}")
                st.text(f"Sortino: {result.metrics['sortino_ratio']:.2f}")
                st.text(f"Calmar: {result.metrics['calmar_ratio']:.2f}")
                # Compatibilit√©: fallback max_drawdown si max_drawdown_pct absent
                max_dd = result.metrics.get('max_drawdown_pct', result.metrics.get('max_drawdown', 0))
                st.text(f"Max DD: {max_dd:.2f}%")

            with col3:
                st.markdown("**üéØ Trading**")
                st.text(f"Trades: {result.metrics['total_trades']}")
                # Compatibilit√©: fallback win_rate si win_rate_pct absent
                win_rate = result.metrics.get('win_rate_pct', result.metrics.get('win_rate', 0))
                st.text(f"Win Rate: {win_rate:.1f}%")
                st.text(f"Profit Factor: {result.metrics['profit_factor']:.2f}")
                st.text(f"Expectancy: ${result.metrics['expectancy']:.2f}")

        if result is not None and not result.trades.empty:
            with st.expander("üìä Analyse Statistique Avanc√©e (Seaborn)", expanded=True):
                col1, col2 = st.columns(2)

                with col1:
                    render_trade_pnl_distribution(
                        trades_df=result.trades,
                        title="Distribution des P&L par Trade",
                        key="pnl_dist_main",
                        height=400,
                    )

                with col2:
                    if hasattr(result, "returns") and result.returns is not None:
                        render_returns_distribution(
                            returns=result.returns,
                            title="Distribution des Rendements",
                            key="returns_dist_main",
                            height=400,
                        )
                    else:
                        st.info("Rendements non disponibles pour cette analyse")

        if result is not None and not result.trades.empty:
            st.subheader("üìã Historique des Trades")

            trades_display = result.trades.copy()

            if "entry_ts" in trades_display.columns:
                trades_display["entry_ts"] = pd.to_datetime(
                    trades_display["entry_ts"]
                ).dt.strftime("%Y-%m-%d %H:%M")
            if "exit_ts" in trades_display.columns:
                trades_display["exit_ts"] = pd.to_datetime(
                    trades_display["exit_ts"]
                ).dt.strftime("%Y-%m-%d %H:%M")
            if "pnl" in trades_display.columns:
                trades_display["pnl"] = trades_display["pnl"].apply(
                    lambda x: f"${x:,.2f}"
                )
            def _format_price(value: float) -> str:
                if value is None or pd.isna(value):
                    return "‚Äî"
                abs_val = abs(float(value))
                if abs_val >= 1000:
                    fmt = "${:,.2f}"
                elif abs_val >= 1:
                    fmt = "${:,.4f}"
                elif abs_val >= 0.01:
                    fmt = "${:,.6f}"
                else:
                    fmt = "${:,.8f}"
                return fmt.format(value)

            if "price_entry" in trades_display.columns:
                trades_display["price_entry"] = trades_display[
                    "price_entry"
                ].apply(_format_price)
            if "price_exit" in trades_display.columns:
                trades_display["price_exit"] = trades_display[
                    "price_exit"
                ].apply(_format_price)

            cols_to_show = [
                "entry_ts",
                "exit_ts",
                "side",
                "price_entry",
                "price_exit",
                "pnl",
                "return_pct",
                "exit_reason",
            ]
            display_cols = [c for c in cols_to_show if c in trades_display.columns]

            st.dataframe(trades_display[display_cols], width="stretch")

            total_trades = len(result.trades)
            winners = (result.trades["pnl"] > 0).sum()
            losers = (result.trades["pnl"] < 0).sum()
            st.caption(
                f"Total: {total_trades} | Gagnants: {winners} | Perdants: {losers}"
            )
        elif result is not None:
            st.info("Aucun trade ex√©cut√© pendant cette p√©riode")

    else:
        render_home(state)


def render_home(state: SidebarState) -> None:
    st.info("üëÜ Configurez dans la sidebar puis cliquez sur **üöÄ Lancer le Backtest**")

    llm_mode_active = state.optimization_mode == "ü§ñ Optimisation LLM"

    tab1, tab2, tab3, tab4 = st.tabs(
        ["üéØ Strat√©gies", "üìä Optimisation", "üìÅ Donn√©es", "‚ùì FAQ"]
    )

    with tab1:
        strategies_table = generate_strategies_table()
        st.markdown(strategies_table)

        st.markdown(
            """
        ### Indicateurs Int√©gr√©s
        - Bollinger Bands, ATR, RSI, EMA, SMA, MACD, ADX
        - Ichimoku, PSAR, Stochastic RSI, Vortex, etc.
        """
        )

    with tab2:
        st.markdown(
            """
        ### Syst√®me d'Optimisation

        **Mode Grille** *(par d√©faut)* : Test de multiples combinaisons.
        - D√©finissez Min/Max/Step pour chaque param√®tre
        - Le syst√®me calcule toutes les combinaisons
        - Limite configurable (jusqu'√† 1,000,000)

        **Mode Simple** : Test d'une seule combinaison de param√®tres.
        """
        )

        table_lines = [
            "| Mode | Combinaisons | Intelligence | Co√ªt |",
            "|------|--------------|--------------|------|",
            "| Simple | 1 | ‚ùå | Gratuit |",
            "| Grille | Jusqu'√† 1M | ‚ùå | Gratuit |",
        ]
        if llm_mode_active:
            table_lines.append("| LLM | ~10-50 cibl√©es | ‚úÖ | Variable |")
        st.markdown("\n".join(table_lines))

        if llm_mode_active:
            st.markdown(
                """
        **Mode LLM** ü§ñ : Optimisation intelligente par agents IA.
        - 4 agents sp√©cialis√©s (Analyst, Strategist, Critic, Validator)
        - Boucle d'am√©lioration it√©rative automatique
        - Walk-Forward anti-overfitting int√©gr√©
        - Supporte Ollama (local/gratuit) ou OpenAI

        ‚ö†Ô∏è Mode LLM n√©cessite Ollama install√© localement ou une cl√© OpenAI.
        """
            )

    with tab3:
        st.markdown(
            f"""
        ### Format des Donn√©es

        Les donn√©es OHLCV doivent √™tre au format Parquet ou CSV:
        - `SYMBOL_TIMEFRAME.parquet` (ex: `BTCUSDT_1h.parquet`)

        **Symboles d√©tect√©s**: {len(state.available_tokens)}
        **Timeframes**: {', '.join(state.available_timeframes)}
        """
        )

    with tab4:
        st.markdown(
            """
        ### Questions Fr√©quentes

        **Q: Comment tester plus de combinaisons?**
        R: En mode Grille, d√©finissez Min/Max/Step pour chaque param√®tre.
        Augmentez la limite de combinaisons si n√©cessaire.

        **Q: Que signifie le Sharpe Ratio?**
        R: Rendement ajust√© au risque. > 1 = bon, > 2 = excellent.

        **Q: Pourquoi le mode Grille est lent?**
        R: Il teste toutes les combinaisons. Augmentez le Step ou r√©duisez la plage.
        """
        )

        if llm_mode_active:
            st.markdown(
                """

        **Q: Comment √©viter l'overfitting?**
        R: Utilisez le Walk-Forward Validation (activ√© par d√©faut en mode LLM).

        **Q: Comment fonctionne le mode LLM?**
        R: 4 agents IA travaillent ensemble:
        1. **Analyst** analyse les m√©triques actuelles
        2. **Strategist** propose de nouveaux param√®tres
        3. **Critic** d√©tecte l'overfitting potentiel
        4. **Validator** d√©cide: approuver, rejeter ou it√©rer

        **Q: Ollama vs OpenAI?**
        R: Ollama est gratuit et local (installer depuis ollama.ai).
        OpenAI est plus puissant mais payant (~0.01$/requ√™te).
        """
            )
```
<!-- MODULE-END: results.py -->

<!-- MODULE-START: results_hub.py -->
```json
{
  "name": "results_hub.py",
  "path": "ui\\results_hub.py",
  "ext": ".py",
  "anchor": "results_hub_py"
}
```
## results_hub_py
*Chemin* : `ui\results_hub.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.results_hub

Purpose: Vue centralisee des resultats (backtests, sweeps, grids, runs LLM).

Role in pipeline: reporting / catalog

Key components: render_results_hub

Inputs: catalogues CSV, session_state last run

Outputs: Page Streamlit avec dernier run + catalogue filtrable

Dependencies: pandas, streamlit, backtest.storage, utils.run_tracker

Conventions: Non-destructif, lecture des catalogues CSV

Read-if: Ajout d'une page de synthese des resultats.

Skip-if: Vous utilisez seulement ui.results.
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, Optional, Tuple

import pandas as pd
import streamlit as st

try:
    import plotly.express as px
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

from backtest.storage import ResultStorage
from ui.helpers import compute_period_days, format_pnl_with_daily
from utils.run_tracker import RunTracker


RESULTS_DIR = Path("backtest_results")
RUNS_DIR = Path("runs")


def _safe_read_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    try:
        return pd.read_csv(path)
    except Exception:
        return pd.DataFrame()


def _coerce_numeric(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:
    if df.empty:
        return df
    for col in columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df


def _load_catalogs(refresh: bool = False) -> Tuple[pd.DataFrame, pd.DataFrame]:
    if refresh:
        if RESULTS_DIR.exists():
            storage = ResultStorage(storage_dir=RESULTS_DIR, auto_save=False)
            storage.build_catalogs()
        if RUNS_DIR.exists():
            tracker = RunTracker(cache_file=RUNS_DIR / ".run_cache.json")
            tracker.build_catalogs()

    backtest_overview = _safe_read_csv(RESULTS_DIR / "_catalog" / "overview.csv")
    runs_overview = _safe_read_csv(RUNS_DIR / "_catalog" / "overview.csv")

    backtest_overview = _coerce_numeric(
        backtest_overview,
        [
            "total_pnl",
            "total_return_pct",
            "sharpe_ratio",
            "max_drawdown_pct",
            "win_rate_pct",
            "profit_factor",
            "total_trades",
            "n_bars",
            "n_trades",
            "n_completed",
            "n_failed",
            "n_trials",
            "n_pruned",
            "best_value",
            "total_time_sec",
            "total_combinations",
            "max_combos",
            "n_workers",
        ],
    )
    runs_overview = _coerce_numeric(
        runs_overview,
        [
            "total_iterations",
            "total_llm_tokens",
            "total_llm_calls",
            "iteration_history_count",
        ],
    )
    return backtest_overview, runs_overview


def _path_to_uri(path: Path) -> str:
    try:
        return path.resolve().as_uri()
    except Exception:
        return str(path)


def _add_open_links_backtest(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "path" not in df.columns:
        return df
    df = df.copy()
    df["open_folder"] = df["path"].apply(
        lambda value: ""
        if value is None or (isinstance(value, float) and pd.isna(value)) or value == ""
        else _path_to_uri(RESULTS_DIR / str(value))
    )
    return df


def _add_open_links_runs(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    df = df.copy()

    def _row_to_uri(row: pd.Series) -> str:
        trace_path = row.get("trace_path", "")
        if isinstance(trace_path, str) and trace_path:
            return _path_to_uri(Path(trace_path).parent)
        session_id = row.get("session_id", "")
        if session_id:
            return _path_to_uri(RUNS_DIR / str(session_id))
        return ""

    df["open_folder"] = df.apply(_row_to_uri, axis=1)
    return df


def _add_pnl_per_day(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "total_pnl" not in df.columns:
        return df
    if "period_start" not in df.columns or "period_end" not in df.columns:
        return df
    df = df.copy()
    start_dt = pd.to_datetime(df["period_start"], errors="coerce")
    end_dt = pd.to_datetime(df["period_end"], errors="coerce")
    period_days = (end_dt.dt.date - start_dt.dt.date).dt.days
    period_days = period_days.where(period_days > 0)
    df["period_days"] = period_days
    df["pnl_per_day"] = df["total_pnl"] / df["period_days"]
    if "data_coverage_pct" in df.columns:
        coverage = pd.to_numeric(df["data_coverage_pct"], errors="coerce")
        effective_days = period_days * (coverage / 100.0)
        effective_days = effective_days.where(effective_days > 0)
        df["pnl_per_day_covered"] = df["total_pnl"] / effective_days
    return df


def _sort_by_metrics(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    sort_cols = []
    if "total_pnl" in df.columns:
        sort_cols.append("total_pnl")
    if "sharpe_ratio" in df.columns:
        sort_cols.append("sharpe_ratio")
    if sort_cols:
        df = df.sort_values(sort_cols, ascending=[False] * len(sort_cols), na_position="last")
    return df


def _pick_latest_from_catalogs(
    backtest_overview: pd.DataFrame,
    runs_overview: pd.DataFrame,
) -> Optional[Dict[str, object]]:
    candidates = []

    if not backtest_overview.empty:
        df = backtest_overview.copy()
        df["timestamp_dt"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
        df = df.dropna(subset=["timestamp_dt"])
        if not df.empty:
            latest = df.sort_values("timestamp_dt", ascending=False).iloc[0]
            candidates.append({
                "source": "backtest_results",
                "kind": latest.get("type", ""),
                "id": latest.get("id", ""),
                "timestamp": latest.get("timestamp", ""),
                "strategy": latest.get("strategy", ""),
                "symbol": latest.get("symbol", ""),
                "timeframe": latest.get("timeframe", ""),
                "period_start": latest.get("period_start", ""),
                "period_end": latest.get("period_end", ""),
                "metrics": {
                    "total_pnl": latest.get("total_pnl", ""),
                    "total_return_pct": latest.get("total_return_pct", ""),
                    "sharpe_ratio": latest.get("sharpe_ratio", ""),
                    "max_drawdown_pct": latest.get("max_drawdown_pct", ""),
                    "win_rate_pct": latest.get("win_rate_pct", ""),
                    "profit_factor": latest.get("profit_factor", ""),
                },
                "path": latest.get("path", ""),
                "timestamp_dt": latest.get("timestamp_dt"),
            })

    if not runs_overview.empty:
        df = runs_overview.copy()
        df["timestamp_dt"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
        df = df.dropna(subset=["timestamp_dt"])
        if not df.empty:
            latest = df.sort_values("timestamp_dt", ascending=False).iloc[0]
            candidates.append({
                "source": "runs",
                "kind": latest.get("mode", ""),
                "id": latest.get("session_id", ""),
                "timestamp": latest.get("timestamp", ""),
                "strategy": latest.get("strategy_name", ""),
                "symbol": "",
                "timeframe": "",
                "metrics": {
                    "total_iterations": latest.get("total_iterations", ""),
                    "total_llm_tokens": latest.get("total_llm_tokens", ""),
                    "total_llm_calls": latest.get("total_llm_calls", ""),
                    "last_decision": latest.get("last_decision", ""),
                },
                "path": latest.get("trace_path", ""),
                "timestamp_dt": latest.get("timestamp_dt"),
            })

    if not candidates:
        return None

    candidates.sort(key=lambda x: x.get("timestamp_dt") or pd.Timestamp.min, reverse=True)
    return candidates[0]


def _render_latest_run(backtest_overview: pd.DataFrame, runs_overview: pd.DataFrame) -> None:
    st.subheader("üïí Dernier run")

    session_result = st.session_state.get("last_run_result")
    session_meta = st.session_state.get("last_winner_meta")

    if session_result is not None:
        metrics = session_result.metrics
        meta = session_result.meta
        period_days = compute_period_days(
            meta.get("period_start"),
            meta.get("period_end"),
        )
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(
                "PnL",
                format_pnl_with_daily(metrics.get("total_pnl", 0), period_days),
            )
        with col2:
            st.metric("Return", f"{metrics.get('total_return_pct', 0):.1f}%")
        with col3:
            st.metric("Sharpe", f"{metrics.get('sharpe_ratio', 0):.2f}")
        with col4:
            st.metric("Max DD", f"{metrics.get('max_drawdown_pct', 0):.1f}%")

        st.caption(
            f"Run: {meta.get('run_id', 'n/a')} | "
            f"{meta.get('strategy', 'n/a')} | "
            f"{meta.get('symbol', 'n/a')}/{meta.get('timeframe', 'n/a')}"
        )
        if session_meta and isinstance(session_meta, dict):
            st.caption(f"Origine: {session_meta.get('run_id', 'n/a')}")
        return

    latest = _pick_latest_from_catalogs(backtest_overview, runs_overview)
    if latest is None:
        st.info("Aucun run d√©tect√© pour le moment.")
        return

    if latest["source"] == "backtest_results":
        col1, col2, col3, col4 = st.columns(4)
        metrics = latest.get("metrics", {})
        period_days = compute_period_days(
            latest.get("period_start"),
            latest.get("period_end"),
        )
        with col1:
            st.metric(
                "PnL",
                format_pnl_with_daily(metrics.get("total_pnl", 0), period_days),
            )
        with col2:
            st.metric("Return", f"{metrics.get('total_return_pct', 0):.1f}%")
        with col3:
            st.metric("Sharpe", f"{metrics.get('sharpe_ratio', 0):.2f}")
        with col4:
            st.metric("Max DD", f"{metrics.get('max_drawdown_pct', 0):.1f}%")
        st.caption(
            f"{latest.get('kind', '')} | {latest.get('id', '')} | "
            f"{latest.get('strategy', '')} {latest.get('symbol', '')}/{latest.get('timeframe', '')} | "
            f"{latest.get('timestamp', '')}"
        )
    else:
        st.info("Dernier run LLM (runs/)")
        metrics = latest.get("metrics", {})
        st.caption(
            f"Mode: {latest.get('kind', '')} | Session: {latest.get('id', '')} | "
            f"Strat√©gie: {latest.get('strategy', '')} | {latest.get('timestamp', '')}"
        )
        if metrics:
            st.caption(
                f"Iter: {metrics.get('total_iterations', 'n/a')} | "
                f"LLM calls: {metrics.get('total_llm_calls', 'n/a')} | "
                f"Tokens: {metrics.get('total_llm_tokens', 'n/a')} | "
                f"Derniere decision: {metrics.get('last_decision', 'n/a')}"
            )


def _render_overview_filters(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    types = sorted([t for t in df.get("type", pd.Series()).dropna().unique().tolist() if t])
    strategies = sorted([s for s in df.get("strategy", pd.Series()).dropna().unique().tolist() if s])
    symbols = sorted([s for s in df.get("symbol", pd.Series()).dropna().unique().tolist() if s])
    timeframes = sorted([t for t in df.get("timeframe", pd.Series()).dropna().unique().tolist() if t])

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        selected_types = st.multiselect("Type", options=types, default=types)
    with col2:
        selected_strategies = st.multiselect("Strat√©gie", options=strategies, default=strategies)
    with col3:
        selected_symbols = st.multiselect("Symbole", options=symbols, default=symbols)
    with col4:
        selected_timeframes = st.multiselect("Timeframe", options=timeframes, default=timeframes)

    if selected_types:
        df = df[df["type"].isin(selected_types)]
    if selected_strategies:
        df = df[df["strategy"].isin(selected_strategies)]
    if selected_symbols:
        df = df[df["symbol"].isin(selected_symbols)]
    if selected_timeframes:
        df = df[df["timeframe"].isin(selected_timeframes)]
    return df


def _render_charts(df: pd.DataFrame) -> None:
    if df.empty:
        return

    numeric_cols = [c for c in ["total_return_pct", "sharpe_ratio", "max_drawdown_pct"] if c in df.columns]
    if not numeric_cols:
        return

    if PLOTLY_AVAILABLE:
        if "total_return_pct" in df.columns:
            fig = px.histogram(df, x="total_return_pct", nbins=30, title="Distribution Return %")
            st.plotly_chart(fig, width="stretch")
        if {"sharpe_ratio", "max_drawdown_pct"}.issubset(df.columns):
            fig = px.scatter(
                df,
                x="max_drawdown_pct",
                y="sharpe_ratio",
                color="type" if "type" in df.columns else None,
                title="Sharpe vs Max Drawdown",
                hover_data=["id", "strategy", "symbol", "timeframe"],
            )
            st.plotly_chart(fig, width="stretch")
    else:
        st.bar_chart(df["total_return_pct"].dropna(), height=200)


def _get_numeric_column_config() -> Dict[str, Any]:
    """Configuration des colonnes num√©riques pour tri correct dans st.dataframe."""
    return {
        "open_folder": st.column_config.LinkColumn("Ouvrir dossier", display_text="üìÇ Ouvrir"),
        "total_pnl": st.column_config.NumberColumn("PnL ($)", format="$%.2f"),
        "pnl_per_day": st.column_config.NumberColumn("PnL/jour ($)", format="$%.2f"),
        "pnl_per_day_covered": st.column_config.NumberColumn("PnL/jour (donn√©es)", format="$%.2f"),
        "total_return_pct": st.column_config.NumberColumn("Return (%)", format="%.2f%%"),
        "sharpe_ratio": st.column_config.NumberColumn("Sharpe", format="%.2f"),
        "max_drawdown_pct": st.column_config.NumberColumn("Max DD (%)", format="%.1f%%"),
        "win_rate_pct": st.column_config.NumberColumn("Win Rate (%)", format="%.1f%%"),
        "data_coverage_pct": st.column_config.NumberColumn("Couverture donn√©es (%)", format="%.1f%%"),
        "profit_factor": st.column_config.NumberColumn("PF", format="%.2f"),
        "total_trades": st.column_config.NumberColumn("Trades", format="%d"),
        "n_bars": st.column_config.NumberColumn("Bars", format="%d"),
        "n_trades": st.column_config.NumberColumn("Trades", format="%d"),
        "n_completed": st.column_config.NumberColumn("Compl√©t√©s", format="%d"),
        "n_failed": st.column_config.NumberColumn("√âchecs", format="%d"),
        "n_trials": st.column_config.NumberColumn("Trials", format="%d"),
        "n_pruned": st.column_config.NumberColumn("Prun√©s", format="%d"),
        "best_value": st.column_config.NumberColumn("Meilleure val.", format="%.4f"),
        "total_time_sec": st.column_config.NumberColumn("Dur√©e (s)", format="%.1f"),
        "total_combinations": st.column_config.NumberColumn("Combinaisons", format="%d"),
        "max_combos": st.column_config.NumberColumn("Max combos", format="%d"),
        "n_workers": st.column_config.NumberColumn("Workers", format="%d"),
        "total_iterations": st.column_config.NumberColumn("It√©rations", format="%d"),
        "total_llm_tokens": st.column_config.NumberColumn("Tokens LLM", format="%d"),
        "total_llm_calls": st.column_config.NumberColumn("Appels LLM", format="%d"),
    }


def render_results_hub() -> None:
    st.header("üìö R√©sultats & Catalogues")

    col_left, col_right = st.columns([1, 2])
    with col_left:
        refresh = st.button("üîÑ Rafra√Æchir catalogues")
    with col_right:
        st.caption("Catalogues CSV non-destructifs bas√©s sur backtest_results/ et runs/.")

    backtest_overview, runs_overview = _load_catalogs(refresh=refresh)
    backtest_overview = _add_open_links_backtest(backtest_overview)
    runs_overview = _add_open_links_runs(runs_overview)
    backtest_overview = _add_pnl_per_day(backtest_overview)

    _render_latest_run(backtest_overview, runs_overview)

    st.markdown("---")
    st.subheader("üóÇÔ∏è Catalogue global")

    if backtest_overview.empty and runs_overview.empty:
        st.info("Aucun catalogue disponible. Lancez un run puis cliquez sur Rafra√Æchir catalogues.")
        return

    # Configuration des colonnes num√©riques pour tri correct
    numeric_col_config = _get_numeric_column_config()

    tabs = st.tabs([
        "Vue d'ensemble",
        "Backtests",
        "Sweeps",
        "Grids",
        "Optuna",
        "Runs LLM",
        "Cat√©gories",
        "Comparaison",
    ])

    with tabs[0]:
        df = backtest_overview.copy()
        if df.empty:
            st.info("Aucun r√©sultat backtest/sweep/grid.")
        else:
            df = _render_overview_filters(df)
            df = _sort_by_metrics(df)
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )
            _render_charts(df)

    with tabs[1]:
        df = backtest_overview[backtest_overview["type"] == "run"].copy() if not backtest_overview.empty else pd.DataFrame()
        if df.empty:
            st.info("Aucun backtest enregistr√©.")
        else:
            df = _sort_by_metrics(df)
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )

    with tabs[2]:
        df = backtest_overview[backtest_overview["type"] == "sweep"].copy() if not backtest_overview.empty else pd.DataFrame()
        if df.empty:
            st.info("Aucun sweep enregistr√©.")
        else:
            df = _sort_by_metrics(df)
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )

    with tabs[3]:
        df = backtest_overview[backtest_overview["type"] == "grid"].copy() if not backtest_overview.empty else pd.DataFrame()
        if df.empty:
            st.info("Aucun grid enregistr√©.")
        else:
            df = _sort_by_metrics(df)
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )

    with tabs[4]:
        df = backtest_overview[backtest_overview["type"] == "optuna"].copy() if not backtest_overview.empty else pd.DataFrame()
        if df.empty:
            st.info("Aucun Optuna enregistr√©.")
        else:
            df = _sort_by_metrics(df)
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )

    with tabs[5]:
        if runs_overview.empty:
            st.info("Aucun run LLM enregistr√©.")
        else:
            df = runs_overview.copy()
            df["timestamp_dt"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
            df = df.sort_values("timestamp_dt", ascending=False, na_position="last").drop(columns=["timestamp_dt"])
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config=numeric_col_config,
            )

    with tabs[6]:
        if backtest_overview.empty:
            st.info("Aucune donn√©e pour les cat√©gories.")
        else:
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Par strat√©gie**")
                st.dataframe(
                    backtest_overview["strategy"].value_counts().rename_axis("strategy").reset_index(name="count"),
                    width="stretch",
                    hide_index=True,
                )
            with col2:
                st.markdown("**Par symbole**")
                st.dataframe(
                    backtest_overview["symbol"].value_counts().rename_axis("symbol").reset_index(name="count"),
                    width="stretch",
                    hide_index=True,
                )
            st.markdown("**Par timeframe**")
            st.dataframe(
                backtest_overview["timeframe"].value_counts().rename_axis("timeframe").reset_index(name="count"),
                width="stretch",
                hide_index=True,
            )

    with tabs[7]:
        df = backtest_overview[backtest_overview["type"] == "run"].copy() if not backtest_overview.empty else pd.DataFrame()
        if df.empty:
            st.info("Aucun backtest disponible pour comparaison.")
        else:
            df = _sort_by_metrics(df)
            options = df["id"].dropna().unique().tolist()
            selected = st.multiselect("S√©lectionner des runs", options=options)
            if selected:
                selected_df = df[df["id"].isin(selected)]
                st.dataframe(
                    selected_df,
                    width="stretch",
                    hide_index=True,
                    column_config=numeric_col_config,
                )
```
<!-- MODULE-END: results_hub.py -->

<!-- MODULE-START: sidebar.py -->
```json
{
  "name": "sidebar.py",
  "path": "ui\\sidebar.py",
  "ext": ".py",
  "anchor": "sidebar_py"
}
```
## sidebar_py
*Chemin* : `ui\sidebar.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.sidebar

Purpose: G√®re la configuration et les contr√¥les de la sidebar pour la s√©lection de strat√©gies et param√®tres.

Role in pipeline: configuration / inputs

Key components: render_sidebar, gestion des param√®tres

Inputs: Donn√©es disponibles, strat√©gies

Outputs: SidebarState configur√©

Dependencies: ui.context, ui.constants

Conventions: Param√®tres valid√©s selon contraintes

Read-if: Configuration de l'interface utilisateur

Skip-if: Logique backend pure
"""

from __future__ import annotations

import hashlib
import json
import re
from typing import Any, Dict, List, Optional

import pandas as pd
import streamlit as st

from ui.constants import (
    MODE_BUTTON_CSS,
    MODE_OPTIONS,
    PARAM_CONSTRAINTS,
    build_strategy_options,
    get_strategy_description,
    get_strategy_ui_indicators,
)
from ui.context import (
    KNOWN_MODELS,
    LLM_AVAILABLE,
    LLM_IMPORT_ERROR,
    RECOMMENDED_FOR_STRATEGY,
    LLMConfig,
    LLMProvider,
    ModelCategory,
    compute_search_space_stats,
    discover_available_data,
    ensure_ollama_running,
    get_available_models_for_ui,
    get_data_date_range,
    get_global_model_config,
    get_model_info,
    get_storage,
    get_strategy,
    get_strategy_info,
    is_ollama_available,
    list_available_models,
    list_strategies,
    list_strategy_versions,
    load_strategy_version,
    resolve_latest_version,
    set_global_model_config,
)
from ui.helpers import (
    _data_cache_key,
    _find_saved_run_meta,
    _parse_run_timestamp,
    apply_versioned_preset,
    create_param_range_selector,
    load_selected_data,
    render_saved_runs_panel,
    validate_param,
)
from ui.state import SidebarState
from utils.observability import is_debug_enabled, set_log_level


def _is_valid_timeframe_format(tf: str) -> bool:
    """Valide qu'un timeframe est dans un format correct."""
    if not tf or len(tf) < 2:
        return False
    unit = tf[-1]
    if unit not in ('m', 'h', 'd', 'w', 'M'):
        return False
    try:
        amount = int(tf[:-1])
        return amount > 0
    except ValueError:
        return False


def _normalize_signature_value(value: Any) -> Any:
    if isinstance(value, dict):
        return {str(k): _normalize_signature_value(v) for k, v in value.items()}
    if isinstance(value, (list, tuple)):
        return [_normalize_signature_value(v) for v in value]
    if isinstance(value, (set, frozenset)):
        return sorted(_normalize_signature_value(v) for v in value)
    if hasattr(value, "tolist"):
        try:
            return value.tolist()
        except Exception:
            pass
    if hasattr(value, "item"):
        try:
            return value.item()
        except Exception:
            pass
    if isinstance(value, (str, int, float, bool)) or value is None:
        return value
    return str(value)


def _extract_llm_signature(llm_config: Optional[LLMConfig]) -> Optional[Dict[str, Any]]:
    if llm_config is None:
        return None
    provider = getattr(llm_config.provider, "value", str(llm_config.provider))
    return {
        "provider": provider,
        "model": getattr(llm_config, "model", None),
        "ollama_host": getattr(llm_config, "ollama_host", None),
        "openai_base_url": getattr(llm_config, "openai_base_url", None),
        "openai_key_set": bool(getattr(llm_config, "openai_api_key", None)),
        "temperature": getattr(llm_config, "temperature", None),
        "max_tokens": getattr(llm_config, "max_tokens", None),
        "top_p": getattr(llm_config, "top_p", None),
        "timeout_seconds": getattr(llm_config, "timeout_seconds", None),
        "max_retries": getattr(llm_config, "max_retries", None),
        "retry_delay_seconds": getattr(llm_config, "retry_delay_seconds", None),
    }


def _extract_role_model_signature(role_model_config: Any) -> Optional[Dict[str, Any]]:
    if role_model_config is None:
        return None

    def _role_payload(role: Any) -> Dict[str, Any]:
        return {
            "models": list(getattr(role, "models", []) or []),
            "allow_heavy_after_iteration": getattr(role, "allow_heavy_after_iteration", None),
        }

    return {
        "analyst": _role_payload(getattr(role_model_config, "analyst", None)),
        "strategist": _role_payload(getattr(role_model_config, "strategist", None)),
        "critic": _role_payload(getattr(role_model_config, "critic", None)),
        "validator": _role_payload(getattr(role_model_config, "validator", None)),
    }


def _build_config_signature(state: SidebarState) -> str:
    payload = {
        "debug_enabled": state.debug_enabled,
        "symbol": state.symbol,
        "timeframe": state.timeframe,
        "symbols": state.symbols,
        "timeframes": state.timeframes,
        "use_date_filter": state.use_date_filter,
        "start_date": state.start_date.isoformat() if state.start_date else None,
        "end_date": state.end_date.isoformat() if state.end_date else None,
        "strategy_key": state.strategy_key,
        "strategy_keys": state.strategy_keys,
        "params": state.params,
        "param_ranges": state.param_ranges,
        "active_indicators": state.active_indicators,
        "optimization_mode": state.optimization_mode,
        "max_combos": state.max_combos,
        "n_workers": state.n_workers,
        "use_optuna": state.use_optuna,
        "optuna_n_trials": state.optuna_n_trials,
        "optuna_sampler": state.optuna_sampler,
        "optuna_pruning": state.optuna_pruning,
        "optuna_metric": state.optuna_metric,
        "optuna_early_stop": state.optuna_early_stop,
        "llm_config": _extract_llm_signature(state.llm_config),
        "llm_model": state.llm_model,
        "llm_use_multi_agent": state.llm_use_multi_agent,
        "role_model_config": _extract_role_model_signature(state.role_model_config),
        "llm_max_iterations": state.llm_max_iterations,
        "llm_use_walk_forward": state.llm_use_walk_forward,
        "llm_unload_during_backtest": state.llm_unload_during_backtest,
        "llm_compare_enabled": state.llm_compare_enabled,
        "llm_compare_auto_run": state.llm_compare_auto_run,
        "llm_compare_strategies": state.llm_compare_strategies,
        "llm_compare_tokens": state.llm_compare_tokens,
        "llm_compare_timeframes": state.llm_compare_timeframes,
        "llm_compare_metric": state.llm_compare_metric,
        "llm_compare_aggregate": state.llm_compare_aggregate,
        "llm_compare_max_runs": state.llm_compare_max_runs,
        "llm_compare_use_preset": state.llm_compare_use_preset,
        "llm_compare_generate_report": state.llm_compare_generate_report,
        "initial_capital": state.initial_capital,
        "leverage": state.leverage,
        "leverage_enabled": state.leverage_enabled,
        "disabled_params": state.disabled_params,
    }
    normalized = _normalize_signature_value(payload)
    encoded = json.dumps(normalized, sort_keys=True, default=str).encode("utf-8")
    return hashlib.sha256(encoded).hexdigest()


def _apply_config_guard(draft_state: SidebarState, apply_slot: Any) -> SidebarState:
    draft_signature = _build_config_signature(draft_state)
    applied_signature = st.session_state.get("applied_config_signature")
    applied_state = st.session_state.get("applied_sidebar_state")

    if applied_signature is None or applied_state is None:
        st.session_state["applied_config_signature"] = draft_signature
        st.session_state["applied_sidebar_state"] = draft_state
        applied_state = draft_state
        pending = False
    else:
        pending = draft_signature != applied_signature

    st.session_state["config_pending_changes"] = pending
    st.session_state["draft_config_signature"] = draft_signature

    with apply_slot:
        st.markdown("---")
        st.caption("Configuration")
        if pending:
            st.warning(
                "Modifications en attente. Cliquez sur 'Appliquer' pour relancer."
            )
            if st.button("‚úÖ Appliquer la configuration", key="apply_sidebar_config"):
                st.session_state["applied_config_signature"] = draft_signature
                st.session_state["applied_sidebar_state"] = draft_state
                st.session_state["config_pending_changes"] = False
                st.rerun()
        else:
            st.success("Configuration appliqu√©e.")

    return applied_state


def render_sidebar() -> SidebarState:
    st.sidebar.header("‚öôÔ∏è Configuration")
    apply_slot = st.sidebar.container()

    with st.sidebar.expander("üîß Debug", expanded=False):
        debug_enabled = st.checkbox(
            "Mode DEBUG",
            value=is_debug_enabled(),
            key="debug_toggle",
        )
        if debug_enabled:
            set_log_level("DEBUG")
            st.caption("üü¢ Logs d√©taill√©s activ√©s")
        else:
            set_log_level("INFO")

    st.sidebar.subheader("üìä Donn√©es")

    data_status = st.sidebar.empty()
    try:
        available_tokens, available_timeframes = discover_available_data()
        if not available_tokens:
            available_tokens = ["BTCUSDC", "ETHUSDC"]
            data_status.warning("Aucune donn√©e trouv√©e, utilisation des d√©fauts")
        else:
            data_status.success(f"‚úÖ {len(available_tokens)} symboles disponibles")

        if not available_timeframes:
            available_timeframes = ["1h", "4h", "1d"]

        # Nettoyer les valeurs de session invalides (bug fix 23/01/2026)
        if "symbol_select" in st.session_state:
            if st.session_state["symbol_select"] not in available_tokens:
                del st.session_state["symbol_select"]

        if "timeframe_select" in st.session_state:
            if not _is_valid_timeframe_format(st.session_state["timeframe_select"]) or \
               st.session_state["timeframe_select"] not in available_timeframes:
                del st.session_state["timeframe_select"]

    except Exception as exc:
        available_tokens = ["BTCUSDC", "ETHUSDC"]
        available_timeframes = ["1h", "4h", "1d"]
        data_status.error(f"Erreur scan: {exc}")

    pending_meta = None
    pending_run_id = st.session_state.get("pending_run_load_id")
    if pending_run_id:
        try:
            storage = get_storage()
            pending_meta = _find_saved_run_meta(storage, pending_run_id)
        except Exception as exc:
            st.session_state["saved_runs_status"] = f"Pending load failed: {exc}"
            pending_meta = None

    if pending_meta is not None:
        # Valider que symbol et timeframe sont valides avant de les ajouter
        if pending_meta.symbol and pending_meta.symbol not in available_tokens:
            # V√©rifier que le symbol est valide (lettres et chiffres seulement)
            if pending_meta.symbol.replace("_", "").replace("-", "").isalnum():
                available_tokens = [pending_meta.symbol] + available_tokens

        if pending_meta.timeframe and pending_meta.timeframe not in available_timeframes:
            # Valider format timeframe (ex: 1m, 5m, 1h, 4h, 1d)
            if _is_valid_timeframe_format(pending_meta.timeframe):
                available_timeframes = [pending_meta.timeframe] + available_timeframes

        if pending_meta.symbol:
            st.session_state["symbol_select"] = pending_meta.symbol
        if pending_meta.timeframe:
            st.session_state["timeframe_select"] = pending_meta.timeframe
        # Activer le filtre de dates seulement si des dates sp√©cifiques sont d√©finies
        start_ts = _parse_run_timestamp(pending_meta.period_start)
        end_ts = _parse_run_timestamp(pending_meta.period_end)
        if start_ts is not None and end_ts is not None:
            st.session_state["use_date_filter"] = True
            # Initialiser seulement si pas d√©j√† d√©fini (√©vite conflit avec widget)
            if "start_date" not in st.session_state:
                st.session_state["start_date"] = start_ts.date()
            if "end_date" not in st.session_state:
                st.session_state["end_date"] = end_ts.date()

    # === NETTOYAGE SESSION STATE ===
    # Nettoyer les cl√©s de session obsol√®tes ou invalides
    session_keys_to_clean = [
        "symbols_select", "timeframes_select", "symbol_select", "timeframe_select"
    ]
    for key in session_keys_to_clean:
        if key in st.session_state:
            if "symbol" in key:
                if isinstance(st.session_state[key], list):
                    # Multi-select : filtrer valeurs invalides
                    valid_symbols = [s for s in st.session_state[key] if s in available_tokens]
                    if not valid_symbols or len(valid_symbols) != len(st.session_state[key]):
                        st.session_state[key] = valid_symbols if valid_symbols else available_tokens[:1]
                elif st.session_state[key] not in available_tokens:
                    del st.session_state[key]
            elif "timeframe" in key:
                if isinstance(st.session_state[key], list):
                    # Multi-select : filtrer valeurs invalides
                    valid_timeframes = [tf for tf in st.session_state[key] if tf in available_timeframes]
                    if not valid_timeframes or len(valid_timeframes) != len(st.session_state[key]):
                        st.session_state[key] = valid_timeframes if valid_timeframes else available_timeframes[:1]
                elif st.session_state[key] not in available_timeframes:
                    del st.session_state[key]

    # === MULTI-S√âLECTION TOKENS (multiselect) ===
    # Tokens √† potentiel (base de comparaison m√©ticuleuse)
    POTENTIAL_TOKENS = [
        "BTCUSDC",    # Bitcoin - R√©f√©rence march√©
        "ETHUSDC",    # Ethereum - Leader DeFi
        "BNBUSDC",    # Binance Coin - Plateforme CEX
        "SOLUSDC",    # Solana - Haute vitesse
        "AVAXUSDC",   # Avalanche - DeFi concurrente
        "LINKUSDC",   # Chainlink - Oracle leader
        "ADAUSDC",    # Cardano - Approche acad√©mique
        "DOTUSDC",    # Polkadot - Interop√©rabilit√©
        "ATOMUSDC",   # Cosmos - Hub inter-cha√Ænes
    ]

    default_symbols = ["BTCUSDC"] if "BTCUSDC" in available_tokens else available_tokens[:1]

    # Appliquer la s√©lection des tokens potentiels avant la cr√©ation du widget
    if st.session_state.get("_apply_potential_tokens", False):
        valid_potential = [t for t in POTENTIAL_TOKENS if t in available_tokens]
        current_symbols = st.session_state.get("symbols_select", default_symbols)
        merged_symbols = list(current_symbols)
        for token in valid_potential:
            if token not in merged_symbols:
                merged_symbols.append(token)
        st.session_state["symbols_select"] = merged_symbols or default_symbols
        del st.session_state["_apply_potential_tokens"]

    # Layout: multiselect + bouton c√¥te √† c√¥te
    col1, col2 = st.sidebar.columns([3, 1])
    with col1:
        multiselect_kwargs = {
            "label": "Symbole(s)",
            "options": available_tokens,
            "key": "symbols_select",
            "help": "S√©lectionnez un ou plusieurs tokens √† analyser",
        }
        if "symbols_select" not in st.session_state:
            multiselect_kwargs["default"] = default_symbols
        symbols = st.multiselect(**multiselect_kwargs)
    with col2:
        st.write("")  # Espacement pour aligner avec le multiselect
        if st.button("üéØ", key="select_potential_tokens", help="S√©lectionner tokens √† potentiel"):
            st.session_state["_apply_potential_tokens"] = True
            st.rerun()

    # Fallback si aucune s√©lection
    if not symbols:
        symbols = default_symbols
        st.sidebar.warning("‚ö†Ô∏è Au moins un symbole requis. BTCUSDC s√©lectionn√© par d√©faut.")
    symbol = symbols[0]  # Compatibilit√© r√©tro

    # === MULTI-S√âLECTION TIMEFRAMES (multiselect) ===
    default_timeframes = ["30m"] if "30m" in available_timeframes else available_timeframes[:1]
    timeframes = st.sidebar.multiselect(
        "Timeframe(s)",
        available_timeframes,
        default=default_timeframes,
        key="timeframes_select",
        help="S√©lectionnez un ou plusieurs timeframes",
    )
    # Fallback si aucune s√©lection
    if not timeframes:
        timeframes = default_timeframes
        st.sidebar.warning("‚ö†Ô∏è Au moins un timeframe requis. 30m s√©lectionn√© par d√©faut.")
    timeframe = timeframes[0]  # Compatibilit√© r√©tro

    # Info multi-sweep si plusieurs s√©lections
    if len(symbols) > 1 or len(timeframes) > 1:
        total_combos = len(symbols) * len(timeframes)
        st.sidebar.info(f"üîÑ Mode multi-sweep: {len(symbols)} token(s) √ó {len(timeframes)} TF(s) = {total_combos} combinaison(s)")

    # Analyse des donn√©es disponibles pour validation (toujours n√©cessaire)
    from data.config import scan_data_availability
    availability_result = scan_data_availability(symbols, timeframes)

    use_date_filter = st.sidebar.checkbox(
        "Filtrer par dates",
        value=False,
        help="D√©sactiv√© = utilise toutes les donn√©es disponibles (recommand√©)",
        key="use_date_filter",
    )
    if use_date_filter:
        # === ANALYSE PAR CAT√âGORIE DE TIMEFRAME ===
        from data.config import (
            analyze_by_timeframe,
            find_optimal_periods,
            get_min_period_days_for_timeframes,
        )

        # Analyse par timeframe (plage commune par TF)
        timeframe_analysis = analyze_by_timeframe(symbols, timeframes)

        # Interface de s√©lection par timeframe
        with st.sidebar.expander("üéØ **Analyse par Timeframe**", expanded=True):
            if len(timeframes) > 1:
                analysis_mode = st.radio(
                    "Mode d'analyse",
                    ["P√©riode harmonis√©e", "P√©riodes ind√©pendantes par timeframe"],
                    help="Harmonis√©e = m√™me p√©riode pour tous. Ind√©pendantes = p√©riode optimale par timeframe",
                )
            else:
                analysis_mode = "P√©riode harmonis√©e"  # Auto si un seul timeframe

            if analysis_mode == "P√©riode harmonis√©e":
                if availability_result.has_common_range:
                    common_start = availability_result.common_start
                    common_end = availability_result.common_end
                    duration = (common_end - common_start).days

                    st.success(f"‚úÖ **P√©riode harmonis√©e**: {common_start.strftime('%d/%m/%Y')} ‚Üí {common_end.strftime('%d/%m/%Y')} ({duration}j)")
                    st.caption(
                        f"üí° Plage commune stricte (max d√©but, min fin) sur "
                        f"{len(symbols)} token(s) √ó {len(timeframes)} TF(s)"
                    )

                    default_start = common_start.date()
                    default_end = common_end.date()
                else:
                    st.warning("‚ö†Ô∏è Impossible de trouver une p√©riode commune (intersection vide)")
                    default_start = pd.Timestamp("2023-01-01").date()
                    default_end = pd.Timestamp.now().date()

            else:
                st.info("üìä **P√©riodes optimales par timeframe**:")

                best_timeframe = None
                best_score = 0.0

                for tf, data in timeframe_analysis.items():
                    st.write(f"**{tf}**")

                    if data['optimal_periods']:
                        best_period = data['optimal_periods'][0]
                        start_fr = best_period.start_date.strftime("%d/%m/%Y")
                        end_fr = best_period.end_date.strftime("%d/%m/%Y")
                        duration = (best_period.end_date - best_period.start_date).days

                        st.write(f"- üéØ {start_fr} ‚Üí {end_fr} ({duration}j)")
                        st.caption(
                            f"  Score: {best_period.completeness_score:.0f}%, "
                            f"Gap tol√©r√©: {data['gap_tolerance']:.0f}%"
                        )

                        for recommendation in data['recommendations']:
                            st.caption(f"  {recommendation}")

                        combined_score = best_period.completeness_score * best_period.avg_data_density
                        if combined_score > best_score:
                            best_score = combined_score
                            best_timeframe = tf
                            default_start = best_period.start_date.date()
                            default_end = best_period.end_date.date()
                    else:
                        st.write("- ‚ùå Aucune p√©riode optimale trouv√©e")

                if best_timeframe:
                    st.success(f"üèÜ **D√©faut bas√© sur {best_timeframe}** (meilleur score: {best_score:.1f})")
                else:
                    st.warning("‚ö†Ô∏è Aucune p√©riode optimale trouv√©e pour les timeframes s√©lectionn√©s")
                    default_start = pd.Timestamp("2023-01-01").date()
                    default_end = pd.Timestamp.now().date()

        # Interface dates avec format fran√ßais
        st.sidebar.caption("üìÖ **P√©riode d'analyse** (format: DD/MM/YYYY)")

        # Auto-aligner les dates sur la plage commune si hors limites.
        if default_start and default_end:
            selection_key = (
                tuple(sorted(symbols)),
                tuple(sorted(timeframes)),
                analysis_mode,
            )
            if st.session_state.get("_date_range_selection_key") != selection_key:
                st.session_state["start_date"] = default_start
                st.session_state["end_date"] = default_end
                st.session_state["_date_range_selection_key"] = selection_key

            start_state = st.session_state.get("start_date")
            end_state = st.session_state.get("end_date")
            if start_state and (start_state < default_start or start_state > default_end):
                st.session_state["start_date"] = default_start
            if end_state and (end_state < default_start or end_state > default_end):
                st.session_state["end_date"] = default_end

            if st.session_state.get("start_date") and st.session_state.get("end_date"):
                if st.session_state["start_date"] >= st.session_state["end_date"]:
                    st.session_state["start_date"] = default_start
                    st.session_state["end_date"] = default_end

        col1, col2 = st.sidebar.columns(2)
        with col1:
            start_date = st.date_input(
                "Date d√©but üìÖ",
                value=default_start,
                key="start_date",
                format="DD/MM/YYYY",
                help="Date de d√©but de la p√©riode d'analyse"
            )
        with col2:
            end_date = st.date_input(
                "Date fin üìÖ",
                value=default_end,
                key="end_date",
                format="DD/MM/YYYY",
                help="Date de fin de la p√©riode d'analyse"
            )

        # Validation que start_date < end_date
        if start_date and end_date and start_date >= end_date:
            st.sidebar.error("‚ö†Ô∏è La date de d√©but doit √™tre ant√©rieure √† la date de fin")

        # Affichage de la dur√©e s√©lectionn√©e
        if start_date and end_date and start_date < end_date:
            selected_days = (end_date - start_date).days
            st.sidebar.caption(f"üìä Dur√©e s√©lectionn√©e: **{selected_days} jours**")

        # Validation de la p√©riode par rapport √† la plage commune
        if availability_result.has_common_range and start_date and end_date:
            start_ts = pd.Timestamp(start_date, tz="UTC")
            end_ts = pd.Timestamp(end_date, tz="UTC")
            common_start = availability_result.common_start
            common_end = availability_result.common_end

            if end_ts < common_start:
                # P√©riode enti√®rement AVANT la plage commune
                st.sidebar.error(
                    f"‚ö†Ô∏è P√©riode demand√©e ({start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}) est AVANT "
                    f"la plage commune ({common_start.strftime('%d/%m/%Y')})"
                )
            elif start_ts > common_end:
                # P√©riode enti√®rement APR√àS la plage commune
                st.sidebar.error(
                    f"‚ö†Ô∏è P√©riode demand√©e ({start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}) est APR√àS "
                    f"la plage commune ({common_end.strftime('%d/%m/%Y')})"
                )
            elif start_ts < common_start:
                # D√©but demand√© AVANT la plage commune (mais fin OK)
                st.sidebar.warning(
                    f"‚ö†Ô∏è D√©but demand√© ({start_date.strftime('%d/%m/%Y')}) est AVANT la plage commune. "
                    f"Donn√©es r√©elles √† partir de **{common_start.strftime('%d/%m/%Y')}**"
                )
            elif end_ts > common_end:
                # Fin demand√©e APR√àS la plage commune (mais d√©but OK)
                st.sidebar.warning(
                    f"‚ö†Ô∏è Fin demand√©e ({end_date.strftime('%d/%m/%Y')}) est APR√àS la plage commune. "
                    f"Donn√©es r√©elles jusqu'√† **{common_end.strftime('%d/%m/%Y')}**"
                )

        # Affichage d√©taill√© de l'analyse des donn√©es
        with st.sidebar.expander("üîç Analyse d√©taill√©e des donn√©es", expanded=False):
            if availability_result.rows:
                df_analysis = pd.DataFrame(availability_result.rows)
                st.dataframe(
                    df_analysis,
                    width="stretch",
                    column_config={
                        "Token": st.column_config.TextColumn("Token", width="small"),
                        "TF": st.column_config.TextColumn("TF", width="small"),
                        "D√©but": st.column_config.TextColumn("D√©but", width="medium"),
                        "Fin": st.column_config.TextColumn("Fin", width="medium"),
                        "Jours": st.column_config.NumberColumn("Jours", width="small"),
                        "Plage commune %": st.column_config.NumberColumn("Plage commune %", format="%.1f%%", width="small"),
                        "Couverture %": st.column_config.NumberColumn("Couverture %", format="%.1f%%", width="small"),
                        "Manquant %": st.column_config.NumberColumn("Manquant %", format="%.1f%%", width="small"),
                        "Jours manquants": st.column_config.NumberColumn("Jours manquants", format="%.1f", width="small"),
                        "Status": st.column_config.TextColumn("Status", width="small"),
                        "D√©tails": st.column_config.TextColumn("D√©tails", width="large")
                    }
                )

                # Statistiques de l'analyse
                total_combos = len(df_analysis)
                complete_combos = len(df_analysis[df_analysis["Status"] == "‚úÖ"])
                incomplete_combos = len(df_analysis[df_analysis["Status"] == "‚ö†Ô∏è"])
                missing_combos = len(df_analysis[df_analysis["Status"] == "‚ùå"])

                st.markdown(f"""
                **R√©sum√© de l'analyse :**
                - ‚úÖ Compl√®tes : {complete_combos}/{total_combos}
                - ‚ö†Ô∏è Incompl√®tes : {incomplete_combos}/{total_combos}
                - ‚ùå Manquantes : {missing_combos}/{total_combos}
                """)

                if hasattr(availability_result, 'optimal_periods') and availability_result.optimal_periods:
                    st.markdown("üí° **Conseil :** Les p√©riodes optimales ci-dessus √©vitent automatiquement les zones avec trop de donn√©es manquantes.")
    else:
        start_date = None
        end_date = None

    current_data_key = _data_cache_key(symbol, timeframe, start_date, end_date)
    if st.session_state.get("ohlcv_cache_key") != current_data_key:
        st.session_state["ohlcv_cache_key"] = current_data_key
        st.session_state["ohlcv_df"] = None
        # FIX 04/01/2026: NE PAS effacer les r√©sultats quand les donn√©es changent
        # Les r√©sultats d'un backtest/grid peuvent √™tre visualis√©s ind√©pendamment
        # des donn√©es OHLCV actuellement charg√©es. Effacer les r√©sultats causait
        # la perte de tous les r√©sultats apr√®s un grid search lors du prochain rerun.
        # st.session_state["last_run_result"] = None
        # st.session_state["last_winner_params"] = None
        # st.session_state["last_winner_metrics"] = None
        # st.session_state["last_winner_origin"] = None
        # st.session_state["last_winner_meta"] = None

    pending_run_id = st.session_state.get("pending_run_load_id")
    if pending_run_id:
        try:
            storage = get_storage()
            result = storage.load_result(pending_run_id)
            st.session_state["last_run_result"] = result
            st.session_state["last_winner_params"] = result.meta.get("params", {})
            st.session_state["last_winner_metrics"] = result.metrics
            st.session_state["last_winner_origin"] = "storage"
            st.session_state["last_winner_meta"] = result.meta
            if st.session_state.get("pending_run_load_data", True):
                df_loaded, msg = load_selected_data(
                    symbol,
                    timeframe,
                    start_date,
                    end_date,
                )
                if df_loaded is None:
                    st.session_state["saved_runs_status"] = f"Data load failed: {msg}"
                else:
                    st.session_state["saved_runs_status"] = f"Run loaded with data: {msg}"
            else:
                st.session_state["saved_runs_status"] = f"Run loaded: {pending_run_id}"
        except Exception as exc:
            st.session_state["saved_runs_status"] = f"Load failed: {exc}"
        st.session_state.pop("pending_run_load_id", None)
        st.session_state.pop("pending_run_load_data", None)

    if st.sidebar.button("Charger donnees", key="load_ohlcv_button"):
        # DEBUG: Afficher les param√®tres de chargement
        st.sidebar.caption(f"üîç Debug: {symbol}/{timeframe}")
        df_loaded, msg = load_selected_data(symbol, timeframe, start_date, end_date)
        if df_loaded is None:
            st.sidebar.error(f"Erreur chargement: {msg}")
        else:
            st.sidebar.success(f"Donnees chargees: {msg}")
    else:
        if st.session_state.get("ohlcv_df") is None:
            st.sidebar.info("Donnees non chargees.")
        else:
            cached_msg = st.session_state.get("ohlcv_status_msg", "")
            if cached_msg:
                st.sidebar.caption(f"Cache: {cached_msg}")

    st.sidebar.subheader("üéØ Strat√©gie")

    available_strategies = list_strategies()
    strategy_options = build_strategy_options(available_strategies)
    strategy_name = st.sidebar.selectbox(
        "Strat√©gie",
        list(strategy_options.keys()),
    )
    strategy_key = strategy_options[strategy_name]

    st.sidebar.caption(get_strategy_description(strategy_key))

    strategy_info = None
    try:
        strategy_info = get_strategy_info(strategy_key)

        if strategy_info.required_indicators:
            indicators_list = ", ".join(
                [f"**{ind.upper()}**" for ind in strategy_info.required_indicators]
            )
            st.sidebar.info(f"üìä Indicateurs requis: {indicators_list}")
        else:
            st.sidebar.info("üìä Indicateurs: Calcul√©s internement")

        if strategy_info.internal_indicators:
            internal_list = ", ".join(
                [f"{ind.upper()}" for ind in strategy_info.internal_indicators]
            )
            st.sidebar.caption(f"_Calcul√©s: {internal_list}_")

    except KeyError:
        st.sidebar.warning(f"‚ö†Ô∏è Indicateurs non d√©finis pour '{strategy_key}'")

    st.sidebar.subheader("Indicateurs")
    available_indicators = get_strategy_ui_indicators(strategy_key)
    # Tous les indicateurs sont toujours affich√©s
    active_indicators: List[str] = available_indicators if available_indicators else []

    if available_indicators:
        st.sidebar.caption(f"üìä {len(available_indicators)} indicateur(s) : {', '.join(available_indicators)}")
    else:
        st.sidebar.caption("Aucun indicateur disponible.")

    st.sidebar.subheader("Versioned presets")

    versioned_presets = list_strategy_versions(strategy_key)

    if "_sync_preset_version" in st.session_state:
        st.session_state["versioned_preset_version"] = st.session_state.pop(
            "_sync_preset_version"
        )
    if "_sync_preset_name" in st.session_state:
        st.session_state["versioned_preset_name"] = st.session_state.pop(
            "_sync_preset_name"
        )

    last_saved = st.session_state.pop("versioned_preset_last_saved", None)
    if last_saved:
        st.sidebar.success(f"Preset saved: {last_saved}")

    if versioned_presets:
        versions = []
        for preset in versioned_presets:
            meta = preset.metadata or {}
            version = meta.get("version")
            if version and version not in versions:
                versions.append(version)

        default_version = resolve_latest_version(strategy_key)
        if default_version in versions:
            default_index = versions.index(default_version)
        else:
            default_index = 0

        if (
            "versioned_preset_version" in st.session_state
            and st.session_state["versioned_preset_version"] not in versions
        ):
            del st.session_state["versioned_preset_version"]

        selected_version = st.sidebar.selectbox(
            "Preset version",
            versions,
            index=default_index,
            key="versioned_preset_version",
        )

        presets_for_version = [
            p for p in versioned_presets if (p.metadata or {}).get("version") == selected_version
        ]
        preset_names = [p.name for p in presets_for_version]

        if (
            "versioned_preset_name" in st.session_state
            and st.session_state["versioned_preset_name"] not in preset_names
        ):
            del st.session_state["versioned_preset_name"]

        selected_preset_name = st.sidebar.selectbox(
            "Preset",
            preset_names,
            key="versioned_preset_name",
        )

        selected_preset = next(
            (p for p in presets_for_version if p.name == selected_preset_name),
            None,
        )

        if selected_preset is not None:
            meta = selected_preset.metadata or {}
            created_at = meta.get("created_at", "")
            if created_at:
                st.sidebar.caption(f"Created: {created_at}")

            indicators = selected_preset.indicators or []
            if indicators:
                st.sidebar.caption(f"Indicators: {', '.join(indicators)}")

            params_values = selected_preset.get_default_values()
            if params_values:
                st.sidebar.json(params_values)

            metrics = meta.get("metrics") or {}
            summary_keys = [
                "sharpe_ratio",
                "total_return_pct",
                "max_drawdown",
                "win_rate",
            ]
            summary = {k: metrics.get(k) for k in summary_keys if k in metrics}
            if summary:
                st.sidebar.json(summary)

        if st.sidebar.button("Load versioned preset", key="load_versioned_preset"):
            try:
                loaded_preset = load_strategy_version(
                    strategy_name=strategy_key,
                    version=selected_version,
                    preset_name=selected_preset_name,
                )
                apply_versioned_preset(loaded_preset, strategy_key)
                st.session_state["loaded_versioned_preset"] = loaded_preset.to_dict()
                st.sidebar.success("Versioned preset loaded")
            except Exception as exc:
                st.sidebar.error(f"Failed to load preset: {exc}")
    else:
        st.sidebar.caption("No versioned presets found.")

    st.sidebar.subheader("üîÑ Mode d'ex√©cution")

    if "optimization_mode" not in st.session_state:
        st.session_state.optimization_mode = "Backtest Simple"

    st.sidebar.markdown(MODE_BUTTON_CSS, unsafe_allow_html=True)

    for mode_name, icon, description in MODE_OPTIONS:
        button_key = f"mode_btn_{mode_name}"
        is_active = st.session_state.optimization_mode == mode_name

        col1, col2 = st.sidebar.columns([1, 10])
        with col1:
            st.write(icon)
        with col2:
            if st.button(
                mode_name,
                key=button_key,
                help=description,
                width="stretch",
                type="primary" if is_active else "secondary",
            ):
                st.session_state.optimization_mode = mode_name
                st.rerun()

    optimization_mode = st.session_state.optimization_mode

    st.sidebar.caption(f"‚ÑπÔ∏è Mode actif: **{optimization_mode}**")

    # LIMITE S√âCURIT√â : 1M combinaisons max par d√©faut (au lieu de 100M)
    max_combos = 30_000_000  # Limite optimis√©e pour exploitation multi-GPU
    # üöÄ BOOST PERFORMANCE: 30 millions de combinaisons pour
    # exploiter pleinement les 2 cartes graphiques
    n_workers = 40  # Augment√© pour dual-GPU utilization

    # Configuration Optuna (int√©gr√©e dans Grille de Param√®tres)
    use_optuna = False
    optuna_n_trials = 100
    optuna_sampler = "tpe"
    optuna_pruning = True
    optuna_metric = "sharpe_ratio"
    optuna_early_stop = 0  # 0 = d√©sactiv√© par d√©faut

    if optimization_mode == "Grille de Param√®tres":
        st.sidebar.markdown("---")
        st.sidebar.subheader("‚öôÔ∏è M√©thode d'exploration")

        use_optuna = st.sidebar.checkbox(
            "Utiliser Optuna (Bay√©sien) ‚ö°",
            value=False,
            help="Optuna explore intelligemment l'espace des param√®tres (10-100x plus rapide que la grille exhaustive)",
        )

        if use_optuna:
            st.sidebar.caption("üéØ **Mode Bay√©sien** - Exploration intelligente")

            optuna_n_trials = st.sidebar.number_input(
                "Nombre de trials",
                min_value=10,
                max_value=10000,
                value=200,
                step=10,
                help="Nombre d'essais bay√©siens (100-500 recommand√©)",
            )

            optuna_sampler = st.sidebar.selectbox(
                "Algorithme",
                ["tpe", "cmaes", "random"],
                index=0,
                help="TPE: Rapide et efficace | CMA-ES: Pour espaces continus | Random: Baseline",
            )

            optuna_metric = st.sidebar.selectbox(
                "M√©trique √† optimiser",
                ["sharpe_ratio", "sortino_ratio", "total_return_pct", "profit_factor", "calmar_ratio"],
                index=0,
                help="M√©trique principale pour l'optimisation",
            )

            optuna_pruning = st.sidebar.checkbox(
                "Pruning (arr√™t pr√©coce) ‚úÇÔ∏è",
                value=True,
                help="Abandonne les trials peu prometteurs pour acc√©l√©rer",
            )

            # Early stop: 0 = d√©sactiv√©, sinon patience en nombre de trials
            optuna_early_stop = st.sidebar.slider(
                "Early stop patience (0=d√©sactiv√©)",
                min_value=0,
                max_value=max(200, optuna_n_trials),
                value=0,  # D√©sactiv√© par d√©faut pour ne pas interrompre pr√©matur√©ment
                help="Arr√™t apr√®s N trials sans am√©lioration. 0 = d√©sactiv√© (recommand√© pour explorer compl√®tement)",
            )

            n_workers = st.sidebar.slider(
                "Workers parall√®les",
                min_value=1,
                max_value=32,
                value=8,
                help="Nombre de trials √©valu√©s en parall√®le",
            )

            st.sidebar.caption(f"‚ö° {optuna_n_trials} trials √ó {n_workers} workers")
        else:
            st.sidebar.caption("üî¢ **Mode Grille** - Exploration exhaustive")

            max_combos = st.sidebar.number_input(
                "Max combinaisons [üöÄ GPU OPTIMIZED]",
                min_value=10,
                max_value=100000000,
                value=30000000,  # Valeur par d√©faut optimis√©e pour GPU
                step=100000,
                help="Limite de combinaisons optimis√©e pour dual-GPU (10 - 100M).",
            )

            n_workers = st.sidebar.slider(
                "Workers parall√®les [üöÄ GPU]",
                min_value=1,
                max_value=61,  # Limite syst√®me Windows
                value=24,      # Optimis√© pour 9950X (32 threads) - balance perf/overhead
                help="24-32 recommand√© pour 9950X. Donn√©es pr√©-charg√©es = initialisation rapide",
            )

    llm_config = None
    llm_max_iterations = 10
    llm_use_walk_forward = True
    role_model_config = None
    llm_compare_enabled = False
    llm_compare_auto_run = True
    llm_compare_strategies: List[str] = []
    llm_compare_tokens: List[str] = []
    llm_compare_timeframes: List[str] = []
    llm_compare_metric = "sharpe_ratio"
    llm_compare_aggregate = "median"
    llm_compare_max_runs = 25
    llm_compare_use_preset = True
    llm_compare_generate_report = True
    llm_use_multi_agent = False
    llm_use_multi_model = False
    llm_limit_small_models = False
    llm_unload_during_backtest = False
    llm_model = None

    if optimization_mode == "ü§ñ Optimisation LLM":
        st.sidebar.markdown("---")
        st.sidebar.subheader("üß† Configuration LLM")

        st.sidebar.markdown("---")
        st.sidebar.caption("**‚öôÔ∏è Param√®tres d'ex√©cution**")

        max_combos = st.sidebar.number_input(
            "Max combinaisons [üöÄ LLM+GPU]",
            min_value=10,
            max_value=100000000,
            value=30000000,  # Optimis√© pour dual-GPU
            step=100000,
            help="Limite optimis√©e pour LLM + dual-GPU (10 - 100M)",
            key="llm_max_combos",
        )

        n_workers = st.sidebar.slider(
            "Workers parall√®les",
            min_value=1,
            max_value=32,
            value=30,
            help="Nombre de backtests ex√©cut√©s en parall√®le (30 recommand√©)",
            key="llm_n_workers",
        )

        st.sidebar.caption(
            f"üîß Parall√©lisation: jusqu'√† {n_workers} backtests simultan√©s"
        )
        st.sidebar.markdown("---")

        if not LLM_AVAILABLE:
            st.sidebar.error("‚ùå Module LLM non disponible")
            st.sidebar.caption(f"Erreur: {LLM_IMPORT_ERROR}")
        else:
            llm_provider = st.sidebar.selectbox(
                "Provider LLM",
                ["Ollama (Local)", "OpenAI"],
                help="Ollama = gratuit et local | OpenAI = API payante",
            )

            llm_use_multi_agent = st.sidebar.checkbox(
                "Mode multi-agents üë•",
                value=False,
                key="llm_use_multi_agent",
                help="Utiliser Analyst/Strategist/Critic/Validator",
            )

            def _extract_model_params_b(model_name: str) -> Optional[float]:
                match = re.search(r"(\d+(?:\.\d+)?)b", model_name.lower())
                if match:
                    return float(match.group(1))
                return None

            def _is_model_under_limit(model_name: str, limit: float) -> bool:
                size = _extract_model_params_b(model_name)
                if size is None:
                    return False
                return size < limit

            def _is_model_over_limit(model_name: str, limit: float) -> bool:
                size = _extract_model_params_b(model_name)
                if size is None:
                    return False
                return size >= limit

            if "Ollama" in llm_provider:
                if is_ollama_available():
                    st.sidebar.success("‚úÖ Ollama connect√©")
                else:
                    st.sidebar.warning("‚ö†Ô∏è Ollama non d√©tect√©")
                    if st.sidebar.button("üöÄ D√©marrer Ollama"):
                        with st.spinner("D√©marrage d'Ollama..."):
                            success, msg = ensure_ollama_running()
                            if success:
                                st.sidebar.success(msg)
                                st.rerun()
                            else:
                                st.sidebar.error(msg)

                llm_use_multi_model = False
                if llm_use_multi_agent:
                    llm_use_multi_model = st.sidebar.checkbox(
                        "Multi-modeles par role",
                        value=False,
                        key="llm_use_multi_model",
                        help="Assigner differents modeles a chaque role d'agent",
                    )

                if llm_use_multi_model:
                    available_models_list = list_available_models()
                    available_model_names = [m.name for m in available_models_list]

                    llm_limit_small_models = st.sidebar.checkbox(
                        "Limiter selection aleatoire a <20B",
                        value=True,
                        key="llm_limit_small_models",
                        help="Filtre la liste par taille et exclut deepseek-r1:70b",
                    )
                    llm_limit_large_models = st.sidebar.checkbox(
                        "Limiter selection aleatoire a >=20B",
                        value=False,
                        key="llm_limit_large_models",
                        help="Filtre la liste par taille (>=20B uniquement)",
                    )

                    effective_small_filter = llm_limit_small_models
                    effective_large_filter = llm_limit_large_models
                    if effective_small_filter and effective_large_filter:
                        st.sidebar.warning(
                            "Filtres <20B et >=20B actifs: >=20B prioritaire."
                        )
                        effective_small_filter = False

                    excluded_models = set()
                    if not effective_large_filter:
                        excluded_models = {"deepseek-r1:70b"}
                    if excluded_models:
                        available_model_names = [
                            m for m in available_model_names if m not in excluded_models
                        ]

                    if effective_small_filter:
                        filtered = [
                            m for m in available_model_names if _is_model_under_limit(m, 20)
                        ]
                        if filtered:
                            available_model_names = filtered
                        else:
                            st.sidebar.warning(
                                "Aucun modele <20B detecte, filtre desactive."
                            )

                    if effective_large_filter:
                        filtered = [
                            m for m in available_model_names if _is_model_over_limit(m, 20)
                        ]
                        if filtered:
                            available_model_names = filtered
                        else:
                            available_model_names = []
                            st.sidebar.warning("Aucun modele >=20B detecte.")
                    if effective_large_filter and not available_model_names:
                        st.sidebar.error(
                            "Selection >=20B activee mais aucun modele compatible."
                        )

                    st.sidebar.markdown("---")
                    st.sidebar.caption("**Configuration des mod√®les**")

                    # ===== GESTION DES PRESETS =====
                    from ui.model_presets import (
                        apply_preset_to_config,
                        delete_model_preset,
                        get_current_config_as_dict,
                        list_model_presets,
                        load_model_preset,
                        save_model_preset,
                    )

                    # Lister tous les presets
                    all_presets = list_model_presets()
                    preset_names = [p["name"] for p in all_presets]

                    # Selectbox pour choisir un preset
                    col1, col2 = st.sidebar.columns([3, 1])
                    with col1:
                        selected_preset = st.selectbox(
                            "Charger un preset",
                            options=["Aucun (manuel)"] + preset_names,
                            key="selected_model_preset",
                            help="Charge une configuration pr√©d√©finie de mod√®les LLM"
                        )

                    with col2:
                        # Bouton pour appliquer le preset
                        if selected_preset != "Aucun (manuel)":
                            if st.button("‚ö°", key="apply_preset", help="Appliquer ce preset"):
                                preset = load_model_preset(selected_preset)
                                apply_preset_to_config(preset, get_global_model_config())
                                st.rerun()

                    # Expander pour sauvegarder/g√©rer les presets
                    with st.sidebar.expander("üíæ G√©rer les presets"):
                        user_presets = [p for p in all_presets if not p.get("builtin", False)]

                        # Tab pour organiser les actions
                        action_choice = st.radio(
                            "Action",
                            ["‚ûï Cr√©er nouveau", "‚úèÔ∏è Modifier existant", "üóëÔ∏è Supprimer"],
                            key="preset_action",
                            horizontal=True
                        )

                        if action_choice == "‚ûï Cr√©er nouveau":
                            st.markdown("**Cr√©er un nouveau preset**")
                            new_preset_name = st.text_input(
                                "Nom du preset",
                                key="new_preset_name",
                                placeholder="Ex: Pr√©cis, Rapide, Test..."
                            )
                            st.caption("üí° Ajustez les mod√®les ci-dessous avant de sauvegarder")

                            if st.button("üíæ Cr√©er", key="create_preset"):
                                if new_preset_name.strip():
                                    try:
                                        current_config = get_current_config_as_dict(get_global_model_config())
                                        save_model_preset(new_preset_name.strip(), current_config["models"])
                                        st.success(f"‚úÖ Preset '{new_preset_name}' cr√©√©")
                                        st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                                else:
                                    st.error("Nom de preset requis")

                        elif action_choice == "‚úèÔ∏è Modifier existant":
                            st.markdown("**Modifier un preset existant**")
                            if user_presets:
                                preset_to_modify = st.selectbox(
                                    "Preset √† modifier",
                                    options=[p["name"] for p in user_presets],
                                    key="preset_to_modify"
                                )
                                st.caption("üí° Chargez le preset ci-dessus, ajustez les mod√®les, puis sauvegardez")

                                if st.button("üíæ Sauvegarder modifications", key="update_preset"):
                                    try:
                                        current_config = get_current_config_as_dict(get_global_model_config())
                                        save_model_preset(preset_to_modify, current_config["models"])
                                        st.success(f"‚úÖ Preset '{preset_to_modify}' mis √† jour")
                                        st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                            else:
                                st.info("Aucun preset utilisateur √† modifier")

                        elif action_choice == "üóëÔ∏è Supprimer":
                            st.markdown("**Supprimer un preset**")
                            if user_presets:
                                preset_to_delete = st.selectbox(
                                    "Preset √† supprimer",
                                    options=[p["name"] for p in user_presets],
                                    key="preset_to_delete"
                                )
                                st.warning(f"‚ö†Ô∏è Supprimer '{preset_to_delete}' d√©finitivement ?")

                                if st.button("üóëÔ∏è Confirmer suppression", key="delete_preset"):
                                    try:
                                        if delete_model_preset(preset_to_delete):
                                            st.success(f"‚úÖ Preset '{preset_to_delete}' supprim√©")
                                            st.rerun()
                                    except ValueError as e:
                                        st.error(f"‚ùå {e}")
                            else:
                                st.info("Aucun preset utilisateur √† supprimer")

                    st.sidebar.markdown("---")
                    st.sidebar.caption("**Modeles par role d'agent**")
                    st.sidebar.caption("Rapide | Moyen | Lent")

                    # Checkbox pour pr√©-configuration optimale
                    use_optimal_config = st.sidebar.checkbox(
                        "Pr√©-config optimale",
                        value=False,
                        key="use_optimal_model_config",
                        help=(
                            "Active la configuration recommand√©e bas√©e sur les benchmarks:\n"
                            "‚Ä¢ Analyst ‚Üí qwen2.5:14b (rapide)\n"
                            "‚Ä¢ Strategist ‚Üí gemma3:27b (√©quilibr√©)\n"
                            "‚Ä¢ Critic ‚Üí llama3.3-70b-optimized (puissant)\n"
                            "‚Ä¢ Validator ‚Üí llama3.3-70b-optimized (critique)"
                        ),
                    )

                    if use_optimal_config:
                        st.sidebar.info(
                            "üí° Configuration optimale activ√©e. "
                            "Vous pouvez ajuster manuellement les s√©lections ci-dessous."
                        )

                    role_model_config = get_global_model_config()

                    def model_with_badge(name: str) -> str:
                        info = KNOWN_MODELS.get(name)
                        if info:
                            if info.category == ModelCategory.LIGHT:
                                return f"[L] {name}"
                            if info.category == ModelCategory.MEDIUM:
                                return f"[M] {name}"
                            return f"[H] {name}"
                        return name

                    model_options_display = [
                        model_with_badge(m) for m in available_model_names
                    ]
                    name_to_display = {
                        n: model_with_badge(n) for n in available_model_names
                    }
                    display_to_name = {v: k for k, v in name_to_display.items()}

                    use_single_model_for_roles = st.sidebar.checkbox(
                        "M√™me mod√®le pour tous les r√¥les",
                        value=False,
                        key="llm_single_model_for_roles",
                        help="Applique un seul mod√®le √† Analyst/Strategist/Critic/Validator.",
                    )

                    single_model_selection = None
                    if use_single_model_for_roles:
                        if model_options_display:
                            default_model = (
                                role_model_config.analyst.models[0]
                                if role_model_config.analyst.models
                                else (available_model_names[0] if available_model_names else None)
                            )
                            default_display = name_to_display.get(
                                default_model, model_options_display[0]
                            )
                            default_index = (
                                model_options_display.index(default_display)
                                if default_display in model_options_display
                                else 0
                            )
                            single_model_selection = st.sidebar.selectbox(
                                "Mod√®le unique (tous r√¥les)",
                                model_options_display,
                                index=default_index,
                                key="llm_single_model_for_roles_name",
                                help="Ce mod√®le sera utilis√© pour tous les r√¥les.",
                            )
                        else:
                            st.sidebar.warning(
                                "Aucun mod√®le disponible pour unifier les r√¥les."
                            )

                    st.sidebar.markdown("**Analyst** (analyse rapide)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("analyst", [])
                        analyst_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        from ui.components.model_selector import get_optimal_config_for_role
                        optimal_analyst = get_optimal_config_for_role("analyst", available_model_names)
                        analyst_default_options = [
                            name_to_display.get(m, m) for m in optimal_analyst
                        ]
                    else:
                        # Comportement existant
                        analyst_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.analyst.models
                            if m in available_model_names
                        ]
                        analyst_default_options = (
                            analyst_defaults[:3] if analyst_defaults else model_options_display[:2]
                        )

                    if not model_options_display:
                        analyst_default_options = []

                    analyst_selection = st.sidebar.multiselect(
                        "Modeles Analyst",
                        model_options_display,
                        default=analyst_default_options,
                        key="analyst_models",
                        help="Modeles rapides recommandes pour l'analyse",
                    )

                    st.sidebar.markdown("**Strategist** (propositions)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("strategist", [])
                        strategist_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_strategist = get_optimal_config_for_role("strategist", available_model_names)
                        strategist_default_options = [
                            name_to_display.get(m, m) for m in optimal_strategist
                        ]
                    else:
                        # Comportement existant
                        strategist_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.strategist.models
                            if m in available_model_names
                        ]
                        strategist_default_options = (
                            strategist_defaults[:3]
                            if strategist_defaults
                            else model_options_display[:2]
                        )

                    if not model_options_display:
                        strategist_default_options = []

                    strategist_selection = st.sidebar.multiselect(
                        "Modeles Strategist",
                        model_options_display,
                        default=strategist_default_options,
                        key="strategist_models",
                        help="Modeles moyens pour la creativite",
                    )

                    st.sidebar.markdown("**Critic** (evaluation critique)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("critic", [])
                        critic_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_critic = get_optimal_config_for_role("critic", available_model_names)
                        critic_default_options = [
                            name_to_display.get(m, m) for m in optimal_critic
                        ]
                    else:
                        # Comportement existant
                        critic_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.critic.models
                            if m in available_model_names
                        ]
                        critic_default_options = (
                            critic_defaults[:3] if critic_defaults else model_options_display[:2]
                        )

                    if not model_options_display:
                        critic_default_options = []

                    critic_selection = st.sidebar.multiselect(
                        "Modeles Critic",
                        model_options_display,
                        default=critic_default_options,
                        key="critic_models",
                        help="Modeles puissants pour la reflexion",
                    )

                    st.sidebar.markdown("**Validator** (decision finale)")

                    if selected_preset and selected_preset != "Aucun (manuel)":
                        # Charger le preset et utiliser ses mod√®les
                        preset = load_model_preset(selected_preset)
                        preset_models = preset["models"].get("validator", [])
                        validator_default_options = [
                            name_to_display.get(m, m)
                            for m in preset_models
                            if m in available_model_names
                        ]
                    elif use_optimal_config:
                        # Utiliser la config optimale
                        optimal_validator = get_optimal_config_for_role("validator", available_model_names)
                        validator_default_options = [
                            name_to_display.get(m, m) for m in optimal_validator
                        ]
                    else:
                        # Comportement existant
                        validator_defaults = [
                            name_to_display.get(m, m)
                            for m in role_model_config.validator.models
                            if m in available_model_names
                        ]
                        validator_default_options = (
                            validator_defaults[:3]
                            if validator_defaults
                            else model_options_display[:2]
                        )

                    if not model_options_display:
                        validator_default_options = []

                    validator_selection = st.sidebar.multiselect(
                        "Modeles Validator",
                        model_options_display,
                        default=validator_default_options,
                        key="validator_models",
                        help="Modeles puissants pour decisions finales",
                    )

                    if use_single_model_for_roles and single_model_selection:
                        analyst_selection = [single_model_selection]
                        strategist_selection = [single_model_selection]
                        critic_selection = [single_model_selection]
                        validator_selection = [single_model_selection]

                    st.sidebar.markdown("---")
                    st.sidebar.caption("Modeles lourds")
                    heavy_after_iter = st.sidebar.number_input(
                        "Autoriser apres iteration N",
                        min_value=1,
                        max_value=20,
                        value=3,
                        help="Les modeles lourds ne seront utilises qu'apres cette iteration",
                    )

                    def _normalize_selection(selection: List[str]) -> List[str]:
                        names = [display_to_name.get(m, m) for m in selection]
                        return [n for n in names if n in available_model_names]

                    role_model_config.analyst.models = _normalize_selection(analyst_selection)
                    role_model_config.strategist.models = _normalize_selection(strategist_selection)
                    role_model_config.critic.models = _normalize_selection(critic_selection)
                    role_model_config.validator.models = _normalize_selection(validator_selection)

                    for assignment in [
                        role_model_config.analyst,
                        role_model_config.strategist,
                        role_model_config.critic,
                        role_model_config.validator,
                    ]:
                        assignment.allow_heavy_after_iteration = heavy_after_iter

                    set_global_model_config(role_model_config)

                    st.sidebar.info(
                        "Si plusieurs modeles sont selectionnes, "
                        "un sera choisi aleatoirement a chaque appel."
                    )

                    if role_model_config.analyst.models:
                        llm_model = role_model_config.analyst.models[0]
                    elif available_model_names:
                        llm_model = available_model_names[0]
                    elif effective_large_filter:
                        llm_model = None
                    else:
                        llm_model = "deepseek-r1:8b"

                else:
                    available_models = get_available_models_for_ui(
                        preferred_order=RECOMMENDED_FOR_STRATEGY
                    )

                    llm_model = st.sidebar.selectbox(
                        "Mod√®le Ollama",
                        available_models,
                        help="Mod√®les install√©s localement via Ollama",
                    )

                    if llm_model:
                        model_info = get_model_info(llm_model)
                        size = model_info["size_gb"]
                        desc = model_info["description"]
                        st.sidebar.caption(f"üì¶ ~{size} GB | {desc}")

                ollama_host = st.sidebar.text_input(
                    "URL Ollama",
                    value="http://localhost:11434",
                    help="Adresse du serveur Ollama",
                )
                if llm_model:
                    llm_config = LLMConfig(
                        provider=LLMProvider.OLLAMA,
                        model=llm_model,
                        ollama_host=ollama_host,
                    )
                else:
                    llm_config = None
            else:
                openai_key = st.sidebar.text_input(
                    "Cl√© API OpenAI",
                    type="password",
                    help="Votre cl√© API OpenAI",
                )
                llm_model = st.sidebar.selectbox(
                    "Mod√®le OpenAI",
                    ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
                    help="gpt-4o-mini recommand√© pour co√ªt/performance",
                )
                if openai_key:
                    llm_config = LLMConfig(
                        provider=LLMProvider.OPENAI,
                        model=llm_model,
                        api_key=openai_key,
                    )
                else:
                    st.sidebar.warning("‚ö†Ô∏è Cl√© API requise")

            st.sidebar.markdown("---")
            st.sidebar.caption("**Options d'optimisation**")

            llm_unlimited_iterations = st.sidebar.checkbox(
                "It√©rations illimit√©es",
                value=True,
                key="llm_unlimited_iterations",
                help="Lance l'optimisation sans limite d'it√©rations (arr√™t manuel requis)",
            )

            if llm_unlimited_iterations:
                llm_max_iterations = 0
                st.sidebar.caption("‚àû it√©rations (arr√™t manuel)")
            else:
                llm_max_iterations = st.sidebar.slider(
                    "Max it√©rations",
                    min_value=3,
                    max_value=50,
                    value=10,
                    help="Nombre max de cycles d'am√©lioration",
                )

            walk_forward_enabled = True
            walk_forward_reason = ""

            df_cached = st.session_state.get("ohlcv_df")
            if df_cached is not None and not df_cached.empty:
                data_duration_days = (df_cached.index[-1] - df_cached.index[0]).days
                data_duration_months = data_duration_days / 30.44

                if data_duration_months < 6:
                    walk_forward_enabled = False
                    walk_forward_reason = (
                        "‚ö†Ô∏è Walk-Forward d√©sactiv√© "
                        f"(dur√©e: {data_duration_months:.1f} mois < 6 mois requis)"
                    )
                else:
                    walk_forward_reason = (
                        f"‚úÖ Walk-Forward disponible (dur√©e: {data_duration_months:.1f} mois)"
                    )

            if walk_forward_reason:
                if walk_forward_enabled:
                    st.sidebar.caption(walk_forward_reason)
                else:
                    st.sidebar.warning(walk_forward_reason)

            llm_use_walk_forward = st.sidebar.checkbox(
                "Walk-Forward Validation",
                value=walk_forward_enabled,
                disabled=not walk_forward_enabled,
                help=(
                    "Anti-overfitting: valide sur donn√©es hors-√©chantillon "
                    "(n√©cessite >6 mois de donn√©es)"
                ),
            )

            llm_unload_during_backtest = st.sidebar.checkbox(
                "D√©charger LLM du GPU",
                value=False,
                help=(
                    "Lib√®re la VRAM GPU pendant les backtests pour am√©liorer les performances. "
                    "Recommand√© si vous utilisez CuPy/GPU pour les indicateurs. "
                    "D√©sactiv√© par d√©faut (compatibilit√© CPU-only)."
                ),
            )

            st.sidebar.markdown("---")
            with st.sidebar.expander("Comparaison multi-strategies", expanded=False):
                llm_compare_enabled = st.checkbox(
                    "Comparer strategies (multi-tokens/timeframes)",
                    value=False,
                    key="llm_compare_enabled",
                )
                if llm_compare_enabled:
                    llm_compare_auto_run = st.checkbox(
                        "Execution automatique",
                        value=True,
                        key="llm_compare_auto_run",
                        help="Lance la comparaison avant l'optimisation LLM",
                    )
                    compare_strategy_labels = st.multiselect(
                        "Strategies a comparer",
                        list(strategy_options.keys()),
                        default=[strategy_name],
                        key="llm_compare_strategy_labels",
                    )
                    llm_compare_strategies = [
                        strategy_options[label]
                        for label in compare_strategy_labels
                        if label in strategy_options
                    ]

                    llm_compare_tokens = st.multiselect(
                        "Tokens",
                        available_tokens,
                        default=[symbol],
                        key="llm_compare_tokens",
                    )
                    llm_compare_timeframes = st.multiselect(
                        "Timeframes",
                        available_timeframes,
                        default=[timeframe],
                        key="llm_compare_timeframes",
                    )

                    llm_compare_metric = st.selectbox(
                        "Metrica principale",
                        [
                            "sharpe_ratio",
                            "total_return_pct",
                            "max_drawdown",
                            "win_rate",
                        ],
                        index=0,
                        key="llm_compare_metric",
                    )
                    llm_compare_aggregate = st.selectbox(
                        "Agregation",
                        ["median", "mean", "worst"],
                        index=0,
                        key="llm_compare_aggregate",
                    )
                    llm_compare_max_runs = st.number_input(
                        "Max runs comparaison",
                        min_value=1,
                        max_value=500,
                        value=25,
                        step=1,
                        key="llm_compare_max_runs",
                    )
                    llm_compare_use_preset = st.checkbox(
                        "Utiliser presets si disponibles",
                        value=True,
                        key="llm_compare_use_preset",
                    )
                    llm_compare_generate_report = st.checkbox(
                        "Generer justification LLM",
                        value=True,
                        key="llm_compare_generate_report",
                    )

                    if (
                        llm_compare_strategies
                        and llm_compare_tokens
                        and llm_compare_timeframes
                    ):
                        total_runs = (
                            len(llm_compare_strategies)
                            * len(llm_compare_tokens)
                            * len(llm_compare_timeframes)
                        )
                        st.caption(
                            f"Estime: {total_runs} runs (cap {llm_compare_max_runs})."
                        )

                    if not llm_compare_auto_run:
                        if "llm_compare_run_now" not in st.session_state:
                            st.session_state["llm_compare_run_now"] = False
                        if st.button("Lancer comparaison", key="llm_compare_run_button"):
                            st.session_state["llm_compare_run_now"] = True
                else:
                    if "llm_compare_run_now" in st.session_state:
                        st.session_state["llm_compare_run_now"] = False

            if llm_use_multi_agent:
                max_iter_label = "‚àû" if llm_max_iterations <= 0 else str(llm_max_iterations)
                st.sidebar.caption(
                    "Agents: Analyst/Strategist/Critic/Validator | "
                    f"Max iterations: {max_iter_label}"
                )
            else:
                max_iter_label = "‚àû" if llm_max_iterations <= 0 else str(llm_max_iterations)
                st.sidebar.caption(
                    f"Agent autonome | Max iterations: {max_iter_label}"
                )

    st.sidebar.subheader("üîß Param√®tres")

    param_mode = "range" if optimization_mode == "Grille de Param√®tres" else "single"

    params: Dict[str, Any] = {}
    param_ranges: Dict[str, Any] = {}
    param_specs: Dict[str, Any] = {}
    strategy_class = get_strategy(strategy_key)
    strategy_instance = None

    if strategy_class:
        temp_strategy = strategy_class()
        strategy_instance = temp_strategy
        param_specs = temp_strategy.parameter_specs or {}
        label_overrides: Dict[str, str] = {}

        if strategy_key == "bollinger_best_longe_3i":
            label_overrides = {
                "entry_level": "Entr√©e",
                "tp_level": "Sortie_gagnante",
                "sl_level": "Stop-loss",
                "bb_std": "Bollinger_amplitude",
                "bb_period": "Bollinger_signal",
            }

        if param_specs:
            validation_errors = []

            for param_name, spec in param_specs.items():
                if not getattr(spec, "optimize", True):
                    continue

                if param_mode == "single":
                    value = create_param_range_selector(
                        param_name,
                        strategy_key,
                        mode="single",
                        spec=spec,
                        label=label_overrides.get(param_name),
                    )
                    if value is not None:
                        params[param_name] = value

                        is_valid, error = validate_param(param_name, value)
                        if not is_valid:
                            validation_errors.append(error)
                else:
                    range_data = create_param_range_selector(
                        param_name,
                        strategy_key,
                        mode="range",
                        spec=spec,
                        label=label_overrides.get(param_name),
                    )
                    if range_data is not None:
                        param_ranges[param_name] = range_data
                        if spec is not None:
                            params[param_name] = spec.default
                        else:
                            params[param_name] = PARAM_CONSTRAINTS[param_name]["default"]
                        # DEBUG: Afficher les ranges g√©n√©r√©s
                        print(f"[DEBUG] param_ranges[{param_name}] = {range_data}")

            if validation_errors:
                for err in validation_errors:
                    st.sidebar.error(err)

            # DEBUG: Afficher le r√©sum√© des param_ranges
            print(f"[DEBUG] param_ranges final = {list(param_ranges.keys())}")
            print(f"[DEBUG] Total param√®tres optimisables: {sum(1 for s in param_specs.values() if getattr(s, 'optimize', True))}")

            if param_mode == "range" and param_ranges:
                st.sidebar.markdown("---")
                stats = compute_search_space_stats(
                    param_ranges,
                    max_combinations=max_combos,
                )

                if stats.is_continuous:
                    st.sidebar.info("‚ÑπÔ∏è Espace continu d√©tect√©")
                elif stats.has_overflow:
                    st.sidebar.warning(
                        f"‚ö†Ô∏è {stats.total_combinations:,} combinaisons (limite: {max_combos:,})"
                    )
                    st.sidebar.caption("R√©duisez les plages ou augmentez le step")
                else:
                    st.sidebar.success(
                        f"‚úÖ {stats.total_combinations:,} combinaisons √† tester"
                    )

                with st.sidebar.expander("üìä D√©tail par param√®tre"):
                    for pname, pcount in stats.per_param_counts.items():
                        st.caption(f"‚Ä¢ {pname}: {pcount} valeurs")
            else:
                st.sidebar.caption("üìä Mode simple: 1 combinaison")
    else:
        st.sidebar.error(f"Strat√©gie '{strategy_key}' non trouv√©e")

    st.sidebar.subheader("üí∞ Trading")

    # Checkbox pour activer/d√©sactiver le leverage
    leverage_enabled = st.sidebar.checkbox(
        "ÔøΩ Activer le leverage",
        value=False,  # D√©sactiv√© par d√©faut = leverage forc√© √† 1
        key="leverage_enabled",
        help="Si d√©coch√©, leverage=1 (sans effet de levier). Recommand√© pour tests s√ªrs.",
    )

    if leverage_enabled:
        leverage = create_param_range_selector("leverage", "trading", mode="single")
        params["leverage"] = leverage
    else:
        leverage = 1.0
        params["leverage"] = 1.0
        st.sidebar.caption("_Leverage d√©sactiv√© ‚Üí forc√© √† 1√ó_")

    initial_capital = st.sidebar.number_input(
        "Capital Initial ($)",
        min_value=1000,
        max_value=1000000,
        value=10000,
        step=1000,
        help="Capital de d√©part (1,000 - 1,000,000)",
    )

    # Liste des param√®tres d√©sactiv√©s (pour transmission au backtest)
    disabled_params: List[str] = []
    if not leverage_enabled:
        disabled_params.append("leverage")

    # Ajouter les indicateurs non coch√©s √† disabled_params (info seulement)
    if available_indicators:
        unchecked_indicators = [ind for ind in available_indicators if ind not in active_indicators]
        if unchecked_indicators:
            st.sidebar.caption(f"_Indicateurs masqu√©s: {', '.join(unchecked_indicators)}_")

    render_saved_runs_panel(
        st.session_state.get("last_run_result"),
        strategy_key,
        symbol,
        timeframe,
    )

    # Multi-sweep lists (symbols et timeframes d√©j√† d√©finis par multiselect)
    # strategy_keys et all_params/ranges/specs bas√©s sur s√©lection simple de strat√©gie
    strategy_keys = [strategy_key]
    all_params = {strategy_key: params}
    all_param_ranges = {strategy_key: param_ranges}
    all_param_specs = {strategy_key: param_specs}

    draft_state = SidebarState(
        debug_enabled=debug_enabled,
        symbol=symbol,
        timeframe=timeframe,
        use_date_filter=use_date_filter,
        start_date=start_date,
        end_date=end_date,
        available_tokens=available_tokens,
        available_timeframes=available_timeframes,
        strategy_key=strategy_key,
        strategy_name=strategy_name,
        strategy_info=strategy_info,
        strategy_instance=strategy_instance,
        params=params,
        param_ranges=param_ranges,
        param_specs=param_specs,
        active_indicators=active_indicators,
        optimization_mode=optimization_mode,
        max_combos=max_combos,
        n_workers=n_workers,
        # Multi-sweep lists
        symbols=symbols,
        timeframes=timeframes,
        strategy_keys=strategy_keys,
        all_params=all_params,
        all_param_ranges=all_param_ranges,
        all_param_specs=all_param_specs,
        # Optuna
        use_optuna=use_optuna,
        optuna_n_trials=optuna_n_trials,
        optuna_sampler=optuna_sampler,
        optuna_pruning=optuna_pruning,
        optuna_metric=optuna_metric,
        optuna_early_stop=optuna_early_stop,
        llm_config=llm_config,
        llm_model=llm_model,
        llm_use_multi_agent=llm_use_multi_agent,
        role_model_config=role_model_config,
        llm_max_iterations=llm_max_iterations,
        llm_use_walk_forward=llm_use_walk_forward,
        llm_unload_during_backtest=llm_unload_during_backtest,
        llm_compare_enabled=llm_compare_enabled,
        llm_compare_auto_run=llm_compare_auto_run,
        llm_compare_strategies=llm_compare_strategies,
        llm_compare_tokens=llm_compare_tokens,
        llm_compare_timeframes=llm_compare_timeframes,
        llm_compare_metric=llm_compare_metric,
        llm_compare_aggregate=llm_compare_aggregate,
        llm_compare_max_runs=llm_compare_max_runs,
        llm_compare_use_preset=llm_compare_use_preset,
        llm_compare_generate_report=llm_compare_generate_report,
        initial_capital=initial_capital,
        leverage=leverage,
        leverage_enabled=leverage_enabled,
        disabled_params=disabled_params,
    )

    return _apply_config_guard(draft_state, apply_slot)
```
<!-- MODULE-END: sidebar.py -->

<!-- MODULE-START: state.py -->
```json
{
  "name": "state.py",
  "path": "ui\\state.py",
  "ext": ".py",
  "anchor": "state_py"
}
```
## state_py
*Chemin* : `ui\state.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.state

Purpose: D√©finit les structures de donn√©es pour l'√©tat de l'interface utilisateur.

Role in pipeline: state management

Key components: SidebarState

Inputs: Param√®tres utilisateur

Outputs: √âtat structur√©

Dependencies: dataclasses

Conventions: √âtat immutable via dataclass

Read-if: Gestion d'√©tat UI

Skip-if: Logique m√©tier pure
"""

from __future__ import annotations

from dataclasses import dataclass
from datetime import date
from typing import TYPE_CHECKING, Dict, List, Optional

if TYPE_CHECKING:
    from agents.llm_client import LLMConfig
    from agents.model_config import RoleModelConfig
    from strategies.base import StrategyBase
    from strategies.indicators_mapping import StrategyIndicators
    from utils.parameters import ParameterSpec


@dataclass
class SidebarState:
    debug_enabled: bool
    symbol: str
    timeframe: str
    use_date_filter: bool
    start_date: Optional[date]
    end_date: Optional[date]
    available_tokens: List[str]
    available_timeframes: List[str]
    strategy_key: str
    strategy_name: str
    strategy_info: Optional["StrategyIndicators"]
    strategy_instance: Optional["StrategyBase"]
    params: Dict[str, float]
    param_ranges: Dict[str, Dict[str, float]]
    param_specs: Dict[str, "ParameterSpec"]
    active_indicators: List[str]
    optimization_mode: str
    max_combos: int
    n_workers: int
    # Multi-sweep config (20/01/2026 - support s√©lection multiple)
    symbols: List[str]  # Liste de symboles s√©lectionn√©s
    timeframes: List[str]  # Liste de timeframes s√©lectionn√©s
    strategy_keys: List[str]  # Liste de strat√©gies s√©lectionn√©es
    all_params: Dict[str, Dict[str, float]]  # Param√®tres par strat√©gie
    all_param_ranges: Dict[str, Dict[str, Dict[str, float]]]  # Ranges par strat√©gie
    all_param_specs: Dict[str, Dict[str, "ParameterSpec"]]  # Specs par strat√©gie
    # Optuna config
    use_optuna: bool
    optuna_n_trials: int
    optuna_sampler: str
    optuna_pruning: bool
    optuna_metric: str
    optuna_early_stop: int
    # LLM config
    llm_config: Optional["LLMConfig"]
    llm_model: Optional[str]
    llm_use_multi_agent: bool
    role_model_config: Optional["RoleModelConfig"]
    llm_max_iterations: int
    llm_use_walk_forward: bool
    llm_unload_during_backtest: bool
    llm_compare_enabled: bool
    llm_compare_auto_run: bool
    llm_compare_strategies: List[str]
    llm_compare_tokens: List[str]
    llm_compare_timeframes: List[str]
    llm_compare_metric: str
    llm_compare_aggregate: str
    llm_compare_max_runs: int
    llm_compare_use_preset: bool
    llm_compare_generate_report: bool
    initial_capital: float
    leverage: float
    leverage_enabled: bool  # Si False, leverage=1 forc√©
    disabled_params: List[str]  # Param√®tres d√©sactiv√©s (utilisent valeur par d√©faut)

    def __post_init__(self) -> None:
        if self.use_date_filter:
            assert self.start_date is not None
            assert self.end_date is not None
        assert self.max_combos >= 1
        assert self.n_workers >= 1
        assert self.llm_max_iterations >= 0
        assert self.initial_capital >= 0
```
<!-- MODULE-END: state.py -->

<!-- MODULE-START: validation_integration.py -->
```json
{
  "name": "validation_integration.py",
  "path": "ui\\validation_integration.py",
  "ext": ".py",
  "anchor": "validation_integration_py"
}
```
## validation_integration_py
*Chemin* : `ui\validation_integration.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.validation_integration

Purpose: Int√®gre la validation walk-forward entre backend et UI.

Role in pipeline: validation / reporting

Key components: convert_fold_to_window_result

Inputs: ValidationFold, m√©triques

Outputs: WindowResult pour UI

Dependencies: backtest.validation, ui.components.validation_viewer

Conventions: Fen√™tres temporelles valid√©es

Read-if: Int√©gration validation walk-forward

Skip-if: Pas de validation walk-forward
"""

from __future__ import annotations

# pylint: disable=import-outside-toplevel
from datetime import datetime
from typing import Any, Dict, List, Optional

import pandas as pd

from backtest.validation import ValidationFold
from ui.components.validation_viewer import ValidationReport, WindowResult


def convert_fold_to_window_result(
    fold: ValidationFold,
    fold_index: int,
    train_metrics: Dict[str, float],
    test_metrics: Dict[str, float],
    params: Dict[str, Any],
) -> WindowResult:
    """
    Convertit un ValidationFold en WindowResult pour le viewer UI.

    Args:
        fold: Fold de validation (contient train_df, test_df, timestamps)
        fold_index: Index de la fen√™tre (0-based)
        train_metrics: M√©triques calcul√©es sur le train set
        test_metrics: M√©triques calcul√©es sur le test set
        params: Param√®tres optimaux trouv√©s pour cette fen√™tre

    Returns:
        WindowResult pr√™t pour l'affichage UI
    """
    return WindowResult(
        window_id=fold_index + 1,  # 1-based pour UI
        train_start=fold.train_start,
        train_end=fold.train_end,
        test_start=fold.test_start,
        test_end=fold.test_end,
        # M√©triques train
        train_sharpe=train_metrics.get("sharpe_ratio", 0.0),
        train_return=train_metrics.get("total_return_pct", 0.0) / 100.0,  # Convertir % ‚Üí ratio
        train_drawdown=abs(train_metrics.get("max_drawdown", 0.0)) / 100.0,
        train_trades=int(train_metrics.get("total_trades", 0)),
        # M√©triques test
        test_sharpe=test_metrics.get("sharpe_ratio", 0.0),
        test_return=test_metrics.get("total_return_pct", 0.0) / 100.0,
        test_drawdown=abs(test_metrics.get("max_drawdown", 0.0)) / 100.0,
        test_trades=int(test_metrics.get("total_trades", 0)),
        # Param√®tres
        params=params,
    )


def create_validation_report_from_results(
    strategy_name: str,
    validation_results: Dict[str, Any],
    created_at: Optional[datetime] = None,
) -> ValidationReport:
    """
    Cr√©e un ValidationReport √† partir des r√©sultats de run_walk_forward_for_agent().

    Args:
        strategy_name: Nom de la strat√©gie test√©e
        validation_results: R√©sultats retourn√©s par run_walk_forward_for_agent()
            Structure attendue:
            {
                'folds': List[Dict] avec keys: 'fold_id', 'train_metrics', 'test_metrics', 'params'
                'n_folds': int
                'train_pct': float (ex: 0.75)
                ... autres champs possibles
            }
        created_at: Timestamp du rapport (optionnel, d√©faut=maintenant)

    Returns:
        ValidationReport pr√™t pour render_validation_report()

    Example:
        >>> from agents.integration import run_walk_forward_for_agent
        >>> results = run_walk_forward_for_agent(strategy_name, params, data)
        >>> report = create_validation_report_from_results("ema_cross", results)
        >>> render_validation_report(report)
    """
    if created_at is None:
        created_at = datetime.now()

    folds_data = validation_results.get("folds", [])
    n_splits = validation_results.get("n_folds", len(folds_data))
    train_ratio = validation_results.get("train_pct", 0.75)

    # Convertir chaque fold en WindowResult
    windows: List[WindowResult] = []

    for i, fold_data in enumerate(folds_data):
        # Le fold peut contenir directement les timestamps ou un objet ValidationFold
        fold_obj = fold_data.get("fold")  # ValidationFold object si disponible
        train_metrics = fold_data.get("train_metrics", {})
        test_metrics = fold_data.get("test_metrics", {})
        params = fold_data.get("params", {})

        if fold_obj is not None and isinstance(fold_obj, ValidationFold):
            # Cas id√©al : on a l'objet ValidationFold complet
            window = convert_fold_to_window_result(
                fold=fold_obj,
                fold_index=i,
                train_metrics=train_metrics,
                test_metrics=test_metrics,
                params=params,
            )
        else:
            # Fallback : reconstruire depuis les timestamps dans fold_data
            window = WindowResult(
                window_id=i + 1,
                train_start=pd.Timestamp(fold_data.get("train_start")),
                train_end=pd.Timestamp(fold_data.get("train_end")),
                test_start=pd.Timestamp(fold_data.get("test_start")),
                test_end=pd.Timestamp(fold_data.get("test_end")),
                # M√©triques train
                train_sharpe=train_metrics.get("sharpe_ratio", 0.0),
                train_return=train_metrics.get("total_return_pct", 0.0) / 100.0,
                train_drawdown=abs(train_metrics.get("max_drawdown", 0.0)) / 100.0,
                train_trades=int(train_metrics.get("total_trades", 0)),
                # M√©triques test
                test_sharpe=test_metrics.get("sharpe_ratio", 0.0),
                test_return=test_metrics.get("total_return_pct", 0.0) / 100.0,
                test_drawdown=abs(test_metrics.get("max_drawdown", 0.0)) / 100.0,
                test_trades=int(test_metrics.get("total_trades", 0)),
                # Param√®tres
                params=params,
            )

        windows.append(window)

    return ValidationReport(
        strategy_name=strategy_name,
        created_at=created_at,
        windows=windows,
        n_splits=n_splits,
        train_ratio=train_ratio,
        purge_gap=0,  # NOTE: recuperer depuis validation_results si disponible
    )


def run_validation_and_display(
    strategy_name: str,
    params: Dict[str, Any],
    data: pd.DataFrame,
    n_windows: int = 6,
    train_ratio: float = 0.75,
    key: str = "walk_forward_validation",
) -> Optional[ValidationReport]:
    """
    Fonction tout-en-un : ex√©cute Walk-Forward et affiche le rapport UI.

    Args:
        strategy_name: Nom de la strat√©gie
        params: Param√®tres √† valider
        data: DataFrame OHLCV
        n_windows: Nombre de fen√™tres (d√©faut: 6 pour 2 ans de donn√©es)
        train_ratio: Ratio train/test (d√©faut: 0.75)
        key: Cl√© Streamlit unique

    Returns:
        ValidationReport g√©n√©r√© (ou None si erreur)

    Example:
        >>> # Dans ui/app.py
        >>> if st.button("üîç Validation Walk-Forward"):
        >>>     report = run_validation_and_display(
        >>>         strategy_name="ema_cross",
        >>>         params={"fast_period": 12, "slow_period": 26},
        >>>         data=df,
        >>>     )
    """
    try:
        import streamlit as st

        from agents.integration import run_walk_forward_for_agent
        from ui.components.validation_viewer import render_validation_report

        # Afficher un spinner pendant l'ex√©cution
        with st.spinner(f"üîÑ Walk-Forward Validation en cours ({n_windows} fen√™tres)..."):
            validation_results = run_walk_forward_for_agent(
                strategy_name=strategy_name,
                params=params,
                data=data,
                n_windows=n_windows,
                train_ratio=train_ratio,
            )

        # Convertir en ValidationReport
        report = create_validation_report_from_results(
            strategy_name=strategy_name,
            validation_results=validation_results,
        )

        # Afficher le rapport UI
        render_validation_report(report, key=key)

        return report

    except Exception as e:
        import streamlit as st
        st.error(f"‚ùå Erreur lors de la validation Walk-Forward: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None


__all__ = [
    "convert_fold_to_window_result",
    "create_validation_report_from_results",
    "run_validation_and_display",
]
```
<!-- MODULE-END: validation_integration.py -->

<!-- MODULE-START: worker_utils.py -->
```json
{
  "name": "worker_utils.py",
  "path": "ui\\worker_utils.py",
  "ext": ".py",
  "anchor": "worker_utils_py"
}
```
## worker_utils_py
*Chemin* : `ui\worker_utils.py`  
*Type* : `.py`  

```python
"""
Utilitaires pour la gestion des workers et threads.

Fournit des fonctions pour l'ex√©cution de backtests en parall√®le
et la configuration des threads dans les processus workers.
"""
from __future__ import annotations

import os
import logging
from typing import Any, Dict, Tuple

import pandas as pd

from ui.helpers import compute_period_days_from_df, safe_run_backtest


def run_backtest_multiprocess(args) -> Dict[str, Any]:
    """
    Wrapper picklable pour ProcessPoolExecutor.

    Args:
        args: tuple (param_combo, initial_capital, df, strategy_key, symbol, timeframe, debug_enabled)

    Returns:
        Dict avec r√©sultats du backtest ou erreur
    """
    param_combo, initial_capital, df, strategy_key, symbol, timeframe, debug_enabled = args

    try:
        # Import local pour √©viter les probl√®mes de pickling avec Streamlit
        from backtest.engine import BacktestEngine as _LocalBacktestEngine
        # Cr√©er l'engine localement (pas picklable donc recr√©√© dans chaque process)
        engine = _LocalBacktestEngine(initial_capital=initial_capital)
        period_days = compute_period_days_from_df(df)

        result_i, msg_i = safe_run_backtest(
            engine,
            df,
            strategy_key,
            param_combo,
            symbol,
            timeframe,
            silent_mode=not debug_enabled,
        )

        params_native = {
            k: float(v) if hasattr(v, "item") else v for k, v in param_combo.items()
        }
        params_str = str(params_native)

        if result_i:
            m = result_i.metrics
            return {
                "params": params_str,
                "params_dict": param_combo,
                "total_pnl": m.get("total_pnl", 0.0),
                "theoretical_pnl": m.get("theoretical_pnl", 0.0),
                "sharpe": m.get("sharpe_ratio", 0.0),
                "max_dd": m.get("max_drawdown_pct", m.get("max_drawdown", 0.0)),
                "win_rate": m.get("win_rate", 0.0),
                "trades": m.get("total_trades", 0),
                "profit_factor": m.get("profit_factor", 0.0),
                "period_days": period_days,
            }
        return {
            "params": params_str,
            "params_dict": param_combo,
            "error": msg_i,
        }
    except Exception as exc:
        params_str = str(param_combo)
        return {
            "params": params_str,
            "params_dict": param_combo,
            "error": str(exc),
        }


def apply_thread_limit(thread_limit: int, label: str = "") -> None:
    """
    Applique des limites de threads pour contr√¥ler l'utilisation CPU.

    Args:
        thread_limit: Nombre max de threads
        label: Label pour le logging (optionnel)
    """
    if thread_limit <= 0:
        return

    os.environ["BACKTEST_WORKER_THREADS"] = str(thread_limit)
    for var in (
        "OMP_NUM_THREADS",
        "MKL_NUM_THREADS",
        "OPENBLAS_NUM_THREADS",
        "NUMEXPR_NUM_THREADS",
        "VECLIB_MAXIMUM_THREADS",
        "BLIS_NUM_THREADS",
    ):
        os.environ[var] = str(thread_limit)

    try:
        from threadpoolctl import threadpool_limits
        threadpool_limits(thread_limit)
    except Exception:
        pass

    try:
        import torch
        torch.set_num_threads(thread_limit)
        torch.set_num_interop_threads(max(1, thread_limit // 2))
    except Exception:
        pass

    if label:
        logger = logging.getLogger(__name__)
        logger.info("Thread limit %s appliqu√©: %s", label, thread_limit)


def init_sweep_worker(thread_limit: int) -> None:
    """
    Initializer ProcessPoolExecutor - applique limites threads AVANT tout calcul.

    Args:
        thread_limit: Nombre max de threads pour ce worker
    """
    apply_thread_limit(thread_limit, label="worker")

    # Forcer avec threadpoolctl (plus efficace que les env vars seules)
    try:
        import threadpoolctl
        info_before = threadpoolctl.threadpool_info()
        threadpoolctl.threadpool_limits(limits=max(1, thread_limit), user_api="blas")
        info_after = threadpoolctl.threadpool_info()

        # Log pour debug
        import logging
        logger = logging.getLogger(__name__)
        num_threads_before = sum(pool.get("num_threads", 0) for pool in info_before)
        num_threads_after = sum(pool.get("num_threads", 0) for pool in info_after)
        logger.debug(f"Worker threads BLAS: {num_threads_before} ‚Üí {num_threads_after}")
    except ImportError:
        pass  # threadpoolctl non install√© - les env vars suffiront
```
<!-- MODULE-END: worker_utils.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "ui\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `ui\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.__init__

Purpose: Package UI - centralizes Streamlit app et components.

Role in pipeline: user interface

Key components: Re-exports components API

Inputs: None (module imports only)

Outputs: Public API via __all__

Dependencies: .app (main Streamlit), .components (UI widgets)

Conventions: __all__ optionnel; app.py est point d'entr√©e (streamlit run).

Read-if: Modification exports ou app entry point.

Skip-if: Vous lancez `streamlit run ui/app.py`.
"""
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: agent_timeline.py -->
```json
{
  "name": "agent_timeline.py",
  "path": "ui\\components\\agent_timeline.py",
  "ext": ".py",
  "anchor": "agent_timeline_py"
}
```
## agent_timeline_py
*Chemin* : `ui\components\agent_timeline.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.agent_timeline

Purpose: Timeline visuelle activit√© agents LLM - events d√©tails par agent (Analyst, Strategist, Critic, Validator).

Role in pipeline: visualization/monitoring

Key components: AgentActivity, AgentActivityTimeline, render_agent_timeline(), render_mini_timeline()

Inputs: Agent events (timestamps, decisions, metrics)

Outputs: Plotly interactive timeline Streamlit

Dependencies: streamlit, plotly, dataclasses

Conventions: AgentType enum, ActivityType categorization, metrics snapshot

Read-if: Afficher timeline agents LLM.

Skip-if: Pas d'agents LLM ou monitoring minimal.

Usage:
    >>> from ui.components.agent_timeline import render_agent_timeline
    >>> render_agent_timeline(timeline)
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional

try:
    import plotly.graph_objects as go
    import streamlit as st
    from plotly.subplots import make_subplots
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False


class AgentType(Enum):
    """Types d'agents dans le syst√®me."""
    ANALYST = "analyst"
    STRATEGIST = "strategist"
    CRITIC = "critic"
    VALIDATOR = "validator"
    ORCHESTRATOR = "orchestrator"
    EXECUTOR = "executor"


class ActivityType(Enum):
    """Types d'activit√©s des agents."""
    STARTED = "started"
    COMPLETED = "completed"
    ANALYSIS = "analysis"
    PROPOSAL = "proposal"
    CRITIQUE = "critique"
    DECISION = "decision"
    BACKTEST = "backtest"
    ERROR = "error"
    ITERATION = "iteration"


class DecisionType(Enum):
    """Types de d√©cisions."""
    APPROVE = "approve"
    REJECT = "reject"
    ITERATE = "iterate"
    STOP = "stop"


# Couleurs par agent
AGENT_COLORS = {
    AgentType.ANALYST: "#2196f3",       # Bleu
    AgentType.STRATEGIST: "#4caf50",    # Vert
    AgentType.CRITIC: "#ff9800",        # Orange
    AgentType.VALIDATOR: "#9c27b0",     # Violet
    AgentType.ORCHESTRATOR: "#607d8b",  # Gris-bleu
    AgentType.EXECUTOR: "#00bcd4",      # Cyan
}

# Ic√¥nes par type d'activit√©
ACTIVITY_ICONS = {
    ActivityType.STARTED: "üöÄ",
    ActivityType.COMPLETED: "‚úÖ",
    ActivityType.ANALYSIS: "üìä",
    ActivityType.PROPOSAL: "üí°",
    ActivityType.CRITIQUE: "üîç",
    ActivityType.DECISION: "‚öñÔ∏è",
    ActivityType.BACKTEST: "üìà",
    ActivityType.ERROR: "‚ùå",
    ActivityType.ITERATION: "üîÑ",
}


@dataclass
class AgentActivity:
    """
    Data carrier for a single agent event inside the orchestration timeline.

    Responsible for keeping metadata (agent type, activity type, iteration, duration)
    so that the UI can plot decisions and alerts without leaking orchestration logic.
    Lifecycle: created by `AgentActivityTimeline.log_activity` when the orchestrator
    reports a new event, then rendered in the Streamlit timeline panels.
    """
    timestamp: datetime
    agent: AgentType
    activity_type: ActivityType
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    duration_ms: Optional[float] = None
    iteration: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "agent": self.agent.value,
            "activity_type": self.activity_type.value,
            "message": self.message,
            "details": self.details,
            "duration_ms": self.duration_ms,
            "iteration": self.iteration,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AgentActivity":
        """Cr√©e depuis un dictionnaire."""
        return cls(
            timestamp=datetime.fromisoformat(data["timestamp"]),
            agent=AgentType(data["agent"]),
            activity_type=ActivityType(data["activity_type"]),
            message=data["message"],
            details=data.get("details", {}),
            duration_ms=data.get("duration_ms"),
            iteration=data.get("iteration", 0),
        )


@dataclass
class MetricsSnapshot:
    """Snapshot des m√©triques √† un moment donn√©."""
    timestamp: datetime
    iteration: int
    sharpe_ratio: float
    total_return: float
    max_drawdown: float
    win_rate: float
    params: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "iteration": self.iteration,
            "sharpe_ratio": self.sharpe_ratio,
            "total_return": self.total_return,
            "max_drawdown": self.max_drawdown,
            "win_rate": self.win_rate,
            "params": self.params,
        }


@dataclass
class AgentDecision:
    """
    Represents a discrete decision emitted by an agent.

    Encapsulates agent identity, reasoning and confidence so that the UI can render
    proposal/approval flows in the timeline. Decisions are collected during a run and
    displayed in the Streamlit detail tab, never altering engine state.
    """
    timestamp: datetime
    agent: AgentType
    decision: DecisionType
    reasoning: str
    confidence: float = 0.0
    iteration: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "agent": self.agent.value,
            "decision": self.decision.value,
            "reasoning": self.reasoning,
            "confidence": self.confidence,
            "iteration": self.iteration,
        }


class AgentActivityTimeline:
    """
    Stateful container that records agent activities, decisions, and metrics for a session.

    Position: UI instrumentation layer that subscribes to orchestrator events.
    Responsibilities: aggregate activities/decisions per iteration, compute summary,
    expose serialization helpers, and drive the timeline renderers.
    Lifecycle: created at start of a backtest session, receives `log_activity`/`log_decision`,
    then passed to Streamlit renderers (`render_agent_timeline`, `render_mini_timeline`).
    """

    def __init__(self, session_name: str = "Session"):
        """
        Initialise la timeline.

        Args:
            session_name: Nom de la session
        """
        self.session_name = session_name
        self.start_time = datetime.now()
        self._activities: List[AgentActivity] = []
        self._metrics_history: List[MetricsSnapshot] = []
        self._decisions: List[AgentDecision] = []
        self._current_iteration = 0

    @property
    def activities(self) -> List[AgentActivity]:
        """Liste des activit√©s."""
        return self._activities

    @property
    def metrics_history(self) -> List[MetricsSnapshot]:
        """Historique des m√©triques."""
        return self._metrics_history

    @property
    def decisions(self) -> List[AgentDecision]:
        """Liste des d√©cisions."""
        return self._decisions

    @property
    def duration(self) -> timedelta:
        """Dur√©e totale de la session."""
        if not self._activities:
            return timedelta(0)
        return self._activities[-1].timestamp - self.start_time

    @property
    def current_iteration(self) -> int:
        """It√©ration courante."""
        return self._current_iteration

    def log_activity(
        self,
        agent: AgentType,
        activity_type: ActivityType,
        message: str,
        details: Optional[Dict[str, Any]] = None,
        duration_ms: Optional[float] = None,
    ) -> AgentActivity:
        """
        Enregistre une activit√©.

        Args:
            agent: Type d'agent
            activity_type: Type d'activit√©
            message: Message descriptif
            details: D√©tails suppl√©mentaires
            duration_ms: Dur√©e en millisecondes

        Returns:
            L'activit√© cr√©√©e
        """
        activity = AgentActivity(
            timestamp=datetime.now(),
            agent=agent,
            activity_type=activity_type,
            message=message,
            details=details or {},
            duration_ms=duration_ms,
            iteration=self._current_iteration,
        )
        self._activities.append(activity)
        return activity

    def log_metrics(
        self,
        sharpe_ratio: float,
        total_return: float,
        max_drawdown: float,
        win_rate: float,
        params: Optional[Dict[str, Any]] = None,
    ) -> MetricsSnapshot:
        """
        Enregistre un snapshot de m√©triques.

        Args:
            sharpe_ratio: Sharpe ratio
            total_return: Rendement total
            max_drawdown: Drawdown maximum
            win_rate: Taux de victoire
            params: Param√®tres utilis√©s

        Returns:
            Le snapshot cr√©√©
        """
        snapshot = MetricsSnapshot(
            timestamp=datetime.now(),
            iteration=self._current_iteration,
            sharpe_ratio=sharpe_ratio,
            total_return=total_return,
            max_drawdown=max_drawdown,
            win_rate=win_rate,
            params=params or {},
        )
        self._metrics_history.append(snapshot)
        return snapshot

    def log_decision(
        self,
        agent: AgentType,
        decision: DecisionType,
        reasoning: str,
        confidence: float = 0.0,
    ) -> AgentDecision:
        """
        Enregistre une d√©cision.

        Args:
            agent: Agent qui prend la d√©cision
            decision: Type de d√©cision
            reasoning: Raisonnement
            confidence: Niveau de confiance (0-1)

        Returns:
            La d√©cision cr√©√©e
        """
        dec = AgentDecision(
            timestamp=datetime.now(),
            agent=agent,
            decision=decision,
            reasoning=reasoning,
            confidence=confidence,
            iteration=self._current_iteration,
        )
        self._decisions.append(dec)
        return dec

    def next_iteration(self) -> int:
        """Passe √† l'it√©ration suivante."""
        self._current_iteration += 1
        return self._current_iteration

    def get_activities_by_agent(self, agent: AgentType) -> List[AgentActivity]:
        """Filtre les activit√©s par agent."""
        return [a for a in self._activities if a.agent == agent]

    def get_activities_by_iteration(self, iteration: int) -> List[AgentActivity]:
        """Filtre les activit√©s par it√©ration."""
        return [a for a in self._activities if a.iteration == iteration]

    def get_summary(self) -> Dict[str, Any]:
        """
        G√©n√®re un r√©sum√© de la timeline.

        Returns:
            Dict avec statistiques de la session
        """
        activities_by_agent = {}
        for agent in AgentType:
            activities_by_agent[agent.value] = len(self.get_activities_by_agent(agent))

        decisions_by_type = {}
        for dec in self._decisions:
            key = dec.decision.value
            decisions_by_type[key] = decisions_by_type.get(key, 0) + 1

        best_metrics = None
        if self._metrics_history:
            best = max(self._metrics_history, key=lambda m: m.sharpe_ratio)
            best_metrics = {
                "iteration": best.iteration,
                "sharpe_ratio": best.sharpe_ratio,
                "total_return": best.total_return,
                "params": best.params,
            }

        return {
            "session_name": self.session_name,
            "duration_seconds": self.duration.total_seconds(),
            "total_activities": len(self._activities),
            "total_iterations": self._current_iteration,
            "activities_by_agent": activities_by_agent,
            "total_decisions": len(self._decisions),
            "decisions_by_type": decisions_by_type,
            "best_metrics": best_metrics,
        }

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise en dictionnaire."""
        return {
            "session_name": self.session_name,
            "start_time": self.start_time.isoformat(),
            "current_iteration": self._current_iteration,
            "activities": [a.to_dict() for a in self._activities],
            "metrics_history": [m.to_dict() for m in self._metrics_history],
            "decisions": [d.to_dict() for d in self._decisions],
        }

    def to_json(self) -> str:
        """S√©rialise en JSON."""
        return json.dumps(self.to_dict(), indent=2)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AgentActivityTimeline":
        """Charge depuis un dictionnaire."""
        timeline = cls(session_name=data["session_name"])
        timeline.start_time = datetime.fromisoformat(data["start_time"])
        timeline._current_iteration = data["current_iteration"]
        timeline._activities = [
            AgentActivity.from_dict(a) for a in data["activities"]
        ]
        # Note: metrics_history et decisions ont des formats simples
        return timeline


def create_timeline_figure(timeline: AgentActivityTimeline) -> go.Figure:
    """
    Builds the Plotly figure used by the timeline renderer.

    This function anchors the streamlit panel with a Gantt-like view of agent activities
    and a summary of metrics history. It is called with the timeline produced by
    `AgentActivityTimeline` just before plotting.

    Args:
        timeline: Timeline containing the current run's activities and metrics.

    Returns:
        Plotly Figure ready for `st.plotly_chart`.
    """
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        row_heights=[0.6, 0.4],
        subplot_titles=("Timeline des agents", "√âvolution des m√©triques"),
    )

    # Timeline des activit√©s par agent
    for agent in AgentType:
        activities = timeline.get_activities_by_agent(agent)
        if not activities:
            continue

        x = [a.timestamp for a in activities]
        y = [agent.value for a in activities]
        text = [f"{ACTIVITY_ICONS.get(a.activity_type, '')} {a.message}" for a in activities]

        fig.add_trace(
            go.Scatter(
                x=x,
                y=y,
                mode="markers+text",
                name=agent.value.capitalize(),
                marker=dict(
                    size=12,
                    color=AGENT_COLORS.get(agent, "#666"),
                    symbol="circle",
                ),
                text=[ACTIVITY_ICONS.get(a.activity_type, "‚Ä¢") for a in activities],
                textposition="top center",
                hovertext=text,
                hoverinfo="text",
            ),
            row=1,
            col=1,
        )

    # √âvolution des m√©triques
    if timeline.metrics_history:
        timestamps = [m.timestamp for m in timeline.metrics_history]
        sharpe = [m.sharpe_ratio for m in timeline.metrics_history]
        returns = [m.total_return * 100 for m in timeline.metrics_history]

        fig.add_trace(
            go.Scatter(
                x=timestamps,
                y=sharpe,
                mode="lines+markers",
                name="Sharpe Ratio",
                line=dict(color="#2196f3", width=2),
                marker=dict(size=8),
            ),
            row=2,
            col=1,
        )

        fig.add_trace(
            go.Scatter(
                x=timestamps,
                y=returns,
                mode="lines+markers",
                name="Return (%)",
                line=dict(color="#4caf50", width=2),
                marker=dict(size=8),
                yaxis="y3",
            ),
            row=2,
            col=1,
        )

    # Styling
    fig.update_layout(
        height=600,
        template="plotly_dark",
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
    )

    fig.update_yaxes(
        title_text="Agent",
        row=1,
        col=1,
        categoryorder="array",
        categoryarray=[a.value for a in AgentType],
    )

    fig.update_yaxes(title_text="Sharpe / Return (%)", row=2, col=1)

    return fig


def render_agent_timeline(
    timeline: AgentActivityTimeline,
    key: str = "agent_timeline",
) -> None:
    """
    Streamlit panel that surfaces agent activity and metrics history.

    Called after each orchestration run to visualize session health for analysts.

    Args:
        timeline: Activity timeline collected from the orchestrator.
        key: Unique widget key to allow reruns without collision.
    """
    if not STREAMLIT_AVAILABLE:
        return

    st.subheader(f"ü§ñ Timeline - {timeline.session_name}")

    # M√©triques r√©sum√©
    summary = timeline.get_summary()

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("‚è±Ô∏è Dur√©e", f"{summary['duration_seconds']:.1f}s")
    col2.metric("üîÑ It√©rations", summary["total_iterations"])
    col3.metric("üìù Activit√©s", summary["total_activities"])
    col4.metric("‚öñÔ∏è D√©cisions", summary["total_decisions"])

    # Graphique timeline
    fig = create_timeline_figure(timeline)
    st.plotly_chart(fig, width='stretch', key=f"{key}_chart")

    # D√©tails par onglets
    tab1, tab2, tab3 = st.tabs(["üìã Activit√©s", "‚öñÔ∏è D√©cisions", "üìä M√©triques"])

    with tab1:
        # Filtrer par agent
        agent_filter = st.multiselect(
            "Filtrer par agent",
            [a.value for a in AgentType],
            default=[a.value for a in AgentType],
            key=f"{key}_agent_filter",
        )

        # Afficher les activit√©s r√©centes
        activities = [
            a for a in reversed(timeline.activities)
            if a.agent.value in agent_filter
        ][:50]  # Limiter √† 50

        for activity in activities:
            icon = ACTIVITY_ICONS.get(activity.activity_type, "‚Ä¢")
            color = AGENT_COLORS.get(activity.agent, "#666")

            with st.container():
                col1, col2 = st.columns([1, 4])
                with col1:
                    st.markdown(
                        f"<span style='color:{color};font-weight:bold'>"
                        f"{activity.agent.value.upper()}</span>",
                        unsafe_allow_html=True,
                    )
                    st.caption(activity.timestamp.strftime("%H:%M:%S"))
                with col2:
                    st.markdown(f"{icon} **{activity.activity_type.value}**")
                    st.write(activity.message)
                    if activity.details:
                        with st.expander("D√©tails"):
                            st.json(activity.details)
                st.divider()

    with tab2:
        for dec in reversed(timeline.decisions):
            icon = "‚úÖ" if dec.decision == DecisionType.APPROVE else \
                   "‚ùå" if dec.decision == DecisionType.REJECT else \
                   "üîÑ" if dec.decision == DecisionType.ITERATE else "‚èπÔ∏è"

            col1, col2, col3 = st.columns([1, 2, 2])
            with col1:
                st.markdown(f"### {icon}")
                st.caption(f"Iter {dec.iteration}")
            with col2:
                st.markdown(f"**{dec.decision.value.upper()}**")
                st.write(f"Par: {dec.agent.value}")
            with col3:
                st.progress(dec.confidence, text=f"Confiance: {dec.confidence:.0%}")

            st.caption(dec.reasoning)
            st.divider()

    with tab3:
        if timeline.metrics_history:
            # Tableau des m√©triques
            data = []
            for m in timeline.metrics_history:
                data.append({
                    "Iteration": m.iteration,
                    "Sharpe": f"{m.sharpe_ratio:.3f}",
                    "Return": f"{m.total_return:.2%}",
                    "Drawdown": f"{m.max_drawdown:.2%}",
                    "Win Rate": f"{m.win_rate:.1%}",
                })

            st.dataframe(data, width='stretch')

            # Best result
            if summary["best_metrics"]:
                st.success(
                    f"üèÜ Meilleur r√©sultat (Iter {summary['best_metrics']['iteration']}): "
                    f"Sharpe = {summary['best_metrics']['sharpe_ratio']:.3f}"
                )
        else:
            st.info("Aucune m√©trique enregistr√©e")

    # Export
    with st.expander("üì• Export"):
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Copier JSON", key=f"{key}_copy"):
                st.code(timeline.to_json(), language="json")
        with col2:
            st.download_button(
                "T√©l√©charger JSON",
                timeline.to_json(),
                f"timeline_{timeline.session_name}.json",
                "application/json",
                key=f"{key}_download",
            )


def render_mini_timeline(
    timeline: AgentActivityTimeline,
    max_activities: int = 5,
    key: str = "mini_timeline",
) -> None:
    """
    Compact sidebar summary of the most recent agent events.

    Used by the sidebar to keep orchestration feedback visible while running backtests.

    Args:
        timeline: Same timeline instance rendered in the main panel.
        max_activities: Maximum number items shown for quick review.
        key: Widget key to avoid Streamlit collisions.
    """
    if not STREAMLIT_AVAILABLE:
        return

    st.markdown("### ü§ñ Agents")

    # Statut rapide
    col1, col2 = st.columns(2)
    col1.metric("Iter", timeline.current_iteration)
    col2.metric("Acts", len(timeline.activities))

    # Derni√®res activit√©s
    st.markdown("**R√©cent:**")
    for activity in list(reversed(timeline.activities))[:max_activities]:
        icon = ACTIVITY_ICONS.get(activity.activity_type, "‚Ä¢")
        agent_short = activity.agent.value[:3].upper()
        st.caption(f"{icon} [{agent_short}] {activity.message[:30]}...")
```
<!-- MODULE-END: agent_timeline.py -->

<!-- MODULE-START: charts.py -->
```json
{
  "name": "charts.py",
  "path": "ui\\components\\charts.py",
  "ext": ".py",
  "anchor": "charts_py"
}
```
## charts_py
*Chemin* : `ui\components\charts.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.charts

Purpose: Renderers Plotly/Seaborn pour UI - equity, OHLCV, comparaisons, strat√©gie diagrams.

Role in pipeline: visualization

Key components: render_equity_and_drawdown(), render_ohlcv_with_trades(), render_comparison_chart()

Inputs: Series/DataFrames (equity, OHLCV, metrics), trade results

Outputs: Plotly figures, Streamlit renderers

Dependencies: plotly, seaborn, pandas, streamlit (optionnel)

Conventions: Couleurs coh√©rentes; resampler pour performance; tooltips interactifs.

Read-if: Modification styling/layout graphiques ou ajout nouveau chart type.

Skip-if: Vous appelez render_equity_and_drawdown(equity, drawdown).
"""

# pylint: disable=too-many-lines

# ============================================================================
# 1. IMPORTS ET CONFIGURATION GLOBALE
# ============================================================================

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots

from utils.log import get_logger
from ui.components.diagram_factory import create_bollinger_atr_diagram

# Import optionnel de seaborn pour distributions statistiques
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    SEABORN_AVAILABLE = True
except ImportError:
    SEABORN_AVAILABLE = False

# Import optionnel de plotly-resampler pour downsampling intelligent
try:
    from plotly_resampler import FigureResampler
    PLOTLY_RESAMPLER_AVAILABLE = True
except ImportError:
    PLOTLY_RESAMPLER_AVAILABLE = False

logger = get_logger(__name__)


# ============================================================================
# 2. CONSTANTES ET CONFIGURATION
# ============================================================================

# Configuration Plotly
PLOTLY_CHART_CONFIG = {"scrollZoom": True}
RESAMPLER_THRESHOLD = 100000  # Utiliser resampler si > 100k points

# Palette de couleurs coh√©rente pour tous les graphiques
COLOR_PALETTE = {
    # Couleurs principales
    "equity_line": "#26a69a",
    "equity_fill": "rgba(38, 166, 154, 0.15)",
    "drawdown_line": "#ef5350",
    "drawdown_fill": "rgba(239, 83, 80, 0.3)",

    # Candlesticks
    "candle_up": "#26a69a",
    "candle_down": "#ef5350",

    # Trades
    "entry_long": "#42a5f5",
    "entry_short": "#ab47bc",
    "exit_profit": "#4caf50",
    "exit_loss": "#f44336",

    # Indicateurs
    "bb_mid": "#ffa726",
    "bb_bands": "#42a5f5",
    "bb_bands_rgba": "rgba(66, 165, 245, 0.1)",
    "bb_entry_z": "rgba(255, 204, 128, 0.9)",
    "ema_fast": "#42a5f5",
    "ema_slow": "#ffb74d",
    "ema_center": "#42a5f5",
    "macd_line": "#26a69a",
    "macd_signal": "#ef5350",
    "rsi_line": "#42a5f5",
    "rsi_oversold": "#26a69a",
    "rsi_overbought": "#ef5350",
    "atr_line": "#ab47bc",
    "atr_threshold": "#ffa726",
    "atr_channel_upper": "#ef5350",
    "atr_channel_lower": "#26a69a",
    "stoch_k": "#42a5f5",
    "stoch_d": "#ffb74d",

    # Diagrammes de strat√©gies
    "price_line": "#e0e0e0",
    "stop_loss": "#ef5350",
    "take_profit": "#4caf50",
    "bollinger_low": "rgba(100, 160, 200, 0.6)",
    "bollinger_high": "rgba(100, 160, 200, 0.6)",
    "bollinger_fill": "rgba(100, 160, 200, 0.15)",
    "bollinger_mid": "rgba(140, 200, 255, 0.9)",
    "stop_long": "rgba(239, 83, 80, 0.7)",
    "stop_short": "rgba(239, 83, 80, 0.7)",
    "entry_level_long": "rgba(76, 175, 80, 0.9)",
    "entry_level_short": "rgba(171, 71, 188, 0.9)",
    "annotation_stop": "#ef9a9a",
    "annotation_tp": "#81c784",

    # UI
    "text_primary": "#a8b2d1",
    "grid_color": "rgba(128,128,128,0.1)",
    "capital_line": "rgba(200, 200, 200, 0.5)",
}

# Configuration de layout par d√©faut pour Plotly
DEFAULT_LAYOUT_CONFIG = {
    "template": "plotly_dark",
    "plot_bgcolor": "rgba(0,0,0,0)",
    "paper_bgcolor": "rgba(0,0,0,0)",
    "font": {"color": COLOR_PALETTE["text_primary"], "size": 11},
    "hovermode": "x unified",
}

DEFAULT_GRID_COLOR = COLOR_PALETTE["grid_color"]

# Constantes Seaborn
SEABORN_BG_COLOR = "#0e1117"
SEABORN_AXES_BG_COLOR = "#1e272e"
SEABORN_EDGE_COLOR = "#1e272e"
SEABORN_TEXT_COLOR = COLOR_PALETTE["text_primary"]


# ============================================================================
# 3. HELPERS UTILITAIRES G√âN√âRAUX
# ============================================================================

def _wrap_with_resampler(fig: go.Figure, n_datapoints: int) -> go.Figure:
    """
    Wrap une figure Plotly avec FigureResampler si le dataset est grand.

    Args:
        fig: Figure Plotly originale
        n_datapoints: Nombre de points de donn√©es

    Returns:
        Figure Plotly (wrapp√©e ou non)
    """
    if PLOTLY_RESAMPLER_AVAILABLE and n_datapoints > RESAMPLER_THRESHOLD:
        logger.info(
            "Dataset large (%s points) - Activation du resampler",
            "{:,}".format(n_datapoints),
        )
        try:
            # Convertir en FigureResampler pour downsampling intelligent
            return FigureResampler(fig, default_n_shown_samples=2000)
        except Exception as e:
            logger.warning(
                "Echec du resampler: %s - Utilisation de la figure standard",
                e,
            )
            return fig
    return fig


def _apply_axis_interaction(fig: go.Figure, lock_x: bool = False) -> None:
    """
    Enable zoom on Y while keeping X interactive when needed.

    Args:
        fig: Figure Plotly
        lock_x: Verrouiller l'axe X
    """
    fig.update_layout(dragmode="zoom")
    fig.update_xaxes(fixedrange=lock_x)
    fig.update_yaxes(fixedrange=False)


def _normalize_trades_df(trades_df: pd.DataFrame) -> pd.DataFrame:
    """
    Normalize trade column names for chart rendering.

    Args:
        trades_df: DataFrame des trades

    Returns:
        DataFrame avec colonnes normalis√©es
    """
    if trades_df is None or trades_df.empty:
        return trades_df

    rename_map = {}
    if "entry_time" not in trades_df.columns and "entry_ts" in trades_df.columns:
        rename_map["entry_ts"] = "entry_time"
    if "exit_time" not in trades_df.columns and "exit_ts" in trades_df.columns:
        rename_map["exit_ts"] = "exit_time"
    if "entry_price" not in trades_df.columns and "price_entry" in trades_df.columns:
        rename_map["price_entry"] = "entry_price"
    if "exit_price" not in trades_df.columns and "price_exit" in trades_df.columns:
        rename_map["price_exit"] = "exit_price"

    if not rename_map:
        return trades_df

    return trades_df.rename(columns=rename_map)


# ============================================================================
# 4. HELPERS DE STYLE PLOTLY
# ============================================================================

def _apply_chart_layout(
    fig: go.Figure,
    height: int = 450,
    y_title: str = "",
    show_rangeslider: bool = False,
) -> None:
    """
    Applique un style coh√©rent aux graphiques Plotly.

    Args:
        fig: Figure Plotly
        height: Hauteur du graphique
        y_title: Titre de l'axe Y
        show_rangeslider: Afficher le range slider en bas
    """
    fig.update_layout(
        height=height,
        margin=dict(l=50, r=50, t=30, b=30),
        template=DEFAULT_LAYOUT_CONFIG["template"],
        xaxis_title="",
        yaxis_title=y_title,
        xaxis=dict(
            rangeslider=dict(visible=show_rangeslider),
            gridcolor=DEFAULT_GRID_COLOR,
        ),
        yaxis=dict(gridcolor=DEFAULT_GRID_COLOR),
        plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        font=DEFAULT_LAYOUT_CONFIG["font"],
        hovermode=DEFAULT_LAYOUT_CONFIG["hovermode"],
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
    )


def _get_base_layout_config(height: int = 520) -> dict:
    """
    Retourne la configuration de layout de base pour les sous-graphiques.

    Args:
        height: Hauteur du graphique

    Returns:
        Dict de configuration
    """
    return {
        "height": height,
        "template": DEFAULT_LAYOUT_CONFIG["template"],
        "plot_bgcolor": DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        "paper_bgcolor": DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        "font": DEFAULT_LAYOUT_CONFIG["font"],
        "legend": dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
        "margin": dict(l=40, r=40, t=60, b=40),
    }


def _apply_dark_theme(fig: go.Figure) -> None:
    """
    Applique le th√®me sombre aux axes d'une figure.

    Args:
        fig: Figure Plotly
    """
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(gridcolor=DEFAULT_GRID_COLOR)


# ============================================================================
# 5. HELPERS DE CALCUL POUR DIAGRAMMES
# ============================================================================

def _create_synthetic_price(n: int = 160, volatility: float = 2.5) -> tuple:
    """
    Cr√©e un prix synth√©tique pour les diagrammes de strat√©gies.

    Args:
        n: Nombre de points
        volatility: Facteur de volatilit√© (d√©faut: 2.5 pour simulation r√©aliste)

    Returns:
        Tuple (x, price, price_series)
    """
    np.random.seed(42)  # Reproductibilit√©
    x = np.arange(n)

    # Tendance de fond (sinuso√Ødale lente)
    base = 100 + 4 * np.sin(np.linspace(0, 4 * np.pi, n))

    # Oscillations moyennes fr√©quences
    mid_freq = 0.9 * np.sin(np.linspace(0, 11 * np.pi, n))

    # Bruit r√©aliste avec marche al√©atoire
    random_walk = np.random.randn(n).cumsum() * 0.3

    # Chocs de volatilit√© (pics al√©atoires)
    shocks = np.random.randn(n) * volatility

    # Composition finale
    price = base + mid_freq + random_walk + shocks
    price_series = pd.Series(price)
    return x, price, price_series


def _calculate_bollinger(
    price_series: pd.Series,
    bb_period: int,
    bb_std: float,
    entry_z: Optional[float] = None,
) -> dict:
    """
    Calcule les bandes de Bollinger.

    Args:
        price_series: S√©rie de prix
        bb_period: P√©riode de la moyenne mobile
        bb_std: Nombre d'√©carts-types
        entry_z: Z-score pour les bandes d'entr√©e (optionnel)

    Returns:
        Dict avec upper, lower, middle, entry_upper, entry_lower
    """
    middle = price_series.rolling(window=bb_period, min_periods=1).mean()
    sigma = price_series.rolling(window=bb_period, min_periods=1).std(ddof=0).fillna(0.5)
    upper = middle + sigma * bb_std
    lower = middle - sigma * bb_std

    result = {
        "upper": upper,
        "lower": lower,
        "middle": middle,
        "sigma": sigma,
    }

    if entry_z is not None:
        result["entry_upper"] = middle + sigma * entry_z
        result["entry_lower"] = middle - sigma * entry_z

    return result


def _calculate_atr(
    price_series: pd.Series,
    atr_period: int,
    atr_percentile: float,
) -> tuple:
    """
    Calcule l'ATR (Average True Range) et son seuil de percentile.

    Args:
        price_series: S√©rie de prix
        atr_period: P√©riode de calcul de l'ATR
        atr_percentile: Percentile pour le seuil

    Returns:
        Tuple (atr_values, atr_threshold)
    """
    atr_values = price_series.diff().abs().rolling(window=atr_period, min_periods=1).mean()
    atr_threshold = float(np.nanpercentile(atr_values, atr_percentile))
    return atr_values, atr_threshold


# ============================================================================
# 6. HELPERS DIAGRAMMES DE STRAT√âGIES
# ============================================================================

def _render_bollinger_atr_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 300,  # Augment√© pour mieux voir l'effet des p√©riodes √©lev√©es
) -> None:
    """
    Diagramme pour la strat√©gie Bollinger ATR v1.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es (augment√© √† 300 pour p√©riodes √©lev√©es)
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    bb_period = max(2, min(int(params.get("bb_period", 20)), n - 1))
    bb_std = float(params.get("bb_std", 2.0))
    entry_z = float(params.get("entry_z", bb_std))
    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))
    atr_percentile = float(params.get("atr_percentile", 30))
    k_sl = float(params.get("k_sl", 1.5))

    # Calcul des indicateurs
    bb = _calculate_bollinger(price_series, bb_period, bb_std, entry_z)
    atr_values, atr_threshold = _calculate_atr(price_series, atr_period, atr_percentile)

    # Cr√©ation du graphique
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.7, 0.3],
        subplot_titles=(
            "Prix + Bandes de Bollinger (entry_z)",
            "ATR et filtre de volatilite (atr_percentile)",
        ),
    )

    # Bandes de Bollinger
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["lower"], name="Bollinger bas",
            line=dict(color=COLOR_PALETTE["bollinger_low"], width=1),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["upper"], name="Bollinger haut",
            line=dict(color=COLOR_PALETTE["bollinger_high"], width=1),
            fill="tonexty", fillcolor=COLOR_PALETTE["bollinger_fill"],
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["middle"], name="Bollinger milieu",
            line=dict(color=COLOR_PALETTE["bollinger_mid"], width=1.5),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["entry_upper"], name="Seuil entry_z haut",
            line=dict(color=COLOR_PALETTE["bb_entry_z"], width=1, dash="dot"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["entry_lower"], name="Seuil entry_z bas",
            line=dict(color=COLOR_PALETTE["bb_entry_z"], width=1, dash="dot"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        ),
        row=1, col=1,
    )

    # Exemple d'entr√©e avec stop-loss
    entry_index = int(n * 0.72)
    entry_price = price[entry_index]
    atr_at_entry = float(atr_values.iloc[entry_index])
    stop_price = entry_price - k_sl * atr_at_entry

    fig.add_trace(
        go.Scatter(
            x=[entry_index], y=[entry_price],
            mode="markers", name="Exemple entree",
            marker=dict(color=COLOR_PALETTE["equity_line"], size=8),
        ),
        row=1, col=1,
    )
    fig.add_shape(
        type="line", x0=entry_index, x1=entry_index,
        y0=entry_price, y1=stop_price,
        line=dict(color=COLOR_PALETTE["stop_loss"], width=2),
        row=1, col=1,
    )
    fig.add_annotation(
        x=entry_index, y=stop_price,
        text=f"Stop = k_sl x ATR ({k_sl:.2f})",
        showarrow=True, arrowhead=2, ax=20, ay=20,
        font=dict(color=COLOR_PALETTE["annotation_stop"], size=10),
        row=1, col=1,
    )

    # ATR
    fig.add_trace(
        go.Scatter(
            x=x, y=atr_values, name="ATR",
            line=dict(color=COLOR_PALETTE["atr_line"], width=1.5),
        ),
        row=2, col=1,
    )
    fig.add_hline(
        y=atr_threshold, line_dash="dot",
        line_color=COLOR_PALETTE["atr_threshold"],
        annotation_text=f"Seuil {atr_percentile:.0f}%",
        annotation_position="top left",
        row=2, col=1,
    )

    # Layout
    fig.update_layout(**_get_base_layout_config())
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(
        f"Parametres: bb_period={bb_period}, bb_std={bb_std:.2f}, entry_z={entry_z:.2f}, "
        f"atr_period={atr_period}, atr_percentile={atr_percentile:.0f}%, k_sl={k_sl:.2f}"
    )
    st.markdown(
        "- bb_period: fenetre de moyenne pour la ligne centrale.\n"
        "- bb_std: largeur des bandes (ecart-type).\n"
        "- entry_z: seuil d'entree en z-score (declenchement).\n"
        "- atr_period: fenetre ATR pour la volatilite.\n"
        "- atr_percentile: seuil de volatilite minimum.\n"
        "- k_sl: distance du stop = k_sl x ATR."
    )


def _render_bollinger_atr_v2_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 300,
) -> None:
    """
    Diagramme pour la strat√©gie Bollinger ATR v2 (stop-loss bas√© sur Bollinger).

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es (augment√© √† 300 pour p√©riodes √©lev√©es)
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    bb_period = max(2, min(int(params.get("bb_period", 20)), n - 1))
    bb_std = float(params.get("bb_std", 2.0))
    entry_z = float(params.get("entry_z", bb_std))
    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))
    atr_percentile = float(params.get("atr_percentile", 30))
    bb_stop_factor = float(params.get("bb_stop_factor", 0.5))

    # Calcul des indicateurs
    bb = _calculate_bollinger(price_series, bb_period, bb_std, entry_z)
    atr_values, atr_threshold = _calculate_atr(price_series, atr_period, atr_percentile)

    # Calculer les stop-loss Bollinger
    bb_distance_lower = bb["middle"] - bb["lower"]
    bb_distance_upper = bb["upper"] - bb["middle"]
    stop_long = bb["lower"] - bb_stop_factor * bb_distance_lower
    stop_short = bb["upper"] + bb_stop_factor * bb_distance_upper

    # Cr√©ation du graphique
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.7, 0.3],
        subplot_titles=(
            "Prix + Bandes de Bollinger + Stop-Loss Bollinger (V2)",
            "ATR et filtre de volatilite",
        ),
    )

    # Bandes de Bollinger
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["lower"], name="Bollinger bas",
            line=dict(color=COLOR_PALETTE["bollinger_low"], width=1),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["upper"], name="Bollinger haut",
            line=dict(color=COLOR_PALETTE["bollinger_high"], width=1),
            fill="tonexty", fillcolor=COLOR_PALETTE["bollinger_fill"],
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["middle"], name="Bollinger milieu",
            line=dict(color=COLOR_PALETTE["bollinger_mid"], width=1.5),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["entry_upper"], name="Seuil entry_z haut",
            line=dict(color=COLOR_PALETTE["bb_entry_z"], width=1, dash="dot"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["entry_lower"], name="Seuil entry_z bas",
            line=dict(color=COLOR_PALETTE["bb_entry_z"], width=1, dash="dot"),
        ),
        row=1, col=1,
    )

    # Niveaux de stop-loss
    fig.add_trace(
        go.Scatter(
            x=x, y=stop_long, name="Stop LONG",
            line=dict(color=COLOR_PALETTE["stop_long"], width=1.2, dash="dash"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=stop_short, name="Stop SHORT",
            line=dict(color=COLOR_PALETTE["stop_short"], width=1.2, dash="dash"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        ),
        row=1, col=1,
    )

    # Exemple d'entr√©e LONG
    entry_index = int(n * 0.25)
    entry_price = float(bb["entry_lower"].iloc[entry_index])
    stop_price = float(stop_long.iloc[entry_index])

    fig.add_trace(
        go.Scatter(
            x=[entry_index], y=[entry_price],
            mode="markers", name="Exemple entree LONG",
            marker=dict(color=COLOR_PALETTE["equity_line"], size=8),
        ),
        row=1, col=1,
    )
    fig.add_shape(
        type="line", x0=entry_index, x1=entry_index,
        y0=entry_price, y1=stop_price,
        line=dict(color=COLOR_PALETTE["stop_loss"], width=2),
        row=1, col=1,
    )
    fig.add_annotation(
        x=entry_index, y=stop_price,
        text=f"Stop = lower - {bb_stop_factor:.1f} √ó (mid-low)",
        showarrow=True, arrowhead=2, ax=-40, ay=20,
        font=dict(color=COLOR_PALETTE["annotation_stop"], size=10),
        row=1, col=1,
    )

    # ATR
    fig.add_trace(
        go.Scatter(
            x=x, y=atr_values, name="ATR",
            line=dict(color=COLOR_PALETTE["atr_line"], width=1.5),
        ),
        row=2, col=1,
    )
    fig.add_hline(
        y=atr_threshold, line_dash="dot",
        line_color=COLOR_PALETTE["atr_threshold"],
        annotation_text=f"Seuil {atr_percentile:.0f}%",
        annotation_position="top left",
        row=2, col=1,
    )

    # Layout
    fig.update_layout(**_get_base_layout_config())
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(
        f"Parametres: bb_period={bb_period}, bb_std={bb_std:.2f}, entry_z={entry_z:.2f}, "
        f"atr_period={atr_period}, atr_percentile={atr_percentile:.0f}%, bb_stop_factor={bb_stop_factor:.2f}"
    )
    st.markdown(
        "**V2: Stop-loss bas√© sur les Bandes de Bollinger**\n\n"
        "- bb_stop_factor: Distance du stop depuis les bandes (0.2=proche, 2.0=loin).\n"
        "- LONG: stop = lower - bb_stop_factor √ó (middle - lower)\n"
        "- SHORT: stop = upper + bb_stop_factor √ó (upper - middle)\n"
        "- Le stop-loss est FIXE au moment de l'entr√©e."
    )


def _render_bollinger_atr_v3_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 300,
) -> None:
    """
    Diagramme pour la strat√©gie Bollinger ATR v3 (entr√©es, stop et TP variables).

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es (augment√© √† 300 pour p√©riodes √©lev√©es)
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    bb_period = max(2, min(int(params.get("bb_period", 20)), n - 1))
    bb_std = float(params.get("bb_std", 2.0))
    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))
    atr_percentile = float(params.get("atr_percentile", 30))
    entry_pct_long = float(params.get("entry_pct_long", 0.0))
    entry_pct_short = float(params.get("entry_pct_short", 1.0))
    stop_factor = float(params.get("stop_factor", 0.5))
    tp_factor = float(params.get("tp_factor", 0.7))

    # Calcul des indicateurs
    bb = _calculate_bollinger(price_series, bb_period, bb_std)
    atr_values, atr_threshold = _calculate_atr(price_series, atr_period, atr_percentile)

    # Calculer les niveaux d'entr√©e sur l'√©chelle unifi√©e
    total_distance = bb["upper"] - bb["lower"]
    entry_level_long = bb["lower"] + entry_pct_long * total_distance
    entry_level_short = bb["lower"] + entry_pct_short * total_distance

    # Cr√©ation du graphique
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.7, 0.3],
        subplot_titles=(
            f"Prix + Bandes de Bollinger (V3: {bb_std:.1f}œÉ) + Niveaux d'entr√©e variables",
            "ATR et filtre de volatilite",
        ),
    )

    # Bandes de Bollinger
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["lower"], name="Bollinger bas (0%)",
            line=dict(color=COLOR_PALETTE["bollinger_low"], width=1),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["upper"], name="Bollinger haut (100%)",
            line=dict(color=COLOR_PALETTE["bollinger_high"], width=1),
            fill="tonexty", fillcolor=COLOR_PALETTE["bollinger_fill"],
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=bb["middle"], name="Bollinger milieu (50%)",
            line=dict(color=COLOR_PALETTE["bollinger_mid"], width=1.5),
        ),
        row=1, col=1,
    )

    # Niveaux d'entr√©e
    fig.add_trace(
        go.Scatter(
            x=x, y=entry_level_long,
            name=f"Entr√©e LONG ({entry_pct_long*100:.0f}%)",
            line=dict(color=COLOR_PALETTE["entry_level_long"], width=1.5, dash="dot"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=entry_level_short,
            name=f"Entr√©e SHORT ({entry_pct_short*100:.0f}%)",
            line=dict(color=COLOR_PALETTE["entry_level_short"], width=1.5, dash="dot"),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        ),
        row=1, col=1,
    )

    # Exemple de trade LONG
    entry_index = int(n * 0.25)
    entry_price = float(entry_level_long.iloc[entry_index])
    distance = float(total_distance.iloc[entry_index])
    stop_price = entry_price - stop_factor * distance
    tp_price = entry_price + tp_factor * distance

    fig.add_trace(
        go.Scatter(
            x=[entry_index], y=[entry_price],
            mode="markers", name="Exemple entree LONG",
            marker=dict(color=COLOR_PALETTE["equity_line"], size=8),
        ),
        row=1, col=1,
    )

    # Ligne Stop
    fig.add_shape(
        type="line", x0=entry_index, x1=entry_index + 15,
        y0=stop_price, y1=stop_price,
        line=dict(color=COLOR_PALETTE["stop_loss"], width=2, dash="dash"),
        row=1, col=1,
    )
    # Ligne TP
    fig.add_shape(
        type="line", x0=entry_index, x1=entry_index + 15,
        y0=tp_price, y1=tp_price,
        line=dict(color=COLOR_PALETTE["take_profit"], width=2, dash="dash"),
        row=1, col=1,
    )
    fig.add_annotation(
        x=entry_index + 15, y=stop_price,
        text=f"Stop ({stop_factor*100:.0f}%)",
        showarrow=False, xshift=45,
        font=dict(color=COLOR_PALETTE["annotation_stop"], size=9),
        row=1, col=1,
    )
    fig.add_annotation(
        x=entry_index + 15, y=tp_price,
        text=f"TP ({tp_factor*100:.0f}%)",
        showarrow=False, xshift=35,
        font=dict(color=COLOR_PALETTE["annotation_tp"], size=9),
        row=1, col=1,
    )

    # ATR
    fig.add_trace(
        go.Scatter(
            x=x, y=atr_values, name="ATR",
            line=dict(color=COLOR_PALETTE["atr_line"], width=1.5),
        ),
        row=2, col=1,
    )
    fig.add_hline(
        y=atr_threshold, line_dash="dot",
        line_color=COLOR_PALETTE["atr_threshold"],
        annotation_text=f"Seuil {atr_percentile:.0f}%",
        annotation_position="top left",
        row=2, col=1,
    )

    # Layout
    fig.update_layout(**_get_base_layout_config())
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(
        f"Parametres: bb_period={bb_period}, bb_std={bb_std:.2f}, "
        f"entry_long={entry_pct_long*100:.0f}%, entry_short={entry_pct_short*100:.0f}%, "
        f"stop_factor={stop_factor:.2f}, tp_factor={tp_factor:.2f}"
    )
    st.markdown(
        "**V3: Entr√©es, Stop et TP Variables sur √âchelle Unifi√©e**\n\n"
        "- **√âchelle**: 0% = lower_band, 50% = middle_band, 100% = upper_band\n"
        "- **entry_pct_long**: Position d'entr√©e LONG (-50% √† +20%)\n"
        "- **entry_pct_short**: Position d'entr√©e SHORT (+80% √† +150%)\n"
        "- **stop_factor**: Distance stop depuis entry_price (10% √† 100% de distance totale)\n"
        "- **tp_factor**: Distance TP depuis entry_price (20% √† 150% de distance totale)\n"
        "- **bb_std**: Amplitude des bandes (1œÉ √† 4œÉ)\n\n"
        "Formule: entry_level = lower + entry_pct √ó (upper - lower)"
    )


def _render_ema_cross_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """
    Diagramme pour la strat√©gie EMA Cross.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    fast_period = max(2, min(int(params.get("fast_period", 12)), n - 1))
    slow_period = max(3, min(int(params.get("slow_period", 26)), n - 1))

    # Calcul des EMA
    ema_fast = price_series.ewm(span=fast_period, adjust=False).mean()
    ema_slow = price_series.ewm(span=slow_period, adjust=False).mean()

    # D√©tection des croisements
    diff = ema_fast - ema_slow
    cross_idx = diff.diff().fillna(0)
    cross_points = cross_idx[cross_idx != 0].index.tolist()
    marker_index = int(cross_points[0]) if cross_points else int(n * 0.55)

    # Cr√©ation du graphique
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=ema_fast, name=f"EMA rapide ({fast_period})",
            line=dict(color=COLOR_PALETTE["ema_fast"], width=1.8),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=ema_slow, name=f"EMA lente ({slow_period})",
            line=dict(color=COLOR_PALETTE["ema_slow"], width=1.8),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=[marker_index], y=[price[marker_index]],
            mode="markers", name="Exemple croisement",
            marker=dict(color=COLOR_PALETTE["equity_line"], size=8),
        )
    )

    # Layout
    fig.update_layout(
        height=460,
        template=DEFAULT_LAYOUT_CONFIG["template"],
        plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        font=DEFAULT_LAYOUT_CONFIG["font"],
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=40, r=40, t=40, b=40),
        title="EMA Cross: croisement de moyennes mobiles",
    )
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(f"Parametres: fast_period={fast_period}, slow_period={slow_period}")
    st.markdown(
        "- fast_period: vitesse de la moyenne rapide.\n"
        "- slow_period: tendance de fond (plus lente).\n"
        "- Un signal apparait quand la rapide croise la lente."
    )


def _render_macd_cross_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """
    Diagramme pour la strat√©gie MACD Cross.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    fast_period = max(2, min(int(params.get("fast_period", 12)), n - 1))
    slow_period = max(3, min(int(params.get("slow_period", 26)), n - 1))
    signal_period = max(2, min(int(params.get("signal_period", 9)), n - 1))

    # Calcul du MACD
    ema_fast = price_series.ewm(span=fast_period, adjust=False).mean()
    ema_slow = price_series.ewm(span=slow_period, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()

    # Cr√©ation du graphique
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.65, 0.35],
        subplot_titles=("Prix", "MACD (ligne vs signal)"),
    )

    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=macd_line, name="MACD",
            line=dict(color=COLOR_PALETTE["macd_line"], width=1.6),
        ),
        row=2, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=signal_line, name="Signal",
            line=dict(color=COLOR_PALETTE["macd_signal"], width=1.4),
        ),
        row=2, col=1,
    )

    # Layout
    fig.update_layout(**_get_base_layout_config())
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(
        f"Parametres: fast_period={fast_period}, slow_period={slow_period}, "
        f"signal_period={signal_period}"
    )
    st.markdown(
        "- fast_period: EMA rapide pour le MACD.\n"
        "- slow_period: EMA lente pour le MACD.\n"
        "- signal_period: lissage de la ligne MACD.\n"
        "- Signal quand MACD croise la ligne signal."
    )


def _render_rsi_reversal_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """
    Diagramme pour la strat√©gie RSI Reversal.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    rsi_period = max(2, min(int(params.get("rsi_period", 14)), n - 1))
    oversold = float(params.get("oversold_level", 30))
    overbought = float(params.get("overbought_level", 70))

    # Calcul du RSI
    delta = price_series.diff().fillna(0)
    gains = delta.clip(lower=0)
    losses = -delta.clip(upper=0)
    avg_gain = gains.ewm(alpha=1 / rsi_period, adjust=False).mean()
    avg_loss = losses.ewm(alpha=1 / rsi_period, adjust=False).mean().replace(0, 1e-6)
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    # Cr√©ation du graphique
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.6, 0.4],
        subplot_titles=("Prix", "RSI et zones extremes"),
    )

    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        ),
        row=1, col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=rsi, name="RSI",
            line=dict(color=COLOR_PALETTE["rsi_line"], width=1.6),
        ),
        row=2, col=1,
    )
    fig.add_hline(
        y=oversold, line_dash="dot",
        line_color=COLOR_PALETTE["rsi_oversold"],
        annotation_text="Oversold",
        annotation_position="bottom left",
        row=2, col=1,
    )
    fig.add_hline(
        y=overbought, line_dash="dot",
        line_color=COLOR_PALETTE["rsi_overbought"],
        annotation_text="Overbought",
        annotation_position="top left",
        row=2, col=1,
    )

    # Layout
    fig.update_layout(**_get_base_layout_config())
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(
        f"Parametres: rsi_period={rsi_period}, oversold={oversold:.0f}, overbought={overbought:.0f}"
    )
    st.markdown(
        "- rsi_period: fenetre de calcul du RSI.\n"
        "- oversold_level: seuil bas pour signal long.\n"
        "- overbought_level: seuil haut pour signal short."
    )


def _render_atr_channel_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """
    Diagramme pour la strat√©gie ATR Channel.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points de donn√©es
    """
    x, price, price_series = _create_synthetic_price(n)

    # Extraction des param√®tres
    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))
    atr_mult = float(params.get("atr_mult", 2.0))

    # Calcul de l'ATR Channel
    ema_center = price_series.ewm(span=atr_period, adjust=False).mean()
    high = price_series + 0.6 + 0.3 * np.sin(np.linspace(0, 8 * np.pi, n))
    low = price_series - 0.6 - 0.3 * np.sin(np.linspace(0, 8 * np.pi, n))
    prev_close = price_series.shift(1).fillna(price_series.iloc[0])
    tr = pd.concat(
        [
            (high - low).abs(),
            (high - prev_close).abs(),
            (low - prev_close).abs(),
        ],
        axis=1,
    ).max(axis=1)
    atr_values = tr.ewm(span=atr_period, adjust=False).mean()
    upper = ema_center + atr_values * atr_mult
    lower = ema_center - atr_values * atr_mult

    # Cr√©ation du graphique
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=x, y=price, name="Prix",
            line=dict(color=COLOR_PALETTE["price_line"], width=1.5),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=upper, name="Canal haut",
            line=dict(color=COLOR_PALETTE["atr_channel_upper"], width=1.2),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=lower, name="Canal bas",
            line=dict(color=COLOR_PALETTE["atr_channel_lower"], width=1.2),
        )
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=ema_center, name="EMA centre",
            line=dict(color=COLOR_PALETTE["ema_center"], width=1.4, dash="dot"),
        )
    )

    # Layout
    fig.update_layout(
        height=460,
        template=DEFAULT_LAYOUT_CONFIG["template"],
        plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        font=DEFAULT_LAYOUT_CONFIG["font"],
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=40, r=40, t=40, b=40),
        title="ATR Channel: EMA +/- ATR * multiplier",
    )
    _apply_dark_theme(fig)
    _apply_axis_interaction(fig)

    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)
    st.caption(f"Parametres: atr_period={atr_period}, atr_mult={atr_mult:.2f}")
    st.markdown(
        "- atr_period: fenetre ATR et EMA du canal.\n"
        "- atr_mult: largeur du canal (volatilite)."
    )


# ============================================================================
# 7. HELPERS SEABORN
# ============================================================================

def _apply_seaborn_dark_style(fig, ax) -> None:
    """
    Applique le style sombre coh√©rent pour les graphiques Seaborn.

    Args:
        fig: Figure matplotlib
        ax: Axes matplotlib
    """
    fig.patch.set_facecolor(SEABORN_BG_COLOR)
    ax.set_facecolor(SEABORN_AXES_BG_COLOR)
    ax.tick_params(colors=SEABORN_TEXT_COLOR)
    ax.spines['bottom'].set_color(SEABORN_TEXT_COLOR)
    ax.spines['top'].set_color(SEABORN_TEXT_COLOR)
    ax.spines['right'].set_color(SEABORN_TEXT_COLOR)
    ax.spines['left'].set_color(SEABORN_TEXT_COLOR)


# ============================================================================
# 8. FONCTIONS PUBLIQUES - EQUITY CURVES
# ============================================================================

def render_equity_and_drawdown(
    equity: pd.Series,
    initial_capital: float = 10000.0,
    key: str = "equity_dd",
    height: int = 550,
) -> None:
    """
    Affiche la courbe d'√©quit√© et le drawdown dans un graphique √† 2 panneaux.

    Args:
        equity: S√©rie pandas de l'√©quit√©
        initial_capital: Capital initial
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    if equity is None or equity.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e d'√©quit√© √† afficher")
        return

    # Calculer le drawdown
    cummax = equity.expanding().max()
    drawdown = ((equity - cummax) / cummax) * 100

    # Cr√©er le graphique √† 2 sous-graphiques
    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.7, 0.3],
        subplot_titles=("üí∞ √âquit√© ($)", "üìâ Drawdown (%)"),
    )

    # Graphique d'√©quit√©
    fig.add_trace(
        go.Scatter(
            x=equity.index,
            y=equity.values,
            name="√âquit√©",
            line=dict(color=COLOR_PALETTE["equity_line"], width=2),
            fill="tozeroy",
            fillcolor=COLOR_PALETTE["equity_fill"],
            hovertemplate="<b>%{x}</b><br>$%{y:,.2f}<extra></extra>",
        ),
        row=1,
        col=1,
    )

    # Ligne du capital initial
    fig.add_hline(
        y=initial_capital,
        line_dash="dash",
        line_color=COLOR_PALETTE["capital_line"],
        annotation_text=f"Capital: ${initial_capital:,.0f}",
        annotation_position="left",
        row=1,
        col=1,
    )

    # Graphique de drawdown
    fig.add_trace(
        go.Scatter(
            x=drawdown.index,
            y=drawdown.values,
            name="Drawdown",
            fill="tozeroy",
            line=dict(color=COLOR_PALETTE["drawdown_line"], width=1),
            fillcolor=COLOR_PALETTE["drawdown_fill"],
            hovertemplate="<b>%{x}</b><br>%{y:.2f}%<extra></extra>",
        ),
        row=2,
        col=1,
    )

    # Mise en forme
    fig.update_layout(
        height=height,
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=50, r=50, t=40, b=30),
        template=DEFAULT_LAYOUT_CONFIG["template"],
        plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        font=DEFAULT_LAYOUT_CONFIG["font"],
        hovermode=DEFAULT_LAYOUT_CONFIG["hovermode"],
    )

    fig.update_xaxes(gridcolor=DEFAULT_GRID_COLOR)
    fig.update_yaxes(title_text="$", gridcolor=DEFAULT_GRID_COLOR, row=1, col=1)
    fig.update_yaxes(title_text="%", gridcolor=DEFAULT_GRID_COLOR, row=2, col=1)
    _apply_axis_interaction(fig)

    # Wrapper avec resampler si grand dataset
    fig = _wrap_with_resampler(fig, len(equity))

    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


def render_equity_curve(
    equity: pd.Series,
    initial_capital: float = 10000.0,
    title: str = "üíπ Courbe d'√âquit√©",
    key: str = "equity_curve",
    height: int = 350,
) -> None:
    """
    Affiche uniquement la courbe d'√©quit√© (version simple).

    Args:
        equity: S√©rie pandas de l'√©quit√©
        initial_capital: Capital initial
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    if equity is None or equity.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e d'√©quit√©")
        return

    st.markdown(f"#### {title}")

    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=equity.index,
            y=equity.values,
            mode="lines",
            name="√âquit√©",
            line=dict(color=COLOR_PALETTE["equity_line"], width=2),
            fill="tozeroy",
            fillcolor=COLOR_PALETTE["equity_fill"],
            hovertemplate="<b>%{x}</b><br>$%{y:,.2f}<extra></extra>",
        )
    )

    # Ligne du capital initial
    fig.add_hline(
        y=initial_capital,
        line_dash="dash",
        line_color=COLOR_PALETTE["capital_line"],
        annotation_text=f"Initial: ${initial_capital:,.0f}",
        annotation_position="right",
    )

    _apply_chart_layout(fig, height=height, y_title="√âquit√© ($)")
    _apply_axis_interaction(fig)
    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


# ============================================================================
# 9. FONCTIONS PUBLIQUES - OHLCV CHARTS
# ============================================================================

def render_ohlcv_with_trades(
    df: pd.DataFrame,
    trades_df: pd.DataFrame,
    title: str = "üìà Prix et Trades",
    key: str = "ohlcv_trades",
    height: int = 500,
) -> None:
    """
    Affiche un graphique OHLCV avec marqueurs de trades.

    Args:
        df: DataFrame OHLCV avec colonnes open, high, low, close
        trades_df: DataFrame des trades avec entry_time, exit_time, entry_price, exit_price
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    if df.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e OHLCV")
        return

    # V√©rifier les colonnes requises
    required_ohlc = {"open", "high", "low", "close"}
    if not required_ohlc.issubset(set(df.columns)):
        st.error(f"‚ùå Colonnes manquantes: {required_ohlc - set(df.columns)}")
        return

    trades_df = _normalize_trades_df(trades_df)

    st.markdown(f"#### {title}")

    fig = go.Figure()

    # Candlestick OHLC
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df["open"],
            high=df["high"],
            low=df["low"],
            close=df["close"],
            name="OHLC",
            increasing_line_color=COLOR_PALETTE["candle_up"],
            decreasing_line_color=COLOR_PALETTE["candle_down"],
        )
    )

    # Ajouter les marqueurs de trades
    if not trades_df.empty and "entry_time" in trades_df.columns:
        # Points d'entr√©e
        entries = trades_df[trades_df["entry_time"].notna()].copy()
        if not entries.empty:
            # D√©terminer les couleurs par type de trade (LONG/SHORT)
            entry_colors = entries.get("side", "LONG").map(
                {"LONG": COLOR_PALETTE["entry_long"], "SHORT": COLOR_PALETTE["entry_short"]}
            ).fillna(COLOR_PALETTE["entry_long"])

            fig.add_trace(
                go.Scatter(
                    x=entries["entry_time"],
                    y=entries["entry_price"],
                    mode="markers",
                    name="Entry",
                    marker=dict(
                        symbol="triangle-up",
                        size=10,
                        color=entry_colors,
                        line=dict(width=1, color="white"),
                    ),
                    hovertemplate="<b>Entry</b><br>%{x}<br>$%{y:.2f}<extra></extra>",
                )
            )

        # Points de sortie
        exits = trades_df[trades_df["exit_time"].notna()].copy()
        if not exits.empty:
            # Couleurs bas√©es sur profit/loss
            exit_colors = []
            pnl_values = []
            for _, trade in exits.iterrows():
                pnl = trade.get("pnl", 0)
                pnl_values.append(pnl)
                exit_colors.append(
                    COLOR_PALETTE["exit_profit"] if pnl > 0 else COLOR_PALETTE["exit_loss"]
                )

            fig.add_trace(
                go.Scatter(
                    x=exits["exit_time"],
                    y=exits["exit_price"],
                    mode="markers",
                    name="Exit",
                    marker=dict(
                        symbol="triangle-down",
                        size=10,
                        color=exit_colors,
                        line=dict(width=1, color="white"),
                    ),
                    customdata=pnl_values,
                    hovertemplate="<b>Exit</b><br>%{x}<br>Prix: $%{y:.2f}<br>PNL: $%{customdata:.2f}<extra></extra>",
                )
            )

    _apply_chart_layout(fig, height=height, y_title="Prix (USD)")
    _apply_axis_interaction(fig)
    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


def render_ohlcv_with_trades_and_indicators(
    df: pd.DataFrame,
    trades_df: pd.DataFrame,
    overlays: Dict[str, Any],
    active_indicators: Optional[List[str]] = None,
    title: str = "üìà Prix, Indicateurs et Trades",
    key: str = "ohlcv_trades_indicators",
    height: int = 650,
) -> None:
    """
    Affiche un graphique OHLCV avec indicateurs et marqueurs de trades.
    """
    if df.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e OHLCV")
        return

    if not {"open", "high", "low", "close"}.issubset(set(df.columns)):
        st.error("‚ùå Colonnes OHLC manquantes")
        return

    trades_df = _normalize_trades_df(trades_df)

    if active_indicators is None:
        active_set = set(overlays.keys())
    else:
        active_set = set(active_indicators)
    active_set = {name for name in active_set if name in overlays}
    has_macd = "macd" in active_set
    has_rsi = "rsi" in active_set
    has_atr = "atr" in active_set
    has_stochastic = "stochastic" in active_set
    show_second_panel = has_macd or has_rsi or has_atr or has_stochastic

    def _add_trace(trace, row: int = 1) -> None:
        if show_second_panel:
            fig.add_trace(trace, row=row, col=1)
        else:
            fig.add_trace(trace)

    if show_second_panel:
        fig = make_subplots(
            rows=2,
            cols=1,
            shared_xaxes=True,
            vertical_spacing=0.08,
            row_heights=[0.7, 0.3],
            subplot_titles=(title, "Oscillators"),
        )
    else:
        fig = go.Figure()

    candlestick = go.Candlestick(
        x=df.index,
        open=df["open"],
        high=df["high"],
        low=df["low"],
        close=df["close"],
        name="OHLC",
        increasing_line_color=COLOR_PALETTE["candle_up"],
        decreasing_line_color=COLOR_PALETTE["candle_down"],
    )
    _add_trace(candlestick, row=1)

    if "bollinger" in active_set:
        bb = overlays["bollinger"]
        upper = bb.get("upper")
        lower = bb.get("lower")
        mid = bb.get("mid")
        entry_upper = bb.get("entry_upper")
        entry_lower = bb.get("entry_lower")
        if mid is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=mid,
                    name="BB Mid",
                    line=dict(color=COLOR_PALETTE["bb_mid"], width=1),
                ),
                row=1,
            )
        if upper is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=upper,
                    name="BB Upper",
                    line=dict(color=COLOR_PALETTE["bb_bands"], width=1, dash="dash"),
                ),
                row=1,
            )
        if lower is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=lower,
                    name="BB Lower",
                    line=dict(color=COLOR_PALETTE["bb_bands"], width=1, dash="dash"),
                    fill="tonexty",
                    fillcolor=COLOR_PALETTE["bb_bands_rgba"],
                ),
                row=1,
            )
        if entry_upper is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=entry_upper,
                    name="Entry Z haut",
                    line=dict(color="#ffcc80", width=1, dash="dot"),
                ),
                row=1,
            )
        if entry_lower is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=entry_lower,
                    name="Entry Z bas",
                    line=dict(color="#ffcc80", width=1, dash="dot"),
                ),
                row=1,
            )

    if "ema" in active_set:
        ema = overlays["ema"]
        fast = ema.get("fast")
        slow = ema.get("slow")
        center = ema.get("center")
        if fast is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=fast,
                    name="EMA rapide",
                    line=dict(color=COLOR_PALETTE["ema_fast"], width=1.4),
                ),
                row=1,
            )
        if slow is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=slow,
                    name="EMA lente",
                    line=dict(color=COLOR_PALETTE["ema_slow"], width=1.4),
                ),
                row=1,
            )
        if center is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=center,
                    name="EMA centre",
                    line=dict(color=COLOR_PALETTE["ema_center"], width=1.4, dash="dot"),
                ),
                row=1,
            )

    if "ma" in active_set:
        ma = overlays["ma"]
        fast = ma.get("fast")
        slow = ma.get("slow")
        center = ma.get("center")
        if fast is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=fast,
                    name="MA rapide",
                    line=dict(color=COLOR_PALETTE["ema_fast"], width=1.4),
                ),
                row=1,
            )
        if slow is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=slow,
                    name="MA lente",
                    line=dict(color=COLOR_PALETTE["ema_slow"], width=1.4),
                ),
                row=1,
            )
        if center is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=center,
                    name="MA",
                    line=dict(color=COLOR_PALETTE["ema_center"], width=1.4, dash="dot"),
                ),
                row=1,
            )

    if "atr_channel" in active_set:
        channel = overlays["atr_channel"]
        upper = channel.get("upper")
        lower = channel.get("lower")
        center = channel.get("center")
        if upper is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=upper,
                    name="Canal haut",
                    line=dict(color=COLOR_PALETTE["atr_channel_upper"], width=1.2),
                ),
                row=1,
            )
        if lower is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=lower,
                    name="Canal bas",
                    line=dict(color=COLOR_PALETTE["atr_channel_lower"], width=1.2),
                ),
                row=1,
            )
        if center is not None:
            _add_trace(
                go.Scatter(
                    x=df.index,
                    y=center,
                    name="EMA centre",
                    line=dict(color=COLOR_PALETTE["ema_center"], width=1.2, dash="dot"),
                ),
                row=1,
            )

    if not trades_df.empty and "entry_time" in trades_df.columns:
        entries = trades_df[trades_df["entry_time"].notna()].copy()
        if not entries.empty:
            entry_colors = entries.get("side", "LONG").map(
                {"LONG": COLOR_PALETTE["entry_long"], "SHORT": COLOR_PALETTE["entry_short"]}
            ).fillna(COLOR_PALETTE["entry_long"])
            _add_trace(
                go.Scatter(
                    x=entries["entry_time"],
                    y=entries["entry_price"],
                    mode="markers",
                    name="Entry",
                    marker=dict(
                        symbol="triangle-up",
                        size=10,
                        color=entry_colors,
                        line=dict(width=1, color="white"),
                    ),
                    hovertemplate="<b>Entry</b><br>%{x}<br>$%{y:.2f}<extra></extra>",
                ),
                row=1,
            )

        exits = trades_df[trades_df["exit_time"].notna()].copy()
        if not exits.empty:
            exit_colors = []
            pnl_values = []
            for _, trade in exits.iterrows():
                pnl = trade.get("pnl", 0)
                pnl_values.append(pnl)
                exit_colors.append(
                    COLOR_PALETTE["exit_profit"] if pnl > 0 else COLOR_PALETTE["exit_loss"]
                )

            _add_trace(
                go.Scatter(
                    x=exits["exit_time"],
                    y=exits["exit_price"],
                    mode="markers",
                    name="Exit",
                    marker=dict(
                        symbol="triangle-down",
                        size=10,
                        color=exit_colors,
                        line=dict(width=1, color="white"),
                    ),
                    customdata=pnl_values,
                    hovertemplate="<b>Exit</b><br>%{x}<br>Prix: $%{y:.2f}<br>PNL: $%{customdata:.2f}<extra></extra>",
                ),
                row=1,
            )

    if show_second_panel:
        if has_macd:
            macd = overlays["macd"]
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=macd.get("macd"),
                    name="MACD",
                    line=dict(color=COLOR_PALETTE["macd_line"], width=1.4),
                ),
                row=2,
                col=1,
            )
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=macd.get("signal"),
                    name="Signal",
                    line=dict(color=COLOR_PALETTE["macd_signal"], width=1.2),
                ),
                row=2,
                col=1,
            )
        if has_rsi:
            rsi = overlays["rsi"]
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=rsi.get("rsi"),
                    name="RSI",
                    line=dict(color=COLOR_PALETTE["rsi_line"], width=1.4),
                ),
                row=2,
                col=1,
            )
            oversold = rsi.get("oversold")
            overbought = rsi.get("overbought")
            if oversold is not None:
                fig.add_hline(
                    y=oversold,
                    line_dash="dot",
                    line_color=COLOR_PALETTE["rsi_oversold"],
                    annotation_text="Oversold",
                    annotation_position="bottom left",
                    row=2,
                    col=1,
                )
            if overbought is not None:
                fig.add_hline(
                    y=overbought,
                    line_dash="dot",
                    line_color=COLOR_PALETTE["rsi_overbought"],
                    annotation_text="Overbought",
                    annotation_position="top left",
                    row=2,
                    col=1,
                )
        if has_stochastic:
            stoch = overlays["stochastic"]
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=stoch.get("k"),
                    name="%K",
                    line=dict(color=COLOR_PALETTE["stoch_k"], width=1.2),
                ),
                row=2,
                col=1,
            )
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=stoch.get("d"),
                    name="%D",
                    line=dict(color=COLOR_PALETTE["stoch_d"], width=1.2),
                ),
                row=2,
                col=1,
            )
            oversold = stoch.get("oversold")
            overbought = stoch.get("overbought")
            if oversold is not None:
                fig.add_hline(
                    y=oversold,
                    line_dash="dot",
                    line_color=COLOR_PALETTE["rsi_oversold"],
                    annotation_text="Oversold",
                    annotation_position="bottom left",
                    row=2,
                    col=1,
                )
            if overbought is not None:
                fig.add_hline(
                    y=overbought,
                    line_dash="dot",
                    line_color=COLOR_PALETTE["rsi_overbought"],
                    annotation_text="Overbought",
                    annotation_position="top left",
                    row=2,
                    col=1,
                )
        if has_atr:
            atr = overlays["atr"]
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=atr.get("atr"),
                    name="ATR",
                    line=dict(color=COLOR_PALETTE["atr_line"], width=1.4),
                ),
                row=2,
                col=1,
            )
            threshold = atr.get("threshold")
            if threshold is not None:
                fig.add_hline(
                    y=threshold,
                    line_dash="dot",
                    line_color=COLOR_PALETTE["atr_threshold"],
                    annotation_text="ATR Threshold",
                    annotation_position="top left",
                    row=2,
                    col=1,
                )

        fig.update_layout(
            height=height,
            template=DEFAULT_LAYOUT_CONFIG["template"],
            plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
            paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
            font=DEFAULT_LAYOUT_CONFIG["font"],
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1,
            ),
            margin=dict(l=40, r=40, t=60, b=40),
            hovermode=DEFAULT_LAYOUT_CONFIG["hovermode"],
        )
        fig.update_xaxes(showgrid=False)
        fig.update_yaxes(gridcolor=DEFAULT_GRID_COLOR)
        _apply_axis_interaction(fig)

        # Wrapper avec resampler si grand dataset
        fig = _wrap_with_resampler(fig, len(df))

        st.plotly_chart(
            fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
        )
        return

    _apply_chart_layout(fig, height=height, y_title="Prix (USD)")
    _apply_axis_interaction(fig)

    # Wrapper avec resampler si grand dataset
    fig = _wrap_with_resampler(fig, len(df))

    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


def render_ohlcv_with_indicators(
    df: pd.DataFrame,
    indicators: Dict[str, Any],
    title: str = "üìä Prix et Indicateurs",
    key: str = "ohlcv_indicators",
    height: int = 500,
) -> None:
    """
    Affiche un graphique OHLCV avec indicateurs techniques.

    Args:
        df: DataFrame OHLCV
        indicators: Dict d'indicateurs (ex: {'bollinger': {'upper': series, 'lower': series}})
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    if df.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e OHLCV")
        return

    st.markdown(f"#### {title}")

    fig = go.Figure()

    # Candlestick
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df["open"],
            high=df["high"],
            low=df["low"],
            close=df["close"],
            name="OHLC",
            increasing_line_color=COLOR_PALETTE["candle_up"],
            decreasing_line_color=COLOR_PALETTE["candle_down"],
        )
    )

    # Ajouter les indicateurs
    if "bollinger" in indicators:
        bb = indicators["bollinger"]
        if "upper" in bb and "lower" in bb and "mid" in bb:
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=bb["mid"],
                    name="BB Mid",
                    line=dict(color=COLOR_PALETTE["bb_mid"], width=1),
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=bb["upper"],
                    name="BB Upper",
                    line=dict(color=COLOR_PALETTE["bb_bands"], width=1, dash="dash"),
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=bb["lower"],
                    name="BB Lower",
                    line=dict(color=COLOR_PALETTE["bb_bands"], width=1, dash="dash"),
                    fill="tonexty",
                    fillcolor=COLOR_PALETTE["bb_bands_rgba"],
                )
            )

    _apply_chart_layout(fig, height=height, y_title="Prix (USD)")
    _apply_axis_interaction(fig)
    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


# ============================================================================
# 10. FONCTIONS PUBLIQUES - COMPARISON
# ============================================================================

def render_comparison_chart(
    results_list: List[Dict[str, Any]],
    metric: str = "sharpe_ratio",
    title: str = "üìä Comparaison des R√©sultats",
    key: str = "comparison",
    height: int = 400,
) -> None:
    """
    Affiche un graphique de comparaison entre plusieurs r√©sultats.

    Args:
        results_list: Liste de dict avec 'name' et 'metrics'
        metric: M√©trique √† comparer
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    if not results_list:
        st.warning("‚ö†Ô∏è Aucun r√©sultat √† comparer")
        return

    st.markdown(f"#### {title}")

    names = [r.get("name", f"Run {i}") for i, r in enumerate(results_list)]
    values = [r.get("metrics", {}).get(metric, 0) for r in results_list]

    fig = go.Figure(
        data=[
            go.Bar(
                x=names,
                y=values,
                marker_color=[
                    COLOR_PALETTE["equity_line"] if v > 0 else COLOR_PALETTE["drawdown_line"]
                    for v in values
                ],
                text=[f"{v:.2f}" for v in values],
                textposition="outside",
            )
        ]
    )

    fig.update_layout(
        title=metric.replace("_", " ").title(),
        height=height,
        showlegend=False,
        template=DEFAULT_LAYOUT_CONFIG["template"],
        plot_bgcolor=DEFAULT_LAYOUT_CONFIG["plot_bgcolor"],
        paper_bgcolor=DEFAULT_LAYOUT_CONFIG["paper_bgcolor"],
        font=DEFAULT_LAYOUT_CONFIG["font"],
        margin=dict(l=50, r=50, t=50, b=50),
    )

    fig.update_xaxes(gridcolor=DEFAULT_GRID_COLOR)
    fig.update_yaxes(gridcolor=DEFAULT_GRID_COLOR)

    _apply_axis_interaction(fig)
    st.plotly_chart(
        fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG
    )


# ============================================================================
# 11. FONCTIONS PUBLIQUES - STRATEGY DIAGRAMS
# ============================================================================

def render_strategy_param_diagram(
    strategy_key: str,
    params: Dict[str, Any],
    key: str = "strategy_diagram",
) -> None:
    """
    Affiche un schema explicatif des indicateurs et parametres d'une strategie.

    Dispatcher pour les diff√©rentes strat√©gies.

    Args:
        strategy_key: Identifiant de la strat√©gie
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
    """
    # Dictionnaire de mapping strat√©gie -> fonction de rendu
    strategy_renderers = {
        "bollinger_atr": _render_bollinger_atr_diagram,
        "bollinger_best_longe_3i": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),
        "bollinger_best_short_3i": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),
        "ema_cross": _render_ema_cross_diagram,
        "macd_cross": _render_macd_cross_diagram,
        "rsi_reversal": _render_rsi_reversal_diagram,
        "atr_channel": _render_atr_channel_diagram,
    }

    # Appeler le renderer appropri√©
    renderer = strategy_renderers.get(strategy_key)
    if renderer:
        renderer(params, key)
    else:
        st.info("Schema non disponible pour cette strategie.")


# ============================================================================
# 12. FONCTIONS PUBLIQUES - DISTRIBUTIONS
# ============================================================================

def render_trade_pnl_distribution(
    trades_df: pd.DataFrame,
    title: str = "üìä Distribution des P&L par Trade",
    key: str = "trade_pnl_dist",
    height: int = 400,
) -> None:
    """
    Affiche la distribution des P&L par trade avec histogramme + KDE (seaborn).

    Args:
        trades_df: DataFrame des trades avec colonne 'pnl'
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    _ = key
    if not SEABORN_AVAILABLE:
        st.warning("‚ö†Ô∏è Seaborn non disponible - Distribution non affich√©e")
        return

    if trades_df.empty or 'pnl' not in trades_df.columns:
        st.warning("‚ö†Ô∏è Aucune donn√©e de P&L √† afficher")
        return

    st.markdown(f"#### {title}")
    st.caption("üìä Graphique g√©n√©r√© avec **Seaborn** (histogramme + KDE)")

    # Configuration style seaborn
    sns.set_style("darkgrid")
    fig, ax = plt.subplots(figsize=(10, height / 100))

    # Histogramme + KDE avec seaborn
    pnl_values = trades_df['pnl'].dropna()
    sns.histplot(
        pnl_values,
        kde=True,
        color=COLOR_PALETTE["equity_line"],
        edgecolor=SEABORN_EDGE_COLOR,
        alpha=0.7,
        ax=ax,
        stat="density"
    )

    # Ligne verticale √† z√©ro
    ax.axvline(0, color='white', linestyle='--', linewidth=1, alpha=0.5)

    # Statistiques
    mean_pnl = pnl_values.mean()
    median_pnl = pnl_values.median()
    ax.axvline(
        mean_pnl,
        color=COLOR_PALETTE["bb_mid"],
        linestyle='-',
        linewidth=2,
        label=f'Moyenne: ${mean_pnl:.2f}'
    )
    ax.axvline(
        median_pnl,
        color=COLOR_PALETTE["ema_fast"],
        linestyle='-',
        linewidth=2,
        label=f'M√©diane: ${median_pnl:.2f}'
    )

    ax.set_xlabel('P&L ($)', color=SEABORN_TEXT_COLOR, fontsize=11)
    ax.set_ylabel('Densit√©', color=SEABORN_TEXT_COLOR, fontsize=11)
    ax.set_title(title, color=SEABORN_TEXT_COLOR, fontsize=13, pad=15)
    ax.legend(
        loc='upper right',
        facecolor=SEABORN_AXES_BG_COLOR,
        edgecolor=SEABORN_TEXT_COLOR,
        labelcolor=SEABORN_TEXT_COLOR
    )

    # Appliquer le style sombre
    _apply_seaborn_dark_style(fig, ax)

    st.pyplot(fig, width="stretch")
    plt.close(fig)


def render_returns_distribution(
    returns: pd.Series,
    title: str = "üìà Distribution des Rendements",
    key: str = "returns_dist",
    height: int = 400,
) -> None:
    """
    Affiche la distribution des rendements avec histogramme + KDE (seaborn).

    Args:
        returns: S√©rie des rendements
        title: Titre du graphique
        key: Cl√© unique Streamlit
        height: Hauteur du graphique
    """
    _ = key
    if not SEABORN_AVAILABLE:
        st.warning("‚ö†Ô∏è Seaborn non disponible - Distribution non affich√©e")
        return

    if returns.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e de rendements √† afficher")
        return

    st.markdown(f"#### {title}")
    st.caption("üìä Graphique g√©n√©r√© avec **Seaborn** (histogramme + KDE)")

    # Configuration style seaborn
    sns.set_style("darkgrid")
    fig, ax = plt.subplots(figsize=(10, height / 100))

    # Histogramme + KDE
    returns_clean = returns.dropna()
    sns.histplot(
        returns_clean,
        kde=True,
        color=COLOR_PALETTE["ema_fast"],
        edgecolor=SEABORN_EDGE_COLOR,
        alpha=0.7,
        ax=ax,
        stat="density"
    )

    # Ligne verticale √† z√©ro
    ax.axvline(0, color='white', linestyle='--', linewidth=1, alpha=0.5)

    # Statistiques
    mean_ret = returns_clean.mean()
    std_ret = returns_clean.std()
    ax.axvline(
        mean_ret,
        color=COLOR_PALETTE["equity_line"],
        linestyle='-',
        linewidth=2,
        label=f'Moyenne: {mean_ret:.4f}'
    )
    ax.axvline(
        mean_ret + std_ret,
        color=COLOR_PALETTE["drawdown_line"],
        linestyle=':',
        linewidth=1.5,
        label=f'+1œÉ: {mean_ret + std_ret:.4f}'
    )
    ax.axvline(
        mean_ret - std_ret,
        color=COLOR_PALETTE["drawdown_line"],
        linestyle=':',
        linewidth=1.5,
        label=f'-1œÉ: {mean_ret - std_ret:.4f}'
    )

    ax.set_xlabel('Rendement', color=SEABORN_TEXT_COLOR, fontsize=11)
    ax.set_ylabel('Densit√©', color=SEABORN_TEXT_COLOR, fontsize=11)
    ax.set_title(title, color=SEABORN_TEXT_COLOR, fontsize=13, pad=15)
    ax.legend(
        loc='upper right',
        facecolor=SEABORN_AXES_BG_COLOR,
        edgecolor=SEABORN_TEXT_COLOR,
        labelcolor=SEABORN_TEXT_COLOR
    )

    # Appliquer le style sombre
    _apply_seaborn_dark_style(fig, ax)

    st.pyplot(fig, width="stretch")
    plt.close(fig)


# ============================================================================
# 13. VISUALISATIONS MULTI-SWEEP
# ============================================================================

def render_multi_sweep_heatmap(
    results_df: pd.DataFrame,
    metric: str = "total_pnl",
    title: Optional[str] = None,
    key: Optional[str] = None,
) -> None:
    """
    Affiche une heatmap interactive des r√©sultats multi-sweep.

    Args:
        results_df: DataFrame avec colonnes strategy, symbol, timeframe, metric
        metric: M√©trique √† afficher (default: total_pnl)
        title: Titre optionnel
        key: Cl√© Streamlit optionnelle
    """
    import plotly.graph_objects as go

    if results_df is None:
        st.warning("Aucun r√©sultat √† afficher")
        return

    if not isinstance(results_df, pd.DataFrame):
        results_df = pd.DataFrame(results_df)

    if results_df.empty:
        st.warning("Aucun r√©sultat √† afficher")
        return

    # Cr√©er pivot table pour heatmap
    # Lignes = strat√©gies, Colonnes = symbol_timeframe
    results_df["token_tf"] = results_df["symbol"] + "_" + results_df["timeframe"]

    pivot = results_df.pivot_table(
        index="strategy",
        columns="token_tf",
        values=metric,
        aggfunc="mean"
    )

    # Colorscale centr√©e sur z√©ro pour PnL
    fig = go.Figure(data=go.Heatmap(
        z=pivot.values,
        x=pivot.columns,
        y=pivot.index,
        colorscale="RdYlGn",  # Rouge n√©gatif, vert positif
        zmid=0,  # Centrer sur z√©ro
        text=pivot.values.round(2),
        texttemplate='%{text}',
        textfont={"size": 10},
        colorbar=dict(title=metric)
    ))

    fig.update_layout(
        title=title or f"Heatmap {metric}",
        xaxis_title="Token √ó Timeframe",
        yaxis_title="Strat√©gie",
        height=400 + len(pivot.index) * 30,  # Hauteur adaptative
        template="plotly_dark"
    )

    st.plotly_chart(fig, width="stretch", key=key)


def render_multi_sweep_ranking(
    results_df: pd.DataFrame,
    metric: str = "total_pnl",
    top_n: int = 20,
    title: Optional[str] = None,
    key: Optional[str] = None,
) -> None:
    """
    Affiche un classement horizontal des meilleurs r√©sultats.

    Args:
        results_df: DataFrame avec colonnes strategy, symbol, timeframe, metric
        metric: M√©trique pour le classement (default: total_pnl)
        top_n: Nombre de r√©sultats √† afficher (default: 20)
        title: Titre optionnel
        key: Cl√© Streamlit optionnelle
    """
    import plotly.graph_objects as go

    if results_df is None:
        st.warning("Aucun r√©sultat √† afficher")
        return

    if not isinstance(results_df, pd.DataFrame):
        results_df = pd.DataFrame(results_df)

    if results_df.empty:
        st.warning("Aucun r√©sultat √† afficher")
        return

    # Filtrer les r√©sultats valides (metric non-None et non-NaN)
    if metric in results_df.columns:
        valid_df = results_df[results_df[metric].notna()].copy()
        if valid_df.empty:
            st.warning(f"Aucun r√©sultat valide pour la m√©trique '{metric}'")
            return
    else:
        st.error(f"M√©trique '{metric}' non trouv√©e dans les r√©sultats")
        return

    # Cr√©er label combin√©
    valid_df["label"] = (
        valid_df["strategy"] + " | " +
        valid_df["symbol"] + " " +
        valid_df["timeframe"]
    )

    # Trier (convertir en num√©rique si n√©cessaire)
    valid_df[metric] = pd.to_numeric(valid_df[metric], errors='coerce')

    # Re-filtrer apr√®s conversion (√©liminer les NaN cr√©√©s par coerce)
    valid_df = valid_df[valid_df[metric].notna()].copy()

    if valid_df.empty:
        st.warning(f"Aucune valeur num√©rique valide pour '{metric}'")
        return

    sorted_df = valid_df.nlargest(top_n, metric)

    # Couleur selon signe (vert positif, rouge n√©gatif)
    colors = ["#00e676" if val > 0 else "#ff5252" for val in sorted_df[metric]]

    fig = go.Figure(data=go.Bar(
        x=sorted_df[metric],
        y=sorted_df["label"],
        orientation='h',
        marker=dict(color=colors),
        text=sorted_df[metric].round(2),
        textposition='auto',
    ))

    fig.update_layout(
        title=title or f"Top {top_n} - {metric}",
        xaxis_title=metric,
        yaxis_title="",
        height=400 + top_n * 20,  # Hauteur adaptative
        yaxis=dict(autorange="reversed"),  # Meilleur en haut
        template="plotly_dark"
    )

    st.plotly_chart(fig, width="stretch", key=key)


# ============================================================================
# 14. API PUBLIQUE
# ============================================================================

__all__ = [
    "render_equity_and_drawdown",
    "render_ohlcv_with_trades",
    "render_ohlcv_with_trades_and_indicators",
    "render_ohlcv_with_indicators",
    "render_equity_curve",
    "render_comparison_chart",
    "render_strategy_param_diagram",
    "render_trade_pnl_distribution",
    "render_returns_distribution",
    "render_multi_sweep_heatmap",
    "render_multi_sweep_ranking",
]
```
<!-- MODULE-END: charts.py -->

<!-- MODULE-START: diagram_factory.py -->
```json
{
  "name": "diagram_factory.py",
  "path": "ui\\components\\diagram_factory.py",
  "ext": ".py",
  "anchor": "diagram_factory_py"
}
```
## diagram_factory_py
*Chemin* : `ui\components\diagram_factory.py`  
*Type* : `.py`  

```python
"""
Factory pour la g√©n√©ration de diagrammes de strat√©gies.

Ce module centralise la logique commune des 8 fonctions _render_*_diagram
en utilisant le pattern Factory pour r√©duire la duplication de code (~860 lignes ‚Üí ~350 lignes).

Architecture:
    - DiagramConfig: Configuration dataclass pour un diagramme
    - create_base_figure(): Cr√©e la figure Plotly avec subplots optionnels
    - add_price_trace(): Ajoute la trace de prix
    - add_bollinger_traces(): Ajoute les bandes de Bollinger
    - add_indicator_panel(): Ajoute un panel d'indicateur (ATR, RSI, MACD)
    - add_entry_marker(): Ajoute un marqueur d'entr√©e
    - render_diagram(): Rendu final avec Streamlit

Usage:
    from ui.components.diagram_factory import (
        DiagramConfig, create_base_figure, add_price_trace,
        add_bollinger_traces, render_diagram
    )

    config = DiagramConfig(rows=2, row_heights=[0.7, 0.3], titles=["Prix", "ATR"])
    fig = create_base_figure(config)
    add_price_trace(fig, x, price)
    add_bollinger_traces(fig, x, bb_upper, bb_middle, bb_lower)
    render_diagram(fig, key="diagram_key", caption="Params: ...", help_text="...")

Cr√©√© le 23/01/2026 - Phase 3 refactoring charts.py
"""

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

# Import du syst√®me de th√®me centralis√©
try:
    from ui.theme import get_color, get_colors
    THEME_AVAILABLE = True
except ImportError:
    THEME_AVAILABLE = False
    def get_color(name: str, default: str = "#ffffff") -> str:
        return default
    def get_colors() -> Dict[str, str]:
        return {}

# Configuration Plotly par d√©faut
PLOTLY_CHART_CONFIG = {
    "displayModeBar": True,
    "displaylogo": False,
    "modeBarButtonsToRemove": ["lasso2d", "select2d"],
    "scrollZoom": True,
}

DEFAULT_LAYOUT = {
    "template": "plotly_dark",
    "plot_bgcolor": "rgba(0,0,0,0)",
    "paper_bgcolor": "rgba(0,0,0,0)",
    "font": {"color": "#e0e0e0", "size": 11},
}


# ============================================================================
# DATACLASSES DE CONFIGURATION
# ============================================================================

@dataclass
class DiagramConfig:
    """Configuration pour un diagramme de strat√©gie."""

    rows: int = 1
    cols: int = 1
    row_heights: Optional[List[float]] = None
    subplot_titles: Optional[Tuple[str, ...]] = None
    shared_xaxes: bool = True
    vertical_spacing: float = 0.08
    height: int = 500
    title: Optional[str] = None

    def __post_init__(self):
        if self.row_heights is None and self.rows > 1:
            # Distribution par d√©faut: 70% prix, 30% indicateur
            self.row_heights = [0.7] + [0.3 / (self.rows - 1)] * (self.rows - 1)


@dataclass
class TraceConfig:
    """Configuration pour une trace Plotly."""

    name: str
    color_key: str  # Cl√© dans le syst√®me de couleurs
    width: float = 1.5
    dash: Optional[str] = None  # "solid", "dot", "dash", "dashdot"
    fill: Optional[str] = None  # "tozeroy", "tonexty", etc.
    fillcolor: Optional[str] = None
    opacity: float = 1.0
    mode: str = "lines"  # "lines", "markers", "lines+markers"
    row: int = 1
    col: int = 1


@dataclass
class MarkerConfig:
    """Configuration pour un marqueur (entr√©e, sortie, signal)."""

    x: float
    y: float
    name: str
    color_key: str
    symbol: str = "triangle-up"  # "triangle-up", "triangle-down", "circle", "x"
    size: int = 14
    row: int = 1
    col: int = 1


# ============================================================================
# PALETTE DE COULEURS (avec fallback)
# ============================================================================

def _get_palette() -> Dict[str, str]:
    """Retourne la palette de couleurs active."""
    if THEME_AVAILABLE:
        return get_colors()
    # Fallback palette
    return {
        "price_line": "#90caf9",
        "bb_upper": "#ff9800",
        "bb_middle": "#9c27b0",
        "bb_lower": "#4caf50",
        "atr_line": "#ff5252",
        "atr_threshold": "#ffeb3b",
        "ema_fast": "#00bcd4",
        "ema_slow": "#ff9800",
        "macd_line": "#2196f3",
        "macd_signal": "#ff9800",
        "rsi_line": "#9c27b0",
        "rsi_oversold": "#4caf50",
        "rsi_overbought": "#f44336",
        "entry_long": "#00e676",
        "entry_short": "#ff5252",
        "stop_loss": "#f44336",
        "take_profit": "#00e676",
        "atr_channel_upper": "#ff9800",
        "atr_channel_lower": "#4caf50",
        "ema_center": "#9c27b0",
        "equity_line": "#00e676",
    }


def _get_color(key: str, default: str = "#ffffff") -> str:
    """R√©cup√®re une couleur du th√®me ou du fallback."""
    palette = _get_palette()
    return palette.get(key, default)


# ============================================================================
# CR√âATION DE FIGURE
# ============================================================================

def create_base_figure(config: DiagramConfig) -> go.Figure:
    """
    Cr√©e une figure Plotly de base avec configuration optionnelle de subplots.

    Args:
        config: Configuration du diagramme

    Returns:
        Figure Plotly configur√©e
    """
    if config.rows > 1 or config.cols > 1:
        fig = make_subplots(
            rows=config.rows,
            cols=config.cols,
            shared_xaxes=config.shared_xaxes,
            vertical_spacing=config.vertical_spacing,
            row_heights=config.row_heights,
            subplot_titles=config.subplot_titles,
        )
    else:
        fig = go.Figure()

    return fig


def apply_standard_layout(
    fig: go.Figure,
    config: DiagramConfig,
    dark_theme: bool = True,
) -> None:
    """
    Applique le layout standard √† une figure.

    Args:
        fig: Figure Plotly
        config: Configuration du diagramme
        dark_theme: Activer le th√®me sombre
    """
    layout_update = {
        "height": config.height,
        "template": DEFAULT_LAYOUT["template"] if dark_theme else "plotly_white",
        "plot_bgcolor": DEFAULT_LAYOUT["plot_bgcolor"],
        "paper_bgcolor": DEFAULT_LAYOUT["paper_bgcolor"],
        "font": DEFAULT_LAYOUT["font"],
        "legend": dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
        "margin": dict(l=40, r=40, t=40, b=40),
    }

    if config.title:
        layout_update["title"] = config.title

    fig.update_layout(**layout_update)

    # Axes interactifs
    _apply_axis_interaction(fig)


def _apply_axis_interaction(fig: go.Figure) -> None:
    """Active l'interaction sur les axes (zoom, pan)."""
    fig.update_xaxes(
        showgrid=True,
        gridwidth=1,
        gridcolor="rgba(128,128,128,0.2)",
        zeroline=False,
    )
    fig.update_yaxes(
        showgrid=True,
        gridwidth=1,
        gridcolor="rgba(128,128,128,0.2)",
        zeroline=False,
    )


# ============================================================================
# DONN√âES SYNTH√âTIQUES
# ============================================================================

def create_synthetic_price(
    n: int = 160,
    seed: int = 42,
) -> Tuple[np.ndarray, np.ndarray, pd.Series]:
    """
    G√©n√®re des donn√©es de prix synth√©tiques pour les diagrammes.

    Args:
        n: Nombre de points
        seed: Graine pour reproductibilit√©

    Returns:
        Tuple (x, price_array, price_series)
    """
    np.random.seed(seed)
    x = np.arange(n)
    trend = np.linspace(100, 110, n)
    noise = np.cumsum(np.random.randn(n) * 0.5)
    cycle = 3 * np.sin(np.linspace(0, 4 * np.pi, n))
    price = trend + noise + cycle
    return x, price, pd.Series(price)


# ============================================================================
# CALCULS D'INDICATEURS
# ============================================================================

def calculate_bollinger(
    price_series: pd.Series,
    period: int,
    num_std: float = 2.0,
) -> Tuple[pd.Series, pd.Series, pd.Series]:
    """
    Calcule les bandes de Bollinger.

    Args:
        price_series: S√©rie de prix
        period: P√©riode de la moyenne mobile
        num_std: Nombre d'√©carts-types

    Returns:
        Tuple (upper, middle, lower)
    """
    middle = price_series.rolling(window=period, min_periods=1).mean()
    std = price_series.rolling(window=period, min_periods=1).std().fillna(0)
    upper = middle + num_std * std
    lower = middle - num_std * std
    return upper, middle, lower


def calculate_atr(
    price_series: pd.Series,
    period: int,
    volatility_factor: float = 0.6,
) -> pd.Series:
    """
    Calcule l'ATR simplifi√© pour les diagrammes.

    Args:
        price_series: S√©rie de prix
        period: P√©riode ATR
        volatility_factor: Facteur de volatilit√© synth√©tique

    Returns:
        S√©rie ATR
    """
    n = len(price_series)
    high = price_series + volatility_factor + 0.3 * np.sin(np.linspace(0, 8 * np.pi, n))
    low = price_series - volatility_factor - 0.3 * np.sin(np.linspace(0, 8 * np.pi, n))
    prev_close = price_series.shift(1).fillna(price_series.iloc[0])

    tr = pd.concat([
        (high - low).abs(),
        (high - prev_close).abs(),
        (low - prev_close).abs(),
    ], axis=1).max(axis=1)

    return tr.ewm(span=period, adjust=False).mean()


def calculate_ema(price_series: pd.Series, period: int) -> pd.Series:
    """Calcule une EMA."""
    return price_series.ewm(span=period, adjust=False).mean()


def calculate_rsi(price_series: pd.Series, period: int) -> pd.Series:
    """Calcule le RSI."""
    delta = price_series.diff().fillna(0)
    gains = delta.clip(lower=0)
    losses = -delta.clip(upper=0)
    avg_gain = gains.ewm(alpha=1/period, adjust=False).mean()
    avg_loss = losses.ewm(alpha=1/period, adjust=False).mean().replace(0, 1e-6)
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))


def calculate_macd(
    price_series: pd.Series,
    fast_period: int,
    slow_period: int,
    signal_period: int,
) -> Tuple[pd.Series, pd.Series]:
    """Calcule le MACD et sa ligne signal."""
    ema_fast = price_series.ewm(span=fast_period, adjust=False).mean()
    ema_slow = price_series.ewm(span=slow_period, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()
    return macd_line, signal_line


# ============================================================================
# AJOUT DE TRACES
# ============================================================================

def add_price_trace(
    fig: go.Figure,
    x: np.ndarray,
    price: np.ndarray,
    name: str = "Prix",
    row: int = 1,
    col: int = 1,
) -> None:
    """Ajoute une trace de prix."""
    color = _get_color("price_line", "#90caf9")
    trace = go.Scatter(
        x=x, y=price, name=name,
        line=dict(color=color, width=1.5),
    )
    if row > 1 or col > 1:
        fig.add_trace(trace, row=row, col=col)
    else:
        fig.add_trace(trace)


def add_bollinger_traces(
    fig: go.Figure,
    x: np.ndarray,
    upper: pd.Series,
    middle: pd.Series,
    lower: pd.Series,
    row: int = 1,
    col: int = 1,
    show_fill: bool = True,
) -> None:
    """Ajoute les traces de Bollinger."""
    palette = _get_palette()

    traces = [
        go.Scatter(
            x=x, y=upper, name="BB Upper",
            line=dict(color=palette.get("bb_upper", "#ff9800"), width=1.2),
        ),
        go.Scatter(
            x=x, y=middle, name="BB Middle",
            line=dict(color=palette.get("bb_middle", "#9c27b0"), width=1.4, dash="dot"),
        ),
        go.Scatter(
            x=x, y=lower, name="BB Lower",
            line=dict(color=palette.get("bb_lower", "#4caf50"), width=1.2),
            fill="tonexty" if show_fill else None,
            fillcolor="rgba(156, 39, 176, 0.1)" if show_fill else None,
        ),
    ]

    for trace in traces:
        if row > 1:
            fig.add_trace(trace, row=row, col=col)
        else:
            fig.add_trace(trace)


def add_atr_panel(
    fig: go.Figure,
    x: np.ndarray,
    atr_values: pd.Series,
    threshold: Optional[float] = None,
    row: int = 2,
    col: int = 1,
) -> None:
    """Ajoute un panel ATR."""
    palette = _get_palette()

    fig.add_trace(
        go.Scatter(
            x=x, y=atr_values, name="ATR",
            line=dict(color=palette.get("atr_line", "#ff5252"), width=1.5),
        ),
        row=row, col=col,
    )

    if threshold is not None:
        fig.add_hline(
            y=threshold, line_dash="dot",
            line_color=palette.get("atr_threshold", "#ffeb3b"),
            annotation_text="Seuil ATR",
            annotation_position="top left",
            row=row, col=col,
        )


def add_rsi_panel(
    fig: go.Figure,
    x: np.ndarray,
    rsi_values: pd.Series,
    oversold: float = 30,
    overbought: float = 70,
    row: int = 2,
    col: int = 1,
) -> None:
    """Ajoute un panel RSI avec zones."""
    palette = _get_palette()

    fig.add_trace(
        go.Scatter(
            x=x, y=rsi_values, name="RSI",
            line=dict(color=palette.get("rsi_line", "#9c27b0"), width=1.6),
        ),
        row=row, col=col,
    )

    fig.add_hline(
        y=oversold, line_dash="dot",
        line_color=palette.get("rsi_oversold", "#4caf50"),
        annotation_text="Oversold",
        annotation_position="bottom left",
        row=row, col=col,
    )
    fig.add_hline(
        y=overbought, line_dash="dot",
        line_color=palette.get("rsi_overbought", "#f44336"),
        annotation_text="Overbought",
        annotation_position="top left",
        row=row, col=col,
    )


def add_macd_panel(
    fig: go.Figure,
    x: np.ndarray,
    macd_line: pd.Series,
    signal_line: pd.Series,
    row: int = 2,
    col: int = 1,
) -> None:
    """Ajoute un panel MACD."""
    palette = _get_palette()

    fig.add_trace(
        go.Scatter(
            x=x, y=macd_line, name="MACD",
            line=dict(color=palette.get("macd_line", "#2196f3"), width=1.6),
        ),
        row=row, col=col,
    )
    fig.add_trace(
        go.Scatter(
            x=x, y=signal_line, name="Signal",
            line=dict(color=palette.get("macd_signal", "#ff9800"), width=1.4),
        ),
        row=row, col=col,
    )


def add_ema_traces(
    fig: go.Figure,
    x: np.ndarray,
    ema_fast: pd.Series,
    ema_slow: pd.Series,
    fast_label: str = "EMA rapide",
    slow_label: str = "EMA lente",
    row: int = 1,
    col: int = 1,
) -> None:
    """Ajoute les traces EMA."""
    palette = _get_palette()

    traces = [
        go.Scatter(
            x=x, y=ema_fast, name=fast_label,
            line=dict(color=palette.get("ema_fast", "#00bcd4"), width=1.5),
        ),
        go.Scatter(
            x=x, y=ema_slow, name=slow_label,
            line=dict(color=palette.get("ema_slow", "#ff9800"), width=1.5),
        ),
    ]

    for trace in traces:
        if row > 1:
            fig.add_trace(trace, row=row, col=col)
        else:
            fig.add_trace(trace)


def add_atr_channel_traces(
    fig: go.Figure,
    x: np.ndarray,
    upper: pd.Series,
    center: pd.Series,
    lower: pd.Series,
) -> None:
    """Ajoute les traces de canal ATR."""
    palette = _get_palette()

    fig.add_trace(go.Scatter(
        x=x, y=upper, name="Canal haut",
        line=dict(color=palette.get("atr_channel_upper", "#ff9800"), width=1.2),
    ))
    fig.add_trace(go.Scatter(
        x=x, y=center, name="EMA centre",
        line=dict(color=palette.get("ema_center", "#9c27b0"), width=1.4, dash="dot"),
    ))
    fig.add_trace(go.Scatter(
        x=x, y=lower, name="Canal bas",
        line=dict(color=palette.get("atr_channel_lower", "#4caf50"), width=1.2),
    ))


def add_entry_marker(
    fig: go.Figure,
    x: float,
    y: float,
    name: str = "Entr√©e",
    is_long: bool = True,
    row: int = 1,
    col: int = 1,
) -> None:
    """Ajoute un marqueur d'entr√©e."""
    palette = _get_palette()
    color = palette.get("entry_long" if is_long else "entry_short", "#00e676" if is_long else "#ff5252")
    symbol = "triangle-up" if is_long else "triangle-down"

    trace = go.Scatter(
        x=[x], y=[y], name=name,
        mode="markers",
        marker=dict(color=color, symbol=symbol, size=14),
    )

    if row > 1:
        fig.add_trace(trace, row=row, col=col)
    else:
        fig.add_trace(trace)


def add_stop_loss_line(
    fig: go.Figure,
    y_value: float,
    x_start: float,
    x_end: float,
    row: int = 1,
    col: int = 1,
) -> None:
    """Ajoute une ligne de stop-loss."""
    palette = _get_palette()

    trace = go.Scatter(
        x=[x_start, x_end], y=[y_value, y_value],
        name="Stop Loss",
        line=dict(color=palette.get("stop_loss", "#f44336"), width=2, dash="dash"),
    )

    if row > 1:
        fig.add_trace(trace, row=row, col=col)
    else:
        fig.add_trace(trace)


def add_take_profit_line(
    fig: go.Figure,
    y_value: float,
    x_start: float,
    x_end: float,
    row: int = 1,
    col: int = 1,
) -> None:
    """Ajoute une ligne de take-profit."""
    palette = _get_palette()

    trace = go.Scatter(
        x=[x_start, x_end], y=[y_value, y_value],
        name="Take Profit",
        line=dict(color=palette.get("take_profit", "#00e676"), width=2, dash="dash"),
    )

    if row > 1:
        fig.add_trace(trace, row=row, col=col)
    else:
        fig.add_trace(trace)


# ============================================================================
# RENDU STREAMLIT
# ============================================================================

def render_diagram(
    fig: go.Figure,
    key: str,
    caption: Optional[str] = None,
    help_text: Optional[str] = None,
) -> None:
    """
    Effectue le rendu final du diagramme avec Streamlit.

    Args:
        fig: Figure Plotly configur√©e
        key: Cl√© unique Streamlit
        caption: Texte de l√©gende (param√®tres)
        help_text: Texte d'aide Markdown
    """
    st.plotly_chart(fig, width="stretch", key=key, config=PLOTLY_CHART_CONFIG)

    if caption:
        st.caption(caption)

    if help_text:
        st.markdown(help_text)


# ============================================================================
# FACTORY FUNCTIONS - DIAGRAMMES COMPLETS
# ============================================================================

def create_bollinger_atr_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
    variant: str = "standard",  # "standard", "v2", "v3", "long_test"
) -> None:
    """
    Factory pour les diagrammes Bollinger + ATR.

    Args:
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit
        n: Nombre de points
        variant: Type de diagramme ("standard", "v2", "v3", "long_test")
    """
    x, price, price_series = create_synthetic_price(n)

    # Extraction des param√®tres communs
    bb_period = max(2, min(int(params.get("bb_period", 20)), n - 1))
    bb_std = float(params.get("bb_std", 2.0))
    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))

    # Calculs
    bb_upper, bb_middle, bb_lower = calculate_bollinger(price_series, bb_period, bb_std)
    atr_values = calculate_atr(price_series, atr_period)

    # Configuration selon variant
    if variant == "long_test":
        # Version simplifi√©e sans ATR panel
        config = DiagramConfig(
            rows=1,
            subplot_titles=("Prix + Bollinger",),
            height=460,
        )
        fig = create_base_figure(config)
        add_price_trace(fig, x, price)
        add_bollinger_traces(fig, x, bb_upper, bb_middle, bb_lower)

        # Niveaux bb_pos
        entry_level = float(params.get("entry_level", 0.0))
        sl_level = float(params.get("sl_level", -0.5))
        tp_level = float(params.get("tp_level", 1.0))

        bb_range = (bb_upper - bb_lower).mean()
        entry_y = bb_lower.iloc[n//2] + entry_level * bb_range
        sl_y = bb_lower.iloc[n//2] + sl_level * bb_range
        tp_y = bb_lower.iloc[n//2] + tp_level * bb_range

        add_entry_marker(fig, n//2, entry_y, "Entr√©e")
        add_stop_loss_line(fig, sl_y, n//2, n-1)
        add_take_profit_line(fig, tp_y, n//2, n-1)

        apply_standard_layout(fig, config)
        caption = f"bb_period={bb_period}, entry={entry_level:.2f}, sl={sl_level:.2f}, tp={tp_level:.2f}"
        help_text = "- Entry: niveau bb_pos pour entr√©e\n- SL/TP: niveaux relatifs aux bandes"

    else:
        # Versions avec panel ATR
        config = DiagramConfig(
            rows=2,
            row_heights=[0.7, 0.3],
            subplot_titles=("Prix + Bollinger", "ATR"),
            height=550,
        )
        fig = create_base_figure(config)
        add_price_trace(fig, x, price, row=1, col=1)
        add_bollinger_traces(fig, x, bb_upper, bb_middle, bb_lower, row=1, col=1)

        # Param√®tres selon variant
        if variant == "v2":
            k_sl = float(params.get("k_sl", 1.5))
            atr_threshold = atr_values.mean() * k_sl
            add_atr_panel(fig, x, atr_values, threshold=atr_threshold, row=2, col=1)
            caption = f"bb_period={bb_period}, bb_std={bb_std:.1f}, atr_period={atr_period}, k_sl={k_sl:.2f}"
            help_text = "- k_sl: multiplicateur ATR pour stop-loss\n- SL bas√© sur Bollinger lower"

        elif variant == "v3":
            entry_pct_long = float(params.get("entry_pct_long", 0.2))
            stop_factor = float(params.get("stop_factor", 1.5))
            tp_factor = float(params.get("tp_factor", 2.0))
            add_atr_panel(fig, x, atr_values, row=2, col=1)
            caption = f"entry_pct_long={entry_pct_long:.2f}, stop_factor={stop_factor:.2f}, tp_factor={tp_factor:.2f}"
            help_text = "- entry_pct: % dans les bandes\n- stop/tp_factor: multiples ATR"

        else:  # standard
            atr_threshold = float(params.get("atr_threshold", 1.2))
            add_atr_panel(fig, x, atr_values, threshold=atr_threshold, row=2, col=1)
            caption = f"bb_period={bb_period}, bb_std={bb_std:.1f}, atr_period={atr_period}, atr_threshold={atr_threshold:.2f}"
            help_text = "- bb_period/bb_std: bandes de Bollinger\n- atr_period/atr_threshold: filtrage volatilit√©"

        apply_standard_layout(fig, config)

    render_diagram(fig, key, caption, help_text)


def create_ema_cross_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """Factory pour le diagramme EMA Cross."""
    x, price, price_series = create_synthetic_price(n)

    fast_period = max(2, min(int(params.get("fast_period", 9)), n - 1))
    slow_period = max(3, min(int(params.get("slow_period", 21)), n - 1))

    ema_fast = calculate_ema(price_series, fast_period)
    ema_slow = calculate_ema(price_series, slow_period)

    config = DiagramConfig(
        rows=1,
        height=460,
        title="EMA Cross: croisement rapide/lente",
    )
    fig = create_base_figure(config)

    add_price_trace(fig, x, price)
    add_ema_traces(fig, x, ema_fast, ema_slow, f"EMA {fast_period}", f"EMA {slow_period}")

    apply_standard_layout(fig, config)
    render_diagram(
        fig, key,
        caption=f"fast_period={fast_period}, slow_period={slow_period}",
        help_text="- fast_period: EMA rapide\n- slow_period: EMA lente\n- Signal sur croisement",
    )


def create_macd_cross_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """Factory pour le diagramme MACD Cross."""
    x, price, price_series = create_synthetic_price(n)

    fast_period = max(2, min(int(params.get("fast_period", 12)), n - 1))
    slow_period = max(3, min(int(params.get("slow_period", 26)), n - 1))
    signal_period = max(2, min(int(params.get("signal_period", 9)), n - 1))

    macd_line, signal_line = calculate_macd(price_series, fast_period, slow_period, signal_period)

    config = DiagramConfig(
        rows=2,
        row_heights=[0.65, 0.35],
        subplot_titles=("Prix", "MACD (ligne vs signal)"),
        height=500,
    )
    fig = create_base_figure(config)

    add_price_trace(fig, x, price, row=1, col=1)
    add_macd_panel(fig, x, macd_line, signal_line, row=2, col=1)

    apply_standard_layout(fig, config)
    render_diagram(
        fig, key,
        caption=f"fast_period={fast_period}, slow_period={slow_period}, signal_period={signal_period}",
        help_text="- fast/slow_period: EMAs du MACD\n- signal_period: lissage\n- Signal sur croisement",
    )


def create_rsi_reversal_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """Factory pour le diagramme RSI Reversal."""
    x, price, price_series = create_synthetic_price(n)

    rsi_period = max(2, min(int(params.get("rsi_period", 14)), n - 1))
    oversold = float(params.get("oversold_level", 30))
    overbought = float(params.get("overbought_level", 70))

    rsi = calculate_rsi(price_series, rsi_period)

    config = DiagramConfig(
        rows=2,
        row_heights=[0.6, 0.4],
        subplot_titles=("Prix", "RSI et zones extremes"),
        height=500,
    )
    fig = create_base_figure(config)

    add_price_trace(fig, x, price, row=1, col=1)
    add_rsi_panel(fig, x, rsi, oversold, overbought, row=2, col=1)

    apply_standard_layout(fig, config)
    render_diagram(
        fig, key,
        caption=f"rsi_period={rsi_period}, oversold={oversold:.0f}, overbought={overbought:.0f}",
        help_text="- rsi_period: fen√™tre RSI\n- oversold/overbought: seuils de signal",
    )


def create_atr_channel_diagram(
    params: Dict[str, Any],
    key: str,
    n: int = 160,
) -> None:
    """Factory pour le diagramme ATR Channel."""
    x, price, price_series = create_synthetic_price(n)

    atr_period = max(2, min(int(params.get("atr_period", 14)), n - 1))
    atr_mult = float(params.get("atr_mult", 2.0))

    ema_center = calculate_ema(price_series, atr_period)
    atr_values = calculate_atr(price_series, atr_period)

    upper = ema_center + atr_values * atr_mult
    lower = ema_center - atr_values * atr_mult

    config = DiagramConfig(
        rows=1,
        height=460,
        title="ATR Channel: EMA +/- ATR * multiplier",
    )
    fig = create_base_figure(config)

    add_price_trace(fig, x, price)
    add_atr_channel_traces(fig, x, upper, ema_center, lower)

    apply_standard_layout(fig, config)
    render_diagram(
        fig, key,
        caption=f"atr_period={atr_period}, atr_mult={atr_mult:.2f}",
        help_text="- atr_period: fen√™tre ATR/EMA\n- atr_mult: largeur du canal",
    )


# ============================================================================
# DISPATCH TABLE
# ============================================================================

DIAGRAM_FACTORIES = {
    "bollinger_atr": lambda p, k: create_bollinger_atr_diagram(p, k, variant="standard"),
    "bollinger_best_longe_3i": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),
    "bollinger_best_short_3i": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),
    "bollinger_long_test": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),
    "bollinger_short_test": lambda p, k: create_bollinger_atr_diagram(p, k, variant="long_test"),  # M√™me logique
    "bollinger_dual": lambda p, k: create_bollinger_atr_diagram(p, k, variant="standard"),
    "ema_cross": create_ema_cross_diagram,
    "macd_cross": create_macd_cross_diagram,
    "rsi_reversal": create_rsi_reversal_diagram,
    "atr_channel": create_atr_channel_diagram,
    "ma_crossover": create_ema_cross_diagram,  # M√™me logique
    "ema_stochastic_scalp": create_ema_cross_diagram,  # Fallback EMA
}


def render_strategy_diagram(
    strategy_key: str,
    params: Dict[str, Any],
    key: str,
) -> bool:
    """
    Point d'entr√©e principal pour rendre un diagramme de strat√©gie.

    Args:
        strategy_key: Cl√© de la strat√©gie
        params: Param√®tres de la strat√©gie
        key: Cl√© unique Streamlit

    Returns:
        True si le diagramme a √©t√© rendu, False sinon
    """
    factory = DIAGRAM_FACTORIES.get(strategy_key)

    if factory is None:
        st.info(f"Sch√©ma non disponible pour la strat√©gie '{strategy_key}'")
        return False

    try:
        factory(params, key)
        return True
    except Exception as e:
        st.warning(f"Erreur lors du rendu du diagramme: {e}")
        return False


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    # Config
    "DiagramConfig",
    "TraceConfig",
    "MarkerConfig",
    "PLOTLY_CHART_CONFIG",
    # Figure
    "create_base_figure",
    "apply_standard_layout",
    # Donn√©es
    "create_synthetic_price",
    # Indicateurs
    "calculate_bollinger",
    "calculate_atr",
    "calculate_ema",
    "calculate_rsi",
    "calculate_macd",
    # Traces
    "add_price_trace",
    "add_bollinger_traces",
    "add_atr_panel",
    "add_rsi_panel",
    "add_macd_panel",
    "add_ema_traces",
    "add_atr_channel_traces",
    "add_entry_marker",
    "add_stop_loss_line",
    "add_take_profit_line",
    # Rendu
    "render_diagram",
    # Factories
    "create_bollinger_atr_diagram",
    "create_ema_cross_diagram",
    "create_macd_cross_diagram",
    "create_rsi_reversal_diagram",
    "create_atr_channel_diagram",
    # Dispatch
    "DIAGRAM_FACTORIES",
    "render_strategy_diagram",
]
```
<!-- MODULE-END: diagram_factory.py -->

<!-- MODULE-START: model_selector.py -->
```json
{
  "name": "model_selector.py",
  "path": "ui\\components\\model_selector.py",
  "ext": ".py",
  "anchor": "model_selector_py"
}
```
## model_selector_py
*Chemin* : `ui\components\model_selector.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.model_selector

Purpose: S√©lecteur mod√®les LLM - query Ollama, fallback list, recommendations par r√¥le.

Role in pipeline: configuration

Key components: get_available_models_for_ui(), FALLBACK_LLM_MODELS, role-based recommendations

Inputs: Ollama endpoint (optionnel), role (Analyst/Strategist/Critic/Validator)

Outputs: Model list [str] orden√©e (recommand√©s en premier), fallback si Ollama down

Dependencies: agents.ollama_manager (optionnel), log

Conventions: Fallback list actualis√©e (Dec 2025); Ollama pr√©f√©r√©; timeout 2s.

Read-if: Modification fallback list ou role mappings.

Skip-if: Vous appelez get_available_models_for_ui().
"""

from __future__ import annotations

from typing import Iterable, List, Sequence

try:
    from agents.ollama_manager import list_ollama_models
except ImportError:
    def list_ollama_models() -> List[str]:
        return []
from utils.log import get_logger
from utils.model_loader import get_model_info_for_ui, get_ollama_model_names

logger = get_logger(__name__)

# Liste de mod√®les recommand√©s utilis√©e comme fallback
FALLBACK_LLM_MODELS: List[str] = [
    # Mod√®les recommand√©s pour trading (Dec 2025)
    "deepseek-r1:70b",              # 34 GB - Le plus puissant
    "deepseek-r1:32b",              # 19 GB - Excellent rapport qualit√©/prix
    "qwq:32b",                      # 23 GB - Tr√®s bon pour raisonnement
    "qwen2.5:32b",                  # 19 GB - Alternative solide
    "mistral:22b",                  # 13 GB - √âquilibr√©
    "gemma3:27b",                   # 17 GB - Bon pour analyse
    "deepseek-r1-distill:14b",      # 9 GB - √âquilibr√©
    "gemma3:12b",                   # 8 GB - Rapide
    "deepseek-r1:8b",               # 5 GB - Builder rapide
    "mistral:7b-instruct",          # 4 GB - Ultra rapide
    "llama3.2",                     # 2 GB - L√©ger
    "phi3",                         # 2 GB - L√©ger alternatif
]

# Mod√®les recommand√©s pour diff√©rentes t√¢ches
RECOMMENDED_FOR_ANALYSIS = ["deepseek-r1:32b", "qwq:32b", "qwen2.5:32b"]
RECOMMENDED_FOR_STRATEGY = ["deepseek-r1:70b", "deepseek-r1:32b", "qwq:32b"]
RECOMMENDED_FOR_CRITICISM = ["mistral:22b", "gemma3:27b", "qwen2.5:32b"]
RECOMMENDED_FOR_FAST = ["deepseek-r1:8b", "mistral:7b-instruct", "llama3.2"]

# Configuration optimale par r√¥le (bas√©e sur benchmarks Dec 2025)
OPTIMAL_CONFIG_BY_ROLE = {
    "analyst": ["qwen2.5:14b"],
    "strategist": ["gemma3:27b"],
    "critic": ["llama3.3-70b-optimized"],
    "validator": ["llama3.3-70b-optimized"],
}

# Fallback si le mod√®le optimal n'est pas install√©
OPTIMAL_CONFIG_FALLBACK = {
    "analyst": ["deepseek-r1:8b", "gemma3:12b"],
    "strategist": ["gemma3:27b", "mistral:22b"],
    "critic": ["deepseek-r1:32b", "qwq:32b"],
    "validator": ["deepseek-r1:32b", "qwq:32b"],
}


def _sort_with_preferred(
    models: Iterable[str], preferred_order: Sequence[str]
) -> List[str]:
    """
    Trie les mod√®les en mettant ceux de preferred_order en premier.

    Args:
        models: Liste des mod√®les √† trier
        preferred_order: Ordre pr√©f√©r√©

    Returns:
        Liste tri√©e de mod√®les
    """
    preferred_index = {name: i for i, name in enumerate(preferred_order)}

    def sort_key(name: str) -> tuple[int, int | str]:
        if name in preferred_index:
            return 0, preferred_index[name]
        return 1, name

    unique = sorted(set(models), key=sort_key)
    return unique


def _get_library_models() -> List[str]:
    try:
        return get_ollama_model_names()
    except Exception as exc:  # noqa: BLE001
        logger.debug("Erreur lecture models.json pour la liste UI: %s", exc)
        return []


def _normalize_model_name(name: str) -> str:
    if name.endswith(":latest"):
        return name.rsplit(":", 1)[0]
    return name


def get_available_models_for_ui(
    preferred_order: Sequence[str] | None = None,
    fallback: Sequence[str] | None = None,
) -> List[str]:
    """
    Retourne la liste des mod√®les LLM √† proposer dans l'UI.

    - Si Ollama r√©pond, on fusionne les mod√®les install√©s avec models.json.
    - Si Ollama est inaccessible, on utilise models.json si dispo.
    - Sinon, fallback sur une liste minimale.

    Args:
        preferred_order: Ordre conseill√© pour le tri (facultatif).
        fallback: Fallback explicite (sinon FALLBACK_LLM_MODELS).

    Returns:
        list[str]: Noms de mod√®les Ollama (install√©s + biblioth√®que).

    Example:
        >>> models = get_available_models_for_ui(
        ...     preferred_order=RECOMMENDED_FOR_STRATEGY
        ... )
        >>> st.selectbox("Mod√®le", models)
    """
    installed = [_normalize_model_name(n) for n in list_ollama_models() if n]
    library_models = _get_library_models()
    available = sorted(set(installed) | set(library_models))

    if available:
        if preferred_order:
            return _sort_with_preferred(available, preferred_order)
        # Par d√©faut: tri alphab√©tique des mod√®les install√©s + biblioth√®que
        return available

    # Ollama inaccessible ou aucun mod√®le retourn√©: fallback
    models = list(fallback or FALLBACK_LLM_MODELS)
    logger.warning(
        "‚ö†Ô∏è Ollama ne renvoie aucun mod√®le, utilisation du fallback UI: %s",
        models[:3]
    )
    return models


def get_model_info(model_name: str) -> dict:
    """
    Retourne des informations sur un mod√®le.

    Priorit√©: models.json > hardcoded fallback

    Args:
        model_name: Nom du mod√®le

    Returns:
        dict: Informations du mod√®le (size, description, etc.)
    """
    # 1. Chercher dans models.json d'abord
    try:
        info = get_model_info_for_ui(model_name)
        if info and info.get("size_gb") != "?":
            return {
                "name": info.get("name", model_name),
                "size_gb": info["size_gb"],
                "description": info.get("description", ""),
            }
    except Exception as exc:  # noqa: BLE001
        logger.debug("Erreur lecture models.json pour %s: %s", model_name, exc)

    # 2. Fallback hardcod√© pour compatibilit√©
    model_sizes = {
        "deepseek-r1:70b": 34,
        "deepseek-r1:32b": 19,
        "qwq:32b": 23,
        "qwen2.5:32b": 19,
        "mistral:22b": 13,
        "gemma3:27b": 17,
        "deepseek-r1-distill:14b": 9,
        "gemma3:12b": 8,
        "deepseek-r1:8b": 5,
        "mistral:7b-instruct": 4,
        "llama3.2": 2,
        "phi3": 2,
    }

    model_descriptions = {
        "deepseek-r1:70b": "Le plus puissant - Excellent pour strat√©gies complexes",
        "deepseek-r1:32b": "Optimal - Meilleur rapport qualit√©/prix",
        "qwq:32b": "Excellent raisonnement - Id√©al pour analyse",
        "qwen2.5:32b": "Alternative solide - Polyvalent",
        "mistral:22b": "√âquilibr√© - Bon pour critique",
        "gemma3:27b": "Bon pour analyse - Rapide",
        "deepseek-r1-distill:14b": "√âquilibr√© - Compact",
        "gemma3:12b": "Rapide - L√©ger",
        "deepseek-r1:8b": "Ultra rapide - Tests rapides",
        "mistral:7b-instruct": "Ultra rapide - Tr√®s l√©ger",
        "llama3.2": "L√©ger - Pour tests",
        "phi3": "L√©ger - Pour tests",
    }

    return {
        "name": model_name,
        "size_gb": model_sizes.get(model_name, "?"),
        "description": model_descriptions.get(model_name, "Mod√®le LLM"),
    }


def get_optimal_config_for_role(
    role: str,
    available_models: List[str],
) -> List[str]:
    """
    Retourne la configuration optimale pour un r√¥le donn√©.

    Si le mod√®le optimal n'est pas install√©, utilise le fallback.

    Args:
        role: R√¥le de l'agent (analyst, strategist, critic, validator)
        available_models: Liste des mod√®les disponibles

    Returns:
        Liste des mod√®les optimaux pour ce r√¥le (filtr√©s par disponibilit√©)

    Example:
        >>> optimal = get_optimal_config_for_role("critic", installed_models)
        >>> # Returns: ["llama3.3-70b-optimized"] if installed, else fallback
    """
    # Mod√®le optimal primaire
    optimal_primary = OPTIMAL_CONFIG_BY_ROLE.get(role, [])

    # V√©rifier si le mod√®le optimal est disponible
    available_set = set(available_models)
    optimal_available = [m for m in optimal_primary if m in available_set]

    if optimal_available:
        return optimal_available

    # Fallback si le mod√®le optimal n'est pas install√©
    fallback_options = OPTIMAL_CONFIG_FALLBACK.get(role, [])
    fallback_available = [m for m in fallback_options if m in available_set]

    if fallback_available:
        return fallback_available[:1]  # Premier fallback disponible

    # Dernier recours: premiers mod√®les disponibles
    return available_models[:1] if available_models else []


def render_model_selector(
    label: str = "Mod√®le LLM",
    key: str = "llm_model",
    preferred_order: Sequence[str] | None = None,
    help_text: str | None = None,
) -> str:
    """
    Rendu d'un s√©lecteur de mod√®le Streamlit avec informations.

    Args:
        label: Label du selectbox
        key: Cl√© du state Streamlit
        preferred_order: Ordre pr√©f√©r√© des mod√®les
        help_text: Texte d'aide optionnel

    Returns:
        str: Nom du mod√®le s√©lectionn√©

    Example:
        >>> import streamlit as st
        >>> model = render_model_selector(
        ...     label="Mod√®le Analyst",
        ...     key="analyst_model",
        ...     preferred_order=RECOMMENDED_FOR_ANALYSIS
        ... )
    """
    import streamlit as st

    models = get_available_models_for_ui(preferred_order=preferred_order)

    if not help_text:
        help_text = "S√©lectionnez un mod√®le LLM Ollama pour l'optimisation"

    selected = st.selectbox(
        label,
        models,
        key=key,
        help=help_text,
    )

    # Afficher les infos du mod√®le s√©lectionn√©
    if selected:
        info = get_model_info(selected)
        size = info["size_gb"]
        desc = info["description"]
        st.caption(f"üì¶ ~{size} GB | {desc}")

    return selected


__all__ = [
    "FALLBACK_LLM_MODELS",
    "RECOMMENDED_FOR_ANALYSIS",
    "RECOMMENDED_FOR_STRATEGY",
    "RECOMMENDED_FOR_CRITICISM",
    "RECOMMENDED_FOR_FAST",
    "OPTIMAL_CONFIG_BY_ROLE",
    "OPTIMAL_CONFIG_FALLBACK",
    "get_available_models_for_ui",
    "get_model_info",
    "get_optimal_config_for_role",
    "render_model_selector",
]
```
<!-- MODULE-END: model_selector.py -->

<!-- MODULE-START: monitor.py -->
```json
{
  "name": "monitor.py",
  "path": "ui\\components\\monitor.py",
  "ext": ".py",
  "anchor": "monitor_py"
}
```
## monitor_py
*Chemin* : `ui\components\monitor.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.monitor

Purpose: Renderer Streamlit pour monitoring syst√®me temps r√©el - CPU, RAM, GPU, Disk.

Role in pipeline: visualization/monitoring

Key components: SystemMonitor, render_system_monitor(), render_mini_monitor(), ResourceReading

Inputs: System snapshots via psutil

Outputs: Streamlit metric cards, rolling history charts

Dependencies: streamlit (optionnel), plotly (optionnel), psutil (optionnel)

Conventions: 1s interval; rolling window 100 points; color alerts (% thresholds).

Read-if: Modification metrics collection ou alert thresholds.

Skip-if: Vous appelez render_system_monitor().
"""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False


@dataclass
class ResourceReading:
    """
    Snapshot of the system resource state at a given timestamp.

    Captures CPU, RAM, GPU and disk utilization so that the monitor panels
    can display time series and thresholds without coupling to psutil later.
    """
    timestamp: datetime
    cpu_percent: float = 0.0
    memory_percent: float = 0.0
    memory_used_gb: float = 0.0
    memory_total_gb: float = 0.0
    gpu_percent: float = 0.0
    gpu_memory_percent: float = 0.0
    gpu_memory_used_gb: float = 0.0
    gpu_memory_total_gb: float = 0.0
    disk_percent: float = 0.0
    disk_used_gb: float = 0.0
    disk_total_gb: float = 0.0


@dataclass
class SystemMonitorConfig:
    """
    Alerting thresholds and refresh settings for the system monitor.

    Defines percent thresholds for warnings/critical states and how often
    telemetry is sampled. Passed to `SystemMonitor` at construction.
    """
    # Seuils d'alerte (pourcentage)
    cpu_warning: float = 80.0
    cpu_critical: float = 95.0
    memory_warning: float = 80.0
    memory_critical: float = 90.0
    gpu_warning: float = 85.0
    gpu_critical: float = 95.0
    disk_warning: float = 85.0
    disk_critical: float = 95.0

    # Historique
    max_history: int = 60  # Points d'historique

    # Rafra√Æchissement
    refresh_interval: float = 2.0  # Secondes


class SystemMonitor:
    """
    Collector responsible for polling and storing `ResourceReading` history.

    Lifecycle: instantiated at Streamlit startup, optionally scheduled to sample every
    `refresh_interval`, and queried by renderers to plot current values or sparkline.
    """

    def __init__(self, config: Optional[SystemMonitorConfig] = None):
        """
        Args:
            config: Configuration du moniteur
        """
        self.config = config or SystemMonitorConfig()
        self._history: List[ResourceReading] = []
        self._gpu_available = self._check_gpu()

    def _check_gpu(self) -> bool:
        """V√©rifie si le monitoring GPU est disponible."""
        try:
            import pynvml
            pynvml.nvmlInit()
            pynvml.nvmlDeviceGetCount()
            return True
        except Exception:
            return False

    def get_current_reading(self) -> ResourceReading:
        """
        Collecte les m√©triques actuelles.

        Returns:
            ResourceReading avec toutes les m√©triques
        """
        reading = ResourceReading(timestamp=datetime.now())

        if PSUTIL_AVAILABLE:
            # CPU
            reading.cpu_percent = psutil.cpu_percent(interval=0.1)

            # Memory
            mem = psutil.virtual_memory()
            reading.memory_percent = mem.percent
            reading.memory_used_gb = mem.used / (1024**3)
            reading.memory_total_gb = mem.total / (1024**3)

            # Disk
            disk = psutil.disk_usage('/')
            reading.disk_percent = disk.percent
            reading.disk_used_gb = disk.used / (1024**3)
            reading.disk_total_gb = disk.total / (1024**3)

        # GPU
        if self._gpu_available:
            try:
                import pynvml
                handle = pynvml.nvmlDeviceGetHandleByIndex(0)

                # Utilisation GPU
                util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                reading.gpu_percent = util.gpu

                # M√©moire GPU
                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                reading.gpu_memory_used_gb = mem_info.used / (1024**3)
                reading.gpu_memory_total_gb = mem_info.total / (1024**3)
                reading.gpu_memory_percent = (mem_info.used / mem_info.total) * 100

            except Exception:
                pass

        return reading

    def update(self) -> ResourceReading:
        """
        Met √† jour l'historique avec une nouvelle lecture.

        Returns:
            Derni√®re lecture
        """
        reading = self.get_current_reading()
        self._history.append(reading)

        # Limiter l'historique
        if len(self._history) > self.config.max_history:
            self._history = self._history[-self.config.max_history:]

        return reading

    @property
    def history(self) -> List[ResourceReading]:
        """Retourne l'historique des lectures."""
        return list(self._history)

    @property
    def gpu_available(self) -> bool:
        """Indique si le GPU est disponible."""
        return self._gpu_available

    def get_status(self, reading: ResourceReading) -> Dict[str, str]:
        """
        D√©termine le status de chaque ressource.

        Returns:
            Dict resource -> status ('ok', 'warning', 'critical')
        """
        status = {}

        # CPU
        if reading.cpu_percent >= self.config.cpu_critical:
            status['cpu'] = 'critical'
        elif reading.cpu_percent >= self.config.cpu_warning:
            status['cpu'] = 'warning'
        else:
            status['cpu'] = 'ok'

        # Memory
        if reading.memory_percent >= self.config.memory_critical:
            status['memory'] = 'critical'
        elif reading.memory_percent >= self.config.memory_warning:
            status['memory'] = 'warning'
        else:
            status['memory'] = 'ok'

        # GPU
        if self._gpu_available:
            if reading.gpu_memory_percent >= self.config.gpu_critical:
                status['gpu'] = 'critical'
            elif reading.gpu_memory_percent >= self.config.gpu_warning:
                status['gpu'] = 'warning'
            else:
                status['gpu'] = 'ok'

        # Disk
        if reading.disk_percent >= self.config.disk_critical:
            status['disk'] = 'critical'
        elif reading.disk_percent >= self.config.disk_warning:
            status['disk'] = 'warning'
        else:
            status['disk'] = 'ok'

        return status

    def clear_history(self):
        """Efface l'historique."""
        self._history.clear()


def _get_status_color(status: str) -> str:
    """Retourne la couleur pour un status."""
    colors = {
        'ok': '#00cc00',       # Vert
        'warning': '#ffaa00',  # Orange
        'critical': '#ff0000',  # Rouge
    }
    return colors.get(status, '#888888')


def _create_gauge(
    value: float,
    title: str,
    status: str,
    suffix: str = "%"
) -> go.Figure:
    """Cr√©e un gauge Plotly."""
    color = _get_status_color(status)

    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=value,
        title={'text': title, 'font': {'size': 14}},
        number={'suffix': suffix, 'font': {'size': 20}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1},
            'bar': {'color': color},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 80], 'color': 'rgba(0, 200, 0, 0.1)'},
                {'range': [80, 90], 'color': 'rgba(255, 170, 0, 0.1)'},
                {'range': [90, 100], 'color': 'rgba(255, 0, 0, 0.1)'},
            ],
        }
    ))

    fig.update_layout(
        height=150,
        margin=dict(l=20, r=20, t=40, b=10),
    )

    return fig


def _create_history_chart(
    history: List[ResourceReading],
    show_gpu: bool = False
) -> go.Figure:
    """Cr√©e le graphique d'historique."""
    if not history:
        fig = go.Figure()
        fig.update_layout(
            height=200,
            title="Historique (en attente de donn√©es...)",
        )
        return fig

    timestamps = [r.timestamp for r in history]

    fig = make_subplots(
        rows=1, cols=1,
        shared_xaxes=True,
    )

    # CPU
    fig.add_trace(go.Scatter(
        x=timestamps,
        y=[r.cpu_percent for r in history],
        name="CPU",
        line=dict(color='#1f77b4', width=2),
        fill='tozeroy',
        fillcolor='rgba(31, 119, 180, 0.1)',
    ))

    # Memory
    fig.add_trace(go.Scatter(
        x=timestamps,
        y=[r.memory_percent for r in history],
        name="RAM",
        line=dict(color='#2ca02c', width=2),
    ))

    # GPU si disponible
    if show_gpu:
        fig.add_trace(go.Scatter(
            x=timestamps,
            y=[r.gpu_percent for r in history],
            name="GPU",
            line=dict(color='#ff7f0e', width=2),
        ))
        fig.add_trace(go.Scatter(
            x=timestamps,
            y=[r.gpu_memory_percent for r in history],
            name="VRAM",
            line=dict(color='#d62728', width=2, dash='dash'),
        ))

    fig.update_layout(
        height=200,
        margin=dict(l=40, r=20, t=30, b=30),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        yaxis=dict(range=[0, 100], title="Usage %"),
        xaxis=dict(title=""),
    )

    return fig


def render_system_monitor(
    key: str = "system_monitor",
    show_history: bool = True,
    show_gauges: bool = True,
    compact: bool = False,
):
    """
    Streamlit panel that keeps system resource usage visible during a backtest.

    Uses the session-scoped `SystemMonitor` instance to poll ResourceReading snapshots,
    then draws alerts/gauges/history so the operator can stop a run before hitting limits.

    Args:
        key: Unique Streamlit key so reruns remain idempotent.
        show_history: Display the time-series history chart.
        show_gauges: Render gauge widgets for CPU/RAM/GPU/Disk.
        compact: Reduce the detail level for sidebar embedding.
    """
    if not STREAMLIT_AVAILABLE:
        raise ImportError("Streamlit non disponible")

    if not PLOTLY_AVAILABLE:
        st.error("Plotly requis pour le System Monitor")
        return

    # Initialiser le moniteur dans session_state
    monitor_key = f"{key}_monitor"
    if monitor_key not in st.session_state:
        st.session_state[monitor_key] = SystemMonitor()

    monitor: SystemMonitor = st.session_state[monitor_key]

    # Collecter les donn√©es
    reading = monitor.update()
    status = monitor.get_status(reading)

    # Header
    st.subheader("üìä System Monitor")

    # Alertes
    alerts = []
    if status.get('cpu') == 'critical':
        alerts.append(f"‚ö†Ô∏è CPU critique: {reading.cpu_percent:.1f}%")
    if status.get('memory') == 'critical':
        alerts.append(f"‚ö†Ô∏è RAM critique: {reading.memory_percent:.1f}%")
    if status.get('gpu') == 'critical':
        alerts.append(f"‚ö†Ô∏è GPU critique: {reading.gpu_memory_percent:.1f}%")
    if status.get('disk') == 'critical':
        alerts.append(f"‚ö†Ô∏è Disk critique: {reading.disk_percent:.1f}%")

    if alerts:
        for alert in alerts:
            st.error(alert)

    # Gauges
    if show_gauges:
        cols = st.columns(4 if monitor.gpu_available else 3)

        with cols[0]:
            fig = _create_gauge(reading.cpu_percent, "CPU", status.get('cpu', 'ok'))
            st.plotly_chart(fig, width='stretch', key=f"{key}_cpu_gauge")
            if not compact:
                st.caption(f"C≈ìurs: {psutil.cpu_count() if PSUTIL_AVAILABLE else 'N/A'}")

        with cols[1]:
            fig = _create_gauge(reading.memory_percent, "RAM", status.get('memory', 'ok'))
            st.plotly_chart(fig, width='stretch', key=f"{key}_ram_gauge")
            if not compact:
                st.caption(f"{reading.memory_used_gb:.1f} / {reading.memory_total_gb:.1f} GB")

        if monitor.gpu_available:
            with cols[2]:
                fig = _create_gauge(reading.gpu_memory_percent, "VRAM", status.get('gpu', 'ok'))
                st.plotly_chart(fig, width='stretch', key=f"{key}_gpu_gauge")
                if not compact:
                    st.caption(f"{reading.gpu_memory_used_gb:.1f} / {reading.gpu_memory_total_gb:.1f} GB")

            disk_col = cols[3]
        else:
            disk_col = cols[2]

        with disk_col:
            fig = _create_gauge(reading.disk_percent, "Disk", status.get('disk', 'ok'))
            st.plotly_chart(fig, width='stretch', key=f"{key}_disk_gauge")
            if not compact:
                st.caption(f"{reading.disk_used_gb:.1f} / {reading.disk_total_gb:.1f} GB")

    # Historique
    if show_history and len(monitor.history) > 1:
        st.markdown("**Historique**")
        fig = _create_history_chart(monitor.history, show_gpu=monitor.gpu_available)
        st.plotly_chart(fig, width='stretch', key=f"{key}_history")

    # Info de mise √† jour
    st.caption(f"Derni√®re mise √† jour: {reading.timestamp.strftime('%H:%M:%S')}")


def render_mini_monitor(key: str = "mini_monitor"):
    """
    Lightweight sidebar card showing the latest CPU/RAM/GPU state.

    Designed to stay visible beside the main Streamlit canvas so that operators
    monitor resource pressure while long sweeps run in the background.

    Args:
        key: Unique widget key for the sidebar card.
    """
    if not STREAMLIT_AVAILABLE or not PSUTIL_AVAILABLE:
        return

    # Collecter les donn√©es basiques
    cpu = psutil.cpu_percent(interval=0.1)
    mem = psutil.virtual_memory()

    # Indicateurs simples
    st.markdown("**üìä Ressources**")

    # CPU avec couleur
    cpu_color = "üü¢" if cpu < 80 else ("üü°" if cpu < 95 else "üî¥")
    st.markdown(f"{cpu_color} CPU: **{cpu:.0f}%**")

    # RAM avec couleur
    mem_color = "üü¢" if mem.percent < 80 else ("üü°" if mem.percent < 90 else "üî¥")
    st.markdown(f"{mem_color} RAM: **{mem.percent:.0f}%** ({mem.used/(1024**3):.1f}GB)")

    # GPU si disponible
    try:
        import pynvml
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(0)
        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
        gpu_pct = (mem_info.used / mem_info.total) * 100
        gpu_color = "üü¢" if gpu_pct < 85 else ("üü°" if gpu_pct < 95 else "üî¥")
        st.markdown(f"{gpu_color} GPU: **{gpu_pct:.0f}%** ({mem_info.used/(1024**3):.1f}GB)")
    except Exception:
        pass


__all__ = [
    "ResourceReading",
    "SystemMonitorConfig",
    "SystemMonitor",
    "render_system_monitor",
    "render_mini_monitor",
]
```
<!-- MODULE-END: monitor.py -->

<!-- MODULE-START: sweep_monitor.py -->
```json
{
  "name": "sweep_monitor.py",
  "path": "ui\\components\\sweep_monitor.py",
  "ext": ".py",
  "anchor": "sweep_monitor_py"
}
```
## sweep_monitor_py
*Chemin* : `ui\components\sweep_monitor.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.sweep_monitor

Purpose: Monitor live pour sweeps/optimisation - progress, ETA, top results, ranking.

Role in pipeline: visualization/monitoring

Key components: SweepMonitor, render_sweep_progress(), render_sweep_summary(), SweepStats

Inputs: Sweep updates {completed, total, current_result}

Outputs: Progress bar, ETA estimate, top-N table, live chart updates

Dependencies: streamlit (optionnel), plotly (optionnel), numpy, dataclasses

Conventions: ETA based on rolling avg; refresh 100ms; top-5 constant display.

Read-if: Modification ETA algo ou layout progress.

Skip-if: Vous appelez render_sweep_progress(monitor).
"""

from __future__ import annotations

from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

import numpy as np
import pandas as pd


def _pnl_per_day(total_pnl: float, period_days: Optional[float]) -> Optional[float]:
    if not period_days:
        return None
    try:
        return float(total_pnl) / float(period_days)
    except Exception:
        return None


@dataclass
class SweepResult:
    """
    Stores the parameters, metrics and timing of a single sweep evaluation.

    Used by `SweepMonitor` to surface the latest runs and compute leaderboards
    without coupling to the backtest engine.
    """
    params: Dict[str, Any]
    metrics: Dict[str, float]
    timestamp: datetime = field(default_factory=lambda: datetime.now())
    duration_ms: float = 0.0

    @property
    def sharpe(self) -> float:
        """Raccourci pour Sharpe Ratio."""
        return self.metrics.get('sharpe_ratio', 0.0)

    @property
    def total_return(self) -> float:
        """Raccourci pour rendement total."""
        return self.metrics.get('total_return', 0.0)


@dataclass
class SweepStats:
    """
    Running statistics for an in-progress sweep.

    Tracks counts, elapsed time and provides ETA/rate helpers so renderers can
    present useful progress indicators.
    """
    total_combinations: int = 0
    evaluated: int = 0
    pruned: int = 0
    errors: int = 0
    start_time: Optional[datetime] = None

    @property
    def progress_percent(self) -> float:
        """Pourcentage de progression."""
        if self.total_combinations == 0:
            return 0.0
        return (self.evaluated / self.total_combinations) * 100

    @property
    def elapsed(self) -> timedelta:
        """Temps √©coul√©."""
        if not self.start_time:
            return timedelta(0)
        return datetime.now() - self.start_time

    @property
    def elapsed_seconds(self) -> float:
        """Temps √©coul√© en secondes."""
        return self.elapsed.total_seconds()

    @property
    def rate(self) -> float:
        """Taux d'√©valuation (eval/sec)."""
        if self.elapsed_seconds == 0:
            return 0.0
        return self.evaluated / self.elapsed_seconds

    @property
    def eta(self) -> Optional[timedelta]:
        """Temps estim√© restant."""
        if self.rate == 0:
            return None
        remaining = self.total_combinations - self.evaluated
        return timedelta(seconds=remaining / self.rate)

    @property
    def eta_str(self) -> str:
        """ETA format√©."""
        eta = self.eta
        if eta is None:
            return "Calcul..."

        total_secs = int(eta.total_seconds())
        if total_secs < 60:
            return f"{total_secs}s"
        elif total_secs < 3600:
            return f"{total_secs // 60}m {total_secs % 60}s"
        else:
            hours = total_secs // 3600
            mins = (total_secs % 3600) // 60
            return f"{hours}h {mins}m"


class SweepMonitor:
    """
    Stateful progress tracker for grid sweeps (optimizations, grid search).

    Lifecycle:
      - Created before a sweep begins with known total combinations.
      - `.update()` is called per evaluation and top results are updated.
      - Handed to `render_sweep_progress`/`render_sweep_summary` for UI render.
    Responsibilities:
      - Record metrics, maintain top-K leaders, and expose ETA/progress.
    """

    def __init__(
        self,
        total_combinations: int,
        objectives: List[str] = None,
        top_k: int = 10,
        max_results: Optional[int] = 100,  # ‚úÖ FIX: Limite par d√©faut pour √©viter OOM
        max_history: Optional[int] = 1000,  # ‚úÖ FIX: Limite par d√©faut pour graphiques
    ):
        """
        Args:
            total_combinations: Nombre total de combinaisons √† √©valuer
            objectives: Liste des objectifs √† tracker
            top_k: Nombre de meilleurs r√©sultats √† garder
            max_results: Limite r√©sultats en m√©moire (d√©faut: 100, 0=illimit√© ‚ö†Ô∏è OOM risk)
            max_history: Limite historique graphiques (d√©faut: 1000, 0=illimit√© ‚ö†Ô∏è OOM risk)
        """
        self.total = total_combinations
        # Note: Utiliser les cl√©s correctes retourn√©es par calculate_metrics
        # Ajout de 'total_pnl' pour tracking visible du meilleur gain
        self.objectives = objectives or ['total_pnl', 'sharpe_ratio', 'total_return_pct', 'max_drawdown']
        self.top_k = top_k
        self.max_results = max_results if max_results != 0 else None  # 0 = illimit√©
        self.max_history = max_history if max_history != 0 else None  # 0 = illimit√©

        # ‚úÖ FIX: Toujours utiliser deque avec maxlen pour √©viter OOM
        self._results: deque = deque(maxlen=self.max_results)
        self._top_results: Dict[str, List[SweepResult]] = {
            obj: [] for obj in self.objectives
        }
        self._stats = SweepStats(total_combinations=total_combinations)
        # ‚úÖ FIX: Toujours deque avec maxlen (1000 par d√©faut)
        self._metric_history = {
            obj: deque(maxlen=self.max_history or 1000) for obj in self.objectives
        }
        self._last_update = None

        # Compteur pour downsampling automatique
        self._update_count = 0

    def start(self):
        """D√©marre le monitoring."""
        self._stats.start_time = datetime.now()

    def update(
        self,
        params: Dict[str, Any],
        metrics: Dict[str, float],
        duration_ms: float = 0.0,
        pruned: bool = False,
        error: bool = False,
    ):
        """
        Met √† jour avec un nouveau r√©sultat.

        Args:
            params: Param√®tres √©valu√©s
            metrics: M√©triques r√©sultantes
            duration_ms: Dur√©e de l'√©valuation
            pruned: Si la combinaison a √©t√© prun√©e
            error: Si une erreur s'est produite
        """
        if self._stats.start_time is None:
            self.start()

        if error:
            self._stats.errors += 1
            self._stats.evaluated += 1
            return

        if pruned:
            self._stats.pruned += 1
            self._stats.evaluated += 1
            return

        self._stats.evaluated += 1
        self._update_count += 1

        result = SweepResult(
            params=params,
            metrics=metrics,
            duration_ms=duration_ms,
        )

        # ‚úÖ FIX: deque g√®re automatiquement la limite (pas besoin de del manuel)
        self._results.append(result)

        # ‚úÖ FIX: Mettre √† jour l'historique (deque auto-limite)
        for obj in self.objectives:
            if obj in metrics:
                self._metric_history[obj].append(metrics[obj])

        # Mettre √† jour les top r√©sultats
        self._update_top_results(result)
        self._last_update = datetime.now()

        # ‚úÖ FIX: Nettoyage m√©moire p√©riodique (tous les 1000 updates)
        if self._update_count % 1000 == 0:
            import gc
            gc.collect()

    def _update_top_results(self, result: SweepResult):
        """Met √† jour les meilleurs r√©sultats."""
        if result.metrics.get("account_ruined"):
            return
        for obj in self.objectives:
            if obj not in result.metrics:
                continue

            top = self._top_results[obj]
            top.append(result)

            # Trier et garder le top_k
            # Minimiser uniquement le drawdown, maximiser tout le reste (PnL, Sharpe, Return)
            reverse = obj not in ['max_drawdown', 'max_drawdown_pct']
            top.sort(key=lambda r: r.metrics.get(obj, 0), reverse=reverse)
            self._top_results[obj] = top[:self.top_k]

    @property
    def stats(self) -> SweepStats:
        """Retourne les statistiques."""
        return self._stats

    @property
    def results(self) -> List[SweepResult]:
        """Retourne tous les r√©sultats."""
        return list(self._results)

    def get_top_results(self, objective: str) -> List[SweepResult]:
        """Retourne les meilleurs r√©sultats pour un objectif."""
        return self._top_results.get(objective, [])

    def get_best_result(self, objective: str) -> Optional[SweepResult]:
        """Retourne le meilleur r√©sultat pour un objectif."""
        top = self.get_top_results(objective)
        return top[0] if top else None

    def get_metric_history(self, objective: str) -> List[float]:
        """Retourne l'historique d'une m√©trique (complet)."""
        history = self._metric_history.get(objective, [])
        return list(history)

    def get_metric_history_downsampled(
        self,
        objective: str,
        max_points: int = 500
    ) -> List[float]:
        """
        Retourne l'historique d'une m√©trique avec downsampling automatique.

        ‚úÖ FIX OOM: Pour sweeps longs (>10k runs), r√©duit automatiquement
        le nombre de points affich√©s sans perdre la tendance visuelle.

        Args:
            objective: M√©trique √† r√©cup√©rer
            max_points: Nombre max de points √† retourner (d√©faut: 500)

        Returns:
            Liste de valeurs (downsampl√©e si n√©cessaire)
        """
        history = list(self._metric_history.get(objective, []))

        if len(history) <= max_points:
            return history

        # Downsampling simple : prendre 1 point tous les N
        step = len(history) // max_points
        if step < 1:
            step = 1

        return history[::step]

    @property
    def is_complete(self) -> bool:
        """Indique si le sweep est termin√©."""
        return self._stats.evaluated >= self.total


def _create_progress_chart(stats: SweepStats) -> go.Figure:
    """Cr√©e un graphique de progression."""
    evaluated = stats.evaluated
    pruned = stats.pruned
    remaining = stats.total_combinations - evaluated - pruned

    fig = go.Figure(data=[go.Pie(
        values=[evaluated, pruned, remaining],
        labels=['√âvalu√©s', 'Prun√©s', 'Restants'],
        marker_colors=['#2ca02c', '#ff7f0e', '#d3d3d3'],
        hole=0.6,
        textinfo='percent',
        textposition='outside',
    )])

    fig.update_layout(
        height=200,
        margin=dict(l=20, r=20, t=20, b=20),
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2),
        annotations=[dict(
            text=f"{stats.progress_percent:.0f}%",
            x=0.5, y=0.5,
            font_size=24,
            showarrow=False
        )],
    )

    return fig


def _create_metric_evolution_chart(
    history: Dict[str, List[float]],
    objectives: List[str],
) -> go.Figure:
    """Cr√©e le graphique d'√©volution des m√©triques."""
    fig = go.Figure()

    colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']

    for i, obj in enumerate(objectives):
        values = list(history.get(obj, []))
        if not values:
            continue

        # Calculer la moyenne mobile
        window = min(20, len(values))
        if window > 1:
            moving_avg = np.convolve(values, np.ones(window)/window, mode='valid')
            x_values = list(range(window-1, len(values)))
        else:
            moving_avg = values
            x_values = list(range(len(values)))

        fig.add_trace(go.Scatter(
            x=x_values,
            y=moving_avg,
            name=obj.replace('_', ' ').title(),
            line=dict(color=colors[i % len(colors)], width=2),
        ))

    fig.update_layout(
        height=200,
        margin=dict(l=40, r=20, t=30, b=30),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        xaxis=dict(title="√âvaluations"),
        yaxis=dict(title="Valeur"),
    )

    return fig


def _create_param_impact_chart(
    results: List[SweepResult],
    objective: str,
    param_name: str,
) -> go.Figure:
    """Cr√©e un graphique d'impact d'un param√®tre."""
    if not results:
        return go.Figure()

    # Extraire les donn√©es
    param_values = []
    metric_values = []

    for r in results:
        if param_name in r.params and objective in r.metrics:
            param_values.append(r.params[param_name])
            metric_values.append(r.metrics[objective])

    if not param_values:
        return go.Figure()

    fig = go.Figure(data=go.Scatter(
        x=param_values,
        y=metric_values,
        mode='markers',
        marker=dict(
            color=metric_values,
            colorscale='Viridis',
            size=8,
            showscale=True,
            colorbar=dict(title=objective),
        ),
    ))

    fig.update_layout(
        height=200,
        margin=dict(l=40, r=20, t=30, b=30),
        xaxis=dict(title=param_name),
        yaxis=dict(title=objective),
    )

    return fig


def render_sweep_progress(
    monitor: SweepMonitor,
    key: str = "sweep_monitor",
    show_top_results: bool = True,
    show_evolution: bool = True,
    static_plots: bool = False,
):
    """
    Streamlit panel that renders live sweep progress and leaderboards.

    Called inside the grid search loop to provide real-time feedback,
    including gauges, evolution chart and top results per objective.

    Args:
        monitor: Stateful sweep tracker updated per result.
        key: Unique widget key for rerun safety.
        show_top_results: Toggle the leaderboard section.
        show_evolution: Toggle the metrics evolution chart.
        static_plots: D√©sactiver interactivit√© Plotly (r√©duit WebSocket overhead).
    """
    if not STREAMLIT_AVAILABLE:
        raise ImportError("Streamlit non disponible")

    stats = monitor.stats

    # Header avec stats principales
    st.subheader("üîÑ Sweep Progress")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üöÄ AFFICHAGE D√âBIT EN TEMPS R√âEL (bt/s) - Style "Gaming"
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    rate = stats.rate
    if rate > 0:
        # Couleur selon performance (vert > 100/s, jaune 10-100, rouge < 10)
        if rate >= 100:
            rate_color = "#00ff88"  # Vert n√©on
            rate_icon = "üöÄ"
            rate_label = "TURBO"
        elif rate >= 10:
            rate_color = "#ffcc00"  # Jaune
            rate_icon = "‚ö°"
            rate_label = "FAST"
        else:
            rate_color = "#ff6b6b"  # Rouge
            rate_icon = "üê¢"
            rate_label = "SLOW"

        st.markdown(
            f"""<div style='background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            padding: 15px 25px; border-radius: 12px; text-align: center; margin-bottom: 15px;
            border: 2px solid {rate_color}; box-shadow: 0 0 20px {rate_color}40;'>
            <span style='color: #888; font-size: 0.9em; text-transform: uppercase; letter-spacing: 2px;'>
            {rate_label} MODE</span>
            <h2 style='color: {rate_color}; margin: 5px 0; font-size: 2.5em; font-weight: bold;
            text-shadow: 0 0 10px {rate_color};'>
            {rate_icon} {rate:,.1f} bt/s {rate_icon}
            </h2>
            <span style='color: #aaa; font-size: 0.85em;'>
            {stats.evaluated:,} / {stats.total_combinations:,} ({stats.progress_percent:.1f}%) ‚Ä¢ ETA: {stats.eta_str}
            </span>
            </div>""",
            unsafe_allow_html=True
        )

    # Afficher le meilleur PnL et le PnL moyen de mani√®re TR√àS VISIBLE (avec gestion d'erreur robuste)
    try:
        # Calculer le PnL moyen et le meilleur PnL pour √©viter les sommes trompeuses
        cumulative_pnl = 0.0
        pnl_values = []
        period_days_sum = 0.0
        period_days_count = 0

        for result in monitor.results:
            if result.metrics and 'total_pnl' in result.metrics:
                pnl_value = result.metrics.get('total_pnl', 0)
                cumulative_pnl += pnl_value
                pnl_values.append(pnl_value)
                if 'period_days' in result.metrics:
                    period_days_sum += result.metrics.get('period_days', 0)
                    period_days_count += 1

        # Moyenne des period_days pour calcul PnL/jour
        if period_days_count > 0:
            period_days_avg = period_days_sum / period_days_count
        else:
            period_days_avg = None

        if pnl_values:
            avg_pnl = cumulative_pnl / len(pnl_values)
            best_pnl = max(pnl_values)
            worst_pnl = min(pnl_values)  # PnL le plus n√©gatif pour identifier le risque de liquidation
            pnl_color = "#28a745" if best_pnl > 0 else "#dc3545"  # Bootstrap colors
            pnl_icon = "üìà" if best_pnl > 0 else "üìâ"
            # Correction : afficher explicitement le signe n√©gatif
            best_sign = "+" if best_pnl > 0 else ("-" if best_pnl < 0 else "")
            avg_sign = "+" if avg_pnl > 0 else ("-" if avg_pnl < 0 else "")
            worst_sign = "+" if worst_pnl > 0 else ("-" if worst_pnl < 0 else "")
            best_per_day = _pnl_per_day(best_pnl, period_days_avg)
            avg_per_day = _pnl_per_day(avg_pnl, period_days_avg)
            worst_per_day = _pnl_per_day(worst_pnl, period_days_avg)
            if best_per_day is not None:
                best_day_text = f" ({best_sign}${abs(best_per_day):,.2f}/jour)"
            else:
                best_day_text = ""
            if avg_per_day is not None:
                avg_day_text = f" ({avg_sign}${abs(avg_per_day):,.2f}/jour)"
            else:
                avg_day_text = ""
            if worst_per_day is not None:
                worst_day_text = f" ({worst_sign}${abs(worst_per_day):,.2f}/jour)"
            else:
                worst_day_text = ""

            # Indicateur de liquidation si worst PnL est tr√®s n√©gatif
            liquidation_warning = ""
            if worst_pnl < -5000:  # Seuil de warning liquidation
                liquidation_warning = " ‚ö†Ô∏è RISQUE LIQUIDATION"
            elif worst_pnl < 0:
                liquidation_warning = " ‚ö†Ô∏è"

            # PnL cumul√© (somme de tous les PnL)
            cumul_sign = "+" if cumulative_pnl > 0 else ("-" if cumulative_pnl < 0 else "")
            cumul_per_day = _pnl_per_day(cumulative_pnl, period_days_avg)
            if cumul_per_day is not None:
                cumul_day_text = f" ({cumul_sign}${abs(cumul_per_day):,.2f}/jour)"
            else:
                cumul_day_text = ""

            # Calcul distribution profitable/non-profitable
            profitable_count = sum(1 for pnl in pnl_values if pnl > 0)
            losing_count = sum(1 for pnl in pnl_values if pnl < 0)
            breakeven_count = sum(1 for pnl in pnl_values if pnl == 0)
            total_configs = len(pnl_values)
            profitable_pct = (profitable_count / total_configs * 100) if total_configs > 0 else 0

            st.markdown(
                f"""<div style='background: linear-gradient(135deg, {pnl_color} 0%, {pnl_color}dd 100%);
                padding: 20px; border-radius: 10px; text-align: center; margin-bottom: 15px;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>
                <h2 style='color: white; margin: 0; font-size: 1.8em;'>
                {pnl_icon} Meilleure Config: <b>{best_sign}${abs(best_pnl):,.2f}{best_day_text}</b> {pnl_icon}
                </h2>
                <div style='color: #f8f9fa; font-size: 0.95em; margin-top: 4px; opacity: 0.9;'>
                (PnL de la configuration optimale parmi {total_configs:,} test√©es)
                </div>
                <div style='color: #f8f9fa; font-size: 1.05em; margin-top: 12px;'>
                üìä PnL Moyen/Config: <b>{avg_sign}${abs(avg_pnl):,.2f}{avg_day_text}</b>
                </div>
                <div style='color: #f8f9fa; font-size: 0.95em; margin-top: 4px; opacity: 0.9;'>
                ‚úÖ {profitable_count:,} profitables ({profitable_pct:.1f}%) ‚Ä¢ ‚ùå {losing_count:,} pertes ‚Ä¢ ‚öñÔ∏è {breakeven_count:,} neutres
                </div>
                <div style='color: #ffe6e6; font-size: 1.05em; margin-top: 8px;'>
                üìâ Pire Config: <b>{worst_sign}${abs(worst_pnl):,.2f}{worst_day_text}</b>{liquidation_warning}
                </div></div>""",
                unsafe_allow_html=True
            )
    except Exception:
        pass  # Ne pas bloquer l'affichage si erreur

    # M√©triques principales avec style am√©lior√©
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric(
            "üìä Progression",
            f"{stats.progress_percent:.1f}%",
            f"{stats.evaluated}/{stats.total_combinations}",
        )

    with col2:
        st.metric(
            "‚ö° Vitesse",
            f"{stats.rate:.1f}/s",
            f"{stats.elapsed_seconds:.0f}s √©coul√©s",
        )

    with col3:
        st.metric("‚è±Ô∏è ETA", stats.eta_str)

    with col4:
        st.metric(
            "‚úÇÔ∏è Prun√©s",
            f"{stats.pruned}",
            delta=f"-{stats.pruned}" if stats.pruned > 0 else None,
            delta_color="off"
        )

    with col5:
        st.metric(
            "‚ùå Erreurs",
            f"{stats.errors}",
            delta=f"+{stats.errors}" if stats.errors > 0 else None,
            delta_color="inverse"
        )

    # Barre de progression avec couleur
    progress_color = "#28a745" if stats.progress_percent > 50 else "#ffc107" if stats.progress_percent > 25 else "#dc3545"
    st.markdown(f"""
        <div style='margin: 10px 0;'>
            <div style='background-color: #e9ecef; border-radius: 10px; overflow: hidden; height: 30px;'>
                <div style='background: linear-gradient(90deg, {progress_color} 0%, {progress_color}aa 100%);
                width: {stats.progress_percent}%; height: 100%; display: flex; align-items: center;
                justify-content: center; color: white; font-weight: bold; transition: width 0.3s;'>
                {stats.progress_percent:.1f}%
                </div>
            </div>
        </div>
    """, unsafe_allow_html=True)

    # Graphiques c√¥te √† c√¥te
    if PLOTLY_AVAILABLE:
        # Configuration Plotly : mode statique r√©duit la taille des messages WebSocket
        plotly_config = {
            "staticPlot": static_plots,  # D√©sactiver toute interactivit√© si demand√©
            "displayModeBar": not static_plots,  # Masquer la toolbar en mode statique
            "displaylogo": False,
        } if static_plots else {"displaylogo": False}

        col_left, col_right = st.columns(2)

        with col_left:
            st.markdown("**Distribution**")
            fig = _create_progress_chart(stats)
            st.plotly_chart(
                fig,
                width="stretch",
                key=f"{key}_dist",
                config=plotly_config
            )

        if show_evolution and monitor.get_metric_history(monitor.objectives[0]):
            with col_right:
                st.markdown("**√âvolution des m√©triques**")
                # ‚úÖ FIX OOM: Utiliser downsampling pour gros volumes
                history_downsampled = {
                    obj: monitor.get_metric_history_downsampled(obj, max_points=500)
                    for obj in monitor.objectives
                }
                fig = _create_metric_evolution_chart(
                    history_downsampled,
                    monitor.objectives,
                )
                st.plotly_chart(
                    fig,
                    width="stretch",
                    key=f"{key}_evol",
                    config=plotly_config
                )

    # Meilleurs r√©sultats avec design am√©lior√©
    if show_top_results:
        st.markdown("---")
        st.markdown("### üèÜ Top R√©sultats par M√©trique")

        tabs = st.tabs([f"{obj.replace('_', ' ').title()}" for obj in monitor.objectives])

        for i, obj in enumerate(monitor.objectives):
            with tabs[i]:
                top_results = monitor.get_top_results(obj)

                if top_results:
                    # Tableau des r√©sultats avec formatage am√©lior√©
                    data = []
                    display_results = top_results[:monitor.top_k]
                    for rank, r in enumerate(display_results, 1):
                        # M√©dailles pour le top 3
                        medal = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else f"#{rank}"

                        row = {"üèÖ": medal}

                        # Ajouter les param√®tres
                        for k, v in r.params.items():
                            if isinstance(v, np.integer):
                                row[k] = int(v)
                            elif isinstance(v, np.floating):
                                row[k] = round(float(v), 3)
                            elif isinstance(v, float):
                                row[k] = round(v, 3)
                            elif isinstance(v, int) and not isinstance(v, bool):
                                row[k] = v
                            else:
                                row[k] = str(v)

                        # Ajouter les m√©triques cl√©s
                        total_pnl = r.metrics.get("total_pnl", 0.0) or 0.0
                        pnl_day = _pnl_per_day(total_pnl, r.metrics.get("period_days"))
                        total_return = r.metrics.get("total_return_pct", 0.0) or 0.0
                        sharpe = r.metrics.get("sharpe_ratio", 0.0) or 0.0
                        max_dd = r.metrics.get("max_drawdown_pct", 0.0) or 0.0
                        row["PnL"] = float(total_pnl)
                        if pnl_day is not None:
                            row["PnL/jour"] = float(pnl_day)
                        row["Return%"] = float(total_return)
                        row["Sharpe"] = float(sharpe)
                        row["MaxDD%"] = abs(float(max_dd))

                        data.append(row)

                    results_df = pd.DataFrame(data)
                    st.dataframe(
                        results_df,
                        width="stretch",
                        hide_index=True,
                        height=min(400, len(results_df) * 35 + 38),  # Hauteur dynamique
                        column_config={
                            "PnL": st.column_config.NumberColumn("PnL", format="$%.0f"),
                            "PnL/jour": st.column_config.NumberColumn("PnL/jour", format="$%.2f"),
                            "Return%": st.column_config.NumberColumn("Return%", format="%.1f%%"),
                            "Sharpe": st.column_config.NumberColumn("Sharpe", format="%.2f"),
                            "MaxDD%": st.column_config.NumberColumn("MaxDD%", format="%.1f%%"),
                        },
                    )
                else:
                    st.info("‚è≥ En attente des premiers r√©sultats...")


def render_sweep_summary(monitor: SweepMonitor, key: str = "sweep_summary"):
    """
    Summary view rendered once the sweep completes.

    Highlights total duration, rate, pruning ratio and best parameter sets per objective.

    Args:
        monitor: SweepMonitor that tracked the recently finished sweep.
        key: Widget key for the summary block.
    """
    if not STREAMLIT_AVAILABLE:
        return

    stats = monitor.stats

    st.success(f"‚úÖ Sweep termin√© - {stats.evaluated} combinaisons √©valu√©es")
    ruined_count = sum(1 for r in monitor.results if r.metrics.get("account_ruined"))
    if ruined_count:
        st.warning(
            f"‚ö†Ô∏è {ruined_count} combinaison(s) ont ruin√© le compte "
            "et sont exclues du classement."
        )

    # Stats finales
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Dur√©e totale", f"{stats.elapsed_seconds:.1f}s")

    with col2:
        st.metric("Vitesse moyenne", f"{stats.rate:.2f}/s")

    with col3:
        st.metric("Taux de pruning", f"{(stats.pruned/stats.total_combinations)*100:.1f}%")

    # Meilleurs param√®tres
    st.markdown("### üèÜ Meilleurs param√®tres")

    any_best_found = False
    for obj in monitor.objectives:
        best = monitor.get_best_result(obj)
        if best:
            any_best_found = True
            with st.expander(f"**{obj.replace('_', ' ').title()}**: {best.metrics.get(obj, 0):.4f}"):
                st.json(best.params)

    if not any_best_found:
        st.warning(
            f"‚ùå Aucun r√©sultat valide trouv√©.\n\n"
            f"**{stats.errors}** erreurs sur **{stats.evaluated}** combinaisons √©valu√©es.\n\n"
            "V√©rifiez les logs ci-dessus pour identifier le probl√®me."
        )


__all__ = [
    "SweepResult",
    "SweepStats",
    "SweepMonitor",
    "render_sweep_progress",
    "render_sweep_summary",
]
```
<!-- MODULE-END: sweep_monitor.py -->

<!-- MODULE-START: validation_viewer.py -->
```json
{
  "name": "validation_viewer.py",
  "path": "ui\\components\\validation_viewer.py",
  "ext": ".py",
  "anchor": "validation_viewer_py"
}
```
## validation_viewer_py
*Chemin* : `ui\components\validation_viewer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.validation_viewer

Purpose: Renderer Streamlit pour rapports walk-forward validation - r√©sum√©, graphiques, overfitting flags.

Role in pipeline: visualization/analysis

Key components: render_validation_report(), render_validation_summary_card(), ValidationReport dataclass

Inputs: WalkForwardValidator results {train_metrics, test_metrics per window}

Outputs: Streamlit UI {tabs, cards, charts}, overfitting warnings

Dependencies: streamlit (optionnel), plotly (optionnel), pandas, dataclasses

Conventions: Train (bleu), Test (orange); overfitting flag si ratio > 1.2; TTL cache 1h.

Read-if: Modification validation rendering ou m√©trique selection.

Skip-if: Vous appelez render_validation_report(report).
"""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

try:
    import plotly.graph_objects as go
    import streamlit as st
    from plotly.subplots import make_subplots
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False


class ValidationStatus(Enum):
    """Statut de validation."""
    PASSED = "passed"
    WARNING = "warning"
    FAILED = "failed"
    OVERFITTING = "overfitting"


@dataclass
class WindowResult:
    """
    Represents metrics and parameters for a single walk-forward fold.

    Captures train/test metrics/degradation to allow UI cards and charts to flag
    problematic windows while keeping the validation logic separated.
    """
    window_id: int
    train_start: datetime
    train_end: datetime
    test_start: datetime
    test_end: datetime

    # M√©triques train
    train_sharpe: float
    train_return: float
    train_drawdown: float
    train_trades: int

    # M√©triques test
    test_sharpe: float
    test_return: float
    test_drawdown: float
    test_trades: int

    # Param√®tres optimaux
    params: Dict[str, Any] = field(default_factory=dict)

    @property
    def sharpe_degradation(self) -> float:
        """D√©gradation du Sharpe entre train et test."""
        if self.train_sharpe == 0:
            return 0.0
        return (self.train_sharpe - self.test_sharpe) / abs(self.train_sharpe)

    @property
    def return_degradation(self) -> float:
        """D√©gradation du return entre train et test."""
        if self.train_return == 0:
            return 0.0
        return (self.train_return - self.test_return) / abs(self.train_return)

    @property
    def is_overfitting(self) -> bool:
        """D√©tecte si cette fen√™tre montre de l'overfitting."""
        # Overfitting si d√©gradation > 50% ou test n√©gatif avec train positif
        if self.sharpe_degradation > 0.5:
            return True
        if self.train_sharpe > 0 and self.test_sharpe < 0:
            return True
        if self.train_return > 0 and self.test_return < 0:
            return True
        return False

    @property
    def status(self) -> ValidationStatus:
        """D√©termine le statut de validation."""
        if self.is_overfitting:
            return ValidationStatus.OVERFITTING
        if self.sharpe_degradation > 0.3:
            return ValidationStatus.WARNING
        if self.test_sharpe < 0:
            return ValidationStatus.FAILED
        return ValidationStatus.PASSED

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "window_id": self.window_id,
            "train_period": f"{self.train_start.date()} ‚Üí {self.train_end.date()}",
            "test_period": f"{self.test_start.date()} ‚Üí {self.test_end.date()}",
            "train_sharpe": self.train_sharpe,
            "test_sharpe": self.test_sharpe,
            "train_return": self.train_return,
            "test_return": self.test_return,
            "train_drawdown": self.train_drawdown,
            "test_drawdown": self.test_drawdown,
            "sharpe_degradation": self.sharpe_degradation,
            "status": self.status.value,
            "params": self.params,
        }


@dataclass
class ValidationReport:
    """
    Aggregated walk-forward validation report.

    Contains windows, aggregate metrics, and helpers to surface the best params.
    Lifespan: produced by the validation runner and consumed by UI renderers.
    """
    strategy_name: str
    created_at: datetime
    windows: List[WindowResult]

    # Configuration
    n_splits: int = 5
    train_ratio: float = 0.8
    purge_gap: int = 0

    # M√©triques globales (calcul√©es)
    _aggregate_metrics: Optional[Dict[str, float]] = field(default=None, repr=False)

    @property
    def aggregate_metrics(self) -> Dict[str, float]:
        """Calcule les m√©triques agr√©g√©es."""
        if self._aggregate_metrics is not None:
            return self._aggregate_metrics

        if not self.windows:
            return {}

        train_sharpes = [w.train_sharpe for w in self.windows]
        test_sharpes = [w.test_sharpe for w in self.windows]
        train_returns = [w.train_return for w in self.windows]
        test_returns = [w.test_return for w in self.windows]
        degradations = [w.sharpe_degradation for w in self.windows]

        import numpy as np

        self._aggregate_metrics = {
            "avg_train_sharpe": float(np.mean(train_sharpes)),
            "avg_test_sharpe": float(np.mean(test_sharpes)),
            "std_test_sharpe": float(np.std(test_sharpes)),
            "avg_train_return": float(np.mean(train_returns)),
            "avg_test_return": float(np.mean(test_returns)),
            "avg_degradation": float(np.mean(degradations)),
            "max_degradation": float(np.max(degradations)),
            "consistency_ratio": float(np.mean([1 if w.test_sharpe > 0 else 0 for w in self.windows])),
            "overfitting_windows": sum(1 for w in self.windows if w.is_overfitting),
        }

        return self._aggregate_metrics

    @property
    def overall_status(self) -> ValidationStatus:
        """Statut global de la validation."""
        metrics = self.aggregate_metrics

        # √âchec si trop de fen√™tres overfitting
        if metrics.get("overfitting_windows", 0) >= len(self.windows) // 2:
            return ValidationStatus.OVERFITTING

        # Warning si d√©gradation moyenne > 30%
        if metrics.get("avg_degradation", 0) > 0.3:
            return ValidationStatus.WARNING

        # √âchec si Sharpe test moyen n√©gatif
        if metrics.get("avg_test_sharpe", 0) < 0:
            return ValidationStatus.FAILED

        # Pass√© si consistance > 70%
        if metrics.get("consistency_ratio", 0) >= 0.7:
            return ValidationStatus.PASSED

        return ValidationStatus.WARNING

    @property
    def is_valid(self) -> bool:
        """La strat√©gie est-elle valid√©e?"""
        return self.overall_status == ValidationStatus.PASSED

    def get_best_params(self) -> Dict[str, Any]:
        """Retourne les param√®tres les plus robustes."""
        if not self.windows:
            return {}

        # Prendre les params de la fen√™tre avec le meilleur test_sharpe
        # tout en ayant une bonne consistance train/test
        valid_windows = [w for w in self.windows if not w.is_overfitting]

        if not valid_windows:
            valid_windows = self.windows

        best = max(valid_windows, key=lambda w: w.test_sharpe)
        return best.params

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise en dictionnaire."""
        return {
            "strategy_name": self.strategy_name,
            "created_at": self.created_at.isoformat(),
            "n_splits": self.n_splits,
            "train_ratio": self.train_ratio,
            "purge_gap": self.purge_gap,
            "overall_status": self.overall_status.value,
            "is_valid": self.is_valid,
            "aggregate_metrics": self.aggregate_metrics,
            "windows": [w.to_dict() for w in self.windows],
            "best_params": self.get_best_params(),
        }


# Couleurs par statut
STATUS_COLORS = {
    ValidationStatus.PASSED: "#4caf50",
    ValidationStatus.WARNING: "#ff9800",
    ValidationStatus.FAILED: "#f44336",
    ValidationStatus.OVERFITTING: "#9c27b0",
}

STATUS_ICONS = {
    ValidationStatus.PASSED: "‚úÖ",
    ValidationStatus.WARNING: "‚ö†Ô∏è",
    ValidationStatus.FAILED: "‚ùå",
    ValidationStatus.OVERFITTING: "üìà‚ùå",
}


def create_validation_figure(report: ValidationReport) -> go.Figure:
    """
    Cr√©e une figure Plotly du rapport de validation.

    Args:
        report: Rapport √† visualiser

    Returns:
        Figure Plotly
    """
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=(
            "Sharpe Ratio: Train vs Test",
            "Return: Train vs Test",
            "D√©gradation par fen√™tre",
            "Statut par fen√™tre",
        ),
        vertical_spacing=0.15,
        horizontal_spacing=0.1,
    )

    window_ids = [w.window_id for w in report.windows]

    # Sharpe comparison
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.train_sharpe for w in report.windows],
            name="Train Sharpe",
            marker_color="#2196f3",
            opacity=0.7,
        ),
        row=1,
        col=1,
    )
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.test_sharpe for w in report.windows],
            name="Test Sharpe",
            marker_color="#4caf50",
            opacity=0.7,
        ),
        row=1,
        col=1,
    )

    # Return comparison
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.train_return * 100 for w in report.windows],
            name="Train Return %",
            marker_color="#2196f3",
            opacity=0.7,
            showlegend=False,
        ),
        row=1,
        col=2,
    )
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.test_return * 100 for w in report.windows],
            name="Test Return %",
            marker_color="#4caf50",
            opacity=0.7,
            showlegend=False,
        ),
        row=1,
        col=2,
    )

    # Degradation
    degradations = [w.sharpe_degradation * 100 for w in report.windows]
    colors = ["#f44336" if d > 50 else "#ff9800" if d > 30 else "#4caf50" for d in degradations]

    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=degradations,
            name="D√©gradation %",
            marker_color=colors,
        ),
        row=2,
        col=1,
    )

    # Ligne seuil 30%
    fig.add_hline(y=30, line_dash="dash", line_color="orange", row=2, col=1)
    fig.add_hline(y=50, line_dash="dash", line_color="red", row=2, col=1)

    # Status indicators
    status_values = []
    status_colors = []
    for w in report.windows:
        status = w.status
        status_values.append(list(ValidationStatus).index(status))
        status_colors.append(STATUS_COLORS[status])

    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[1] * len(window_ids),
            name="Statut",
            marker_color=status_colors,
            text=[STATUS_ICONS[w.status] for w in report.windows],
            textposition="inside",
        ),
        row=2,
        col=2,
    )

    # Styling
    fig.update_layout(
        height=600,
        template="plotly_dark",
        barmode="group",
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
    )

    fig.update_xaxes(title_text="Fen√™tre", row=2, col=1)
    fig.update_xaxes(title_text="Fen√™tre", row=2, col=2)
    fig.update_yaxes(title_text="Sharpe Ratio", row=1, col=1)
    fig.update_yaxes(title_text="Return (%)", row=1, col=2)
    fig.update_yaxes(title_text="D√©gradation (%)", row=2, col=1)

    return fig


def render_validation_report(
    report: ValidationReport,
    key: str = "validation_report",
) -> None:
    """
    Streamlit dashboard that surfaces a Walk-Forward validation report.

    Displays status badges, global metrics, per-window tables and the multi-panel figure
    so that users can judge strategy robustness during backtests.

    Args:
        report: ValidationReport produced by `validation_integration`.
        key: Widget key preventing Streamlit rerun collisions.
    """
    if not STREAMLIT_AVAILABLE:
        return

    # En-t√™te avec statut global
    status = report.overall_status
    status_color = STATUS_COLORS[status]
    status_icon = STATUS_ICONS[status]

    st.markdown(
        f"## {status_icon} Rapport de Validation - {report.strategy_name}"
    )

    # Badge statut
    st.markdown(
        f"<span style='background-color:{status_color};color:white;padding:5px 15px;"
        f"border-radius:15px;font-weight:bold'>{status.value.upper()}</span>",
        unsafe_allow_html=True,
    )

    st.caption(f"Cr√©√© le {report.created_at.strftime('%d/%m/%Y %H:%M')}")

    # M√©triques r√©sum√©
    st.markdown("### üìä M√©triques Globales")

    metrics = report.aggregate_metrics

    col1, col2, col3, col4 = st.columns(4)

    col1.metric(
        "Sharpe Train (moy)",
        f"{metrics.get('avg_train_sharpe', 0):.3f}",
    )
    col2.metric(
        "Sharpe Test (moy)",
        f"{metrics.get('avg_test_sharpe', 0):.3f}",
        delta=f"{-metrics.get('avg_degradation', 0):.1%}",
        delta_color="inverse",
    )
    col3.metric(
        "Consistance",
        f"{metrics.get('consistency_ratio', 0):.0%}",
    )
    col4.metric(
        "Fen√™tres Overfitting",
        f"{metrics.get('overfitting_windows', 0)}/{len(report.windows)}",
    )

    col1, col2, col3, col4 = st.columns(4)

    col1.metric(
        "Return Train (moy)",
        f"{metrics.get('avg_train_return', 0):.2%}",
    )
    col2.metric(
        "Return Test (moy)",
        f"{metrics.get('avg_test_return', 0):.2%}",
    )
    col3.metric(
        "D√©gradation Max",
        f"{metrics.get('max_degradation', 0):.1%}",
    )
    col4.metric(
        "√âcart-type Test",
        f"{metrics.get('std_test_sharpe', 0):.3f}",
    )

    # Graphique
    st.markdown("### üìà Visualisation")
    fig = create_validation_figure(report)
    st.plotly_chart(fig, width='stretch', key=f"{key}_chart")

    # D√©tails par fen√™tre
    st.markdown("### üîç D√©tails par Fen√™tre")

    # Tableau r√©capitulatif
    data = []
    for w in report.windows:
        data.append({
            "Fen√™tre": w.window_id,
            "Train": f"{w.train_start.date()} ‚Üí {w.train_end.date()}",
            "Test": f"{w.test_start.date()} ‚Üí {w.test_end.date()}",
            "Sharpe (T)": f"{w.train_sharpe:.3f}",
            "Sharpe (V)": f"{w.test_sharpe:.3f}",
            "D√©gr.": f"{w.sharpe_degradation:.1%}",
            "Statut": f"{STATUS_ICONS[w.status]} {w.status.value}",
        })

    st.dataframe(data, width='stretch')

    # D√©tails expandables
    for w in report.windows:
        status_icon = STATUS_ICONS[w.status]
        with st.expander(f"Fen√™tre {w.window_id} {status_icon}", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**üìà Train**")
                st.write(f"P√©riode: {w.train_start.date()} ‚Üí {w.train_end.date()}")
                st.write(f"Sharpe: {w.train_sharpe:.3f}")
                st.write(f"Return: {w.train_return:.2%}")
                st.write(f"Drawdown: {w.train_drawdown:.2%}")
                st.write(f"Trades: {w.train_trades}")

            with col2:
                st.markdown("**üß™ Test**")
                st.write(f"P√©riode: {w.test_start.date()} ‚Üí {w.test_end.date()}")
                st.write(f"Sharpe: {w.test_sharpe:.3f}")
                st.write(f"Return: {w.test_return:.2%}")
                st.write(f"Drawdown: {w.test_drawdown:.2%}")
                st.write(f"Trades: {w.test_trades}")

            if w.params:
                st.markdown("**üîß Param√®tres optimaux**")
                st.json(w.params)

    # Recommandation
    st.markdown("### üí° Recommandation")

    if report.overall_status == ValidationStatus.PASSED:
        st.success(
            "‚úÖ **Strat√©gie valid√©e** - Les performances sont consistantes entre "
            "l'entra√Ænement et le test. La strat√©gie peut √™tre utilis√©e en production."
        )
        best_params = report.get_best_params()
        if best_params:
            st.markdown("**Param√®tres recommand√©s:**")
            st.json(best_params)

    elif report.overall_status == ValidationStatus.WARNING:
        st.warning(
            "‚ö†Ô∏è **Attention** - D√©gradation significative entre train et test. "
            "Consid√©rez d'ajuster les param√®tres ou de r√©duire la complexit√©."
        )

    elif report.overall_status == ValidationStatus.OVERFITTING:
        st.error(
            "üìà‚ùå **Overfitting d√©tect√©** - Les performances train ne se g√©n√©ralisent pas "
            "sur les donn√©es de test. Simplifiez la strat√©gie ou utilisez moins de param√®tres."
        )

    else:
        st.error(
            "‚ùå **√âchec de validation** - La strat√©gie ne performe pas de mani√®re "
            "satisfaisante sur les donn√©es de test."
        )

    # Export
    with st.expander("üì• Export"):
        import json
        report_json = json.dumps(report.to_dict(), indent=2, default=str)

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "T√©l√©charger JSON",
                report_json,
                f"validation_{report.strategy_name}.json",
                "application/json",
                key=f"{key}_download",
            )
        with col2:
            if st.button("Afficher JSON", key=f"{key}_show_json"):
                st.code(report_json, language="json")


def render_validation_summary_card(
    report: ValidationReport,
    key: str = "validation_card",
) -> None:
    """
    Compact sidebar card summarizing validation status and best candidates.

    Useful for quick sanity checks without expanding the full report panel.

    Args:
        report: Same validation report as the main panel.
        key: Streamlit widget key.
    """
    if not STREAMLIT_AVAILABLE:
        return

    status = report.overall_status
    status_color = STATUS_COLORS[status]
    status_icon = STATUS_ICONS[status]
    metrics = report.aggregate_metrics

    with st.container():
        st.markdown(
            f"<div style='border-left: 4px solid {status_color}; padding-left: 10px;'>"
            f"<strong>{status_icon} {report.strategy_name}</strong><br/>"
            f"<small>Sharpe Test: {metrics.get('avg_test_sharpe', 0):.3f} | "
            f"Consistance: {metrics.get('consistency_ratio', 0):.0%}</small>"
            f"</div>",
            unsafe_allow_html=True,
        )


def create_sample_report() -> ValidationReport:
    """Cr√©e un rapport exemple pour les tests."""
    import random
    from datetime import timedelta

    windows = []
    base_date = datetime(2024, 1, 1)

    for i in range(5):
        train_start = base_date + timedelta(days=i * 60)
        train_end = train_start + timedelta(days=180)
        test_start = train_end + timedelta(days=1)
        test_end = test_start + timedelta(days=45)

        train_sharpe = random.uniform(0.8, 2.5)
        degradation = random.uniform(0.1, 0.6)

        windows.append(WindowResult(
            window_id=i + 1,
            train_start=train_start,
            train_end=train_end,
            test_start=test_start,
            test_end=test_end,
            train_sharpe=train_sharpe,
            train_return=random.uniform(0.05, 0.25),
            train_drawdown=random.uniform(0.05, 0.15),
            train_trades=random.randint(50, 150),
            test_sharpe=train_sharpe * (1 - degradation),
            test_return=random.uniform(-0.02, 0.15),
            test_drawdown=random.uniform(0.05, 0.20),
            test_trades=random.randint(10, 40),
            params={"fast_period": 10 + i, "slow_period": 20 + i * 2},
        ))

    return ValidationReport(
        strategy_name="ema_cross",
        created_at=datetime.now(),
        windows=windows,
        n_splits=5,
        train_ratio=0.8,
    )
```
<!-- MODULE-END: validation_viewer.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "ui\\components\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `ui\components\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.__init__

Purpose: Package UI components - centralizes re-exports (charts, monitor, selector, validation, sweep).

Role in pipeline: user interface

Key components: Re-exports render_* functions from active modules

Inputs: None (module imports only)

Outputs: Public API via __all__

Dependencies: .charts, .monitor, .model_selector, .validation_viewer, .sweep_monitor

Conventions: __all__ d√©finit API publique; imports optionnels si deps manquent.

Read-if: Ajout nouveau component ou modification structure.

Skip-if: Vous importez directement depuis ui.components.charts.
"""

from .agent_timeline import *  # noqa: F401,F403
from .charts import *  # noqa: F401,F403
from .model_selector import *  # noqa: F401,F403
from .monitor import *  # noqa: F401,F403
from .sweep_monitor import *  # noqa: F401,F403
from .validation_viewer import *  # noqa: F401,F403

__all__ = [
    # Exports depuis les modules individuels
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: indicator_explorer.py -->
```json
{
  "name": "indicator_explorer.py",
  "path": "ui\\components\\archive\\indicator_explorer.py",
  "ext": ".py",
  "anchor": "indicator_explorer_py"
}
```
## indicator_explorer_py
*Chemin* : `ui\components\archive\indicator_explorer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.archive.indicator_explorer

Purpose: Explorateur indicateurs interactif Phase 5.3 - visualiser indicateurs techniques avec overlay prix OHLCV.

Role in pipeline: visualization (archive)

Key components: IndicatorExplorer, render_explorer(), dynamique param inputs

Inputs: DataFrame OHLCV, indicateur s√©lectionn√©, params

Outputs: Graphique Plotly interactif (candlesticks + indicateur)

Dependencies: streamlit, plotly, indicators.registry

Conventions: Composant Streamlit optionnel

Read-if: Vous voulez explorer/visualiser indicateurs.

Skip-if: Archive - utiliser composants actifs ui/components/
"""

from __future__ import annotations

from dataclasses import MISSING, dataclass, field, fields, is_dataclass
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd

try:
    import plotly.graph_objects as go
    import streamlit as st
    from plotly.subplots import make_subplots
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

try:
    from indicators.registry import calculate_indicator, get_indicator, list_indicators
    REGISTRY_AVAILABLE = True
except Exception:
    REGISTRY_AVAILABLE = False

from utils.indicator_ranges import get_indicator_param_specs, load_indicator_ranges


class IndicatorType(Enum):
    """Type d'indicateur pour le placement sur le graphique."""
    OVERLAY = "overlay"        # Sur le prix (MA, Bollinger, etc.)
    OSCILLATOR = "oscillator"  # Panel s√©par√© (RSI, MACD, etc.)
    VOLUME = "volume"          # Panel volume


@dataclass
class IndicatorConfig:
    """Configuration d'un indicateur √† afficher."""
    name: str
    indicator_fn: Callable
    params: Dict[str, Any] = field(default_factory=dict)
    indicator_type: IndicatorType = IndicatorType.OVERLAY
    color: str = "#1f77b4"
    line_width: int = 1
    opacity: float = 1.0
    show_by_default: bool = True

    # Pour les indicateurs multi-lignes (Bollinger, MACD)
    secondary_colors: List[str] = field(default_factory=lambda: ["#ff7f0e", "#2ca02c", "#d62728"])


@dataclass
class ChartConfig:
    """Configuration globale du graphique."""
    height: int = 800
    show_volume: bool = True
    candlestick_colors: Tuple[str, str] = ("#26a69a", "#ef5350")  # Up, Down
    background_color: str = "#0e1117"
    grid_color: str = "#1e2130"
    text_color: str = "#fafafa"
    range_slider: bool = False


# Configurations par d√©faut pour les indicateurs connus
DEFAULT_INDICATOR_CONFIGS: Dict[str, Dict[str, Any]] = {
    "sma": {"type": IndicatorType.OVERLAY, "color": "#ff9800"},
    "ema": {"type": IndicatorType.OVERLAY, "color": "#2196f3"},
    "bollinger": {"type": IndicatorType.OVERLAY, "color": "#9c27b0"},
    "keltner": {"type": IndicatorType.OVERLAY, "color": "#00bcd4"},
    "donchian": {"type": IndicatorType.OVERLAY, "color": "#4caf50"},
    "supertrend": {"type": IndicatorType.OVERLAY, "color": "#e91e63"},
    "ichimoku": {"type": IndicatorType.OVERLAY, "color": "#ff5722"},
    "psar": {"type": IndicatorType.OVERLAY, "color": "#ffeb3b"},
    "rsi": {"type": IndicatorType.OSCILLATOR, "color": "#9c27b0", "levels": [30, 70]},
    "stochastic": {"type": IndicatorType.OSCILLATOR, "color": "#2196f3", "levels": [20, 80]},
    "stoch_rsi": {"type": IndicatorType.OSCILLATOR, "color": "#00bcd4", "levels": [20, 80]},
    "williams_r": {"type": IndicatorType.OSCILLATOR, "color": "#ff9800", "levels": [-80, -20]},
    "cci": {"type": IndicatorType.OSCILLATOR, "color": "#4caf50", "levels": [-100, 100]},
    "mfi": {"type": IndicatorType.OSCILLATOR, "color": "#e91e63", "levels": [20, 80]},
    "macd": {"type": IndicatorType.OSCILLATOR, "color": "#2196f3"},
    "adx": {"type": IndicatorType.OSCILLATOR, "color": "#ff5722", "levels": [25]},
    "momentum": {"type": IndicatorType.OSCILLATOR, "color": "#9c27b0"},
    "roc": {"type": IndicatorType.OSCILLATOR, "color": "#00bcd4"},
    "vortex": {"type": IndicatorType.OSCILLATOR, "color": "#4caf50"},
    "aroon": {"type": IndicatorType.OSCILLATOR, "color": "#ff9800"},
    "atr": {"type": IndicatorType.OSCILLATOR, "color": "#e91e63"},
    "obv": {"type": IndicatorType.VOLUME, "color": "#2196f3"},
    "vwap": {"type": IndicatorType.OVERLAY, "color": "#ffeb3b"},
    "volume_oscillator": {"type": IndicatorType.VOLUME, "color": "#8bc34a"},
    "standard_deviation": {"type": IndicatorType.OSCILLATOR, "color": "#795548"},
    "fibonacci_levels": {"type": IndicatorType.OVERLAY, "color": "#ff9800"},
    "pivot_points": {"type": IndicatorType.OVERLAY, "color": "#9e9e9e"},
    "onchain_smoothing": {"type": IndicatorType.OVERLAY, "color": "#03a9f4"},
    "fear_greed": {"type": IndicatorType.OSCILLATOR, "color": "#ffc107", "levels": [20, 80]},
    "pi_cycle": {"type": IndicatorType.OVERLAY, "color": "#ff5722"},
    "amplitude_hunter": {"type": IndicatorType.OSCILLATOR, "color": "#00bcd4"},
}


class IndicatorExplorer:
    """
    Explorateur interactif d'indicateurs techniques.

    Permet de visualiser les indicateurs sur un graphique OHLCV
    avec configuration dynamique des param√®tres.
    """

    def __init__(
        self,
        df: pd.DataFrame,
        chart_config: Optional[ChartConfig] = None,
    ):
        """
        Initialise l'explorateur.

        Args:
            df: DataFrame OHLCV avec colonnes open, high, low, close, volume
            chart_config: Configuration du graphique
        """
        self.df = df.copy()
        self.config = chart_config or ChartConfig()
        self._indicators: Dict[str, Dict[str, Any]] = {}
        self._computed_values: Dict[str, Any] = {}

        # V√©rifier colonnes requises
        required = ["open", "high", "low", "close"]
        missing = [c for c in required if c not in df.columns]
        if missing:
            raise ValueError(f"Colonnes manquantes: {missing}")

    def add_indicator(
        self,
        name: str,
        values: Union[np.ndarray, pd.Series, Dict[str, np.ndarray]],
        indicator_type: Optional[IndicatorType] = None,
        color: str = "#1f77b4",
        label: Optional[str] = None,
        **kwargs,
    ) -> "IndicatorExplorer":
        """
        Ajoute un indicateur calcul√©.

        Args:
            name: Nom unique de l'indicateur
            values: Valeurs (array, Series, ou dict pour multi-lignes)
            indicator_type: Type (overlay, oscillator, volume)
            color: Couleur principale
            label: Label d'affichage
            **kwargs: Options suppl√©mentaires

        Returns:
            Self pour cha√Ænage
        """
        # D√©terminer le type automatiquement si non sp√©cifi√©
        if indicator_type is None:
            default_config = DEFAULT_INDICATOR_CONFIGS.get(name.lower(), {})
            indicator_type = default_config.get("type", IndicatorType.OVERLAY)

        self._indicators[name] = {
            "values": values,
            "type": indicator_type,
            "color": color,
            "label": label or name,
            **kwargs,
        }

        return self

    def remove_indicator(self, name: str) -> "IndicatorExplorer":
        """Supprime un indicateur."""
        self._indicators.pop(name, None)
        return self

    def clear_indicators(self) -> "IndicatorExplorer":
        """Supprime tous les indicateurs."""
        self._indicators.clear()
        return self

    def _create_candlestick(self, fig: go.Figure, row: int = 1) -> None:
        """Ajoute le candlestick au graphique."""
        fig.add_trace(
            go.Candlestick(
                x=self.df.index,
                open=self.df["open"],
                high=self.df["high"],
                low=self.df["low"],
                close=self.df["close"],
                increasing_line_color=self.config.candlestick_colors[0],
                decreasing_line_color=self.config.candlestick_colors[1],
                name="OHLC",
            ),
            row=row,
            col=1,
        )

    def _add_overlay_indicator(
        self,
        fig: go.Figure,
        name: str,
        config: Dict[str, Any],
        row: int = 1,
    ) -> None:
        """Ajoute un indicateur overlay sur le prix."""
        values = config["values"]
        color = config["color"]
        label = config["label"]

        if isinstance(values, dict):
            # Multi-lignes (ex: Bollinger bands)
            colors = [color] + config.get("secondary_colors", ["#ff7f0e", "#2ca02c", "#d62728"])
            for i, (key, val) in enumerate(values.items()):
                fig.add_trace(
                    go.Scatter(
                        x=self.df.index,
                        y=val,
                        mode="lines",
                        name=f"{label} {key}",
                        line=dict(color=colors[i % len(colors)], width=1),
                        opacity=config.get("opacity", 0.8),
                    ),
                    row=row,
                    col=1,
                )
        else:
            # Ligne simple
            fig.add_trace(
                go.Scatter(
                    x=self.df.index,
                    y=values,
                    mode="lines",
                    name=label,
                    line=dict(color=color, width=config.get("line_width", 1)),
                    opacity=config.get("opacity", 1.0),
                ),
                row=row,
                col=1,
            )

    def _add_oscillator_indicator(
        self,
        fig: go.Figure,
        name: str,
        config: Dict[str, Any],
        row: int,
    ) -> None:
        """Ajoute un indicateur oscillateur dans un panel s√©par√©."""
        values = config["values"]
        color = config["color"]
        label = config["label"]
        levels = config.get("levels", [])

        if isinstance(values, dict):
            # Multi-lignes (ex: MACD)
            colors = [color, "#ff7f0e", "#2ca02c"]
            for i, (key, val) in enumerate(values.items()):
                # Histogram sp√©cial pour MACD
                if key == "histogram" and "macd" in name.lower():
                    colors_hist = np.where(val >= 0, "#26a69a", "#ef5350")
                    fig.add_trace(
                        go.Bar(
                            x=self.df.index,
                            y=val,
                            name=f"{label} {key}",
                            marker_color=colors_hist.tolist() if hasattr(colors_hist, 'tolist') else list(colors_hist),
                        ),
                        row=row,
                        col=1,
                    )
                else:
                    fig.add_trace(
                        go.Scatter(
                            x=self.df.index,
                            y=val,
                            mode="lines",
                            name=f"{label} {key}",
                            line=dict(color=colors[i % len(colors)], width=1),
                        ),
                        row=row,
                        col=1,
                    )
        else:
            fig.add_trace(
                go.Scatter(
                    x=self.df.index,
                    y=values,
                    mode="lines",
                    name=label,
                    line=dict(color=color, width=1),
                ),
                row=row,
                col=1,
            )

        # Ajouter les niveaux de r√©f√©rence
        for level in levels:
            fig.add_hline(
                y=level,
                line_dash="dash",
                line_color="gray",
                opacity=0.5,
                row=row,
                col=1,
            )

    def _add_volume(self, fig: go.Figure, row: int) -> None:
        """Ajoute le volume."""
        if "volume" not in self.df.columns:
            return

        colors = np.where(
            self.df["close"] >= self.df["open"],
            self.config.candlestick_colors[0],
            self.config.candlestick_colors[1],
        )

        fig.add_trace(
            go.Bar(
                x=self.df.index,
                y=self.df["volume"],
                name="Volume",
                marker_color=colors.tolist(),
                opacity=0.7,
            ),
            row=row,
            col=1,
        )

    def create_figure(self) -> go.Figure:
        """
        Cr√©e la figure Plotly compl√®te.

        Returns:
            Figure Plotly avec tous les indicateurs
        """
        # Compter les panels n√©cessaires
        oscillators = [
            (name, cfg) for name, cfg in self._indicators.items()
            if cfg["type"] == IndicatorType.OSCILLATOR
        ]

        n_rows = 1  # Prix
        if self.config.show_volume and "volume" in self.df.columns:
            n_rows += 1
        n_rows += len(oscillators)

        # Cr√©er les row heights
        row_heights = [0.5]  # Prix
        if self.config.show_volume and "volume" in self.df.columns:
            row_heights.append(0.1)
        row_heights.extend([0.15] * len(oscillators))

        # Normaliser
        total = sum(row_heights)
        row_heights = [h / total for h in row_heights]

        # Cr√©er la figure avec subplots
        fig = make_subplots(
            rows=n_rows,
            cols=1,
            shared_xaxes=True,
            vertical_spacing=0.02,
            row_heights=row_heights,
        )

        # Ajouter le candlestick
        self._create_candlestick(fig, row=1)

        # Ajouter les overlays
        for name, config in self._indicators.items():
            if config["type"] == IndicatorType.OVERLAY:
                self._add_overlay_indicator(fig, name, config, row=1)

        current_row = 2

        # Ajouter le volume
        if self.config.show_volume and "volume" in self.df.columns:
            self._add_volume(fig, row=current_row)
            current_row += 1

        # Ajouter les oscillateurs
        for name, config in oscillators:
            self._add_oscillator_indicator(fig, name, config, row=current_row)
            current_row += 1

        # Styling
        fig.update_layout(
            height=self.config.height,
            template="plotly_dark",
            paper_bgcolor=self.config.background_color,
            plot_bgcolor=self.config.background_color,
            font=dict(color=self.config.text_color),
            xaxis_rangeslider_visible=self.config.range_slider,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1,
            ),
            margin=dict(l=50, r=50, t=50, b=50),
        )

        # Update axes
        fig.update_xaxes(
            gridcolor=self.config.grid_color,
            showgrid=True,
        )
        fig.update_yaxes(
            gridcolor=self.config.grid_color,
            showgrid=True,
        )

        return fig

    def get_indicator_summary(self) -> Dict[str, Dict[str, Any]]:
        """
        Retourne un r√©sum√© des indicateurs ajout√©s.

        Returns:
            Dict avec infos sur chaque indicateur
        """
        summary = {}
        for name, config in self._indicators.items():
            values = config["values"]

            if isinstance(values, dict):
                stats = {}
                for key, val in values.items():
                    arr = np.asarray(val)
                    valid = arr[~np.isnan(arr)]
                    if len(valid) > 0:
                        stats[key] = {
                            "current": float(valid[-1]),
                            "min": float(np.min(valid)),
                            "max": float(np.max(valid)),
                            "mean": float(np.mean(valid)),
                        }
            else:
                arr = np.asarray(values)
                valid = arr[~np.isnan(arr)]
                if len(valid) > 0:
                    stats = {
                        "current": float(valid[-1]),
                        "min": float(np.min(valid)),
                        "max": float(np.max(valid)),
                        "mean": float(np.mean(valid)),
                    }
                else:
                    stats = {}

            summary[name] = {
                "type": config["type"].value,
                "label": config["label"],
                "stats": stats,
            }

        return summary


def _clamp_value(value: float, min_val: float, max_val: float) -> float:
    if value is None:
        return min_val
    return max(min_val, min(max_val, value))


def _is_int_spec(spec: Dict[str, Any]) -> bool:
    min_val = spec.get("min")
    max_val = spec.get("max")
    default = spec.get("default")
    step = spec.get("step")
    values = [min_val, max_val, default]
    if any(val is None for val in values):
        return False
    if not all(isinstance(val, int) for val in values):
        return False
    return step is None or isinstance(step, int)


def _render_param_widget_from_spec(
    indicator_name: str,
    param_name: str,
    spec: Dict[str, Any],
    key_prefix: str,
) -> Any:
    label = spec.get("label", param_name)
    description = spec.get("description", "")
    default = spec.get("default")
    options = spec.get("options")
    param_type = spec.get("type")
    widget_key = f"{key_prefix}_{indicator_name}_{param_name}"

    if options:
        options_list = list(options)
        if default not in options_list and options_list:
            default = options_list[0]
        index = options_list.index(default) if default in options_list else 0
        return st.selectbox(
            label,
            options_list,
            index=index,
            key=widget_key,
            help=description,
        )

    if param_type == "string":
        return st.text_input(
            label,
            value="" if default is None else str(default),
            key=widget_key,
            help=description,
        )

    if param_type == "bool" or isinstance(default, bool):
        return st.checkbox(
            label,
            value=bool(default),
            key=widget_key,
            help=description,
        )

    min_val = spec.get("min")
    max_val = spec.get("max")
    step = spec.get("step")

    if min_val is None or max_val is None:
        if isinstance(default, int):
            return st.number_input(
                label,
                value=int(default),
                step=1,
                key=widget_key,
                help=description,
            )
        step_value = float(step) if step is not None else 0.1
        return st.number_input(
            label,
            value=float(default) if default is not None else 0.0,
            step=step_value,
            key=widget_key,
            help=description,
        )

    if _is_int_spec(spec):
        min_val = int(min_val)
        max_val = int(max_val)
        default_value = int(_clamp_value(default, min_val, max_val))
        step_value = int(step) if step is not None else 1
        return st.slider(
            label,
            min_val,
            max_val,
            value=default_value,
            step=step_value,
            key=widget_key,
            help=description,
        )

    min_val = float(min_val)
    max_val = float(max_val)
    default_value = float(_clamp_value(default, min_val, max_val))
    if step is not None:
        return st.slider(
            label,
            min_val,
            max_val,
            value=default_value,
            step=float(step),
            key=widget_key,
            help=description,
        )
    return st.slider(
        label,
        min_val,
        max_val,
        value=default_value,
        key=widget_key,
        help=description,
    )


def _build_params_from_specs(
    indicator_name: str,
    key_prefix: str,
    param_specs: Dict[str, Dict[str, Any]],
    allowed_params: Optional[set[str]] = None,
) -> Dict[str, Any]:
    params: Dict[str, Any] = {}
    for param_name, spec in param_specs.items():
        if allowed_params is not None and param_name not in allowed_params:
            continue
        params[param_name] = _render_param_widget_from_spec(
            indicator_name,
            param_name,
            spec,
            key_prefix,
        )
    return params


def _build_params_from_settings(
    indicator_name: str,
    key_prefix: str,
    settings_class: Optional[type],
    exclude: Optional[set[str]] = None,
) -> Dict[str, Any]:
    if not settings_class or not is_dataclass(settings_class):
        return {}

    exclude = exclude or set()
    params: Dict[str, Any] = {}
    for param in fields(settings_class):
        if param.name in exclude:
            continue
        if param.default is not MISSING:
            default = param.default
        elif param.default_factory is not MISSING:  # type: ignore[comparison-overlap]
            default = param.default_factory()  # type: ignore[misc]
        else:
            continue

        widget_key = f"{key_prefix}_{indicator_name}_{param.name}"
        label = param.name

        if isinstance(default, bool):
            params[param.name] = st.checkbox(
                label,
                value=default,
                key=widget_key,
            )
        elif isinstance(default, int):
            params[param.name] = st.number_input(
                label,
                value=default,
                step=1,
                key=widget_key,
            )
        elif isinstance(default, float):
            params[param.name] = st.number_input(
                label,
                value=default,
                step=0.1,
                key=widget_key,
            )
        elif isinstance(default, str):
            params[param.name] = st.text_input(
                label,
                value=default,
                key=widget_key,
            )

    return params


def _normalize_indicator_result(indicator_name: str, result: Any) -> Any:
    if isinstance(result, tuple):
        if indicator_name.lower() == "bollinger" and len(result) == 3:
            return {"upper": result[0], "middle": result[1], "lower": result[2]}
        if indicator_name.lower() == "stochastic" and len(result) == 2:
            return {"k": result[0], "d": result[1]}
        return {f"line_{idx + 1}": value for idx, value in enumerate(result)}
    return result


def render_indicator_explorer(
    df: pd.DataFrame,
    available_indicators: Optional[Dict[str, Callable]] = None,
    key: str = "indicator_explorer",
) -> Optional[go.Figure]:
    """
    Rendu Streamlit de l'explorateur d'indicateurs.

    Args:
        df: DataFrame OHLCV
        available_indicators: Dict {nom: fonction} des indicateurs disponibles
        key: Cl√© unique pour les widgets Streamlit

    Returns:
        Figure Plotly ou None
    """
    if not STREAMLIT_AVAILABLE:
        return None

    indicator_ranges = load_indicator_ranges()
    use_registry = REGISTRY_AVAILABLE and available_indicators is None
    indicator_infos: Dict[str, Any] = {}

    if use_registry:
        indicator_names = list_indicators()
        for name in indicator_names:
            info = get_indicator(name)
            if info is not None:
                indicator_infos[name] = info
        available_indicators = {name: info.function for name, info in indicator_infos.items()}
    else:
        if available_indicators is None:
            available_indicators = {}
        indicator_names = list(available_indicators.keys())

    st.subheader("üìä Explorateur d'Indicateurs")

    # Configuration du graphique
    with st.expander("‚öôÔ∏è Configuration graphique", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            height = st.slider("Hauteur", 400, 1200, 800, key=f"{key}_height")
        with col2:
            show_volume = st.checkbox("Afficher volume", value=True, key=f"{key}_volume")
        with col3:
            range_slider = st.checkbox("Range slider", value=False, key=f"{key}_slider")

    chart_config = ChartConfig(
        height=height,
        show_volume=show_volume,
        range_slider=range_slider,
    )

    explorer = IndicatorExplorer(df, chart_config)

    # S√©lection des indicateurs
    st.markdown("### üìà S√©lection des indicateurs")

    # Grouper par type
    overlay_indicators = []
    oscillator_indicators = []

    for name in indicator_names:
        default_config = DEFAULT_INDICATOR_CONFIGS.get(name.lower(), {})
        ind_type = default_config.get("type", IndicatorType.OVERLAY)
        if ind_type == IndicatorType.OSCILLATOR:
            oscillator_indicators.append(name)
        else:
            overlay_indicators.append(name)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**Overlays (sur le prix)**")
        selected_overlays = st.multiselect(
            "Choisir overlays",
            overlay_indicators,
            default=[],
            key=f"{key}_overlays",
            label_visibility="collapsed",
        )

    with col2:
        st.markdown("**Oscillateurs (panels s√©par√©s)**")
        selected_oscillators = st.multiselect(
            "Choisir oscillateurs",
            oscillator_indicators,
            default=[],
            key=f"{key}_oscillators",
            label_visibility="collapsed",
        )

    # Configuration des param√®tres pour chaque indicateur s√©lectionn√©
    all_selected = selected_overlays + selected_oscillators

    if all_selected:
        st.markdown("### üîß Param√®tres des indicateurs")

        for ind_name in all_selected:
            with st.expander(f"üìä {ind_name}", expanded=False):
                indicator_fn = available_indicators.get(ind_name)
                if indicator_fn is None:
                    st.warning(f"Indicateur {ind_name} non disponible")
                    continue

                # Param√®tres depuis indicator_ranges.toml (fallback settings_class)
                params = {}
                param_specs = get_indicator_param_specs(ind_name, indicator_ranges)
                info = indicator_infos.get(ind_name)
                if info is None and REGISTRY_AVAILABLE:
                    info = get_indicator(ind_name)

                allowed_params = None
                if info and info.settings_class and is_dataclass(info.settings_class):
                    allowed_params = {field.name for field in fields(info.settings_class)}

                if param_specs:
                    params.update(
                        _build_params_from_specs(
                            ind_name,
                            key,
                            param_specs,
                            allowed_params=allowed_params,
                        )
                    )

                if info and info.settings_class:
                    params.update(
                        _build_params_from_settings(
                            ind_name,
                            key,
                            info.settings_class,
                            exclude=set(params.keys()),
                        )
                    )

                # Calculer l'indicateur
                try:
                    if use_registry and REGISTRY_AVAILABLE:
                        result = calculate_indicator(ind_name, df, params)
                    else:
                        # Pr√©parer les donn√©es pour les indicateurs custom
                        if "volume" in df.columns:
                            result = indicator_fn(
                                df["high"].values,
                                df["low"].values,
                                df["close"].values,
                                **params
                            ) if ind_name.lower() not in ["sma", "ema", "rsi", "momentum", "roc"] else indicator_fn(
                                df["close"].values,
                                **params
                            )
                        else:
                            result = indicator_fn(df["close"].values, **params)

                    result = _normalize_indicator_result(ind_name, result)

                    # D√©terminer le type
                    default_config = DEFAULT_INDICATOR_CONFIGS.get(ind_name.lower(), {})
                    ind_type = default_config.get("type", IndicatorType.OVERLAY)
                    color = default_config.get("color", "#1f77b4")

                    explorer.add_indicator(
                        ind_name,
                        result,
                        indicator_type=ind_type,
                        color=color,
                        levels=default_config.get("levels", []),
                    )

                    st.success(f"‚úÖ {ind_name} calcul√©")

                except Exception as e:
                    st.error(f"‚ùå Erreur: {e}")

    # Cr√©er et afficher le graphique
    if st.button("üöÄ G√©n√©rer graphique", key=f"{key}_generate", type="primary"):
        with st.spinner("G√©n√©ration du graphique..."):
            fig = explorer.create_figure()
            st.plotly_chart(fig, width='stretch', key=f"{key}_chart")

            # R√©sum√© des indicateurs
            summary = explorer.get_indicator_summary()
            if summary:
                st.markdown("### üìã R√©sum√© des indicateurs")
                for name, info in summary.items():
                    with st.expander(f"üìä {info['label']}", expanded=False):
                        if isinstance(info["stats"], dict) and "current" in info["stats"]:
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("Actuel", f"{info['stats']['current']:.4f}")
                            col2.metric("Min", f"{info['stats']['min']:.4f}")
                            col3.metric("Max", f"{info['stats']['max']:.4f}")
                            col4.metric("Moyenne", f"{info['stats']['mean']:.4f}")
                        elif isinstance(info["stats"], dict):
                            for key, stats in info["stats"].items():
                                if isinstance(stats, dict):
                                    st.write(f"**{key}**: {stats.get('current', 'N/A'):.4f}")

            return fig

    return None


def render_quick_indicator_chart(
    df: pd.DataFrame,
    indicators: Dict[str, Union[np.ndarray, Dict[str, np.ndarray]]],
    title: str = "Indicateurs",
    height: int = 600,
) -> go.Figure:
    """
    G√©n√®re rapidement un graphique avec indicateurs pr√©-calcul√©s.

    Args:
        df: DataFrame OHLCV
        indicators: Dict {nom: valeurs} des indicateurs
        title: Titre du graphique
        height: Hauteur en pixels

    Returns:
        Figure Plotly
    """
    config = ChartConfig(height=height, show_volume=True)
    explorer = IndicatorExplorer(df, config)

    for name, values in indicators.items():
        default_config = DEFAULT_INDICATOR_CONFIGS.get(name.lower(), {})
        ind_type = default_config.get("type", IndicatorType.OVERLAY)
        color = default_config.get("color", "#1f77b4")

        explorer.add_indicator(
            name,
            values,
            indicator_type=ind_type,
            color=color,
            levels=default_config.get("levels", []),
        )

    fig = explorer.create_figure()
    fig.update_layout(title=title)

    return fig
```
<!-- MODULE-END: indicator_explorer.py -->

<!-- MODULE-START: sweep_monitor.py -->
```json
{
  "name": "sweep_monitor.py",
  "path": "ui\\components\\archive\\sweep_monitor.py",
  "ext": ".py",
  "anchor": "sweep_monitor_py"
}
```
## sweep_monitor_py
*Chemin* : `ui\components\archive\sweep_monitor.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.archive.sweep_monitor

Purpose: Composant monitoring sweep temps r√©el Phase 5.2 - progression, meilleurs r√©sultats, m√©triques.

Role in pipeline: visualization (archive)

Key components: SweepMonitor, render_sweep_progress(), render_sweep_summary()

Inputs: Param grid, backtest results en continu

Outputs: UI temps r√©el avec progress bar, top results

Dependencies: streamlit, backtest.sweep

Conventions: Composant optionnel archive

Read-if: Vous voulez monitoring temps r√©el sweep.

Skip-if: Archive - utiliser composants actifs ui/components/
"""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

import numpy as np


@dataclass
class SweepResult:
    """R√©sultat d'une √©valuation de sweep."""
    params: Dict[str, Any]
    metrics: Dict[str, float]
    timestamp: datetime = field(default_factory=lambda: datetime.now())
    duration_ms: float = 0.0

    @property
    def sharpe(self) -> float:
        """Raccourci pour Sharpe Ratio."""
        return self.metrics.get('sharpe_ratio', 0.0)

    @property
    def total_return(self) -> float:
        """Raccourci pour rendement total."""
        return self.metrics.get('total_return', 0.0)


@dataclass
class SweepStats:
    """Statistiques du sweep en cours."""
    total_combinations: int = 0
    evaluated: int = 0
    pruned: int = 0
    errors: int = 0
    start_time: Optional[datetime] = None

    @property
    def progress_percent(self) -> float:
        """Pourcentage de progression."""
        if self.total_combinations == 0:
            return 0.0
        return (self.evaluated / self.total_combinations) * 100

    @property
    def elapsed(self) -> timedelta:
        """Temps √©coul√©."""
        if not self.start_time:
            return timedelta(0)
        return datetime.now() - self.start_time

    @property
    def elapsed_seconds(self) -> float:
        """Temps √©coul√© en secondes."""
        return self.elapsed.total_seconds()

    @property
    def rate(self) -> float:
        """Taux d'√©valuation (eval/sec)."""
        if self.elapsed_seconds == 0:
            return 0.0
        return self.evaluated / self.elapsed_seconds

    @property
    def eta(self) -> Optional[timedelta]:
        """Temps estim√© restant."""
        if self.rate == 0:
            return None
        remaining = self.total_combinations - self.evaluated
        return timedelta(seconds=remaining / self.rate)

    @property
    def eta_str(self) -> str:
        """ETA format√©."""
        eta = self.eta
        if eta is None:
            return "Calcul..."

        total_secs = int(eta.total_seconds())
        if total_secs < 60:
            return f"{total_secs}s"
        elif total_secs < 3600:
            return f"{total_secs // 60}m {total_secs % 60}s"
        else:
            hours = total_secs // 3600
            mins = (total_secs % 3600) // 60
            return f"{hours}h {mins}m"


class SweepMonitor:
    """
    Moniteur de progression pour les optimisations sweep.

    Collecte les r√©sultats et fournit des statistiques en temps r√©el.
    """

    def __init__(
        self,
        total_combinations: int,
        objectives: List[str] = None,
        top_k: int = 10,
    ):
        """
        Args:
            total_combinations: Nombre total de combinaisons √† √©valuer
            objectives: Liste des objectifs √† tracker
            top_k: Nombre de meilleurs r√©sultats √† garder
        """
        self.total = total_combinations
        # Note: Utiliser les cl√©s correctes retourn√©es par calculate_metrics
        self.objectives = objectives or ['sharpe_ratio', 'total_return_pct', 'max_drawdown']
        self.top_k = top_k

        self._results: List[SweepResult] = []
        self._top_results: Dict[str, List[SweepResult]] = {
            obj: [] for obj in self.objectives
        }
        self._stats = SweepStats(total_combinations=total_combinations)
        self._metric_history: Dict[str, List[float]] = {
            obj: [] for obj in self.objectives
        }
        self._last_update = None

    def start(self):
        """D√©marre le monitoring."""
        self._stats.start_time = datetime.now()

    def update(
        self,
        params: Dict[str, Any],
        metrics: Dict[str, float],
        duration_ms: float = 0.0,
        pruned: bool = False,
        error: bool = False,
    ):
        """
        Met √† jour avec un nouveau r√©sultat.

        Args:
            params: Param√®tres √©valu√©s
            metrics: M√©triques r√©sultantes
            duration_ms: Dur√©e de l'√©valuation
            pruned: Si la combinaison a √©t√© prun√©e
            error: Si une erreur s'est produite
        """
        if self._stats.start_time is None:
            self.start()

        if error:
            self._stats.errors += 1
            return

        if pruned:
            self._stats.pruned += 1
            return

        self._stats.evaluated += 1

        result = SweepResult(
            params=params,
            metrics=metrics,
            duration_ms=duration_ms,
        )
        self._results.append(result)

        # Mettre √† jour l'historique des m√©triques
        for obj in self.objectives:
            if obj in metrics:
                self._metric_history[obj].append(metrics[obj])

        # Mettre √† jour les top r√©sultats
        self._update_top_results(result)
        self._last_update = datetime.now()

    def _update_top_results(self, result: SweepResult):
        """Met √† jour les meilleurs r√©sultats."""
        for obj in self.objectives:
            if obj not in result.metrics:
                continue

            top = self._top_results[obj]
            top.append(result)

            # Trier et garder le top_k
            reverse = obj != 'max_drawdown'  # Minimiser le drawdown
            top.sort(key=lambda r: r.metrics.get(obj, 0), reverse=reverse)
            self._top_results[obj] = top[:self.top_k]

    @property
    def stats(self) -> SweepStats:
        """Retourne les statistiques."""
        return self._stats

    @property
    def results(self) -> List[SweepResult]:
        """Retourne tous les r√©sultats."""
        return list(self._results)

    def get_top_results(self, objective: str) -> List[SweepResult]:
        """Retourne les meilleurs r√©sultats pour un objectif."""
        return self._top_results.get(objective, [])

    def get_best_result(self, objective: str) -> Optional[SweepResult]:
        """Retourne le meilleur r√©sultat pour un objectif."""
        top = self.get_top_results(objective)
        return top[0] if top else None

    def get_metric_history(self, objective: str) -> List[float]:
        """Retourne l'historique d'une m√©trique."""
        return self._metric_history.get(objective, [])

    @property
    def is_complete(self) -> bool:
        """Indique si le sweep est termin√©."""
        return self._stats.evaluated >= self.total


def _create_progress_chart(stats: SweepStats) -> go.Figure:
    """Cr√©e un graphique de progression."""
    evaluated = stats.evaluated
    pruned = stats.pruned
    remaining = stats.total_combinations - evaluated - pruned

    fig = go.Figure(data=[go.Pie(
        values=[evaluated, pruned, remaining],
        labels=['√âvalu√©s', 'Prun√©s', 'Restants'],
        marker_colors=['#2ca02c', '#ff7f0e', '#d3d3d3'],
        hole=0.6,
        textinfo='percent',
        textposition='outside',
    )])

    fig.update_layout(
        height=200,
        margin=dict(l=20, r=20, t=20, b=20),
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2),
        annotations=[dict(
            text=f"{stats.progress_percent:.0f}%",
            x=0.5, y=0.5,
            font_size=24,
            showarrow=False
        )],
    )

    return fig


def _create_metric_evolution_chart(
    history: Dict[str, List[float]],
    objectives: List[str],
) -> go.Figure:
    """Cr√©e le graphique d'√©volution des m√©triques."""
    fig = go.Figure()

    colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']

    for i, obj in enumerate(objectives):
        values = history.get(obj, [])
        if not values:
            continue

        # Calculer la moyenne mobile
        window = min(20, len(values))
        if window > 1:
            moving_avg = np.convolve(values, np.ones(window)/window, mode='valid')
            x_values = list(range(window-1, len(values)))
        else:
            moving_avg = values
            x_values = list(range(len(values)))

        fig.add_trace(go.Scatter(
            x=x_values,
            y=moving_avg,
            name=obj.replace('_', ' ').title(),
            line=dict(color=colors[i % len(colors)], width=2),
        ))

    fig.update_layout(
        height=200,
        margin=dict(l=40, r=20, t=30, b=30),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        xaxis=dict(title="√âvaluations"),
        yaxis=dict(title="Valeur"),
    )

    return fig


def _create_param_impact_chart(
    results: List[SweepResult],
    objective: str,
    param_name: str,
) -> go.Figure:
    """Cr√©e un graphique d'impact d'un param√®tre."""
    if not results:
        return go.Figure()

    # Extraire les donn√©es
    param_values = []
    metric_values = []

    for r in results:
        if param_name in r.params and objective in r.metrics:
            param_values.append(r.params[param_name])
            metric_values.append(r.metrics[objective])

    if not param_values:
        return go.Figure()

    fig = go.Figure(data=go.Scatter(
        x=param_values,
        y=metric_values,
        mode='markers',
        marker=dict(
            color=metric_values,
            colorscale='Viridis',
            size=8,
            showscale=True,
            colorbar=dict(title=objective),
        ),
    ))

    fig.update_layout(
        height=200,
        margin=dict(l=40, r=20, t=30, b=30),
        xaxis=dict(title=param_name),
        yaxis=dict(title=objective),
    )

    return fig


def render_sweep_progress(
    monitor: SweepMonitor,
    key: str = "sweep_monitor",
    show_top_results: bool = True,
    show_evolution: bool = True,
):
    """
    Render le composant Sweep Monitor dans Streamlit.

    Args:
        monitor: Instance de SweepMonitor
        key: Cl√© unique pour le composant
        show_top_results: Afficher les meilleurs r√©sultats
        show_evolution: Afficher l'√©volution des m√©triques
    """
    if not STREAMLIT_AVAILABLE:
        raise ImportError("Streamlit non disponible")

    stats = monitor.stats

    # Header avec stats principales
    st.subheader("üîÑ Sweep Progress")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "Progression",
            f"{stats.progress_percent:.1f}%",
            f"{stats.evaluated}/{stats.total_combinations}",
        )

    with col2:
        st.metric(
            "Vitesse",
            f"{stats.rate:.1f}/s",
            f"{stats.elapsed_seconds:.0f}s √©coul√©s",
        )

    with col3:
        st.metric("ETA", stats.eta_str)

    with col4:
        st.metric(
            "Prun√©s/Erreurs",
            f"{stats.pruned}",
            f"{stats.errors} erreurs",
        )

    # Barre de progression
    st.progress(stats.progress_percent / 100)

    # Graphiques c√¥te √† c√¥te
    if PLOTLY_AVAILABLE:
        col_left, col_right = st.columns(2)

        with col_left:
            st.markdown("**Distribution**")
            fig = _create_progress_chart(stats)
            st.plotly_chart(fig, width='stretch', key=f"{key}_progress")

        if show_evolution and monitor.get_metric_history(monitor.objectives[0]):
            with col_right:
                st.markdown("**√âvolution des m√©triques**")
                fig = _create_metric_evolution_chart(
                    monitor._metric_history,
                    monitor.objectives,
                )
                st.plotly_chart(fig, width='stretch', key=f"{key}_evolution")

    # Meilleurs r√©sultats
    if show_top_results:
        st.markdown("**üèÜ Meilleurs r√©sultats**")

        tabs = st.tabs([obj.replace('_', ' ').title() for obj in monitor.objectives])

        for i, obj in enumerate(monitor.objectives):
            with tabs[i]:
                top_results = monitor.get_top_results(obj)

                if top_results:
                    # Tableau des r√©sultats
                    data = []
                    for rank, r in enumerate(top_results[:5], 1):
                        row = {
                            "Rank": rank,
                            **{k: f"{v:.4f}" if isinstance(v, float) else v
                               for k, v in r.params.items()},
                            obj: f"{r.metrics.get(obj, 0):.4f}",
                        }
                        data.append(row)

                    st.dataframe(data, width='stretch')
                else:
                    st.info("Pas encore de r√©sultats")


def render_sweep_summary(monitor: SweepMonitor, key: str = "sweep_summary"):
    """
    Render un r√©sum√© final du sweep.

    Args:
        monitor: Instance de SweepMonitor termin√©
        key: Cl√© unique
    """
    if not STREAMLIT_AVAILABLE:
        return

    stats = monitor.stats

    st.success(f"‚úÖ Sweep termin√© - {stats.evaluated} combinaisons √©valu√©es")

    # Stats finales
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Dur√©e totale", f"{stats.elapsed_seconds:.1f}s")

    with col2:
        st.metric("Vitesse moyenne", f"{stats.rate:.2f}/s")

    with col3:
        st.metric("Taux de pruning", f"{(stats.pruned/stats.total_combinations)*100:.1f}%")

    # Meilleurs param√®tres
    st.markdown("### üèÜ Meilleurs param√®tres")

    for obj in monitor.objectives:
        best = monitor.get_best_result(obj)
        if best:
            with st.expander(f"**{obj.replace('_', ' ').title()}**: {best.metrics.get(obj, 0):.4f}"):
                st.json(best.params)


__all__ = [
    "SweepResult",
    "SweepStats",
    "SweepMonitor",
    "render_sweep_progress",
    "render_sweep_summary",
]
```
<!-- MODULE-END: sweep_monitor.py -->

<!-- MODULE-START: themes.py -->
```json
{
  "name": "themes.py",
  "path": "ui\\components\\archive\\themes.py",
  "ext": ".py",
  "anchor": "themes_py"
}
```
## themes_py
*Chemin* : `ui\components\archive\themes.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.archive.themes

Purpose: Gestion th√®mes UI et persistance pr√©f√©rences Phase 5.6 - personnaliser apparence + sauvegarder settings.

Role in pipeline: visualization (archive)

Key components: ThemeMode, ColorPalette, set_theme(), get_theme(), persist_settings()

Inputs: Pr√©f√©rences utilisateur (light/dark/auto)

Outputs: Style CSS/Streamlit apply√©

Dependencies: streamlit, json, pathlib

Conventions: Persistance via fichier local .streamlit/config.toml

Read-if: Personnaliser th√®mes ou persistance settings.

Skip-if: Archive - utiliser composants actifs ou th√®mes standard.
"""

from __future__ import annotations

import json
from dataclasses import asdict, dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False


class ThemeMode(Enum):
    """Mode de th√®me."""
    LIGHT = "light"
    DARK = "dark"
    AUTO = "auto"


class ColorPalette(Enum):
    """Palettes de couleurs pr√©d√©finies."""
    DEFAULT = "default"
    OCEAN = "ocean"
    FOREST = "forest"
    SUNSET = "sunset"
    MONOCHROME = "monochrome"
    CYBERPUNK = "cyberpunk"


# D√©finitions des palettes
PALETTES: Dict[ColorPalette, Dict[str, str]] = {
    ColorPalette.DEFAULT: {
        "primary": "#2196f3",
        "secondary": "#ff9800",
        "success": "#4caf50",
        "warning": "#ff9800",
        "error": "#f44336",
        "info": "#00bcd4",
        "background": "#0e1117",
        "surface": "#1e2130",
        "text": "#fafafa",
        "text_secondary": "#b0b0b0",
        "chart_up": "#26a69a",
        "chart_down": "#ef5350",
    },
    ColorPalette.OCEAN: {
        "primary": "#0077b6",
        "secondary": "#00b4d8",
        "success": "#06d6a0",
        "warning": "#ffd166",
        "error": "#ef476f",
        "info": "#118ab2",
        "background": "#03045e",
        "surface": "#023e8a",
        "text": "#caf0f8",
        "text_secondary": "#90e0ef",
        "chart_up": "#06d6a0",
        "chart_down": "#ef476f",
    },
    ColorPalette.FOREST: {
        "primary": "#2d6a4f",
        "secondary": "#40916c",
        "success": "#52b788",
        "warning": "#e9c46a",
        "error": "#e76f51",
        "info": "#74c69d",
        "background": "#1b4332",
        "surface": "#2d6a4f",
        "text": "#d8f3dc",
        "text_secondary": "#95d5b2",
        "chart_up": "#52b788",
        "chart_down": "#e76f51",
    },
    ColorPalette.SUNSET: {
        "primary": "#ff6b6b",
        "secondary": "#feca57",
        "success": "#1dd1a1",
        "warning": "#feca57",
        "error": "#ee5a24",
        "info": "#54a0ff",
        "background": "#2c2c54",
        "surface": "#474787",
        "text": "#f5f6fa",
        "text_secondary": "#dcdde1",
        "chart_up": "#1dd1a1",
        "chart_down": "#ee5a24",
    },
    ColorPalette.MONOCHROME: {
        "primary": "#888888",
        "secondary": "#666666",
        "success": "#a0a0a0",
        "warning": "#c0c0c0",
        "error": "#505050",
        "info": "#707070",
        "background": "#1a1a1a",
        "surface": "#2a2a2a",
        "text": "#e0e0e0",
        "text_secondary": "#909090",
        "chart_up": "#a0a0a0",
        "chart_down": "#505050",
    },
    ColorPalette.CYBERPUNK: {
        "primary": "#00ffff",
        "secondary": "#ff00ff",
        "success": "#00ff00",
        "warning": "#ffff00",
        "error": "#ff0000",
        "info": "#00ffff",
        "background": "#0a0a0a",
        "surface": "#1a1a2e",
        "text": "#eaeaea",
        "text_secondary": "#00ffff",
        "chart_up": "#00ff00",
        "chart_down": "#ff00ff",
    },
}


@dataclass
class ChartSettings:
    """Param√®tres des graphiques."""
    default_height: int = 600
    show_volume: bool = True
    show_grid: bool = True
    show_legend: bool = True
    range_slider: bool = False
    candlestick_style: str = "hollow"  # "hollow", "filled", "ohlc"

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class PerformanceSettings:
    """Param√®tres de performance."""
    use_gpu: bool = True
    max_workers: int = 4
    cache_enabled: bool = True
    cache_ttl_hours: int = 24

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class DefaultParams:
    """Param√®tres par d√©faut pour le backtest."""
    initial_capital: float = 10000.0
    fees_bps: int = 10
    slippage_bps: int = 5
    default_strategy: str = "ema_cross"
    default_timeframe: str = "1h"

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class UserPreferences:
    """Pr√©f√©rences utilisateur compl√®tes."""
    # Apparence
    theme_mode: ThemeMode = ThemeMode.DARK
    color_palette: ColorPalette = ColorPalette.DEFAULT
    font_size: str = "medium"  # "small", "medium", "large"

    # Graphiques
    chart_settings: ChartSettings = field(default_factory=ChartSettings)

    # Performance
    performance_settings: PerformanceSettings = field(default_factory=PerformanceSettings)

    # D√©fauts backtest
    default_params: DefaultParams = field(default_factory=DefaultParams)

    # Favoris
    favorite_strategies: List[str] = field(default_factory=list)
    favorite_indicators: List[str] = field(default_factory=list)
    recent_data_files: List[str] = field(default_factory=list)

    # UI State
    sidebar_expanded: bool = True
    show_tips: bool = True

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise en dictionnaire."""
        return {
            "theme_mode": self.theme_mode.value,
            "color_palette": self.color_palette.value,
            "font_size": self.font_size,
            "chart_settings": self.chart_settings.to_dict(),
            "performance_settings": self.performance_settings.to_dict(),
            "default_params": self.default_params.to_dict(),
            "favorite_strategies": self.favorite_strategies,
            "favorite_indicators": self.favorite_indicators,
            "recent_data_files": self.recent_data_files,
            "sidebar_expanded": self.sidebar_expanded,
            "show_tips": self.show_tips,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "UserPreferences":
        """Charge depuis un dictionnaire."""
        return cls(
            theme_mode=ThemeMode(data.get("theme_mode", "dark")),
            color_palette=ColorPalette(data.get("color_palette", "default")),
            font_size=data.get("font_size", "medium"),
            chart_settings=ChartSettings(**data.get("chart_settings", {})),
            performance_settings=PerformanceSettings(**data.get("performance_settings", {})),
            default_params=DefaultParams(**data.get("default_params", {})),
            favorite_strategies=data.get("favorite_strategies", []),
            favorite_indicators=data.get("favorite_indicators", []),
            recent_data_files=data.get("recent_data_files", []),
            sidebar_expanded=data.get("sidebar_expanded", True),
            show_tips=data.get("show_tips", True),
        )

    def get_colors(self) -> Dict[str, str]:
        """Retourne les couleurs de la palette active."""
        return PALETTES.get(self.color_palette, PALETTES[ColorPalette.DEFAULT])


class PreferencesManager:
    """
    Gestionnaire de persistance des pr√©f√©rences.

    Sauvegarde et charge les pr√©f√©rences utilisateur
    depuis un fichier JSON local.
    """

    DEFAULT_PATH = Path.home() / ".backtest_core" / "preferences.json"

    def __init__(self, path: Optional[Path] = None):
        """
        Initialise le gestionnaire.

        Args:
            path: Chemin du fichier de pr√©f√©rences
        """
        self.path = path or self.DEFAULT_PATH
        self._preferences: Optional[UserPreferences] = None

    @property
    def preferences(self) -> UserPreferences:
        """Retourne les pr√©f√©rences (charge si n√©cessaire)."""
        if self._preferences is None:
            self._preferences = self.load()
        return self._preferences

    def load(self) -> UserPreferences:
        """
        Charge les pr√©f√©rences depuis le fichier.

        Returns:
            Pr√©f√©rences charg√©es ou d√©faut
        """
        if self.path.exists():
            try:
                with open(self.path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                return UserPreferences.from_dict(data)
            except Exception:
                pass
        return UserPreferences()

    def save(self, preferences: Optional[UserPreferences] = None) -> bool:
        """
        Sauvegarde les pr√©f√©rences dans le fichier.

        Args:
            preferences: Pr√©f√©rences √† sauvegarder (ou celles en cache)

        Returns:
            True si succ√®s
        """
        prefs = preferences or self._preferences or UserPreferences()

        try:
            self.path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.path, "w", encoding="utf-8") as f:
                json.dump(prefs.to_dict(), f, indent=2)
            self._preferences = prefs
            return True
        except Exception:
            return False

    def update(self, **kwargs) -> UserPreferences:
        """
        Met √† jour des pr√©f√©rences sp√©cifiques.

        Args:
            **kwargs: Attributs √† mettre √† jour

        Returns:
            Pr√©f√©rences mises √† jour
        """
        prefs = self.preferences

        for key, value in kwargs.items():
            if hasattr(prefs, key):
                setattr(prefs, key, value)

        self.save(prefs)
        return prefs

    def reset(self) -> UserPreferences:
        """R√©initialise aux valeurs par d√©faut."""
        self._preferences = UserPreferences()
        self.save(self._preferences)
        return self._preferences

    def add_favorite_strategy(self, strategy: str) -> None:
        """Ajoute une strat√©gie aux favoris."""
        prefs = self.preferences
        if strategy not in prefs.favorite_strategies:
            prefs.favorite_strategies.append(strategy)
            self.save(prefs)

    def remove_favorite_strategy(self, strategy: str) -> None:
        """Retire une strat√©gie des favoris."""
        prefs = self.preferences
        if strategy in prefs.favorite_strategies:
            prefs.favorite_strategies.remove(strategy)
            self.save(prefs)

    def add_recent_file(self, filepath: str, max_recent: int = 10) -> None:
        """Ajoute un fichier r√©cent."""
        prefs = self.preferences
        if filepath in prefs.recent_data_files:
            prefs.recent_data_files.remove(filepath)
        prefs.recent_data_files.insert(0, filepath)
        prefs.recent_data_files = prefs.recent_data_files[:max_recent]
        self.save(prefs)


# Instance globale
_preferences_manager: Optional[PreferencesManager] = None


def get_preferences_manager() -> PreferencesManager:
    """Retourne l'instance globale du gestionnaire."""
    global _preferences_manager
    if _preferences_manager is None:
        _preferences_manager = PreferencesManager()
    return _preferences_manager


def get_preferences() -> UserPreferences:
    """Raccourci pour obtenir les pr√©f√©rences."""
    return get_preferences_manager().preferences


def apply_theme(preferences: Optional[UserPreferences] = None) -> None:
    """
    Applique le th√®me aux composants Streamlit.

    Note: Streamlit ne supporte pas le changement de th√®me programmatique
    complet, mais on peut styler certains √©l√©ments.
    """
    if not STREAMLIT_AVAILABLE:
        return

    prefs = preferences or get_preferences()
    colors = prefs.get_colors()

    # CSS personnalis√©
    st.markdown(
        f"""
        <style>
        .stApp {{
            background-color: {colors['background']};
        }}
        .stMetric {{
            background-color: {colors['surface']};
            padding: 10px;
            border-radius: 5px;
        }}
        .stMetric label {{
            color: {colors['text_secondary']} !important;
        }}
        .stMetric [data-testid="stMetricValue"] {{
            color: {colors['text']} !important;
        }}
        .css-1d391kg {{
            background-color: {colors['surface']};
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )


def render_theme_settings(key: str = "theme_settings") -> Optional[UserPreferences]:
    """
    Rendu Streamlit des param√®tres de th√®me.

    Args:
        key: Cl√© unique pour les widgets

    Returns:
        Pr√©f√©rences mises √† jour ou None
    """
    if not STREAMLIT_AVAILABLE:
        return None

    manager = get_preferences_manager()
    prefs = manager.preferences
    changed = False

    st.subheader("üé® Th√®me et Apparence")

    col1, col2 = st.columns(2)

    with col1:
        # Mode th√®me
        theme_options = [m.value for m in ThemeMode]
        current_theme = theme_options.index(prefs.theme_mode.value)
        new_theme = st.selectbox(
            "Mode",
            theme_options,
            index=current_theme,
            key=f"{key}_theme_mode",
        )
        if new_theme != prefs.theme_mode.value:
            prefs.theme_mode = ThemeMode(new_theme)
            changed = True

    with col2:
        # Palette de couleurs
        palette_options = [p.value for p in ColorPalette]
        current_palette = palette_options.index(prefs.color_palette.value)
        new_palette = st.selectbox(
            "Palette",
            palette_options,
            index=current_palette,
            key=f"{key}_palette",
        )
        if new_palette != prefs.color_palette.value:
            prefs.color_palette = ColorPalette(new_palette)
            changed = True

    # Pr√©visualisation des couleurs
    colors = prefs.get_colors()
    st.markdown("**Aper√ßu des couleurs:**")

    cols = st.columns(6)
    color_keys = ["primary", "secondary", "success", "warning", "error", "info"]
    for i, key_name in enumerate(color_keys):
        color = colors[key_name]
        cols[i].markdown(
            f"<div style='background-color:{color};width:50px;height:30px;"
            f"border-radius:5px;margin:auto;'></div>"
            f"<small style='display:block;text-align:center'>{key_name}</small>",
            unsafe_allow_html=True,
        )

    # Taille de police
    font_options = ["small", "medium", "large"]
    font_options.index(prefs.font_size)
    new_font = st.select_slider(
        "Taille de police",
        options=font_options,
        value=prefs.font_size,
        key=f"{key}_font",
    )
    if new_font != prefs.font_size:
        prefs.font_size = new_font
        changed = True

    if changed:
        manager.save(prefs)
        st.success("‚úÖ Th√®me mis √† jour!")
        apply_theme(prefs)

    return prefs if changed else None


def render_chart_settings(key: str = "chart_settings") -> Optional[ChartSettings]:
    """
    Rendu des param√®tres de graphique.

    Args:
        key: Cl√© unique

    Returns:
        Settings mis √† jour ou None
    """
    if not STREAMLIT_AVAILABLE:
        return None

    manager = get_preferences_manager()
    prefs = manager.preferences
    settings = prefs.chart_settings
    changed = False

    st.subheader("üìä Param√®tres Graphiques")

    col1, col2 = st.columns(2)

    with col1:
        new_height = st.slider(
            "Hauteur par d√©faut",
            300, 1000, settings.default_height, 50,
            key=f"{key}_height",
        )
        if new_height != settings.default_height:
            settings.default_height = new_height
            changed = True

        new_volume = st.checkbox(
            "Afficher volume",
            value=settings.show_volume,
            key=f"{key}_volume",
        )
        if new_volume != settings.show_volume:
            settings.show_volume = new_volume
            changed = True

    with col2:
        new_grid = st.checkbox(
            "Afficher grille",
            value=settings.show_grid,
            key=f"{key}_grid",
        )
        if new_grid != settings.show_grid:
            settings.show_grid = new_grid
            changed = True

        new_legend = st.checkbox(
            "Afficher l√©gende",
            value=settings.show_legend,
            key=f"{key}_legend",
        )
        if new_legend != settings.show_legend:
            settings.show_legend = new_legend
            changed = True

        new_slider = st.checkbox(
            "Range slider",
            value=settings.range_slider,
            key=f"{key}_slider",
        )
        if new_slider != settings.range_slider:
            settings.range_slider = new_slider
            changed = True

    # Style candlestick
    style_options = ["hollow", "filled", "ohlc"]
    current_style = style_options.index(settings.candlestick_style)
    new_style = st.selectbox(
        "Style chandelier",
        style_options,
        index=current_style,
        key=f"{key}_style",
    )
    if new_style != settings.candlestick_style:
        settings.candlestick_style = new_style
        changed = True

    if changed:
        manager.save(prefs)
        st.success("‚úÖ Param√®tres graphiques sauvegard√©s!")

    return settings if changed else None


def render_default_params(key: str = "default_params") -> Optional[DefaultParams]:
    """
    Rendu des param√®tres par d√©faut de backtest.

    Args:
        key: Cl√© unique

    Returns:
        Params mis √† jour ou None
    """
    if not STREAMLIT_AVAILABLE:
        return None

    manager = get_preferences_manager()
    prefs = manager.preferences
    params = prefs.default_params
    changed = False

    st.subheader("‚öôÔ∏è Param√®tres par D√©faut")

    col1, col2 = st.columns(2)

    with col1:
        new_capital = st.number_input(
            "Capital initial",
            min_value=100.0,
            max_value=10000000.0,
            value=params.initial_capital,
            step=1000.0,
            key=f"{key}_capital",
        )
        if new_capital != params.initial_capital:
            params.initial_capital = new_capital
            changed = True

        new_fees = st.number_input(
            "Frais (BPS)",
            min_value=0,
            max_value=100,
            value=params.fees_bps,
            step=1,
            key=f"{key}_fees",
        )
        if new_fees != params.fees_bps:
            params.fees_bps = new_fees
            changed = True

    with col2:
        new_slippage = st.number_input(
            "Slippage (BPS)",
            min_value=0,
            max_value=50,
            value=params.slippage_bps,
            step=1,
            key=f"{key}_slippage",
        )
        if new_slippage != params.slippage_bps:
            params.slippage_bps = new_slippage
            changed = True

        new_tf = st.selectbox(
            "Timeframe par d√©faut",
            ["1m", "5m", "15m", "1h", "4h", "1d"],
            index=["1m", "5m", "15m", "1h", "4h", "1d"].index(params.default_timeframe),
            key=f"{key}_tf",
        )
        if new_tf != params.default_timeframe:
            params.default_timeframe = new_tf
            changed = True

    if changed:
        manager.save(prefs)
        st.success("‚úÖ Param√®tres par d√©faut sauvegard√©s!")

    return params if changed else None


def render_full_settings_page(key: str = "settings") -> None:
    """
    Page compl√®te de param√®tres.

    Args:
        key: Cl√© unique
    """
    if not STREAMLIT_AVAILABLE:
        return

    st.title("‚öôÔ∏è Param√®tres")

    manager = get_preferences_manager()

    tabs = st.tabs(["üé® Th√®me", "üìä Graphiques", "‚öôÔ∏è D√©fauts", "‚≠ê Favoris"])

    with tabs[0]:
        render_theme_settings(f"{key}_theme")

    with tabs[1]:
        render_chart_settings(f"{key}_chart")

    with tabs[2]:
        render_default_params(f"{key}_params")

    with tabs[3]:
        prefs = manager.preferences

        st.subheader("‚≠ê Strat√©gies Favorites")
        if prefs.favorite_strategies:
            for strat in prefs.favorite_strategies:
                col1, col2 = st.columns([4, 1])
                col1.write(f"üìà {strat}")
                if col2.button("‚ùå", key=f"{key}_remove_{strat}"):
                    manager.remove_favorite_strategy(strat)
                    st.rerun()
        else:
            st.info("Aucune strat√©gie favorite")

        st.subheader("üìÇ Fichiers R√©cents")
        if prefs.recent_data_files:
            for filepath in prefs.recent_data_files[:5]:
                st.caption(f"üìÑ {filepath}")
        else:
            st.info("Aucun fichier r√©cent")

    # Actions
    st.divider()
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üîÑ R√©initialiser tout", key=f"{key}_reset"):
            manager.reset()
            st.success("‚úÖ Pr√©f√©rences r√©initialis√©es")
            st.rerun()

    with col2:
        prefs_json = json.dumps(manager.preferences.to_dict(), indent=2)
        st.download_button(
            "üì• Exporter",
            prefs_json,
            "backtest_preferences.json",
            "application/json",
            key=f"{key}_export",
        )

    with col3:
        uploaded = st.file_uploader(
            "üì§ Importer",
            type="json",
            key=f"{key}_import",
            label_visibility="collapsed",
        )
        if uploaded:
            try:
                data = json.load(uploaded)
                new_prefs = UserPreferences.from_dict(data)
                manager.save(new_prefs)
                st.success("‚úÖ Pr√©f√©rences import√©es")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå Erreur: {e}")
```
<!-- MODULE-END: themes.py -->

<!-- MODULE-START: thinking_viewer.py -->
```json
{
  "name": "thinking_viewer.py",
  "path": "ui\\components\\archive\\thinking_viewer.py",
  "ext": ".py",
  "anchor": "thinking_viewer_py"
}
```
## thinking_viewer_py
*Chemin* : `ui\components\archive\thinking_viewer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.archive.thinking_viewer

Purpose: Afficheur pens√©es agents LLM temps r√©el - stream raisonnement, cat√©gorisation, timestamp.

Role in pipeline: visualization (archive)

Key components: ThinkingStreamViewer, ThoughtCategory, render()

Inputs: Flux pens√©es LLM (thinking, conclusion, decision, error)

Outputs: Interface Streamlit affichage stream live

Dependencies: streamlit, dataclasses

Conventions: Composant optionnel archive

Read-if: Afficher pens√©es agents LLM en direct.

Skip-if: Archive - utiliser composants actifs orchestration.
"""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import List, Literal

import streamlit as st

ThoughtCategory = Literal["thinking", "conclusion", "decision", "error"]


@dataclass
class ThoughtEntry:
    """Entr√©e de pens√©e dans le stream."""

    timestamp: datetime
    agent_name: str
    model: str
    thought: str
    category: ThoughtCategory


class ThinkingStreamViewer:
    """
    Visualisation stream de pens√©es des LLMs en temps r√©el.

    Affiche:
    - Raisonnement de chaque agent
    - Conclusions et m√©triques
    - D√©cisions prises
    - Erreurs rencontr√©es

    Example:
        >>> viewer = ThinkingStreamViewer(container_key="llm_stream")
        >>> viewer.add_thought(
        ...     agent_name="Analyst",
        ...     model="deepseek-r1:32b",
        ...     thought="Sharpe actuel: 1.23 - Volatilit√© acceptable",
        ...     category="thinking"
        ... )
        >>> viewer.render()
    """

    def __init__(self, container_key: str = "thinking_stream"):
        """
        Initialise le viewer.

        Args:
            container_key: Cl√© unique pour session state Streamlit
        """
        self.container_key = container_key
        self._init_session_state()

    def _init_session_state(self):
        """Initialise variables session state."""
        key_stream = f"{self.container_key}_stream"
        if key_stream not in st.session_state:
            st.session_state[key_stream] = []

    def add_thought(
        self,
        agent_name: str,
        model: str,
        thought: str,
        category: ThoughtCategory = "thinking",
    ) -> None:
        """
        Ajoute une pens√©e au stream.

        Args:
            agent_name: Nom de l'agent (Analyst, Strategist, Critic, Validator)
            model: Mod√®le LLM utilis√©
            thought: Contenu de la pens√©e
            category: Type de pens√©e ('thinking', 'conclusion', 'decision', 'error')

        Example:
            >>> viewer.add_thought(
            ...     "Strategist",
            ...     "qwq:32b",
            ...     "Testing bb_period=25 with k_sl=2.0",
            ...     "thinking"
            ... )
        """
        key_stream = f"{self.container_key}_stream"

        entry = ThoughtEntry(
            timestamp=datetime.now(),
            agent_name=agent_name,
            model=model,
            thought=thought,
            category=category,
        )

        st.session_state[key_stream].append(entry)

        # Limiter historique √† 100 entr√©es pour √©viter surcharge m√©moire
        if len(st.session_state[key_stream]) > 100:
            st.session_state[key_stream] = st.session_state[key_stream][-100:]

    def clear(self) -> None:
        """Vide le stream de pens√©es."""
        key_stream = f"{self.container_key}_stream"
        st.session_state[key_stream] = []

    def get_thought_count(self) -> int:
        """Retourne le nombre de pens√©es dans le stream."""
        key_stream = f"{self.container_key}_stream"
        return len(st.session_state.get(key_stream, []))

    def render(self, max_entries: int = 20, show_header: bool = True) -> None:
        """
        Affiche le stream de pens√©es.

        Args:
            max_entries: Nombre maximum de pens√©es √† afficher
            show_header: Afficher le header "Stream de Pens√©es LLM"

        Example:
            >>> viewer.render(max_entries=10, show_header=True)
        """
        key_stream = f"{self.container_key}_stream"
        stream: List[ThoughtEntry] = st.session_state.get(key_stream, [])

        if show_header:
            st.markdown("### üí≠ Stream de Pens√©es LLM")

        if not stream:
            st.info("üí≠ Aucune activit√© mentale pour le moment...")
            st.caption(
                "Les pens√©es des agents LLM s'afficheront ici pendant l'optimisation"
            )
            return

        # Afficher les derni√®res entr√©es (ordre inverse = plus r√©cent en haut)
        for entry in reversed(stream[-max_entries:]):
            self._render_thought_entry(entry)

    def _render_thought_entry(self, entry: ThoughtEntry) -> None:
        """
        Affiche une entr√©e de pens√©e avec style appropri√©.

        Args:
            entry: Entr√©e de pens√©e √† afficher
        """
        # Style selon cat√©gorie
        category_config = {
            "thinking": {"emoji": "ü§î", "alert_type": "info"},
            "conclusion": {"emoji": "üí°", "alert_type": "success"},
            "decision": {"emoji": "üéØ", "alert_type": "warning"},
            "error": {"emoji": "‚ùå", "alert_type": "error"},
        }

        config = category_config.get(entry.category, {"emoji": "üí¨", "alert_type": "info"})
        emoji = config["emoji"]
        alert_type = config["alert_type"]

        # Format timestamp
        timestamp_str = entry.timestamp.strftime("%H:%M:%S")

        # En-t√™te avec timestamp, agent et mod√®le
        with st.container():
            st.markdown(
                f"**{timestamp_str}** | {emoji} **{entry.agent_name}** (`{entry.model}`)"
            )

            # Contenu avec style appropri√©
            if alert_type == "info":
                st.info(entry.thought)
            elif alert_type == "success":
                st.success(entry.thought)
            elif alert_type == "warning":
                st.warning(entry.thought)
            elif alert_type == "error":
                st.error(entry.thought)

            st.divider()


def render_thinking_stream(
    container_key: str = "thinking_stream",
    max_entries: int = 20,
    show_header: bool = True,
) -> ThinkingStreamViewer:
    """
    Fonction helper pour cr√©er et afficher le viewer en une ligne.

    Args:
        container_key: Cl√© unique pour session state
        max_entries: Nombre maximum de pens√©es √† afficher
        show_header: Afficher le header

    Returns:
        ThinkingStreamViewer: Instance du viewer pour ajouter des pens√©es

    Example:
        >>> # Dans Streamlit:
        >>> viewer = render_thinking_stream()
        >>> # Plus tard, pour ajouter une pens√©e:
        >>> viewer.add_thought("Analyst", "qwq:32b", "Analyzing...", "thinking")
    """
    viewer = ThinkingStreamViewer(container_key=container_key)
    viewer.render(max_entries=max_entries, show_header=show_header)
    return viewer


__all__ = [
    "ThinkingStreamViewer",
    "ThoughtEntry",
    "ThoughtCategory",
    "render_thinking_stream",
]
```
<!-- MODULE-END: thinking_viewer.py -->

<!-- MODULE-START: validation_viewer.py -->
```json
{
  "name": "validation_viewer.py",
  "path": "ui\\components\\archive\\validation_viewer.py",
  "ext": ".py",
  "anchor": "validation_viewer_py"
}
```
## validation_viewer_py
*Chemin* : `ui\components\archive\validation_viewer.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.components.archive.validation_viewer

Purpose: Afficheur rapports walk-forward Phase 5.5 - visualiser r√©sultats validation anti-overfitting par fen√™tre.

Role in pipeline: visualization (archive)

Key components: ValidationStatus, render_validation_report(), fenetre details, m√©triques

Inputs: WalkForwardResult, metriques, overfitting ratio

Outputs: Interface Streamlit multi-onglets (overview, details, metrics)

Dependencies: streamlit, plotly, backtest.validation

Conventions: Composant optionnel archive

Read-if: Afficher rapports walk-forward d√©taill√©s.

Skip-if: Archive - utiliser composants actifs validation.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

try:
    import plotly.graph_objects as go
    import streamlit as st
    from plotly.subplots import make_subplots
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False


class ValidationStatus(Enum):
    """Statut de validation."""
    PASSED = "passed"
    WARNING = "warning"
    FAILED = "failed"
    OVERFITTING = "overfitting"


@dataclass
class WindowResult:
    """R√©sultat d'une fen√™tre de validation."""
    window_id: int
    train_start: datetime
    train_end: datetime
    test_start: datetime
    test_end: datetime

    # M√©triques train
    train_sharpe: float
    train_return: float
    train_drawdown: float
    train_trades: int

    # M√©triques test
    test_sharpe: float
    test_return: float
    test_drawdown: float
    test_trades: int

    # Param√®tres optimaux
    params: Dict[str, Any] = field(default_factory=dict)

    @property
    def sharpe_degradation(self) -> float:
        """D√©gradation du Sharpe entre train et test."""
        if self.train_sharpe == 0:
            return 0.0
        return (self.train_sharpe - self.test_sharpe) / abs(self.train_sharpe)

    @property
    def return_degradation(self) -> float:
        """D√©gradation du return entre train et test."""
        if self.train_return == 0:
            return 0.0
        return (self.train_return - self.test_return) / abs(self.train_return)

    @property
    def is_overfitting(self) -> bool:
        """D√©tecte si cette fen√™tre montre de l'overfitting."""
        # Overfitting si d√©gradation > 50% ou test n√©gatif avec train positif
        if self.sharpe_degradation > 0.5:
            return True
        if self.train_sharpe > 0 and self.test_sharpe < 0:
            return True
        if self.train_return > 0 and self.test_return < 0:
            return True
        return False

    @property
    def status(self) -> ValidationStatus:
        """D√©termine le statut de validation."""
        if self.is_overfitting:
            return ValidationStatus.OVERFITTING
        if self.sharpe_degradation > 0.3:
            return ValidationStatus.WARNING
        if self.test_sharpe < 0:
            return ValidationStatus.FAILED
        return ValidationStatus.PASSED

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "window_id": self.window_id,
            "train_period": f"{self.train_start.date()} ‚Üí {self.train_end.date()}",
            "test_period": f"{self.test_start.date()} ‚Üí {self.test_end.date()}",
            "train_sharpe": self.train_sharpe,
            "test_sharpe": self.test_sharpe,
            "train_return": self.train_return,
            "test_return": self.test_return,
            "train_drawdown": self.train_drawdown,
            "test_drawdown": self.test_drawdown,
            "sharpe_degradation": self.sharpe_degradation,
            "status": self.status.value,
            "params": self.params,
        }


@dataclass
class ValidationReport:
    """Rapport complet de validation Walk-Forward."""
    strategy_name: str
    created_at: datetime
    windows: List[WindowResult]

    # Configuration
    n_splits: int = 5
    train_ratio: float = 0.8
    purge_gap: int = 0

    # M√©triques globales (calcul√©es)
    _aggregate_metrics: Optional[Dict[str, float]] = field(default=None, repr=False)

    @property
    def aggregate_metrics(self) -> Dict[str, float]:
        """Calcule les m√©triques agr√©g√©es."""
        if self._aggregate_metrics is not None:
            return self._aggregate_metrics

        if not self.windows:
            return {}

        train_sharpes = [w.train_sharpe for w in self.windows]
        test_sharpes = [w.test_sharpe for w in self.windows]
        train_returns = [w.train_return for w in self.windows]
        test_returns = [w.test_return for w in self.windows]
        degradations = [w.sharpe_degradation for w in self.windows]

        import numpy as np

        self._aggregate_metrics = {
            "avg_train_sharpe": float(np.mean(train_sharpes)),
            "avg_test_sharpe": float(np.mean(test_sharpes)),
            "std_test_sharpe": float(np.std(test_sharpes)),
            "avg_train_return": float(np.mean(train_returns)),
            "avg_test_return": float(np.mean(test_returns)),
            "avg_degradation": float(np.mean(degradations)),
            "max_degradation": float(np.max(degradations)),
            "consistency_ratio": float(np.mean([1 if w.test_sharpe > 0 else 0 for w in self.windows])),
            "overfitting_windows": sum(1 for w in self.windows if w.is_overfitting),
        }

        return self._aggregate_metrics

    @property
    def overall_status(self) -> ValidationStatus:
        """Statut global de la validation."""
        metrics = self.aggregate_metrics

        # √âchec si trop de fen√™tres overfitting
        if metrics.get("overfitting_windows", 0) >= len(self.windows) // 2:
            return ValidationStatus.OVERFITTING

        # Warning si d√©gradation moyenne > 30%
        if metrics.get("avg_degradation", 0) > 0.3:
            return ValidationStatus.WARNING

        # √âchec si Sharpe test moyen n√©gatif
        if metrics.get("avg_test_sharpe", 0) < 0:
            return ValidationStatus.FAILED

        # Pass√© si consistance > 70%
        if metrics.get("consistency_ratio", 0) >= 0.7:
            return ValidationStatus.PASSED

        return ValidationStatus.WARNING

    @property
    def is_valid(self) -> bool:
        """La strat√©gie est-elle valid√©e?"""
        return self.overall_status == ValidationStatus.PASSED

    def get_best_params(self) -> Dict[str, Any]:
        """Retourne les param√®tres les plus robustes."""
        if not self.windows:
            return {}

        # Prendre les params de la fen√™tre avec le meilleur test_sharpe
        # tout en ayant une bonne consistance train/test
        valid_windows = [w for w in self.windows if not w.is_overfitting]

        if not valid_windows:
            valid_windows = self.windows

        best = max(valid_windows, key=lambda w: w.test_sharpe)
        return best.params

    def to_dict(self) -> Dict[str, Any]:
        """S√©rialise en dictionnaire."""
        return {
            "strategy_name": self.strategy_name,
            "created_at": self.created_at.isoformat(),
            "n_splits": self.n_splits,
            "train_ratio": self.train_ratio,
            "purge_gap": self.purge_gap,
            "overall_status": self.overall_status.value,
            "is_valid": self.is_valid,
            "aggregate_metrics": self.aggregate_metrics,
            "windows": [w.to_dict() for w in self.windows],
            "best_params": self.get_best_params(),
        }


# Couleurs par statut
STATUS_COLORS = {
    ValidationStatus.PASSED: "#4caf50",
    ValidationStatus.WARNING: "#ff9800",
    ValidationStatus.FAILED: "#f44336",
    ValidationStatus.OVERFITTING: "#9c27b0",
}

STATUS_ICONS = {
    ValidationStatus.PASSED: "‚úÖ",
    ValidationStatus.WARNING: "‚ö†Ô∏è",
    ValidationStatus.FAILED: "‚ùå",
    ValidationStatus.OVERFITTING: "üìà‚ùå",
}


def create_validation_figure(report: ValidationReport) -> go.Figure:
    """
    Cr√©e une figure Plotly du rapport de validation.

    Args:
        report: Rapport √† visualiser

    Returns:
        Figure Plotly
    """
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=(
            "Sharpe Ratio: Train vs Test",
            "Return: Train vs Test",
            "D√©gradation par fen√™tre",
            "Statut par fen√™tre",
        ),
        vertical_spacing=0.15,
        horizontal_spacing=0.1,
    )

    window_ids = [w.window_id for w in report.windows]

    # Sharpe comparison
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.train_sharpe for w in report.windows],
            name="Train Sharpe",
            marker_color="#2196f3",
            opacity=0.7,
        ),
        row=1,
        col=1,
    )
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.test_sharpe for w in report.windows],
            name="Test Sharpe",
            marker_color="#4caf50",
            opacity=0.7,
        ),
        row=1,
        col=1,
    )

    # Return comparison
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.train_return * 100 for w in report.windows],
            name="Train Return %",
            marker_color="#2196f3",
            opacity=0.7,
            showlegend=False,
        ),
        row=1,
        col=2,
    )
    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[w.test_return * 100 for w in report.windows],
            name="Test Return %",
            marker_color="#4caf50",
            opacity=0.7,
            showlegend=False,
        ),
        row=1,
        col=2,
    )

    # Degradation
    degradations = [w.sharpe_degradation * 100 for w in report.windows]
    colors = ["#f44336" if d > 50 else "#ff9800" if d > 30 else "#4caf50" for d in degradations]

    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=degradations,
            name="D√©gradation %",
            marker_color=colors,
        ),
        row=2,
        col=1,
    )

    # Ligne seuil 30%
    fig.add_hline(y=30, line_dash="dash", line_color="orange", row=2, col=1)
    fig.add_hline(y=50, line_dash="dash", line_color="red", row=2, col=1)

    # Status indicators
    status_values = []
    status_colors = []
    for w in report.windows:
        status = w.status
        status_values.append(list(ValidationStatus).index(status))
        status_colors.append(STATUS_COLORS[status])

    fig.add_trace(
        go.Bar(
            x=window_ids,
            y=[1] * len(window_ids),
            name="Statut",
            marker_color=status_colors,
            text=[STATUS_ICONS[w.status] for w in report.windows],
            textposition="inside",
        ),
        row=2,
        col=2,
    )

    # Styling
    fig.update_layout(
        height=600,
        template="plotly_dark",
        barmode="group",
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
    )

    fig.update_xaxes(title_text="Fen√™tre", row=2, col=1)
    fig.update_xaxes(title_text="Fen√™tre", row=2, col=2)
    fig.update_yaxes(title_text="Sharpe Ratio", row=1, col=1)
    fig.update_yaxes(title_text="Return (%)", row=1, col=2)
    fig.update_yaxes(title_text="D√©gradation (%)", row=2, col=1)

    return fig


def render_validation_report(
    report: ValidationReport,
    key: str = "validation_report",
) -> None:
    """
    Rendu Streamlit du rapport de validation.

    Args:
        report: Rapport √† afficher
        key: Cl√© unique pour les widgets
    """
    if not STREAMLIT_AVAILABLE:
        return

    # En-t√™te avec statut global
    status = report.overall_status
    status_color = STATUS_COLORS[status]
    status_icon = STATUS_ICONS[status]

    st.markdown(
        f"## {status_icon} Rapport de Validation - {report.strategy_name}"
    )

    # Badge statut
    st.markdown(
        f"<span style='background-color:{status_color};color:white;padding:5px 15px;"
        f"border-radius:15px;font-weight:bold'>{status.value.upper()}</span>",
        unsafe_allow_html=True,
    )

    st.caption(f"Cr√©√© le {report.created_at.strftime('%d/%m/%Y %H:%M')}")

    # M√©triques r√©sum√©
    st.markdown("### üìä M√©triques Globales")

    metrics = report.aggregate_metrics

    col1, col2, col3, col4 = st.columns(4)

    col1.metric(
        "Sharpe Train (moy)",
        f"{metrics.get('avg_train_sharpe', 0):.3f}",
    )
    col2.metric(
        "Sharpe Test (moy)",
        f"{metrics.get('avg_test_sharpe', 0):.3f}",
        delta=f"{-metrics.get('avg_degradation', 0):.1%}",
        delta_color="inverse",
    )
    col3.metric(
        "Consistance",
        f"{metrics.get('consistency_ratio', 0):.0%}",
    )
    col4.metric(
        "Fen√™tres Overfitting",
        f"{metrics.get('overfitting_windows', 0)}/{len(report.windows)}",
    )

    col1, col2, col3, col4 = st.columns(4)

    col1.metric(
        "Return Train (moy)",
        f"{metrics.get('avg_train_return', 0):.2%}",
    )
    col2.metric(
        "Return Test (moy)",
        f"{metrics.get('avg_test_return', 0):.2%}",
    )
    col3.metric(
        "D√©gradation Max",
        f"{metrics.get('max_degradation', 0):.1%}",
    )
    col4.metric(
        "√âcart-type Test",
        f"{metrics.get('std_test_sharpe', 0):.3f}",
    )

    # Graphique
    st.markdown("### üìà Visualisation")
    fig = create_validation_figure(report)
    st.plotly_chart(fig, width='stretch', key=f"{key}_chart")

    # D√©tails par fen√™tre
    st.markdown("### üîç D√©tails par Fen√™tre")

    # Tableau r√©capitulatif
    data = []
    for w in report.windows:
        data.append({
            "Fen√™tre": w.window_id,
            "Train": f"{w.train_start.date()} ‚Üí {w.train_end.date()}",
            "Test": f"{w.test_start.date()} ‚Üí {w.test_end.date()}",
            "Sharpe (T)": f"{w.train_sharpe:.3f}",
            "Sharpe (V)": f"{w.test_sharpe:.3f}",
            "D√©gr.": f"{w.sharpe_degradation:.1%}",
            "Statut": f"{STATUS_ICONS[w.status]} {w.status.value}",
        })

    st.dataframe(data, width='stretch')

    # D√©tails expandables
    for w in report.windows:
        status_icon = STATUS_ICONS[w.status]
        with st.expander(f"Fen√™tre {w.window_id} {status_icon}", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**üìà Train**")
                st.write(f"P√©riode: {w.train_start.date()} ‚Üí {w.train_end.date()}")
                st.write(f"Sharpe: {w.train_sharpe:.3f}")
                st.write(f"Return: {w.train_return:.2%}")
                st.write(f"Drawdown: {w.train_drawdown:.2%}")
                st.write(f"Trades: {w.train_trades}")

            with col2:
                st.markdown("**üß™ Test**")
                st.write(f"P√©riode: {w.test_start.date()} ‚Üí {w.test_end.date()}")
                st.write(f"Sharpe: {w.test_sharpe:.3f}")
                st.write(f"Return: {w.test_return:.2%}")
                st.write(f"Drawdown: {w.test_drawdown:.2%}")
                st.write(f"Trades: {w.test_trades}")

            if w.params:
                st.markdown("**üîß Param√®tres optimaux**")
                st.json(w.params)

    # Recommandation
    st.markdown("### üí° Recommandation")

    if report.overall_status == ValidationStatus.PASSED:
        st.success(
            "‚úÖ **Strat√©gie valid√©e** - Les performances sont consistantes entre "
            "l'entra√Ænement et le test. La strat√©gie peut √™tre utilis√©e en production."
        )
        best_params = report.get_best_params()
        if best_params:
            st.markdown("**Param√®tres recommand√©s:**")
            st.json(best_params)

    elif report.overall_status == ValidationStatus.WARNING:
        st.warning(
            "‚ö†Ô∏è **Attention** - D√©gradation significative entre train et test. "
            "Consid√©rez d'ajuster les param√®tres ou de r√©duire la complexit√©."
        )

    elif report.overall_status == ValidationStatus.OVERFITTING:
        st.error(
            "üìà‚ùå **Overfitting d√©tect√©** - Les performances train ne se g√©n√©ralisent pas "
            "sur les donn√©es de test. Simplifiez la strat√©gie ou utilisez moins de param√®tres."
        )

    else:
        st.error(
            "‚ùå **√âchec de validation** - La strat√©gie ne performe pas de mani√®re "
            "satisfaisante sur les donn√©es de test."
        )

    # Export
    with st.expander("üì• Export"):
        import json
        report_json = json.dumps(report.to_dict(), indent=2, default=str)

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "T√©l√©charger JSON",
                report_json,
                f"validation_{report.strategy_name}.json",
                "application/json",
                key=f"{key}_download",
            )
        with col2:
            if st.button("Afficher JSON", key=f"{key}_show_json"):
                st.code(report_json, language="json")


def render_validation_summary_card(
    report: ValidationReport,
    key: str = "validation_card",
) -> None:
    """
    Carte r√©sum√© compacte pour le dashboard.

    Args:
        report: Rapport √† afficher
        key: Cl√© unique
    """
    if not STREAMLIT_AVAILABLE:
        return

    status = report.overall_status
    status_color = STATUS_COLORS[status]
    status_icon = STATUS_ICONS[status]
    metrics = report.aggregate_metrics

    with st.container():
        st.markdown(
            f"<div style='border-left: 4px solid {status_color}; padding-left: 10px;'>"
            f"<strong>{status_icon} {report.strategy_name}</strong><br/>"
            f"<small>Sharpe Test: {metrics.get('avg_test_sharpe', 0):.3f} | "
            f"Consistance: {metrics.get('consistency_ratio', 0):.0%}</small>"
            f"</div>",
            unsafe_allow_html=True,
        )


def create_sample_report() -> ValidationReport:
    """Cr√©e un rapport exemple pour les tests."""
    import random
    from datetime import timedelta

    windows = []
    base_date = datetime(2024, 1, 1)

    for i in range(5):
        train_start = base_date + timedelta(days=i * 60)
        train_end = train_start + timedelta(days=180)
        test_start = train_end + timedelta(days=1)
        test_end = test_start + timedelta(days=45)

        train_sharpe = random.uniform(0.8, 2.5)
        degradation = random.uniform(0.1, 0.6)

        windows.append(WindowResult(
            window_id=i + 1,
            train_start=train_start,
            train_end=train_end,
            test_start=test_start,
            test_end=test_end,
            train_sharpe=train_sharpe,
            train_return=random.uniform(0.05, 0.25),
            train_drawdown=random.uniform(0.05, 0.15),
            train_trades=random.randint(50, 150),
            test_sharpe=train_sharpe * (1 - degradation),
            test_return=random.uniform(-0.02, 0.15),
            test_drawdown=random.uniform(0.05, 0.20),
            test_trades=random.randint(10, 40),
            params={"fast_period": 10 + i, "slow_period": 20 + i * 2},
        ))

    return ValidationReport(
        strategy_name="ema_cross",
        created_at=datetime.now(),
        windows=windows,
        n_splits=5,
        train_ratio=0.8,
    )
```
<!-- MODULE-END: validation_viewer.py -->

<!-- MODULE-START: colors.py -->
```json
{
  "name": "colors.py",
  "path": "ui\\theme\\colors.py",
  "ext": ".py",
  "anchor": "colors_py"
}
```
## colors_py
*Chemin* : `ui\theme\colors.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.theme.colors

Purpose: Syst√®me de couleurs centralis√© pour toute l'application.

Role in pipeline: configuration / theming

Key components: ColorPalette, ThemeMode, PALETTES, get_color(), ChartColors

Inputs: Nom de couleur, palette active

Outputs: Code couleur hex (#RRGGBB) ou rgba()

Dependencies: enum, dataclasses

Conventions: TOUTES les couleurs du projet doivent venir d'ici. Aucun hardcode ailleurs.

Read-if: Modification th√®mes, ajout palette, changement couleurs globales.

Skip-if: Vous appelez juste get_color("success").
"""

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum
from typing import Dict, Optional


# ============================================================================
# ENUMS
# ============================================================================

class ThemeMode(Enum):
    """Mode de th√®me global."""
    LIGHT = "light"
    DARK = "dark"
    AUTO = "auto"


class ColorPalette(Enum):
    """Palettes de couleurs disponibles."""
    DEFAULT = "default"
    OCEAN = "ocean"
    FOREST = "forest"
    SUNSET = "sunset"
    MONOCHROME = "monochrome"
    CYBERPUNK = "cyberpunk"
    TRADING = "trading"  # Nouvelle palette optimis√©e trading


# ============================================================================
# D√âFINITION DES PALETTES
# ============================================================================

PALETTES: Dict[ColorPalette, Dict[str, str]] = {
    ColorPalette.DEFAULT: {
        # Couleurs s√©mantiques
        "primary": "#2196f3",
        "secondary": "#ff9800",
        "success": "#4caf50",
        "warning": "#ff9800",
        "error": "#f44336",
        "info": "#00bcd4",

        # Arri√®re-plans
        "background": "#0e1117",
        "surface": "#1e2130",
        "surface_variant": "#262b3d",

        # Textes
        "text": "#fafafa",
        "text_primary": "#a8b2d1",
        "text_secondary": "#b0b0b0",
        "text_muted": "#6c7086",

        # Charts - Trading
        "chart_up": "#26a69a",
        "chart_down": "#ef5350",
        "candle_up": "#26a69a",
        "candle_down": "#ef5350",

        # Charts - Equity
        "equity_line": "#26a69a",
        "equity_fill": "rgba(38, 166, 154, 0.15)",
        "drawdown_line": "#ef5350",
        "drawdown_fill": "rgba(239, 83, 80, 0.3)",
        "capital_line": "rgba(200, 200, 200, 0.5)",

        # Charts - Trades
        "entry_long": "#42a5f5",
        "entry_short": "#ab47bc",
        "exit_profit": "#4caf50",
        "exit_loss": "#f44336",
        "stop_loss": "#ef5350",
        "take_profit": "#4caf50",

        # Charts - Indicateurs
        "bb_mid": "#ffa726",
        "bb_bands": "#42a5f5",
        "bb_bands_rgba": "rgba(66, 165, 245, 0.1)",
        "bb_entry_z": "rgba(255, 204, 128, 0.9)",
        "ema_fast": "#42a5f5",
        "ema_slow": "#ffb74d",
        "ema_center": "#42a5f5",
        "macd_line": "#26a69a",
        "macd_signal": "#ef5350",
        "rsi_line": "#42a5f5",
        "rsi_oversold": "#26a69a",
        "rsi_overbought": "#ef5350",
        "atr_line": "#ab47bc",
        "atr_threshold": "#ffa726",
        "atr_channel_upper": "#ef5350",
        "atr_channel_lower": "#26a69a",
        "stoch_k": "#42a5f5",
        "stoch_d": "#ffb74d",

        # Charts - Diagrammes strat√©gies
        "price_line": "#e0e0e0",
        "bollinger_low": "rgba(100, 160, 200, 0.6)",
        "bollinger_high": "rgba(100, 160, 200, 0.6)",
        "bollinger_fill": "rgba(100, 160, 200, 0.15)",
        "bollinger_mid": "rgba(140, 200, 255, 0.9)",
        "stop_long": "rgba(239, 83, 80, 0.7)",
        "stop_short": "rgba(239, 83, 80, 0.7)",
        "entry_level_long": "rgba(76, 175, 80, 0.9)",
        "entry_level_short": "rgba(171, 71, 188, 0.9)",
        "annotation_stop": "#ef9a9a",
        "annotation_tp": "#81c784",

        # UI - Grilles et bordures
        "grid_color": "rgba(128, 128, 128, 0.1)",
        "border": "rgba(128, 128, 128, 0.3)",
        "divider": "rgba(128, 128, 128, 0.2)",

        # Agents LLM
        "agent_analyst": "#42a5f5",
        "agent_strategist": "#4caf50",
        "agent_critic": "#ff9800",
        "agent_validator": "#ab47bc",
    },

    ColorPalette.OCEAN: {
        "primary": "#0077b6",
        "secondary": "#00b4d8",
        "success": "#06d6a0",
        "warning": "#ffd166",
        "error": "#ef476f",
        "info": "#118ab2",
        "background": "#03045e",
        "surface": "#023e8a",
        "surface_variant": "#0077b6",
        "text": "#caf0f8",
        "text_primary": "#caf0f8",
        "text_secondary": "#90e0ef",
        "text_muted": "#48cae4",
        "chart_up": "#06d6a0",
        "chart_down": "#ef476f",
        "candle_up": "#06d6a0",
        "candle_down": "#ef476f",
        "equity_line": "#06d6a0",
        "equity_fill": "rgba(6, 214, 160, 0.15)",
        "drawdown_line": "#ef476f",
        "drawdown_fill": "rgba(239, 71, 111, 0.3)",
        "capital_line": "rgba(144, 224, 239, 0.5)",
        "entry_long": "#00b4d8",
        "entry_short": "#7209b7",
        "exit_profit": "#06d6a0",
        "exit_loss": "#ef476f",
        "stop_loss": "#ef476f",
        "take_profit": "#06d6a0",
        "bb_mid": "#ffd166",
        "bb_bands": "#00b4d8",
        "bb_bands_rgba": "rgba(0, 180, 216, 0.1)",
        "bb_entry_z": "rgba(255, 209, 102, 0.9)",
        "ema_fast": "#00b4d8",
        "ema_slow": "#ffd166",
        "ema_center": "#00b4d8",
        "macd_line": "#06d6a0",
        "macd_signal": "#ef476f",
        "rsi_line": "#00b4d8",
        "rsi_oversold": "#06d6a0",
        "rsi_overbought": "#ef476f",
        "atr_line": "#7209b7",
        "atr_threshold": "#ffd166",
        "atr_channel_upper": "#ef476f",
        "atr_channel_lower": "#06d6a0",
        "stoch_k": "#00b4d8",
        "stoch_d": "#ffd166",
        "price_line": "#caf0f8",
        "bollinger_low": "rgba(0, 180, 216, 0.6)",
        "bollinger_high": "rgba(0, 180, 216, 0.6)",
        "bollinger_fill": "rgba(0, 180, 216, 0.15)",
        "bollinger_mid": "rgba(144, 224, 239, 0.9)",
        "stop_long": "rgba(239, 71, 111, 0.7)",
        "stop_short": "rgba(239, 71, 111, 0.7)",
        "entry_level_long": "rgba(6, 214, 160, 0.9)",
        "entry_level_short": "rgba(114, 9, 183, 0.9)",
        "annotation_stop": "#f8a5b8",
        "annotation_tp": "#7ddba3",
        "grid_color": "rgba(144, 224, 239, 0.1)",
        "border": "rgba(144, 224, 239, 0.3)",
        "divider": "rgba(144, 224, 239, 0.2)",
        "agent_analyst": "#00b4d8",
        "agent_strategist": "#06d6a0",
        "agent_critic": "#ffd166",
        "agent_validator": "#7209b7",
    },

    ColorPalette.FOREST: {
        "primary": "#2d6a4f",
        "secondary": "#40916c",
        "success": "#52b788",
        "warning": "#e9c46a",
        "error": "#e76f51",
        "info": "#74c69d",
        "background": "#1b4332",
        "surface": "#2d6a4f",
        "surface_variant": "#40916c",
        "text": "#d8f3dc",
        "text_primary": "#d8f3dc",
        "text_secondary": "#95d5b2",
        "text_muted": "#74c69d",
        "chart_up": "#52b788",
        "chart_down": "#e76f51",
        "candle_up": "#52b788",
        "candle_down": "#e76f51",
        "equity_line": "#52b788",
        "equity_fill": "rgba(82, 183, 136, 0.15)",
        "drawdown_line": "#e76f51",
        "drawdown_fill": "rgba(231, 111, 81, 0.3)",
        "capital_line": "rgba(149, 213, 178, 0.5)",
        "entry_long": "#74c69d",
        "entry_short": "#9b2226",
        "exit_profit": "#52b788",
        "exit_loss": "#e76f51",
        "stop_loss": "#e76f51",
        "take_profit": "#52b788",
        "bb_mid": "#e9c46a",
        "bb_bands": "#74c69d",
        "bb_bands_rgba": "rgba(116, 198, 157, 0.1)",
        "bb_entry_z": "rgba(233, 196, 106, 0.9)",
        "ema_fast": "#74c69d",
        "ema_slow": "#e9c46a",
        "ema_center": "#74c69d",
        "macd_line": "#52b788",
        "macd_signal": "#e76f51",
        "rsi_line": "#74c69d",
        "rsi_oversold": "#52b788",
        "rsi_overbought": "#e76f51",
        "atr_line": "#9b2226",
        "atr_threshold": "#e9c46a",
        "atr_channel_upper": "#e76f51",
        "atr_channel_lower": "#52b788",
        "stoch_k": "#74c69d",
        "stoch_d": "#e9c46a",
        "price_line": "#d8f3dc",
        "bollinger_low": "rgba(116, 198, 157, 0.6)",
        "bollinger_high": "rgba(116, 198, 157, 0.6)",
        "bollinger_fill": "rgba(116, 198, 157, 0.15)",
        "bollinger_mid": "rgba(149, 213, 178, 0.9)",
        "stop_long": "rgba(231, 111, 81, 0.7)",
        "stop_short": "rgba(231, 111, 81, 0.7)",
        "entry_level_long": "rgba(82, 183, 136, 0.9)",
        "entry_level_short": "rgba(155, 34, 38, 0.9)",
        "annotation_stop": "#f4a298",
        "annotation_tp": "#95d5b2",
        "grid_color": "rgba(149, 213, 178, 0.1)",
        "border": "rgba(149, 213, 178, 0.3)",
        "divider": "rgba(149, 213, 178, 0.2)",
        "agent_analyst": "#74c69d",
        "agent_strategist": "#52b788",
        "agent_critic": "#e9c46a",
        "agent_validator": "#9b2226",
    },

    ColorPalette.SUNSET: {
        "primary": "#ff6b6b",
        "secondary": "#feca57",
        "success": "#1dd1a1",
        "warning": "#feca57",
        "error": "#ee5a24",
        "info": "#54a0ff",
        "background": "#2c2c54",
        "surface": "#474787",
        "surface_variant": "#5a5a8f",
        "text": "#f5f6fa",
        "text_primary": "#f5f6fa",
        "text_secondary": "#dcdde1",
        "text_muted": "#a5a5c0",
        "chart_up": "#1dd1a1",
        "chart_down": "#ee5a24",
        "candle_up": "#1dd1a1",
        "candle_down": "#ee5a24",
        "equity_line": "#1dd1a1",
        "equity_fill": "rgba(29, 209, 161, 0.15)",
        "drawdown_line": "#ee5a24",
        "drawdown_fill": "rgba(238, 90, 36, 0.3)",
        "capital_line": "rgba(220, 221, 225, 0.5)",
        "entry_long": "#54a0ff",
        "entry_short": "#ff6b6b",
        "exit_profit": "#1dd1a1",
        "exit_loss": "#ee5a24",
        "stop_loss": "#ee5a24",
        "take_profit": "#1dd1a1",
        "bb_mid": "#feca57",
        "bb_bands": "#54a0ff",
        "bb_bands_rgba": "rgba(84, 160, 255, 0.1)",
        "bb_entry_z": "rgba(254, 202, 87, 0.9)",
        "ema_fast": "#54a0ff",
        "ema_slow": "#feca57",
        "ema_center": "#54a0ff",
        "macd_line": "#1dd1a1",
        "macd_signal": "#ee5a24",
        "rsi_line": "#54a0ff",
        "rsi_oversold": "#1dd1a1",
        "rsi_overbought": "#ee5a24",
        "atr_line": "#ff6b6b",
        "atr_threshold": "#feca57",
        "atr_channel_upper": "#ee5a24",
        "atr_channel_lower": "#1dd1a1",
        "stoch_k": "#54a0ff",
        "stoch_d": "#feca57",
        "price_line": "#f5f6fa",
        "bollinger_low": "rgba(84, 160, 255, 0.6)",
        "bollinger_high": "rgba(84, 160, 255, 0.6)",
        "bollinger_fill": "rgba(84, 160, 255, 0.15)",
        "bollinger_mid": "rgba(220, 221, 225, 0.9)",
        "stop_long": "rgba(238, 90, 36, 0.7)",
        "stop_short": "rgba(238, 90, 36, 0.7)",
        "entry_level_long": "rgba(29, 209, 161, 0.9)",
        "entry_level_short": "rgba(255, 107, 107, 0.9)",
        "annotation_stop": "#f8a5a5",
        "annotation_tp": "#7ee8c7",
        "grid_color": "rgba(220, 221, 225, 0.1)",
        "border": "rgba(220, 221, 225, 0.3)",
        "divider": "rgba(220, 221, 225, 0.2)",
        "agent_analyst": "#54a0ff",
        "agent_strategist": "#1dd1a1",
        "agent_critic": "#feca57",
        "agent_validator": "#ff6b6b",
    },

    ColorPalette.CYBERPUNK: {
        "primary": "#00ffff",
        "secondary": "#ff00ff",
        "success": "#00ff00",
        "warning": "#ffff00",
        "error": "#ff0000",
        "info": "#00ffff",
        "background": "#0a0a0a",
        "surface": "#1a1a2e",
        "surface_variant": "#16213e",
        "text": "#eaeaea",
        "text_primary": "#eaeaea",
        "text_secondary": "#00ffff",
        "text_muted": "#888888",
        "chart_up": "#00ff00",
        "chart_down": "#ff00ff",
        "candle_up": "#00ff00",
        "candle_down": "#ff00ff",
        "equity_line": "#00ff00",
        "equity_fill": "rgba(0, 255, 0, 0.15)",
        "drawdown_line": "#ff00ff",
        "drawdown_fill": "rgba(255, 0, 255, 0.3)",
        "capital_line": "rgba(0, 255, 255, 0.5)",
        "entry_long": "#00ffff",
        "entry_short": "#ff00ff",
        "exit_profit": "#00ff00",
        "exit_loss": "#ff0000",
        "stop_loss": "#ff0000",
        "take_profit": "#00ff00",
        "bb_mid": "#ffff00",
        "bb_bands": "#00ffff",
        "bb_bands_rgba": "rgba(0, 255, 255, 0.1)",
        "bb_entry_z": "rgba(255, 255, 0, 0.9)",
        "ema_fast": "#00ffff",
        "ema_slow": "#ffff00",
        "ema_center": "#00ffff",
        "macd_line": "#00ff00",
        "macd_signal": "#ff00ff",
        "rsi_line": "#00ffff",
        "rsi_oversold": "#00ff00",
        "rsi_overbought": "#ff0000",
        "atr_line": "#ff00ff",
        "atr_threshold": "#ffff00",
        "atr_channel_upper": "#ff0000",
        "atr_channel_lower": "#00ff00",
        "stoch_k": "#00ffff",
        "stoch_d": "#ffff00",
        "price_line": "#eaeaea",
        "bollinger_low": "rgba(0, 255, 255, 0.6)",
        "bollinger_high": "rgba(0, 255, 255, 0.6)",
        "bollinger_fill": "rgba(0, 255, 255, 0.15)",
        "bollinger_mid": "rgba(255, 255, 0, 0.9)",
        "stop_long": "rgba(255, 0, 0, 0.7)",
        "stop_short": "rgba(255, 0, 0, 0.7)",
        "entry_level_long": "rgba(0, 255, 0, 0.9)",
        "entry_level_short": "rgba(255, 0, 255, 0.9)",
        "annotation_stop": "#ff6666",
        "annotation_tp": "#66ff66",
        "grid_color": "rgba(0, 255, 255, 0.1)",
        "border": "rgba(0, 255, 255, 0.3)",
        "divider": "rgba(0, 255, 255, 0.2)",
        "agent_analyst": "#00ffff",
        "agent_strategist": "#00ff00",
        "agent_critic": "#ffff00",
        "agent_validator": "#ff00ff",
    },

    ColorPalette.MONOCHROME: {
        "primary": "#888888",
        "secondary": "#666666",
        "success": "#a0a0a0",
        "warning": "#c0c0c0",
        "error": "#505050",
        "info": "#707070",
        "background": "#1a1a1a",
        "surface": "#2a2a2a",
        "surface_variant": "#3a3a3a",
        "text": "#e0e0e0",
        "text_primary": "#e0e0e0",
        "text_secondary": "#909090",
        "text_muted": "#606060",
        "chart_up": "#a0a0a0",
        "chart_down": "#505050",
        "candle_up": "#a0a0a0",
        "candle_down": "#505050",
        "equity_line": "#a0a0a0",
        "equity_fill": "rgba(160, 160, 160, 0.15)",
        "drawdown_line": "#505050",
        "drawdown_fill": "rgba(80, 80, 80, 0.3)",
        "capital_line": "rgba(144, 144, 144, 0.5)",
        "entry_long": "#888888",
        "entry_short": "#666666",
        "exit_profit": "#a0a0a0",
        "exit_loss": "#505050",
        "stop_loss": "#505050",
        "take_profit": "#a0a0a0",
        "bb_mid": "#c0c0c0",
        "bb_bands": "#888888",
        "bb_bands_rgba": "rgba(136, 136, 136, 0.1)",
        "bb_entry_z": "rgba(192, 192, 192, 0.9)",
        "ema_fast": "#888888",
        "ema_slow": "#c0c0c0",
        "ema_center": "#888888",
        "macd_line": "#a0a0a0",
        "macd_signal": "#505050",
        "rsi_line": "#888888",
        "rsi_oversold": "#a0a0a0",
        "rsi_overbought": "#505050",
        "atr_line": "#666666",
        "atr_threshold": "#c0c0c0",
        "atr_channel_upper": "#505050",
        "atr_channel_lower": "#a0a0a0",
        "stoch_k": "#888888",
        "stoch_d": "#c0c0c0",
        "price_line": "#e0e0e0",
        "bollinger_low": "rgba(136, 136, 136, 0.6)",
        "bollinger_high": "rgba(136, 136, 136, 0.6)",
        "bollinger_fill": "rgba(136, 136, 136, 0.15)",
        "bollinger_mid": "rgba(192, 192, 192, 0.9)",
        "stop_long": "rgba(80, 80, 80, 0.7)",
        "stop_short": "rgba(80, 80, 80, 0.7)",
        "entry_level_long": "rgba(160, 160, 160, 0.9)",
        "entry_level_short": "rgba(102, 102, 102, 0.9)",
        "annotation_stop": "#808080",
        "annotation_tp": "#b0b0b0",
        "grid_color": "rgba(144, 144, 144, 0.1)",
        "border": "rgba(144, 144, 144, 0.3)",
        "divider": "rgba(144, 144, 144, 0.2)",
        "agent_analyst": "#888888",
        "agent_strategist": "#a0a0a0",
        "agent_critic": "#c0c0c0",
        "agent_validator": "#666666",
    },

    ColorPalette.TRADING: {
        # Palette optimis√©e pour le trading avec contrastes forts
        "primary": "#2196f3",
        "secondary": "#ff9800",
        "success": "#00e676",  # Vert vif profits
        "warning": "#ffab00",
        "error": "#ff5252",    # Rouge vif pertes
        "info": "#40c4ff",
        "background": "#0d1117",
        "surface": "#161b22",
        "surface_variant": "#21262d",
        "text": "#f0f6fc",
        "text_primary": "#c9d1d9",
        "text_secondary": "#8b949e",
        "text_muted": "#6e7681",
        "chart_up": "#00e676",
        "chart_down": "#ff5252",
        "candle_up": "#00e676",
        "candle_down": "#ff5252",
        "equity_line": "#00e676",
        "equity_fill": "rgba(0, 230, 118, 0.1)",
        "drawdown_line": "#ff5252",
        "drawdown_fill": "rgba(255, 82, 82, 0.2)",
        "capital_line": "rgba(201, 209, 217, 0.4)",
        "entry_long": "#40c4ff",
        "entry_short": "#e040fb",
        "exit_profit": "#00e676",
        "exit_loss": "#ff5252",
        "stop_loss": "#ff5252",
        "take_profit": "#00e676",
        "bb_mid": "#ffab00",
        "bb_bands": "#40c4ff",
        "bb_bands_rgba": "rgba(64, 196, 255, 0.1)",
        "bb_entry_z": "rgba(255, 171, 0, 0.9)",
        "ema_fast": "#40c4ff",
        "ema_slow": "#ffab00",
        "ema_center": "#40c4ff",
        "macd_line": "#00e676",
        "macd_signal": "#ff5252",
        "rsi_line": "#40c4ff",
        "rsi_oversold": "#00e676",
        "rsi_overbought": "#ff5252",
        "atr_line": "#e040fb",
        "atr_threshold": "#ffab00",
        "atr_channel_upper": "#ff5252",
        "atr_channel_lower": "#00e676",
        "stoch_k": "#40c4ff",
        "stoch_d": "#ffab00",
        "price_line": "#c9d1d9",
        "bollinger_low": "rgba(64, 196, 255, 0.6)",
        "bollinger_high": "rgba(64, 196, 255, 0.6)",
        "bollinger_fill": "rgba(64, 196, 255, 0.1)",
        "bollinger_mid": "rgba(255, 171, 0, 0.9)",
        "stop_long": "rgba(255, 82, 82, 0.7)",
        "stop_short": "rgba(255, 82, 82, 0.7)",
        "entry_level_long": "rgba(0, 230, 118, 0.9)",
        "entry_level_short": "rgba(224, 64, 251, 0.9)",
        "annotation_stop": "#ff8a80",
        "annotation_tp": "#69f0ae",
        "grid_color": "rgba(139, 148, 158, 0.1)",
        "border": "rgba(139, 148, 158, 0.3)",
        "divider": "rgba(139, 148, 158, 0.2)",
        "agent_analyst": "#40c4ff",
        "agent_strategist": "#00e676",
        "agent_critic": "#ffab00",
        "agent_validator": "#e040fb",
    },
}


# ============================================================================
# √âTAT GLOBAL ET GETTERS
# ============================================================================

# Palette active par d√©faut
_active_palette: ColorPalette = ColorPalette.TRADING
_theme_mode: ThemeMode = ThemeMode.DARK


def set_palette(palette: ColorPalette) -> None:
    """Change la palette active."""
    global _active_palette
    _active_palette = palette


def get_palette() -> ColorPalette:
    """Retourne la palette active."""
    return _active_palette


def set_theme_mode(mode: ThemeMode) -> None:
    """Change le mode de th√®me."""
    global _theme_mode
    _theme_mode = mode


def get_theme_mode() -> ThemeMode:
    """Retourne le mode de th√®me actif."""
    return _theme_mode


def get_color(
    name: str,
    palette: Optional[ColorPalette] = None,
    fallback: str = "#888888"
) -> str:
    """
    R√©cup√®re une couleur par son nom.

    Args:
        name: Nom de la couleur (ex: "success", "chart_up", "equity_line")
        palette: Palette √† utiliser (None = palette active)
        fallback: Couleur de fallback si non trouv√©e

    Returns:
        Code couleur hex ou rgba
    """
    p = palette or _active_palette
    colors = PALETTES.get(p, PALETTES[ColorPalette.DEFAULT])
    return colors.get(name, fallback)


def get_colors(palette: Optional[ColorPalette] = None) -> Dict[str, str]:
    """
    Retourne toutes les couleurs d'une palette.

    Args:
        palette: Palette √† utiliser (None = palette active)

    Returns:
        Dictionnaire complet des couleurs
    """
    p = palette or _active_palette
    return PALETTES.get(p, PALETTES[ColorPalette.DEFAULT]).copy()


def get_palette_names() -> list[str]:
    """Retourne la liste des noms de palettes disponibles."""
    return [p.value for p in ColorPalette]


# ============================================================================
# HELPERS SP√âCIALIS√âS
# ============================================================================

def get_profit_color(pnl: float, palette: Optional[ColorPalette] = None) -> str:
    """Retourne la couleur appropri√©e pour un PnL (profit/perte)."""
    return get_color("success" if pnl >= 0 else "error", palette)


def get_trade_color(
    side: str,
    action: str,
    pnl: Optional[float] = None,
    palette: Optional[ColorPalette] = None
) -> str:
    """
    Retourne la couleur pour un trade.

    Args:
        side: "LONG" ou "SHORT"
        action: "entry" ou "exit"
        pnl: PnL pour les exits (d√©termine profit/loss)
        palette: Palette √† utiliser
    """
    if action == "entry":
        return get_color("entry_long" if side == "LONG" else "entry_short", palette)
    else:
        if pnl is not None:
            return get_color("exit_profit" if pnl >= 0 else "exit_loss", palette)
        return get_color("text_secondary", palette)


def get_agent_color(agent_role: str, palette: Optional[ColorPalette] = None) -> str:
    """Retourne la couleur pour un agent LLM."""
    role_map = {
        "analyst": "agent_analyst",
        "strategist": "agent_strategist",
        "critic": "agent_critic",
        "validator": "agent_validator",
    }
    color_key = role_map.get(agent_role.lower(), "primary")
    return get_color(color_key, palette)


# ============================================================================
# DATACLASS POUR CONFIGURATION CHARTS
# ============================================================================

@dataclass
class ChartColorConfig:
    """Configuration compl√®te des couleurs pour un graphique."""

    # R√©cup√©r√©es depuis la palette active
    candle_up: str = ""
    candle_down: str = ""
    equity_line: str = ""
    equity_fill: str = ""
    drawdown_line: str = ""
    drawdown_fill: str = ""
    entry_long: str = ""
    entry_short: str = ""
    exit_profit: str = ""
    exit_loss: str = ""
    grid_color: str = ""
    text_primary: str = ""
    background: str = ""

    @classmethod
    def from_palette(cls, palette: Optional[ColorPalette] = None) -> "ChartColorConfig":
        """Cr√©e une config depuis une palette."""
        return cls(
            candle_up=get_color("candle_up", palette),
            candle_down=get_color("candle_down", palette),
            equity_line=get_color("equity_line", palette),
            equity_fill=get_color("equity_fill", palette),
            drawdown_line=get_color("drawdown_line", palette),
            drawdown_fill=get_color("drawdown_fill", palette),
            entry_long=get_color("entry_long", palette),
            entry_short=get_color("entry_short", palette),
            exit_profit=get_color("exit_profit", palette),
            exit_loss=get_color("exit_loss", palette),
            grid_color=get_color("grid_color", palette),
            text_primary=get_color("text_primary", palette),
            background=get_color("background", palette),
        )


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    # Enums
    "ThemeMode",
    "ColorPalette",
    # Data
    "PALETTES",
    # Setters/Getters
    "set_palette",
    "get_palette",
    "set_theme_mode",
    "get_theme_mode",
    "get_color",
    "get_colors",
    "get_palette_names",
    # Helpers
    "get_profit_color",
    "get_trade_color",
    "get_agent_color",
    # Dataclass
    "ChartColorConfig",
]
```
<!-- MODULE-END: colors.py -->

<!-- MODULE-START: plotly_config.py -->
```json
{
  "name": "plotly_config.py",
  "path": "ui\\theme\\plotly_config.py",
  "ext": ".py",
  "anchor": "plotly_config_py"
}
```
## plotly_config_py
*Chemin* : `ui\theme\plotly_config.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.theme.plotly_config

Purpose: Configuration Plotly centralis√©e - layouts, grilles, fonts, th√®mes.

Role in pipeline: visualization config

Key components: get_layout_config(), apply_dark_theme(), CHART_CONFIG

Inputs: Param√®tres de graphique (height, title, etc.)

Outputs: Dicts de configuration Plotly

Dependencies: ui.theme.colors

Conventions: Tout graphique Plotly doit utiliser ces configs pour coh√©rence.

Read-if: Modification layouts globaux, ajout templates.

Skip-if: Vous appelez juste get_layout_config().
"""

from __future__ import annotations

from typing import Any, Dict, Optional

import plotly.graph_objects as go

from .colors import get_color, get_colors, get_palette, ColorPalette


# ============================================================================
# CONFIGURATION GLOBALE PLOTLY
# ============================================================================

# Config par d√©faut pour st.plotly_chart
PLOTLY_CHART_CONFIG: Dict[str, Any] = {
    "scrollZoom": True,
    "displayModeBar": True,
    "modeBarButtonsToRemove": ["lasso2d", "select2d"],
    "displaylogo": False,
}

# Seuil pour activer le resampler (si install√©)
RESAMPLER_THRESHOLD = 100_000


# ============================================================================
# LAYOUT CONFIGS
# ============================================================================

def get_layout_config(
    height: int = 520,
    title: Optional[str] = None,
    show_legend: bool = True,
    palette: Optional[ColorPalette] = None,
) -> Dict[str, Any]:
    """
    Retourne la configuration de layout Plotly standard.

    Args:
        height: Hauteur du graphique
        title: Titre optionnel
        show_legend: Afficher la l√©gende
        palette: Palette de couleurs

    Returns:
        Dict de configuration pour fig.update_layout()
    """
    colors = get_colors(palette)

    config = {
        "height": height,
        "template": "plotly_dark",
        "plot_bgcolor": "rgba(0,0,0,0)",
        "paper_bgcolor": "rgba(0,0,0,0)",
        "font": {
            "color": colors.get("text_primary", "#a8b2d1"),
            "size": 11,
            "family": "Inter, -apple-system, BlinkMacSystemFont, sans-serif",
        },
        "hovermode": "x unified",
        "margin": {"l": 50, "r": 50, "t": 50, "b": 50},
        "legend": {
            "orientation": "h",
            "yanchor": "bottom",
            "y": 1.02,
            "xanchor": "right",
            "x": 1,
            "bgcolor": "rgba(0,0,0,0.3)",
            "bordercolor": colors.get("border", "rgba(128,128,128,0.3)"),
            "borderwidth": 1,
        },
        "showlegend": show_legend,
    }

    if title:
        config["title"] = {
            "text": title,
            "font": {"size": 14, "color": colors.get("text", "#fafafa")},
            "x": 0.5,
            "xanchor": "center",
        }

    return config


def get_axis_config(
    title: Optional[str] = None,
    show_grid: bool = True,
    palette: Optional[ColorPalette] = None,
) -> Dict[str, Any]:
    """
    Retourne la configuration d'axe Plotly.

    Args:
        title: Titre de l'axe
        show_grid: Afficher la grille
        palette: Palette de couleurs

    Returns:
        Dict de configuration pour xaxis/yaxis
    """
    grid_color = get_color("grid_color", palette)
    text_color = get_color("text_secondary", palette)

    config = {
        "showgrid": show_grid,
        "gridcolor": grid_color if show_grid else "rgba(0,0,0,0)",
        "zeroline": False,
        "tickfont": {"color": text_color, "size": 10},
    }

    if title:
        config["title"] = {
            "text": title,
            "font": {"color": text_color, "size": 11},
        }

    return config


def get_colorscale_diverging(palette: Optional[ColorPalette] = None) -> list:
    """
    Retourne une √©chelle de couleurs divergente (rouge-blanc-vert).
    Utilis√© pour heatmaps PnL.
    """
    down = get_color("chart_down", palette)
    up = get_color("chart_up", palette)

    return [
        [0.0, down],
        [0.5, "rgba(255,255,255,0.1)"],
        [1.0, up],
    ]


def get_colorscale_sequential(
    color_key: str = "primary",
    palette: Optional[ColorPalette] = None
) -> list:
    """Retourne une √©chelle de couleurs s√©quentielle."""
    base = get_color(color_key, palette)
    return [
        [0.0, "rgba(0,0,0,0)"],
        [1.0, base],
    ]


# ============================================================================
# APPLICATION DE TH√àME
# ============================================================================

def apply_dark_theme(fig: go.Figure, palette: Optional[ColorPalette] = None) -> None:
    """
    Applique le th√®me dark √† une figure Plotly.

    Args:
        fig: Figure Plotly √† modifier
        palette: Palette de couleurs
    """
    colors = get_colors(palette)

    fig.update_layout(
        template="plotly_dark",
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
        font=dict(color=colors.get("text_primary", "#a8b2d1")),
    )

    grid_color = colors.get("grid_color", "rgba(128,128,128,0.1)")
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(gridcolor=grid_color)


def apply_chart_layout(
    fig: go.Figure,
    height: int = 520,
    y_title: Optional[str] = None,
    x_title: Optional[str] = None,
    palette: Optional[ColorPalette] = None,
) -> None:
    """
    Applique le layout complet √† une figure.

    Args:
        fig: Figure Plotly
        height: Hauteur
        y_title: Titre axe Y
        x_title: Titre axe X
        palette: Palette
    """
    layout = get_layout_config(height=height, palette=palette)
    fig.update_layout(**layout)

    if y_title:
        fig.update_yaxes(**get_axis_config(title=y_title, palette=palette))
    else:
        fig.update_yaxes(**get_axis_config(palette=palette))

    if x_title:
        fig.update_xaxes(**get_axis_config(title=x_title, show_grid=False, palette=palette))
    else:
        fig.update_xaxes(showgrid=False)


def apply_axis_interaction(fig: go.Figure, lock_x: bool = False) -> None:
    """
    Configure les interactions de zoom/pan sur les axes.

    Args:
        fig: Figure Plotly
        lock_x: Verrouiller l'axe X (pour comparaisons)
    """
    if lock_x:
        fig.update_xaxes(fixedrange=True)
    fig.update_yaxes(fixedrange=False)


# ============================================================================
# CANDLESTICK CONFIG
# ============================================================================

def get_candlestick_colors(palette: Optional[ColorPalette] = None) -> Dict[str, str]:
    """Retourne les couleurs pour candlesticks."""
    return {
        "increasing_line_color": get_color("candle_up", palette),
        "decreasing_line_color": get_color("candle_down", palette),
        "increasing_fillcolor": get_color("candle_up", palette),
        "decreasing_fillcolor": get_color("candle_down", palette),
    }


def get_volume_colors(palette: Optional[ColorPalette] = None) -> Dict[str, str]:
    """Retourne les couleurs pour barres de volume."""
    return {
        "up": get_color("candle_up", palette),
        "down": get_color("candle_down", palette),
    }


# ============================================================================
# TRADE MARKERS CONFIG
# ============================================================================

def get_entry_marker_config(
    side: str = "LONG",
    palette: Optional[ColorPalette] = None
) -> Dict[str, Any]:
    """
    Retourne la configuration de marqueur d'entr√©e.

    Args:
        side: "LONG" ou "SHORT"
        palette: Palette

    Returns:
        Dict pour marker=dict(...)
    """
    color = get_color("entry_long" if side == "LONG" else "entry_short", palette)
    return {
        "symbol": "triangle-up" if side == "LONG" else "triangle-down",
        "size": 10,
        "color": color,
        "line": {"width": 1, "color": "white"},
    }


def get_exit_marker_config(
    pnl: float,
    palette: Optional[ColorPalette] = None
) -> Dict[str, Any]:
    """
    Retourne la configuration de marqueur de sortie.

    Args:
        pnl: Profit/Loss du trade
        palette: Palette

    Returns:
        Dict pour marker=dict(...)
    """
    color = get_color("exit_profit" if pnl >= 0 else "exit_loss", palette)
    return {
        "symbol": "triangle-down",
        "size": 10,
        "color": color,
        "line": {"width": 1, "color": "white"},
    }


# ============================================================================
# INDICATOR LINE CONFIG
# ============================================================================

def get_indicator_line_config(
    indicator: str,
    palette: Optional[ColorPalette] = None
) -> Dict[str, Any]:
    """
    Retourne la configuration de ligne pour un indicateur.

    Args:
        indicator: Nom de l'indicateur (bb_mid, ema_fast, etc.)
        palette: Palette

    Returns:
        Dict pour line=dict(...)
    """
    color = get_color(indicator, palette)

    # Styles par d√©faut selon le type
    width = 1.4
    dash = None

    if "mid" in indicator or "center" in indicator:
        width = 1.5
    elif "upper" in indicator or "lower" in indicator:
        dash = "dash"
        width = 1.2
    elif "threshold" in indicator:
        dash = "dot"
        width = 1.0

    config = {"color": color, "width": width}
    if dash:
        config["dash"] = dash

    return config


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    # Config globale
    "PLOTLY_CHART_CONFIG",
    "RESAMPLER_THRESHOLD",
    # Layout
    "get_layout_config",
    "get_axis_config",
    "get_colorscale_diverging",
    "get_colorscale_sequential",
    # Application
    "apply_dark_theme",
    "apply_chart_layout",
    "apply_axis_interaction",
    # Candlesticks
    "get_candlestick_colors",
    "get_volume_colors",
    # Trade markers
    "get_entry_marker_config",
    "get_exit_marker_config",
    # Indicators
    "get_indicator_line_config",
]
```
<!-- MODULE-END: plotly_config.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "ui\\theme\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `ui\theme\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: ui.theme

Purpose: Syst√®me de th√®me centralis√© pour toute l'application.

Role in pipeline: UI theming

Key components: colors, plotly_config

Usage:
    from ui.theme import get_color, get_layout_config, ColorPalette

    # Couleur simple
    color = get_color("primary")

    # Couleur avec palette sp√©cifique
    color = get_color("chart_up", ColorPalette.TRADING)

    # Layout Plotly
    layout = get_layout_config(height=500)

    # Config candlestick
    candle_colors = get_candlestick_colors()

Dependencies: Aucune externe

Conventions:
    - Utiliser get_color() pour toute couleur
    - Utiliser get_layout_config() pour tout layout Plotly
    - Ne JAMAIS hardcoder de couleurs
"""

from .colors import (
    # Enums
    ThemeMode,
    ColorPalette,
    # Fonctions principales
    get_color,
    get_colors,
    get_palette,
    set_palette,
    get_palette_names,
    set_theme_mode,
    get_theme_mode,
    # Helpers
    get_profit_color,
    get_trade_color,
    get_agent_color,
    # Dataclass
    ChartColorConfig,
    # Constantes
    PALETTES,
)

from .plotly_config import (
    # Config globale
    PLOTLY_CHART_CONFIG,
    RESAMPLER_THRESHOLD,
    # Layout
    get_layout_config,
    get_axis_config,
    get_colorscale_diverging,
    get_colorscale_sequential,
    # Application
    apply_dark_theme,
    apply_chart_layout,
    apply_axis_interaction,
    # Candlesticks
    get_candlestick_colors,
    get_volume_colors,
    # Trade markers
    get_entry_marker_config,
    get_exit_marker_config,
    # Indicators
    get_indicator_line_config,
)


__all__ = [
    # === colors.py ===
    # Enums
    "ThemeMode",
    "ColorPalette",
    # Fonctions principales
    "get_color",
    "get_colors",
    "get_palette",
    "set_palette",
    "get_palette_names",
    "set_theme_mode",
    "get_theme_mode",
    # Helpers
    "get_profit_color",
    "get_trade_color",
    "get_agent_color",
    # Dataclass
    "ChartColorConfig",
    # Constantes
    "PALETTES",

    # === plotly_config.py ===
    # Config globale
    "PLOTLY_CHART_CONFIG",
    "RESAMPLER_THRESHOLD",
    # Layout
    "get_layout_config",
    "get_axis_config",
    "get_colorscale_diverging",
    "get_colorscale_sequential",
    # Application
    "apply_dark_theme",
    "apply_chart_layout",
    "apply_axis_interaction",
    # Candlesticks
    "get_candlestick_colors",
    "get_volume_colors",
    # Trade markers
    "get_entry_marker_config",
    "get_exit_marker_config",
    # Indicators
    "get_indicator_line_config",
]
```
<!-- MODULE-END: __init__.py -->

<!-- MODULE-START: checkpoint.py -->
```json
{
  "name": "checkpoint.py",
  "path": "utils\\checkpoint.py",
  "ext": ".py",
  "anchor": "checkpoint_py"
}
```
## checkpoint_py
*Chemin* : `utils\checkpoint.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.checkpoint

Purpose: Gestionnaire de checkpoints pour sauvegarde/reprise automatique d'op√©rations longues (sweeps, optimisations).

Role in pipeline: resilience / state management

Key components: CheckpointManager, CheckpointMetadata, checkpoint_context (context manager)

Inputs: operation_type (str), state (dict), checkpoint_dir (Path optionnel)

Outputs: Fichiers JSON checkpoint (state + metadata), resume capability apr√®s crash/interruption

Dependencies: json, pathlib, dataclasses, utils.log, hashlib

Conventions: Checkpoints JSON pour portabilit√©/lisibilit√©; checkpoint_id unique (hash params); progress 0.0-1.0; auto-save p√©riodique; resume transparente via checkpoint_context(); nettoyage automatique anciens checkpoints.

Read-if: Gestion checkpoints pour sweeps, recovery apr√®s crash, ou state persistence long-running ops.

Skip-if: Op√©rations courtes sans besoin de resume/recovery.
"""

import hashlib
import json
import time
from contextlib import contextmanager
from dataclasses import asdict, dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, TypeVar

from utils.log import get_logger

logger = get_logger(__name__)

T = TypeVar('T')


@dataclass
class CheckpointMetadata:
    """
    M√©tadonn√©es d'un checkpoint.

    Attributes:
        checkpoint_id: Identifiant unique
        created_at: Timestamp cr√©ation
        operation_type: Type d'op√©ration (sweep, validation, etc.)
        progress: Progression (0.0 √† 1.0)
        total_items: Nombre total d'√©l√©ments
        completed_items: √âl√©ments termin√©s
        status: 'running', 'paused', 'completed', 'failed'
    """
    checkpoint_id: str
    created_at: str
    operation_type: str
    progress: float = 0.0
    total_items: int = 0
    completed_items: int = 0
    status: str = "running"
    last_updated: Optional[str] = None
    error_message: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "CheckpointMetadata":
        """Cr√©e depuis un dictionnaire."""
        return cls(**data)


@dataclass
class Checkpoint:
    """
    Point de sauvegarde complet.

    Attributes:
        metadata: M√©tadonn√©es du checkpoint
        state: √âtat √† sauvegarder (dict arbitraire)
        results: R√©sultats partiels accumul√©s
    """
    metadata: CheckpointMetadata
    state: Dict[str, Any] = field(default_factory=dict)
    results: List[Dict[str, Any]] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "metadata": self.metadata.to_dict(),
            "state": self.state,
            "results": self.results,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Checkpoint":
        """Cr√©e depuis un dictionnaire."""
        return cls(
            metadata=CheckpointMetadata.from_dict(data["metadata"]),
            state=data.get("state", {}),
            results=data.get("results", []),
        )

    def add_result(self, result: Dict[str, Any]):
        """Ajoute un r√©sultat."""
        self.results.append(result)
        self.metadata.completed_items = len(self.results)
        if self.metadata.total_items > 0:
            self.metadata.progress = len(self.results) / self.metadata.total_items
        self.metadata.last_updated = datetime.now().isoformat()


class CheckpointManager:
    """
    Gestionnaire de checkpoints pour op√©rations longues.

    Example:
        >>> manager = CheckpointManager("./checkpoints")
        >>>
        >>> # Cr√©er un nouveau checkpoint
        >>> checkpoint = manager.create("sweep", total_items=100)
        >>>
        >>> # Boucle avec sauvegarde p√©riodique
        >>> for i, params in enumerate(param_grid):
        ...     result = run_backtest(params)
        ...     checkpoint.add_result({"params": params, "score": result})
        ...
        ...     if i % 10 == 0:
        ...         manager.save(checkpoint)
        >>>
        >>> # Marquer comme termin√©
        >>> manager.complete(checkpoint)
    """

    def __init__(
        self,
        checkpoint_dir: str = ".checkpoints",
        auto_save_interval: int = 10,
        max_checkpoints: int = 5,
    ):
        """
        Initialise le gestionnaire.

        Args:
            checkpoint_dir: R√©pertoire de stockage
            auto_save_interval: Intervalle de sauvegarde auto (en items)
            max_checkpoints: Nombre max de checkpoints √† conserver
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.auto_save_interval = auto_save_interval
        self.max_checkpoints = max_checkpoints

        # Cr√©er le r√©pertoire si n√©cessaire
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

        logger.debug(f"CheckpointManager initialis√©: {self.checkpoint_dir}")

    def _generate_id(self, operation_type: str) -> str:
        """G√©n√®re un ID unique pour le checkpoint."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        hash_part = hashlib.md5(
            f"{operation_type}_{time.time()}".encode()
        ).hexdigest()[:8]
        return f"{operation_type}_{timestamp}_{hash_part}"

    def _get_checkpoint_path(self, checkpoint_id: str) -> Path:
        """Retourne le chemin du fichier checkpoint."""
        return self.checkpoint_dir / f"{checkpoint_id}.json"

    def create(
        self,
        operation_type: str,
        total_items: int = 0,
        initial_state: Optional[Dict[str, Any]] = None,
    ) -> Checkpoint:
        """
        Cr√©e un nouveau checkpoint.

        Args:
            operation_type: Type d'op√©ration (ex: "sweep", "validation")
            total_items: Nombre total d'√©l√©ments √† traiter
            initial_state: √âtat initial optionnel

        Returns:
            Nouveau Checkpoint
        """
        checkpoint_id = self._generate_id(operation_type)

        metadata = CheckpointMetadata(
            checkpoint_id=checkpoint_id,
            created_at=datetime.now().isoformat(),
            operation_type=operation_type,
            total_items=total_items,
            status="running",
        )

        checkpoint = Checkpoint(
            metadata=metadata,
            state=initial_state or {},
            results=[],
        )

        # Sauvegarde initiale
        self.save(checkpoint)

        logger.info(f"Checkpoint cr√©√©: {checkpoint_id}")

        return checkpoint

    def save(self, checkpoint: Checkpoint):
        """
        Sauvegarde un checkpoint.

        Args:
            checkpoint: Checkpoint √† sauvegarder
        """
        checkpoint.metadata.last_updated = datetime.now().isoformat()

        path = self._get_checkpoint_path(checkpoint.metadata.checkpoint_id)

        with open(path, 'w', encoding='utf-8') as f:
            json.dump(checkpoint.to_dict(), f, indent=2, ensure_ascii=False)

        logger.debug(
            f"Checkpoint sauvegard√©: {checkpoint.metadata.checkpoint_id} "
            f"({checkpoint.metadata.completed_items}/{checkpoint.metadata.total_items})"
        )

        # Nettoyer les vieux checkpoints
        self._cleanup_old_checkpoints(checkpoint.metadata.operation_type)

    def load(self, checkpoint_id: str) -> Optional[Checkpoint]:
        """
        Charge un checkpoint existant.

        Args:
            checkpoint_id: ID du checkpoint

        Returns:
            Checkpoint charg√© ou None si non trouv√©
        """
        path = self._get_checkpoint_path(checkpoint_id)

        if not path.exists():
            logger.warning(f"Checkpoint non trouv√©: {checkpoint_id}")
            return None

        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            checkpoint = Checkpoint.from_dict(data)
            logger.info(
                f"Checkpoint charg√©: {checkpoint_id} "
                f"(progress: {checkpoint.metadata.progress:.1%})"
            )
            return checkpoint

        except Exception as e:
            logger.error(f"Erreur chargement checkpoint: {e}")
            return None

    def find_latest(self, operation_type: str) -> Optional[Checkpoint]:
        """
        Trouve le checkpoint le plus r√©cent pour un type d'op√©ration.

        Args:
            operation_type: Type d'op√©ration

        Returns:
            Checkpoint le plus r√©cent ou None
        """
        checkpoints = self.list_checkpoints(operation_type)

        if not checkpoints:
            return None

        # Trier par date de cr√©ation
        checkpoints.sort(key=lambda c: c.metadata.created_at, reverse=True)

        return checkpoints[0]

    def find_incomplete(self, operation_type: str) -> Optional[Checkpoint]:
        """
        Trouve un checkpoint incomplet pour reprise.

        Args:
            operation_type: Type d'op√©ration

        Returns:
            Checkpoint incomplet le plus r√©cent ou None
        """
        checkpoints = self.list_checkpoints(operation_type)

        # Filtrer les incomplets
        incomplete = [
            c for c in checkpoints
            if c.metadata.status in ("running", "paused")
        ]

        if not incomplete:
            return None

        # Trier par date
        incomplete.sort(key=lambda c: c.metadata.created_at, reverse=True)

        return incomplete[0]

    def list_checkpoints(
        self,
        operation_type: Optional[str] = None
    ) -> List[Checkpoint]:
        """
        Liste tous les checkpoints.

        Args:
            operation_type: Filtrer par type (optionnel)

        Returns:
            Liste des checkpoints
        """
        checkpoints = []

        for path in self.checkpoint_dir.glob("*.json"):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                checkpoint = Checkpoint.from_dict(data)

                if operation_type is None or \
                   checkpoint.metadata.operation_type == operation_type:
                    checkpoints.append(checkpoint)

            except Exception as e:
                logger.warning(f"Erreur lecture {path}: {e}")

        return checkpoints

    def complete(self, checkpoint: Checkpoint):
        """
        Marque un checkpoint comme termin√©.

        Args:
            checkpoint: Checkpoint √† marquer
        """
        checkpoint.metadata.status = "completed"
        checkpoint.metadata.progress = 1.0
        self.save(checkpoint)
        logger.info(f"Checkpoint termin√©: {checkpoint.metadata.checkpoint_id}")

    def fail(self, checkpoint: Checkpoint, error: str):
        """
        Marque un checkpoint comme √©chou√©.

        Args:
            checkpoint: Checkpoint
            error: Message d'erreur
        """
        checkpoint.metadata.status = "failed"
        checkpoint.metadata.error_message = error
        self.save(checkpoint)
        logger.error(f"Checkpoint √©chou√©: {checkpoint.metadata.checkpoint_id}")

    def pause(self, checkpoint: Checkpoint):
        """
        Met en pause un checkpoint.

        Args:
            checkpoint: Checkpoint √† mettre en pause
        """
        checkpoint.metadata.status = "paused"
        self.save(checkpoint)
        logger.info(f"Checkpoint en pause: {checkpoint.metadata.checkpoint_id}")

    def delete(self, checkpoint_id: str):
        """
        Supprime un checkpoint.

        Args:
            checkpoint_id: ID du checkpoint
        """
        path = self._get_checkpoint_path(checkpoint_id)

        if path.exists():
            path.unlink()
            logger.info(f"Checkpoint supprim√©: {checkpoint_id}")

    def _cleanup_old_checkpoints(self, operation_type: str):
        """
        Nettoie les vieux checkpoints pour √©conomiser l'espace.

        Garde seulement les max_checkpoints plus r√©cents par type.
        """
        checkpoints = self.list_checkpoints(operation_type)

        # Trier par date (plus r√©cent en premier)
        checkpoints.sort(key=lambda c: c.metadata.created_at, reverse=True)

        # Supprimer les exc√©dentaires
        for checkpoint in checkpoints[self.max_checkpoints:]:
            if checkpoint.metadata.status == "completed":
                self.delete(checkpoint.metadata.checkpoint_id)

    @contextmanager
    def checkpoint_context(
        self,
        operation_type: str,
        total_items: int,
        resume: bool = True,
    ):
        """
        Context manager pour checkpoint automatique.

        Args:
            operation_type: Type d'op√©ration
            total_items: Nombre total d'√©l√©ments
            resume: Tenter de reprendre un checkpoint existant

        Yields:
            Tuple (checkpoint, start_index)
        """
        # Essayer de reprendre
        checkpoint = None
        start_index = 0

        if resume:
            checkpoint = self.find_incomplete(operation_type)
            if checkpoint:
                start_index = checkpoint.metadata.completed_items
                checkpoint.metadata.status = "running"
                logger.info(
                    f"Reprise checkpoint: {checkpoint.metadata.checkpoint_id} "
                    f"√† l'index {start_index}"
                )

        # Cr√©er nouveau si pas de reprise
        if checkpoint is None:
            checkpoint = self.create(operation_type, total_items)

        try:
            yield checkpoint, start_index
            self.complete(checkpoint)
        except KeyboardInterrupt:
            self.pause(checkpoint)
            raise
        except Exception as e:
            self.fail(checkpoint, str(e))
            raise


# Singleton global
_default_manager: Optional[CheckpointManager] = None


def get_checkpoint_manager(
    checkpoint_dir: str = ".checkpoints"
) -> CheckpointManager:
    """
    R√©cup√®re le gestionnaire de checkpoints global.

    Args:
        checkpoint_dir: R√©pertoire de stockage

    Returns:
        CheckpointManager singleton
    """
    global _default_manager

    if _default_manager is None:
        _default_manager = CheckpointManager(checkpoint_dir)

    return _default_manager
```
<!-- MODULE-END: checkpoint.py -->

<!-- MODULE-START: circuit_breaker.py -->
```json
{
  "name": "circuit_breaker.py",
  "path": "utils\\circuit_breaker.py",
  "ext": ".py",
  "anchor": "circuit_breaker_py"
}
```
## circuit_breaker_py
*Chemin* : `utils\circuit_breaker.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.circuit_breaker

Purpose: Circuit Breaker - protection contre cascades d'erreurs r√©p√©t√©es.

Role in pipeline: resilience

Key components: CircuitBreaker, CircuitBreakerState, CircuitBreakerError

Inputs: √âchecs threshold, success threshold, timeout

Outputs: Autorisation/blocage appels, notifications √©tat

Dependencies: threading, time, dataclasses, Enum

Conventions: √âtats CLOSED/OPEN/HALF_OPEN; exponential backoff; async-safe avec locks.

Read-if: Modification seuils d'erreur/succ√®s, timeouts.

Skip-if: Vous utilisez juste CircuitBreaker.call().
"""

import threading
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from functools import wraps
from typing import Any, Callable, Dict, List, Optional, Type

from utils.log import get_logger

logger = get_logger(__name__)


class CircuitState(Enum):
    """√âtats possibles du circuit breaker."""
    CLOSED = "closed"      # Normal, appels autoris√©s
    OPEN = "open"          # Bloqu√©, appels refus√©s
    HALF_OPEN = "half_open"  # Test de r√©cup√©ration


class CircuitBreakerError(Exception):
    """Exception lev√©e quand le circuit est ouvert."""

    def __init__(self, breaker_name: str, message: str = ""):
        self.breaker_name = breaker_name
        super().__init__(
            f"Circuit '{breaker_name}' est OUVERT. {message}"
        )


@dataclass
class CircuitStats:
    """
    Statistiques du circuit breaker.

    Attributes:
        total_calls: Nombre total d'appels
        successful_calls: Appels r√©ussis
        failed_calls: Appels √©chou√©s
        rejected_calls: Appels refus√©s (circuit ouvert)
        last_failure_time: Timestamp dernier √©chec
        last_success_time: Timestamp dernier succ√®s
        consecutive_failures: √âchecs cons√©cutifs actuels
        state_changes: Historique des changements d'√©tat
    """
    total_calls: int = 0
    successful_calls: int = 0
    failed_calls: int = 0
    rejected_calls: int = 0
    last_failure_time: Optional[datetime] = None
    last_success_time: Optional[datetime] = None
    consecutive_failures: int = 0
    state_changes: List[Dict[str, Any]] = field(default_factory=list)

    @property
    def success_rate(self) -> float:
        """Taux de succ√®s."""
        if self.total_calls == 0:
            return 1.0
        return self.successful_calls / self.total_calls

    @property
    def failure_rate(self) -> float:
        """Taux d'√©chec."""
        if self.total_calls == 0:
            return 0.0
        return self.failed_calls / self.total_calls

    def record_success(self):
        """Enregistre un succ√®s."""
        self.total_calls += 1
        self.successful_calls += 1
        self.last_success_time = datetime.now()
        self.consecutive_failures = 0

    def record_failure(self):
        """Enregistre un √©chec."""
        self.total_calls += 1
        self.failed_calls += 1
        self.last_failure_time = datetime.now()
        self.consecutive_failures += 1

    def record_rejection(self):
        """Enregistre un rejet (circuit ouvert)."""
        self.rejected_calls += 1

    def record_state_change(self, from_state: CircuitState, to_state: CircuitState):
        """Enregistre un changement d'√©tat."""
        self.state_changes.append({
            "timestamp": datetime.now().isoformat(),
            "from": from_state.value,
            "to": to_state.value,
        })

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "total_calls": self.total_calls,
            "successful_calls": self.successful_calls,
            "failed_calls": self.failed_calls,
            "rejected_calls": self.rejected_calls,
            "success_rate": round(self.success_rate, 4),
            "failure_rate": round(self.failure_rate, 4),
            "consecutive_failures": self.consecutive_failures,
            "last_failure": (
                self.last_failure_time.isoformat()
                if self.last_failure_time else None
            ),
            "last_success": (
                self.last_success_time.isoformat()
                if self.last_success_time else None
            ),
            "state_changes": len(self.state_changes),
        }


class CircuitBreaker:
    """
    Circuit Breaker pour prot√©ger les appels √† des composants externes.

    Example:
        >>> breaker = CircuitBreaker("backtest", failure_threshold=3)
        >>>
        >>> @breaker
        >>> def run_backtest(params):
        ...     return engine.run(params)
        >>>
        >>> # Ou manuellement:
        >>> with breaker:
        ...     result = engine.run(params)
    """

    def __init__(
        self,
        name: str,
        failure_threshold: int = 5,
        recovery_timeout: float = 30.0,
        half_open_max_calls: int = 1,
        excluded_exceptions: Optional[List[Type[Exception]]] = None,
    ):
        """
        Initialise le circuit breaker.

        Args:
            name: Nom du circuit (pour logging)
            failure_threshold: Nombre d'√©checs avant ouverture
            recovery_timeout: Secondes avant tentative de r√©cup√©ration
            half_open_max_calls: Appels autoris√©s en half-open
            excluded_exceptions: Exceptions qui ne comptent pas comme √©chec
        """
        self.name = name
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_max_calls = half_open_max_calls
        self.excluded_exceptions = excluded_exceptions or []

        self._state = CircuitState.CLOSED
        self._stats = CircuitStats()
        self._opened_at: Optional[float] = None
        self._half_open_calls = 0
        self._lock = threading.RLock()

        logger.debug(f"CircuitBreaker '{name}' cr√©√© (threshold={failure_threshold})")

    @property
    def state(self) -> CircuitState:
        """√âtat actuel du circuit."""
        with self._lock:
            self._check_state_transition()
            return self._state

    @property
    def stats(self) -> CircuitStats:
        """Statistiques du circuit."""
        return self._stats

    @property
    def is_closed(self) -> bool:
        """True si le circuit est ferm√© (normal)."""
        return self.state == CircuitState.CLOSED

    @property
    def is_open(self) -> bool:
        """True si le circuit est ouvert (bloqu√©)."""
        return self.state == CircuitState.OPEN

    def _check_state_transition(self):
        """V√©rifie si une transition d'√©tat est n√©cessaire."""
        if self._state == CircuitState.OPEN and self._opened_at:
            elapsed = time.time() - self._opened_at
            if elapsed >= self.recovery_timeout:
                self._transition_to(CircuitState.HALF_OPEN)

    def _transition_to(self, new_state: CircuitState):
        """Effectue une transition d'√©tat."""
        if self._state == new_state:
            return

        old_state = self._state
        self._state = new_state
        self._stats.record_state_change(old_state, new_state)

        if new_state == CircuitState.OPEN:
            self._opened_at = time.time()
            logger.warning(
                f"CircuitBreaker '{self.name}' OUVERT "
                f"(√©checs cons√©cutifs: {self._stats.consecutive_failures})"
            )
        elif new_state == CircuitState.HALF_OPEN:
            self._half_open_calls = 0
            logger.info(f"CircuitBreaker '{self.name}' en HALF_OPEN (test r√©cup√©ration)")
        elif new_state == CircuitState.CLOSED:
            self._opened_at = None
            logger.info(f"CircuitBreaker '{self.name}' FERM√â (r√©cup√©ration r√©ussie)")

    def _handle_success(self):
        """G√®re un appel r√©ussi."""
        with self._lock:
            self._stats.record_success()

            if self._state == CircuitState.HALF_OPEN:
                self._transition_to(CircuitState.CLOSED)

    def _handle_failure(self, exc: Exception):
        """G√®re un appel √©chou√©."""
        # V√©rifier si l'exception est exclue
        if any(isinstance(exc, e) for e in self.excluded_exceptions):
            return

        with self._lock:
            self._stats.record_failure()

            if self._state == CircuitState.HALF_OPEN:
                # Retour imm√©diat √† OPEN
                self._transition_to(CircuitState.OPEN)
            elif self._state == CircuitState.CLOSED:
                if self._stats.consecutive_failures >= self.failure_threshold:
                    self._transition_to(CircuitState.OPEN)

    def _can_execute(self) -> bool:
        """V√©rifie si un appel peut √™tre ex√©cut√©."""
        with self._lock:
            self._check_state_transition()

            if self._state == CircuitState.CLOSED:
                return True
            elif self._state == CircuitState.OPEN:
                self._stats.record_rejection()
                return False
            elif self._state == CircuitState.HALF_OPEN:
                if self._half_open_calls < self.half_open_max_calls:
                    self._half_open_calls += 1
                    return True
                self._stats.record_rejection()
                return False
        return False

    def call(self, func: Callable, *args, **kwargs) -> Any:
        """
        Ex√©cute une fonction √† travers le circuit breaker.

        Args:
            func: Fonction √† ex√©cuter
            *args, **kwargs: Arguments de la fonction

        Returns:
            R√©sultat de la fonction

        Raises:
            CircuitBreakerError: Si le circuit est ouvert
        """
        if not self._can_execute():
            raise CircuitBreakerError(
                self.name,
                f"R√©essayez dans {self.recovery_timeout}s"
            )

        try:
            result = func(*args, **kwargs)
            self._handle_success()
            return result
        except Exception as e:
            self._handle_failure(e)
            raise

    def __call__(self, func: Callable) -> Callable:
        """
        D√©corateur pour prot√©ger une fonction.

        Example:
            >>> @breaker
            >>> def my_function():
            ...     pass
        """
        @wraps(func)
        def wrapper(*args, **kwargs):
            return self.call(func, *args, **kwargs)
        return wrapper

    def __enter__(self):
        """Context manager - v√©rifie si ex√©cution autoris√©e."""
        if not self._can_execute():
            raise CircuitBreakerError(self.name)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager - enregistre succ√®s/√©chec."""
        if exc_type is None:
            self._handle_success()
        else:
            if exc_val is not None:
                self._handle_failure(exc_val)
        return False  # Ne pas supprimer l'exception

    def reset(self):
        """R√©initialise le circuit breaker."""
        with self._lock:
            self._transition_to(CircuitState.CLOSED)
            self._stats = CircuitStats()
            self._opened_at = None
            self._half_open_calls = 0
            logger.info(f"CircuitBreaker '{self.name}' r√©initialis√©")

    def force_open(self):
        """Force l'ouverture du circuit (maintenance)."""
        with self._lock:
            self._transition_to(CircuitState.OPEN)

    def force_close(self):
        """Force la fermeture du circuit."""
        with self._lock:
            self._transition_to(CircuitState.CLOSED)


class CircuitBreakerRegistry:
    """
    Registre central des circuit breakers.

    Permet de g√©rer plusieurs circuits et d'obtenir des stats globales.
    """

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._breakers: Dict[str, CircuitBreaker] = {}
        return cls._instance

    def get_or_create(
        self,
        name: str,
        **kwargs
    ) -> CircuitBreaker:
        """
        R√©cup√®re ou cr√©e un circuit breaker.

        Args:
            name: Nom du circuit
            **kwargs: Arguments pour CircuitBreaker si cr√©ation

        Returns:
            CircuitBreaker existant ou nouveau
        """
        if name not in self._breakers:
            self._breakers[name] = CircuitBreaker(name, **kwargs)
        return self._breakers[name]

    def get(self, name: str) -> Optional[CircuitBreaker]:
        """R√©cup√®re un circuit breaker par son nom."""
        return self._breakers.get(name)

    def list_all(self) -> List[str]:
        """Liste tous les circuits enregistr√©s."""
        return list(self._breakers.keys())

    def get_all_stats(self) -> Dict[str, Dict[str, Any]]:
        """R√©cup√®re les stats de tous les circuits."""
        return {
            name: {
                "state": breaker.state.value,
                **breaker.stats.to_dict()
            }
            for name, breaker in self._breakers.items()
        }

    def reset_all(self):
        """R√©initialise tous les circuits."""
        for breaker in self._breakers.values():
            breaker.reset()

    def clear(self):
        """Supprime tous les circuits (pour tests)."""
        self._breakers.clear()


# Singleton global
_registry = CircuitBreakerRegistry()


def get_circuit_breaker(name: str, **kwargs) -> CircuitBreaker:
    """
    Raccourci pour r√©cup√©rer/cr√©er un circuit breaker.

    Args:
        name: Nom du circuit
        **kwargs: Arguments pour CircuitBreaker

    Returns:
        CircuitBreaker
    """
    return _registry.get_or_create(name, **kwargs)


def circuit_breaker(
    name: str,
    failure_threshold: int = 5,
    recovery_timeout: float = 30.0,
    **kwargs
) -> Callable:
    """
    D√©corateur pour prot√©ger une fonction avec un circuit breaker.

    Example:
        >>> @circuit_breaker("backtest", failure_threshold=3)
        >>> def run_backtest(params):
        ...     return engine.run(params)
    """
    breaker = get_circuit_breaker(
        name,
        failure_threshold=failure_threshold,
        recovery_timeout=recovery_timeout,
        **kwargs
    )
    return breaker
```
<!-- MODULE-END: circuit_breaker.py -->

<!-- MODULE-START: config.py -->
```json
{
  "name": "config.py",
  "path": "utils\\config.py",
  "ext": ".py",
  "anchor": "config_py"
}
```
## config_py
*Chemin* : `utils\config.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.config

Purpose: Configuration centralis√©e du moteur (data_dir, frais, slippage, etc.).

Role in pipeline: core

Key components: Config (dataclass), singleton pattern, env var override

Inputs: Fichier config, variables d'environnement

Outputs: Config dict accessible globalement

Dependencies: dataclasses, pathlib, json

Conventions: BPS pour frais/slippage; data_dir obligatoire; env vars override config file.

Read-if: Modification params config, defaults, ou env var parsing.

Skip-if: Vous appelez juste Config.get_instance().
"""

import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional


@dataclass
class Config:
    """
    Configuration globale du moteur de backtest.

    Attributes:
        data_dir: R√©pertoire des donn√©es OHLCV
        initial_capital: Capital de d√©part
        default_leverage: Levier par d√©faut
        fees_bps: Frais en points de base (10 = 0.1%)
        slippage_bps: Slippage en points de base
        seed: Seed pour reproductibilit√©
    """

    # Chemins
    data_dir: Path = field(default_factory=lambda: Path(r"D:\ThreadX_big\data\crypto\processed\parquet"))
    # Mod√®les LLM: configur√©s via D:\models\models.json (voir utils.model_loader)

    # Capital & Trading
    initial_capital: float = 10_000.0
    default_leverage: float = 1.0
    fees_bps: float = 10.0  # 0.1%
    slippage_bps: float = 5.0  # 0.05%

    # D√©terminisme
    seed: int = 42

    # Granularit√© des param√®tres (pour limiter les combinaisons)
    granularity: float = 0.5  # 0=fin, 1=grossier
    max_values_per_param: int = 4  # Plafond combinatoire

    # M√©ta
    _instance: Optional["Config"] = field(default=None, repr=False)

    @classmethod
    def get_instance(cls) -> "Config":
        """Singleton pour configuration globale."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    @classmethod
    def from_file(cls, path: Path) -> "Config":
        """Charge la configuration depuis un fichier JSON."""
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return cls(**data)

    def to_dict(self) -> dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "data_dir": str(self.data_dir),
            "initial_capital": self.initial_capital,
            "default_leverage": self.default_leverage,
            "fees_bps": self.fees_bps,
            "slippage_bps": self.slippage_bps,
            "seed": self.seed,
            "granularity": self.granularity,
            "max_values_per_param": self.max_values_per_param,
        }

    def save(self, path: Path) -> None:
        """Sauvegarde la configuration dans un fichier JSON."""
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.to_dict(), f, indent=2)


# Configuration par d√©faut des Safe Ranges (inspir√© de ThreadX)
SAFE_RANGES_PRESET = {
    "bollinger": {
        "period": {"min": 10, "max": 50, "default": 20},
        "std_dev": {"min": 1.5, "max": 3.0, "default": 2.0}
    },
    "atr": {
        "period": {"min": 7, "max": 21, "default": 14}
    },
    "rsi": {
        "period": {"min": 7, "max": 21, "default": 14},
        "overbought": {"min": 65, "max": 80, "default": 70},
        "oversold": {"min": 20, "max": 35, "default": 30}
    },
    "ema": {
        "fast_period": {"min": 5, "max": 20, "default": 12},
        "slow_period": {"min": 15, "max": 50, "default": 26}
    },
    "strategy": {
        "entry_z": {"min": 1.5, "max": 3.0, "default": 2.0},
        "k_sl": {"min": 1.0, "max": 3.0, "default": 1.5},
        "leverage": {"min": 1, "max": 10, "default": 3}
    }
}


def parameter_values(
    min_val: float,
    max_val: float,
    granularity: float = 0.5,
    max_values: int = 4,
) -> list[float]:
    """
    G√©n√®re les valeurs de param√®tre selon la granularit√©.

    Logique inspir√©e de ThreadX pour limiter l'explosion combinatoire:
    - granularity=0: maximum de valeurs (finesse maximale)
    - granularity=1: une seule valeur m√©diane
    - max_values: plafond absolu (d√©faut=4)

    Args:
        min_val: Valeur minimale
        max_val: Valeur maximale
        granularity: Coefficient de granularit√© [0, 1]
        max_values: Nombre maximum de valeurs retourn√©es

    Returns:
        Liste de valeurs √©chantillonn√©es
    """
    import numpy as np

    if min_val >= max_val:
        return [min_val]

    # Nombre de valeurs souhait√© (inversement proportionnel √† granularity)
    base_steps = max(2, int(10 * (1 - granularity)))

    # R√©duire si plage √©troite (<5% de variation)
    range_pct = (max_val - min_val) / max(abs(min_val), 1e-10)
    if range_pct < 0.05:
        base_steps = max(2, int(base_steps * 0.3))

    # Appliquer le plafond
    n_values = min(base_steps, max_values)

    # G√©n√©rer les valeurs
    if n_values <= 1:
        return [(min_val + max_val) / 2]

    values = np.linspace(min_val, max_val, n_values)
    return [round(v, 4) for v in values]


__all__ = ["Config", "SAFE_RANGES_PRESET", "parameter_values"]
```
<!-- MODULE-END: config.py -->

<!-- MODULE-START: config_validator.py -->
```json
{
  "name": "config_validator.py",
  "path": "utils\\config_validator.py",
  "ext": ".py",
  "anchor": "config_validator_py"
}
```
## config_validator_py
*Chemin* : `utils\config_validator.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.config_validator

Purpose: Valider les param√®tres de configuration contre les contraintes d√©finies dans indicator_ranges.toml

Role in pipeline: validation

Key components: validate_params, load_constraints, check_constraint

Inputs: Param√®tres dict, nom de cat√©gorie (ex: "ema_cross")

Outputs: Tuple (bool, list[str]) - (valide, liste_erreurs)

Dependencies: tomli (Python 3.11+) ou tomllib, pathlib

Conventions: Utilise eval() de mani√®re s√©curis√©e avec namespace restreint.

Read-if: Validation de param√®tres avant backtest/optimisation

Skip-if: Vous ne faites que lire les configs sans les valider
"""

import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple

# Python 3.11+ a tomllib built-in, sinon utiliser tomli
if sys.version_info >= (3, 11):
    import tomllib
else:
    try:
        import tomli as tomllib
    except ImportError:
        raise ImportError(
            "Python < 3.11 n√©cessite 'tomli'. Installez avec: pip install tomli"
        )

from utils.log import get_logger

logger = get_logger(__name__)

# Cache global pour √©viter de recharger le fichier TOML √† chaque validation
_CONSTRAINTS_CACHE: Dict[str, List[str]] = {}


def load_constraints(config_path: Path = None) -> Dict[str, List[str]]:
    """
    Charge les contraintes depuis indicator_ranges.toml.

    Args:
        config_path: Chemin optionnel vers le fichier TOML.
                     Par d√©faut: config/indicator_ranges.toml

    Returns:
        Dict mapping category -> list of constraint expressions

    Example:
        >>> constraints = load_constraints()
        >>> constraints["ema_cross"]
        ["fast_period < slow_period"]
    """
    global _CONSTRAINTS_CACHE

    if _CONSTRAINTS_CACHE:
        return _CONSTRAINTS_CACHE

    if config_path is None:
        # D√©tecter le r√©pertoire racine du projet
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent  # utils/ -> backtest_core/
        config_path = project_root / "config" / "indicator_ranges.toml"

    if not config_path.exists():
        logger.warning(f"Fichier de contraintes introuvable: {config_path}")
        return {}

    with open(config_path, "rb") as f:
        config = tomllib.load(f)

    constraints = config.get("constraints", {})
    _CONSTRAINTS_CACHE = constraints

    logger.info(
        f"Contraintes charg√©es: {len(constraints)} cat√©gories depuis {config_path}"
    )
    return constraints


def check_constraint(
    expression: str, params: Dict[str, Any], safe_namespace: Dict[str, Any] = None
) -> Tuple[bool, str]:
    """
    √âvalue une expression de contrainte de mani√®re s√©curis√©e.

    Args:
        expression: Expression Python (ex: "fast_period < slow_period")
        params: Dictionnaire des param√®tres avec leurs valeurs
        safe_namespace: Namespace optionnel pour eval (s√©curit√©)

    Returns:
        (is_valid, error_message)

    Example:
        >>> params = {"fast_period": 12, "slow_period": 26}
        >>> check_constraint("fast_period < slow_period", params)
        (True, "")
    """
    if safe_namespace is None:
        # Namespace s√©curis√©: seulement les op√©rateurs de comparaison
        safe_namespace = {
            "__builtins__": {},
            # Op√©rateurs autoris√©s (pas de fonction dangereuse)
        }

    # Merger les param√®tres dans le namespace
    eval_namespace = {**safe_namespace, **params}

    try:
        result = eval(expression, eval_namespace)
        if not isinstance(result, bool):
            logger.warning(
                f"Contrainte non bool√©enne: '{expression}' -> {result} (type: {type(result)})"
            )
            return False, f"Expression non bool√©enne: {expression}"

        if not result:
            return False, f"Contrainte viol√©e: {expression}"

        return True, ""

    except NameError as e:
        # Param√®tre manquant dans params (peut-√™tre optionnel)
        missing_param = str(e).split("'")[1] if "'" in str(e) else "unknown"
        logger.debug(
            f"Param√®tre manquant pour contrainte '{expression}': {missing_param}"
        )
        return True, ""  # On consid√®re valide si param√®tre optionnel manquant

    except Exception as e:
        logger.error(f"Erreur lors de l'√©valuation de '{expression}': {e}")
        return False, f"Erreur √©valuation: {expression} -> {e}"


def validate_params(
    category: str, params: Dict[str, Any], config_path: Path = None
) -> Tuple[bool, List[str]]:
    """
    Valide les param√®tres d'une cat√©gorie contre ses contraintes.

    Args:
        category: Nom de la cat√©gorie (ex: "ema_cross", "rsi", "macd")
        params: Dictionnaire des param√®tres avec leurs valeurs
        config_path: Chemin optionnel vers indicator_ranges.toml

    Returns:
        (is_valid, list_of_errors)

    Example:
        >>> params = {"fast_period": 50, "slow_period": 26}  # INVALIDE!
        >>> is_valid, errors = validate_params("ema_cross", params)
        >>> print(is_valid, errors)
        False ['Contrainte viol√©e: fast_period < slow_period']

        >>> params = {"fast_period": 12, "slow_period": 26}  # VALIDE
        >>> is_valid, errors = validate_params("ema_cross", params)
        >>> print(is_valid, errors)
        True []
    """
    constraints = load_constraints(config_path)

    if category not in constraints:
        logger.debug(f"Aucune contrainte d√©finie pour la cat√©gorie: {category}")
        return True, []

    constraint_rules = constraints[category]
    errors = []

    for rule in constraint_rules:
        is_valid, error_msg = check_constraint(rule, params)
        if not is_valid and error_msg:
            errors.append(error_msg)

    is_valid = len(errors) == 0

    if not is_valid:
        logger.warning(
            f"Validation √©chou√©e pour {category}: {len(errors)} contrainte(s) viol√©e(s)"
        )
        for error in errors:
            logger.warning(f"  - {error}")

    return is_valid, errors


def validate_preset(preset_dict: Dict[str, Any]) -> Tuple[bool, List[str]]:
    """
    Valide un preset complet (depuis profitable_presets.toml).

    Args:
        preset_dict: Dict contenant 'strategy' et 'params'

    Returns:
        (is_valid, list_of_errors)

    Example:
        >>> preset = {
        ...     "strategy": "ema_cross",
        ...     "params": {"fast_period": 15, "slow_period": 50}
        ... }
        >>> is_valid, errors = validate_preset(preset)
        >>> print(is_valid)
        True
    """
    if "strategy" not in preset_dict:
        return False, ["Cl√© 'strategy' manquante dans le preset"]

    strategy = preset_dict["strategy"]
    params = preset_dict.get("params", {})

    return validate_params(strategy, params)


# ==========================================================================
# TESTS UNITAIRES (ex√©cutables avec: python -m utils.config_validator)
# ==========================================================================

if __name__ == "__main__":
    print("=== Tests de validation de contraintes ===\n")

    # Test 1: EMA Cross valide
    print("Test 1: EMA Cross valide")
    params = {"fast_period": 15, "slow_period": 50}
    is_valid, errors = validate_params("ema_cross", params)
    assert is_valid, f"Devrait √™tre valide: {errors}"
    print(f"‚úÖ PASS: {params} -> valide\n")

    # Test 2: EMA Cross invalide (fast > slow)
    print("Test 2: EMA Cross invalide")
    params = {"fast_period": 50, "slow_period": 26}
    is_valid, errors = validate_params("ema_cross", params)
    assert not is_valid, "Devrait √™tre invalide"
    print(f"‚úÖ PASS: {params} -> invalide ({errors})\n")

    # Test 3: RSI valide
    print("Test 3: RSI valide")
    params = {"oversold": 30, "overbought": 70}
    is_valid, errors = validate_params("rsi", params)
    assert is_valid, f"Devrait √™tre valide: {errors}"
    print(f"‚úÖ PASS: {params} -> valide\n")

    # Test 4: RSI invalide (oversold > overbought)
    print("Test 4: RSI invalide")
    params = {"oversold": 70, "overbought": 30}
    is_valid, errors = validate_params("rsi", params)
    assert not is_valid, "Devrait √™tre invalide"
    print(f"‚úÖ PASS: {params} -> invalide ({errors})\n")

    # Test 5: MACD valide
    print("Test 5: MACD valide")
    params = {"fast_period": 12, "slow_period": 26, "signal_period": 9}
    is_valid, errors = validate_params("macd", params)
    assert is_valid, f"Devrait √™tre valide: {errors}"
    print(f"‚úÖ PASS: {params} -> valide\n")

    # Test 6: MACD invalide (fast >= slow)
    print("Test 6: MACD invalide")
    params = {"fast_period": 26, "slow_period": 12, "signal_period": 9}
    is_valid, errors = validate_params("macd", params)
    assert not is_valid, "Devrait √™tre invalide"
    print(f"‚úÖ PASS: {params} -> invalide ({errors})\n")

    # Test 7: Preset complet
    print("Test 7: Validation preset complet")
    preset = {
        "strategy": "rsi_reversal",
        "params": {"rsi_period": 14, "overbought": 70, "oversold": 30},
    }
    is_valid, errors = validate_preset(preset)
    assert is_valid, f"Devrait √™tre valide: {errors}"
    print(f"‚úÖ PASS: Preset rsi_reversal -> valide\n")

    # Test 8: Cat√©gorie sans contraintes
    print("Test 8: Cat√©gorie sans contraintes (bollinger)")
    params = {"period": 20, "std_dev": 2.0}
    is_valid, errors = validate_params("bollinger", params)
    assert is_valid, "Devrait √™tre valide (aucune contrainte)"
    print(f"‚úÖ PASS: bollinger sans contraintes -> valide\n")

    print("=== üéâ Tous les tests passent! ===")
```
<!-- MODULE-END: config_validator.py -->

<!-- MODULE-START: data.py -->
```json
{
  "name": "data.py",
  "path": "utils\\data.py",
  "ext": ".py",
  "anchor": "data_py"
}
```
## data_py
*Chemin* : `utils\data.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.data

Purpose: Utilitaires analyse/validation donn√©es OHLCV (d√©tection gaps, stats).

Role in pipeline: data quality

Key components: detect_gaps(), DataFrame validators

Inputs: pandas DataFrame avec DatetimeIndex OHLCV

Outputs: Gap dict {gaps_count, gaps_pct, gaps_sample}, validation results

Dependencies: pandas

Conventions: DatetimeIndex requis; fr√©quence inf√©r√©e si non fournie.

Read-if: Modification validation donn√©es ou d√©tection gaps.

Skip-if: Vous utilisez juste detect_gaps().
"""

from typing import Optional

import pandas as pd


def detect_gaps(df: pd.DataFrame, expected_freq: Optional[str] = None) -> dict:
    """
    D√©tecte les gaps temporels dans un DataFrame OHLCV.

    Les gaps sont des p√©riodes manquantes dans la s√©rie temporelle qui devraient
    normalement √™tre pr√©sentes selon la fr√©quence attendue.

    Args:
        df: DataFrame avec DatetimeIndex contenant les donn√©es OHLCV
        expected_freq: Fr√©quence attendue ('1h', '4h', '1d', etc.). Si None, sera inf√©r√©e.

    Returns:
        Dict avec:
            - gaps_count: Nombre total de gaps d√©tect√©s
            - gaps_pct: Pourcentage de donn√©es manquantes
            - gaps_sample: √âchantillon (max 5) des timestamps manquants
            - note: Information suppl√©mentaire si d√©tection impossible

    Examples:
        >>> df = load_ohlcv_data()
        >>> gaps = detect_gaps(df, expected_freq='1h')
        >>> print(f"Gaps trouv√©s : {gaps['gaps_count']} ({gaps['gaps_pct']:.2f}%)")
    """
    # V√©rifier que l'index est DatetimeIndex
    if not isinstance(df.index, pd.DatetimeIndex):
        return {
            "gaps_count": 0,
            "gaps_pct": 0.0,
            "gaps_sample": [],
            "note": "not_datetime_index"
        }

    # Inf√©rer fr√©quence si non fournie
    if expected_freq is None:
        expected_freq = pd.infer_freq(df.index)

    if expected_freq is None:
        return {
            "gaps_count": 0,
            "gaps_pct": 0.0,
            "gaps_sample": [],
            "note": "freq_not_inferable"
        }

    # Cr√©er s√©rie compl√®te attendue
    try:
        full_index = pd.date_range(
            start=df.index[0],
            end=df.index[-1],
            freq=expected_freq
        )
    except Exception:
        return {
            "gaps_count": 0,
            "gaps_pct": 0.0,
            "gaps_sample": [],
            "note": "freq_invalid"
        }

    # Identifier gaps (timestamps manquants)
    missing = full_index.difference(df.index)

    gaps_count = len(missing)
    gaps_pct = (gaps_count / len(full_index) * 100) if len(full_index) > 0 else 0.0

    return {
        "gaps_count": gaps_count,
        "gaps_pct": gaps_pct,
        "gaps_sample": missing.tolist()[:5] if gaps_count > 0 else []
    }


__all__ = ["detect_gaps"]
```
<!-- MODULE-END: data.py -->

<!-- MODULE-START: diagnose_sweep_activity.py -->
```json
{
  "name": "diagnose_sweep_activity.py",
  "path": "utils\\diagnose_sweep_activity.py",
  "ext": ".py",
  "anchor": "diagnose_sweep_activity_py"
}
```
## diagnose_sweep_activity_py
*Chemin* : `utils\diagnose_sweep_activity.py`  
*Type* : `.py`  

```python
"""
Script de diagnostic pour v√©rifier l'activit√© d'un sweep en cours.

Usage:
    python utils/diagnose_sweep_activity.py

V√©rifie:
- Processus Python actifs (workers)
- Utilisation CPU/RAM par processus
- Logs r√©cents du backtest
- Vitesse d'√©criture dans les fichiers de r√©sultats (si actifs)
"""

import os
import sys
import time
from pathlib import Path

# Ajouter le r√©pertoire parent au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    print("‚ö†Ô∏è  psutil non disponible. Installez-le avec: pip install psutil")


def find_backtest_processes():
    """Trouve tous les processus Python li√©s au backtest."""
    if not HAS_PSUTIL:
        return []

    backtest_procs = []
    for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 'memory_percent']):
        try:
            if proc.info['name'] and 'python' in proc.info['name'].lower():
                cmdline = proc.info.get('cmdline', [])
                if cmdline and any('backtest' in str(arg).lower() or 'streamlit' in str(arg).lower() for arg in cmdline):
                    backtest_procs.append(proc)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass
    return backtest_procs


def get_system_stats():
    """R√©cup√®re les stats syst√®me globales."""
    if not HAS_PSUTIL:
        return None

    cpu_percent = psutil.cpu_percent(interval=1, percpu=False)
    mem = psutil.virtual_memory()
    return {
        'cpu_percent': cpu_percent,
        'ram_used_gb': mem.used / (1024**3),
        'ram_total_gb': mem.total / (1024**3),
        'ram_percent': mem.percent,
    }


def check_log_activity():
    """V√©rifie l'activit√© dans les logs r√©cents."""
    log_files = [
        "logs/backtest.log",
        "logs/sweep.log",
    ]

    for log_file in log_files:
        log_path = Path(__file__).parent.parent / log_file
        if log_path.exists():
            stat = log_path.stat()
            modified_ago = time.time() - stat.st_mtime
            size_mb = stat.st_size / (1024**2)
            print(f"\nüìÑ {log_file}")
            print(f"   Taille: {size_mb:.2f} MB")
            print(f"   Modifi√©: il y a {modified_ago:.0f}s")
            if modified_ago < 60:
                print(f"   ‚úÖ Activit√© r√©cente d√©tect√©e")
            elif modified_ago < 300:
                print(f"   ‚ö†Ô∏è  Pas d'activit√© depuis {modified_ago/60:.0f} minutes")
            else:
                print(f"   ‚ùå Inactif depuis {modified_ago/60:.0f} minutes")


def check_result_files():
    """V√©rifie l'√©criture dans les fichiers de r√©sultats."""
    results_dir = Path(__file__).parent.parent / "backtest_results"
    if not results_dir.exists():
        print("\n‚ö†Ô∏è  Dossier backtest_results non trouv√©")
        return

    recent_files = []
    now = time.time()
    for file in results_dir.rglob("*.json"):
        mtime = file.stat().st_mtime
        age = now - mtime
        if age < 3600:  # Modifi√© dans la derni√®re heure
            recent_files.append((file, age))

    if recent_files:
        print(f"\nüìä {len(recent_files)} fichiers de r√©sultats modifi√©s r√©cemment:")
        for file, age in sorted(recent_files, key=lambda x: x[1])[:5]:
            print(f"   ‚Ä¢ {file.name} (il y a {age/60:.0f}m)")
    else:
        print("\n‚ùå Aucun fichier de r√©sultats r√©cent (< 1h)")


def main():
    """Point d'entr√©e principal."""
    print("=" * 70)
    print("üîç DIAGNOSTIC D'ACTIVIT√â SWEEP")
    print("=" * 70)

    # Stats syst√®me globales
    stats = get_system_stats()
    if stats:
        print(f"\nüñ•Ô∏è  Syst√®me:")
        print(f"   CPU: {stats['cpu_percent']:.1f}%")
        print(f"   RAM: {stats['ram_used_gb']:.1f}/{stats['ram_total_gb']:.1f} GB ({stats['ram_percent']:.1f}%)")

    # Processus Python actifs
    procs = find_backtest_processes()
    if procs:
        print(f"\nüêç Processus Python backtest actifs: {len(procs)}")
        total_cpu = 0
        total_mem = 0
        for proc in procs:
            try:
                cpu = proc.cpu_percent(interval=0.1)
                mem = proc.memory_percent()
                total_cpu += cpu
                total_mem += mem
                cmdline_str = ' '.join(proc.cmdline()[:3]) if proc.cmdline() else 'N/A'
                print(f"   PID {proc.pid}: CPU {cpu:.1f}% | RAM {mem:.1f}% | {cmdline_str[:60]}")
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

        print(f"\n   Total: CPU {total_cpu:.1f}% | RAM {total_mem:.1f}%")

        if total_cpu > 5:
            print(f"   ‚úÖ Activit√© CPU d√©tect√©e - Le sweep est probablement actif")
        else:
            print(f"   ‚ö†Ô∏è  CPU faible - Le sweep pourrait √™tre bloqu√© ou en attente")
    else:
        print("\n‚ùå Aucun processus Python backtest trouv√©")

    # V√©rifier logs
    check_log_activity()

    # V√©rifier fichiers de r√©sultats
    check_result_files()

    print("\n" + "=" * 70)
    print("Diagnostic termin√©")
    print("=" * 70)

    # Recommandations
    if procs and stats and stats['cpu_percent'] < 10:
        print("\nüí° Recommandation: CPU faible d√©tect√©.")
        print("   Le sweep utilise peut-√™tre peu de workers ou est bloqu√©.")
        print("   V√©rifiez les logs pour d'√©ventuelles erreurs.")


if __name__ == "__main__":
    main()
```
<!-- MODULE-END: diagnose_sweep_activity.py -->

<!-- MODULE-START: error_recovery.py -->
```json
{
  "name": "error_recovery.py",
  "path": "utils\\error_recovery.py",
  "ext": ".py",
  "anchor": "error_recovery_py"
}
```
## error_recovery_py
*Chemin* : `utils\error_recovery.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.error_recovery

Purpose: Error Recovery - retry avec backoff exponentiel et classification erreurs.

Role in pipeline: resilience

Key components: RetryHandler, ErrorClassifier, RetryStrategy, TransientError

Inputs: Exception, max_retries, backoff_factor

Outputs: Succ√®s apr√®s retry, ou final ErrorExhausted apr√®s N tentatives

Dependencies: functools, logging, time, traceback

Conventions: Backoff exponentiel optionnel; classification transitoire/permanent; callbacks setup/cleanup.

Read-if: Modification strat√©gies retry, classification erreurs.

Skip-if: Vous utilisez juste @retry_on_error decorator.
"""

from __future__ import annotations

import functools
import logging
import time
import traceback
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple, Type

logger = logging.getLogger(__name__)


class ErrorCategory(Enum):
    """Cat√©gorie d'erreur pour d√©terminer la strat√©gie de r√©cup√©ration."""
    TRANSIENT = "transient"      # Erreur temporaire, retry possible
    PERMANENT = "permanent"      # Erreur permanente, pas de retry
    RESOURCE = "resource"        # Erreur ressource (m√©moire, disk)
    NETWORK = "network"          # Erreur r√©seau
    VALIDATION = "validation"    # Erreur de validation
    UNKNOWN = "unknown"          # Erreur inconnue


@dataclass
class ErrorInfo:
    """Informations sur une erreur captur√©e."""
    exception: Exception
    category: ErrorCategory
    timestamp: float
    context: Dict[str, Any] = field(default_factory=dict)
    traceback_str: str = ""
    attempt: int = 1

    def __post_init__(self):
        if not self.traceback_str:
            self.traceback_str = traceback.format_exc()


@dataclass
class RetryConfig:
    """Configuration du retry."""
    max_attempts: int = 3
    initial_delay: float = 1.0
    max_delay: float = 60.0
    exponential_base: float = 2.0
    jitter: bool = True

    # Erreurs √† retrier
    retry_exceptions: Tuple[Type[Exception], ...] = (
        ConnectionError,
        TimeoutError,
        OSError,
    )

    # Erreurs √† ne jamais retrier
    no_retry_exceptions: Tuple[Type[Exception], ...] = (
        ValueError,
        TypeError,
        KeyError,
        AttributeError,
    )


class ErrorClassifier:
    """Classifie les erreurs par cat√©gorie."""

    # Mapping par d√©faut type d'exception -> cat√©gorie
    DEFAULT_MAPPING: Dict[Type[Exception], ErrorCategory] = {
        ConnectionError: ErrorCategory.NETWORK,
        TimeoutError: ErrorCategory.NETWORK,
        MemoryError: ErrorCategory.RESOURCE,
        OSError: ErrorCategory.RESOURCE,
        ValueError: ErrorCategory.VALIDATION,
        TypeError: ErrorCategory.VALIDATION,
        KeyError: ErrorCategory.PERMANENT,
        AttributeError: ErrorCategory.PERMANENT,
    }

    def __init__(self, custom_mapping: Optional[Dict[Type[Exception], ErrorCategory]] = None):
        """
        Args:
            custom_mapping: Mapping personnalis√© type -> cat√©gorie
        """
        self.mapping = {**self.DEFAULT_MAPPING}
        if custom_mapping:
            self.mapping.update(custom_mapping)

    def classify(self, exc: Exception) -> ErrorCategory:
        """
        Classifie une exception.

        Args:
            exc: Exception √† classifier

        Returns:
            Cat√©gorie de l'erreur
        """
        # V√©rifier le type exact
        exc_type = type(exc)
        if exc_type in self.mapping:
            return self.mapping[exc_type]

        # V√©rifier les classes parentes
        for error_type, category in self.mapping.items():
            if isinstance(exc, error_type):
                return category

        # Heuristiques bas√©es sur le message
        msg = str(exc).lower()

        if any(w in msg for w in ["timeout", "connection", "network", "refused"]):
            return ErrorCategory.NETWORK

        if any(w in msg for w in ["memory", "oom", "allocation", "out of memory"]):
            return ErrorCategory.RESOURCE

        if any(w in msg for w in ["invalid", "validation", "required"]):
            return ErrorCategory.VALIDATION

        return ErrorCategory.UNKNOWN

    def is_retryable(self, exc: Exception) -> bool:
        """D√©termine si une erreur peut √™tre retri√©e."""
        category = self.classify(exc)
        return category in (ErrorCategory.TRANSIENT, ErrorCategory.NETWORK, ErrorCategory.RESOURCE)


class RetryHandler:
    """
    Gestionnaire de retry avec exponential backoff.

    Example:
        >>> handler = RetryHandler(max_attempts=3)
        >>>
        >>> @handler.retry
        >>> def unstable_function():
        >>>     ...
        >>>
        >>> # Ou manuellement:
        >>> result = handler.execute(unstable_function, arg1, arg2)
    """

    def __init__(
        self,
        config: Optional[RetryConfig] = None,
        classifier: Optional[ErrorClassifier] = None,
        on_retry: Optional[Callable[[ErrorInfo], None]] = None,
        on_failure: Optional[Callable[[ErrorInfo], None]] = None,
    ):
        """
        Args:
            config: Configuration du retry
            classifier: Classifier d'erreurs
            on_retry: Callback appel√© avant chaque retry
            on_failure: Callback appel√© apr√®s √©chec final
        """
        self.config = config or RetryConfig()
        self.classifier = classifier or ErrorClassifier()
        self.on_retry = on_retry
        self.on_failure = on_failure

        self._errors: List[ErrorInfo] = []

    def _calculate_delay(self, attempt: int) -> float:
        """Calcule le d√©lai avant le prochain retry."""
        delay = self.config.initial_delay * (self.config.exponential_base ** (attempt - 1))
        delay = min(delay, self.config.max_delay)

        if self.config.jitter:
            import random
            delay *= (0.5 + random.random())

        return delay

    def _should_retry(self, exc: Exception, attempt: int) -> bool:
        """D√©termine si on doit retrier."""
        # Limite d'attempts
        if attempt >= self.config.max_attempts:
            return False

        # V√©rifier si exception dans no_retry
        if isinstance(exc, self.config.no_retry_exceptions):
            return False

        # V√©rifier si exception retryable
        if isinstance(exc, self.config.retry_exceptions):
            return True

        # Utiliser le classifier
        return self.classifier.is_retryable(exc)

    def execute(
        self,
        func: Callable,
        *args,
        context: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Any:
        """
        Ex√©cute une fonction avec retry.

        Args:
            func: Fonction √† ex√©cuter
            *args: Arguments positionnels
            context: Contexte pour le logging
            **kwargs: Arguments nomm√©s

        Returns:
            R√©sultat de la fonction

        Raises:
            Exception: Derni√®re exception si tous les retries √©chouent
        """
        context = context or {}
        attempt = 0
        last_error: Optional[ErrorInfo] = None

        while attempt < self.config.max_attempts:
            attempt += 1

            try:
                return func(*args, **kwargs)

            except Exception as exc:
                error_info = ErrorInfo(
                    exception=exc,
                    category=self.classifier.classify(exc),
                    timestamp=time.time(),
                    context=context,
                    attempt=attempt,
                )
                self._errors.append(error_info)
                last_error = error_info

                logger.warning(
                    f"Attempt {attempt}/{self.config.max_attempts} failed: {exc}"
                )

                if not self._should_retry(exc, attempt):
                    logger.error(f"Error not retryable: {error_info.category}")
                    if self.on_failure:
                        self.on_failure(error_info)
                    raise

                # Callback before retry
                if self.on_retry:
                    self.on_retry(error_info)

                # Attendre avant retry
                if attempt < self.config.max_attempts:
                    delay = self._calculate_delay(attempt)
                    logger.info(f"Retrying in {delay:.2f}s...")
                    time.sleep(delay)

        # Tous les retries ont √©chou√©
        if self.on_failure and last_error:
            self.on_failure(last_error)

        raise last_error.exception if last_error else RuntimeError("No attempts made")

    def retry(self, func: Callable) -> Callable:
        """
        D√©corateur pour ajouter retry √† une fonction.

        Example:
            >>> @retry_handler.retry
            >>> def my_function():
            >>>     ...
        """
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            return self.execute(func, *args, **kwargs)
        return wrapper

    def get_errors(self) -> List[ErrorInfo]:
        """Retourne l'historique des erreurs."""
        return list(self._errors)

    def clear_errors(self):
        """Efface l'historique des erreurs."""
        self._errors.clear()


class RecoveryStrategy:
    """
    Strat√©gie de r√©cup√©ration pour erreurs sp√©cifiques.

    D√©finit des actions de r√©cup√©ration personnalis√©es.
    """

    def __init__(self):
        """Initialise les strat√©gies."""
        self._strategies: Dict[ErrorCategory, Callable[[ErrorInfo], bool]] = {}
        self._setup_defaults()

    def _setup_defaults(self):
        """Configure les strat√©gies par d√©faut."""

        def handle_resource(error: ErrorInfo) -> bool:
            """G√®re les erreurs de ressources."""
            import gc
            gc.collect()

            # Tenter de lib√©rer la m√©moire GPU
            try:
                import cupy as cp
                cp.get_default_memory_pool().free_all_blocks()
            except ImportError:
                pass

            logger.info("Memory cleared for recovery")
            return True

        def handle_network(error: ErrorInfo) -> bool:
            """G√®re les erreurs r√©seau."""
            # Attendre un peu avant retry
            time.sleep(2.0)
            return True

        def handle_permanent(error: ErrorInfo) -> bool:
            """G√®re les erreurs permanentes."""
            logger.error(f"Permanent error, no recovery: {error.exception}")
            return False

        self._strategies[ErrorCategory.RESOURCE] = handle_resource
        self._strategies[ErrorCategory.NETWORK] = handle_network
        self._strategies[ErrorCategory.PERMANENT] = handle_permanent

    def register(
        self,
        category: ErrorCategory,
        handler: Callable[[ErrorInfo], bool]
    ):
        """
        Enregistre une strat√©gie de r√©cup√©ration.

        Args:
            category: Cat√©gorie d'erreur
            handler: Fonction de r√©cup√©ration (retourne True si r√©cup√©r√©)
        """
        self._strategies[category] = handler

    def recover(self, error: ErrorInfo) -> bool:
        """
        Tente de r√©cup√©rer d'une erreur.

        Args:
            error: Information sur l'erreur

        Returns:
            True si r√©cup√©ration r√©ussie
        """
        handler = self._strategies.get(error.category)

        if handler:
            try:
                return handler(error)
            except Exception as e:
                logger.error(f"Recovery handler failed: {e}")
                return False

        return False


# D√©corateurs utilitaires

def with_retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    exceptions: Tuple[Type[Exception], ...] = (Exception,),
    on_retry: Optional[Callable] = None,
):
    """
    D√©corateur pour ajouter retry √† une fonction.

    Args:
        max_attempts: Nombre max de tentatives
        delay: D√©lai initial entre retries
        exceptions: Types d'exceptions √† retrier
        on_retry: Callback appel√© avant retry

    Example:
        >>> @with_retry(max_attempts=3, delay=1.0)
        >>> def unstable_api_call():
        >>>     ...
    """
    config = RetryConfig(
        max_attempts=max_attempts,
        initial_delay=delay,
        retry_exceptions=exceptions,
    )
    handler = RetryHandler(config=config, on_retry=on_retry)

    def decorator(func: Callable) -> Callable:
        return handler.retry(func)

    return decorator


def retry_on_memory_error(func: Callable) -> Callable:
    """D√©corateur sp√©cifique pour les erreurs m√©moire."""
    config = RetryConfig(
        max_attempts=3,
        initial_delay=2.0,
        retry_exceptions=(MemoryError,),
    )

    def on_retry(error: ErrorInfo):
        import gc
        gc.collect()
        try:
            import cupy as cp
            cp.get_default_memory_pool().free_all_blocks()
        except ImportError:
            pass

    handler = RetryHandler(config=config, on_retry=on_retry)
    return handler.retry(func)


__all__ = [
    "ErrorCategory",
    "ErrorInfo",
    "RetryConfig",
    "ErrorClassifier",
    "RetryHandler",
    "RecoveryStrategy",
    "with_retry",
    "retry_on_memory_error",
]
```
<!-- MODULE-END: error_recovery.py -->

<!-- MODULE-START: gpu_monitor.py -->
```json
{
  "name": "gpu_monitor.py",
  "path": "utils\\gpu_monitor.py",
  "ext": ".py",
  "anchor": "gpu_monitor_py"
}
```
## gpu_monitor_py
*Chemin* : `utils\gpu_monitor.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.gpu_monitor

Purpose: Monitoring GPU temps r√©el - Affichage fiable utilisation/m√©moire multi-GPU.

Usage:
    python -m utils.gpu_monitor              # Mode interactif terminal
    python -m utils.gpu_monitor --web        # Mode web browser (recommand√©)
    python -m utils.gpu_monitor --log        # Mode logging fichier
"""

from __future__ import annotations

import argparse
import os
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

# Ajouter racine projet au path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


@dataclass
class GPUStats:
    """Statistiques d'un GPU √† un instant T."""
    index: int
    name: str
    utilization_gpu: int      # % compute
    utilization_memory: int   # % m√©moire utilis√©e
    memory_used_mb: int
    memory_total_mb: int
    temperature: int
    power_draw_w: float
    power_limit_w: float
    timestamp: datetime


def get_gpu_stats_nvidia_smi() -> List[GPUStats]:
    """R√©cup√®re les stats GPU via nvidia-smi (m√©thode la plus fiable)."""
    import subprocess

    try:
        result = subprocess.run(
            [
                "nvidia-smi",
                "--query-gpu=index,name,utilization.gpu,utilization.memory,"
                "memory.used,memory.total,temperature.gpu,power.draw,power.limit",
                "--format=csv,noheader,nounits"
            ],
            capture_output=True,
            text=True,
            timeout=5
        )

        if result.returncode != 0:
            return []

        stats = []
        now = datetime.now()

        for line in result.stdout.strip().split("\n"):
            if not line.strip():
                continue

            parts = [p.strip() for p in line.split(",")]
            if len(parts) < 9:
                continue

            try:
                stats.append(GPUStats(
                    index=int(parts[0]),
                    name=parts[1],
                    utilization_gpu=int(parts[2]) if parts[2] != "[N/A]" else 0,
                    utilization_memory=int(parts[3]) if parts[3] != "[N/A]" else 0,
                    memory_used_mb=int(float(parts[4])) if parts[4] != "[N/A]" else 0,
                    memory_total_mb=int(float(parts[5])) if parts[5] != "[N/A]" else 0,
                    temperature=int(parts[6]) if parts[6] != "[N/A]" else 0,
                    power_draw_w=float(parts[7]) if parts[7] != "[N/A]" else 0,
                    power_limit_w=float(parts[8]) if parts[8] != "[N/A]" else 0,
                    timestamp=now
                ))
            except (ValueError, IndexError):
                continue

        return stats

    except Exception as e:
        print(f"Erreur nvidia-smi: {e}")
        return []


def get_gpu_processes() -> dict:
    """R√©cup√®re les processus utilisant chaque GPU."""
    import subprocess

    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-compute-apps=gpu_uuid,pid,name,used_memory",
             "--format=csv,noheader,nounits"],
            capture_output=True,
            text=True,
            timeout=5
        )

        # Mapper UUID -> index
        uuid_result = subprocess.run(
            ["nvidia-smi", "--query-gpu=index,uuid", "--format=csv,noheader"],
            capture_output=True,
            text=True,
            timeout=5
        )

        uuid_to_idx = {}
        for line in uuid_result.stdout.strip().split("\n"):
            if "," in line:
                idx, uuid = line.split(",", 1)
                uuid_to_idx[uuid.strip()] = int(idx.strip())

        processes = {i: [] for i in uuid_to_idx.values()}

        for line in result.stdout.strip().split("\n"):
            if not line.strip():
                continue
            parts = [p.strip() for p in line.split(",")]
            if len(parts) >= 4:
                uuid = parts[0]
                if uuid in uuid_to_idx:
                    idx = uuid_to_idx[uuid]
                    processes[idx].append({
                        "pid": parts[1],
                        "name": parts[2],
                        "memory_mb": parts[3]
                    })

        return processes

    except Exception:
        return {}


def print_gpu_bar(value: int, max_val: int = 100, width: int = 30, label: str = "") -> str:
    """G√©n√®re une barre de progression ASCII."""
    filled = int(width * value / max_val)
    bar = "‚ñà" * filled + "‚ñë" * (width - filled)

    # Couleur selon utilisation
    if value < 30:
        color = "\033[92m"  # Vert
    elif value < 70:
        color = "\033[93m"  # Jaune
    else:
        color = "\033[91m"  # Rouge

    reset = "\033[0m"
    return f"{label}{color}{bar}{reset} {value:3d}%"


def clear_screen():
    """Efface l'√©cran terminal."""
    os.system('cls' if os.name == 'nt' else 'clear')


def run_terminal_monitor(interval: float = 1.0):
    """Mode monitoring terminal interactif."""
    print("\033[?25l")  # Cacher curseur

    try:
        while True:
            clear_screen()
            stats = get_gpu_stats_nvidia_smi()
            processes = get_gpu_processes()

            print("=" * 70)
            print(f"  GPU MONITOR - {datetime.now().strftime('%H:%M:%S')}  (Ctrl+C pour quitter)")
            print("=" * 70)

            if not stats:
                print("\n  ‚ö†Ô∏è  Aucun GPU NVIDIA d√©tect√© ou nvidia-smi indisponible")
                time.sleep(interval)
                continue

            for gpu in stats:
                mem_pct = int(100 * gpu.memory_used_mb / gpu.memory_total_mb) if gpu.memory_total_mb > 0 else 0

                print(f"\n  GPU {gpu.index}: {gpu.name}")
                print(f"  {'‚îÄ' * 50}")
                print(f"  {print_gpu_bar(gpu.utilization_gpu, label='  Compute: ')}")
                print(f"  {print_gpu_bar(mem_pct, label='  M√©moire: ')}  ({gpu.memory_used_mb:,} / {gpu.memory_total_mb:,} MB)")
                print(f"  üå°Ô∏è  Temp: {gpu.temperature}¬∞C   ‚ö° Power: {gpu.power_draw_w:.0f}W / {gpu.power_limit_w:.0f}W")

                # Processus sur ce GPU
                if gpu.index in processes and processes[gpu.index]:
                    print(f"  üìã Processus:")
                    for proc in processes[gpu.index][:5]:  # Max 5
                        print(f"      ‚Ä¢ {proc['name'][:30]:30s}  {proc['memory_mb']:>6s} MB")

            print("\n" + "=" * 70)
            print("  üí° Note: Ces valeurs viennent de nvidia-smi (CUDA), pas de Windows")
            print("=" * 70)

            time.sleep(interval)

    except KeyboardInterrupt:
        print("\033[?25h")  # R√©afficher curseur
        print("\n\nMonitoring arr√™t√©.")


def run_web_monitor(port: int = 8765):
    """Mode monitoring web avec graphiques temps r√©el."""
    try:
        from http.server import HTTPServer, SimpleHTTPRequestHandler
        import json
        import threading
    except ImportError as e:
        print(f"Erreur import: {e}")
        return

    html_content = """<!DOCTYPE html>
<html>
<head>
    <title>GPU Monitor - Backtest Core</title>
    <meta charset="utf-8">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            background: #1a1a2e;
            color: #eee;
            padding: 20px;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
            color: #00d4ff;
        }
        .gpu-container {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            justify-content: center;
        }
        .gpu-card {
            background: #16213e;
            border-radius: 15px;
            padding: 20px;
            min-width: 350px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
        .gpu-name {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 15px;
            color: #00d4ff;
        }
        .metric {
            margin: 10px 0;
        }
        .metric-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
        }
        .progress-bar {
            height: 25px;
            background: #0f3460;
            border-radius: 12px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            transition: width 0.3s ease, background 0.3s ease;
            border-radius: 12px;
        }
        .fill-green { background: linear-gradient(90deg, #00c853, #69f0ae); }
        .fill-yellow { background: linear-gradient(90deg, #ffc107, #ffeb3b); }
        .fill-red { background: linear-gradient(90deg, #ff5252, #ff8a80); }
        .stats-row {
            display: flex;
            justify-content: space-around;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #0f3460;
        }
        .stat-item {
            text-align: center;
        }
        .stat-value {
            font-size: 1.5em;
            font-weight: bold;
        }
        .stat-label {
            font-size: 0.8em;
            color: #888;
        }
        .chart-container {
            margin-top: 15px;
            height: 100px;
            background: #0f3460;
            border-radius: 10px;
            padding: 10px;
            position: relative;
        }
        canvas { width: 100% !important; height: 100% !important; }
        .timestamp {
            text-align: center;
            margin-top: 20px;
            color: #666;
        }
        .legend {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 10px;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 5px;
        }
        .legend-color {
            width: 15px;
            height: 15px;
            border-radius: 3px;
        }
    </style>
</head>
<body>
    <h1>üñ•Ô∏è GPU Monitor - Backtest Core</h1>
    <div id="gpus" class="gpu-container"></div>
    <div class="timestamp" id="timestamp"></div>
    <div class="legend">
        <div class="legend-item"><div class="legend-color fill-green"></div> &lt;30%</div>
        <div class="legend-item"><div class="legend-color fill-yellow"></div> 30-70%</div>
        <div class="legend-item"><div class="legend-color fill-red"></div> &gt;70%</div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script>
        const history = {};
        const charts = {};
        const MAX_HISTORY = 60;

        function getColorClass(value) {
            if (value < 30) return 'fill-green';
            if (value < 70) return 'fill-yellow';
            return 'fill-red';
        }

        function updateGPU(gpu) {
            const id = `gpu-${gpu.index}`;
            let card = document.getElementById(id);

            if (!card) {
                card = document.createElement('div');
                card.id = id;
                card.className = 'gpu-card';
                document.getElementById('gpus').appendChild(card);
            }

            const memPct = Math.round(100 * gpu.memory_used_mb / gpu.memory_total_mb);

            card.innerHTML = `
                <div class="gpu-name">GPU ${gpu.index}: ${gpu.name}</div>
                <div class="metric">
                    <div class="metric-label">
                        <span>‚ö° Compute</span>
                        <span>${gpu.utilization_gpu}%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill ${getColorClass(gpu.utilization_gpu)}"
                             style="width: ${gpu.utilization_gpu}%"></div>
                    </div>
                </div>
                <div class="metric">
                    <div class="metric-label">
                        <span>üíæ M√©moire</span>
                        <span>${memPct}% (${gpu.memory_used_mb.toLocaleString()} MB)</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill ${getColorClass(memPct)}"
                             style="width: ${memPct}%"></div>
                    </div>
                </div>
                <div class="stats-row">
                    <div class="stat-item">
                        <div class="stat-value">${gpu.temperature}¬∞C</div>
                        <div class="stat-label">üå°Ô∏è Temp</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value">${gpu.power_draw_w.toFixed(0)}W</div>
                        <div class="stat-label">‚ö° Power</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value">${gpu.memory_total_mb.toLocaleString()}</div>
                        <div class="stat-label">üíæ Total MB</div>
                    </div>
                </div>
                <div class="chart-container">
                    <canvas id="chart-${gpu.index}"></canvas>
                </div>
            `;

            // Update history
            if (!history[gpu.index]) {
                history[gpu.index] = { compute: [], memory: [], labels: [] };
            }
            const h = history[gpu.index];
            h.compute.push(gpu.utilization_gpu);
            h.memory.push(memPct);
            h.labels.push('');

            if (h.compute.length > MAX_HISTORY) {
                h.compute.shift();
                h.memory.shift();
                h.labels.shift();
            }

            // Update chart
            const ctx = document.getElementById(`chart-${gpu.index}`);
            if (ctx) {
                if (!charts[gpu.index]) {
                    charts[gpu.index] = new Chart(ctx, {
                        type: 'line',
                        data: {
                            labels: h.labels,
                            datasets: [
                                {
                                    label: 'Compute %',
                                    data: h.compute,
                                    borderColor: '#00d4ff',
                                    backgroundColor: 'rgba(0, 212, 255, 0.1)',
                                    fill: true,
                                    tension: 0.3
                                },
                                {
                                    label: 'Memory %',
                                    data: h.memory,
                                    borderColor: '#ff6b6b',
                                    backgroundColor: 'rgba(255, 107, 107, 0.1)',
                                    fill: true,
                                    tension: 0.3
                                }
                            ]
                        },
                        options: {
                            responsive: true,
                            maintainAspectRatio: false,
                            plugins: { legend: { display: false } },
                            scales: {
                                x: { display: false },
                                y: { min: 0, max: 100, display: false }
                            },
                            animation: { duration: 0 }
                        }
                    });
                } else {
                    charts[gpu.index].data.datasets[0].data = h.compute;
                    charts[gpu.index].data.datasets[1].data = h.memory;
                    charts[gpu.index].data.labels = h.labels;
                    charts[gpu.index].update('none');
                }
            }
        }

        async function fetchStats() {
            try {
                const response = await fetch('/api/stats');
                const data = await response.json();

                data.forEach(gpu => updateGPU(gpu));
                document.getElementById('timestamp').textContent =
                    `Derni√®re mise √† jour: ${new Date().toLocaleTimeString()} (nvidia-smi)`;
            } catch (e) {
                console.error('Erreur fetch:', e);
            }
        }

        // Refresh toutes les secondes
        setInterval(fetchStats, 1000);
        fetchStats();
    </script>
</body>
</html>"""

    class MonitorHandler(SimpleHTTPRequestHandler):
        def do_GET(self):
            if self.path == '/':
                self.send_response(200)
                self.send_header('Content-type', 'text/html')
                self.end_headers()
                self.wfile.write(html_content.encode())
            elif self.path == '/api/stats':
                stats = get_gpu_stats_nvidia_smi()
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()

                data = []
                for s in stats:
                    data.append({
                        'index': s.index,
                        'name': s.name,
                        'utilization_gpu': s.utilization_gpu,
                        'utilization_memory': s.utilization_memory,
                        'memory_used_mb': s.memory_used_mb,
                        'memory_total_mb': s.memory_total_mb,
                        'temperature': s.temperature,
                        'power_draw_w': s.power_draw_w,
                        'power_limit_w': s.power_limit_w
                    })

                self.wfile.write(json.dumps(data).encode())
            else:
                self.send_error(404)

        def log_message(self, format, *args):
            pass  # Silence logs

    print(f"\nüñ•Ô∏è  GPU Monitor Web Server")
    print(f"   Ouvrez: http://localhost:{port}")
    print(f"   Ctrl+C pour arr√™ter\n")

    # Ouvrir navigateur automatiquement
    import webbrowser
    webbrowser.open(f"http://localhost:{port}")

    server = HTTPServer(('localhost', port), MonitorHandler)
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nServeur arr√™t√©.")


def run_log_mode(interval: float = 1.0, output_file: str = "gpu_stats.csv"):
    """Mode logging CSV pour analyse ult√©rieure."""
    import csv

    print(f"üìù Logging GPU stats vers {output_file} (Ctrl+C pour arr√™ter)")

    with open(output_file, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow([
            'timestamp', 'gpu_index', 'gpu_name', 'utilization_gpu',
            'utilization_memory', 'memory_used_mb', 'memory_total_mb',
            'temperature', 'power_draw_w'
        ])

        try:
            while True:
                stats = get_gpu_stats_nvidia_smi()
                for gpu in stats:
                    writer.writerow([
                        gpu.timestamp.isoformat(),
                        gpu.index,
                        gpu.name,
                        gpu.utilization_gpu,
                        gpu.utilization_memory,
                        gpu.memory_used_mb,
                        gpu.memory_total_mb,
                        gpu.temperature,
                        gpu.power_draw_w
                    ])
                f.flush()
                print(f"  {datetime.now().strftime('%H:%M:%S')} - {len(stats)} GPU(s) logged")
                time.sleep(interval)

        except KeyboardInterrupt:
            print(f"\n‚úÖ Log sauvegard√©: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="GPU Monitor - Backtest Core")
    parser.add_argument('--web', action='store_true', help="Mode web avec graphiques (recommand√©)")
    parser.add_argument('--log', action='store_true', help="Mode logging CSV")
    parser.add_argument('--interval', type=float, default=1.0, help="Intervalle refresh (secondes)")
    parser.add_argument('--port', type=int, default=8765, help="Port serveur web")
    parser.add_argument('--output', type=str, default="gpu_stats.csv", help="Fichier log CSV")

    args = parser.parse_args()

    if args.web:
        run_web_monitor(port=args.port)
    elif args.log:
        run_log_mode(interval=args.interval, output_file=args.output)
    else:
        run_terminal_monitor(interval=args.interval)


if __name__ == "__main__":
    main()
```
<!-- MODULE-END: gpu_monitor.py -->

<!-- MODULE-START: gpu_oom.py -->
```json
{
  "name": "gpu_oom.py",
  "path": "utils\\gpu_oom.py",
  "ext": ".py",
  "anchor": "gpu_oom_py"
}
```
## gpu_oom_py
*Chemin* : `utils\gpu_oom.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.gpu_oom

Purpose: GPU OOM Handler - fallback automatique CPU si m√©moire GPU insuffisante.

Role in pipeline: performance / resilience

Key components: GPUOOMHandler, gpu_memory_available, fallback_to_cpu context manager

Inputs: M√©moire estim√©e requise, device

Outputs: Calculs GPU ou fallback CPU, notifications

Dependencies: cupy (optionnel), numpy, logging, contextlib

Conventions: Estimation proactive m√©moire; nettoyage cache GPU avant fallback; transparent pour caller.

Read-if: Modification estimation m√©moire, logique fallback.

Skip-if: Vous utilisez juste @gpu_safe decorator.
"""

from __future__ import annotations

import functools
import logging
from contextlib import contextmanager
from dataclasses import dataclass
from enum import Enum
from typing import Any, Callable, Dict, Optional, Tuple

import numpy as np

logger = logging.getLogger(__name__)


class MemoryStatus(Enum):
    """√âtat de la m√©moire GPU."""
    OK = "ok"                    # M√©moire suffisante
    LOW = "low"                  # M√©moire basse
    CRITICAL = "critical"        # M√©moire critique
    OOM = "oom"                  # Out of memory
    UNAVAILABLE = "unavailable"  # GPU non disponible


@dataclass
class GPUMemoryInfo:
    """Informations sur la m√©moire GPU."""
    total: int = 0           # M√©moire totale en bytes
    used: int = 0            # M√©moire utilis√©e
    free: int = 0            # M√©moire libre
    status: MemoryStatus = MemoryStatus.UNAVAILABLE

    @property
    def usage_percent(self) -> float:
        """Pourcentage de m√©moire utilis√©e."""
        if self.total == 0:
            return 0.0
        return (self.used / self.total) * 100

    @property
    def free_mb(self) -> float:
        """M√©moire libre en MB."""
        return self.free / (1024 * 1024)

    @property
    def free_gb(self) -> float:
        """M√©moire libre en GB."""
        return self.free / (1024 ** 3)


class GPUOOMHandler:
    """
    Gestionnaire d'erreurs Out-Of-Memory GPU.

    Surveille la m√©moire GPU et g√®re les fallbacks vers CPU.

    Example:
        >>> handler = GPUOOMHandler()
        >>>
        >>> @handler.safe_gpu_operation
        >>> def compute_on_gpu(data):
        >>>     import cupy as cp
        >>>     return cp.sum(cp.array(data))
        >>>
        >>> # Tente sur GPU, fallback sur CPU si OOM
        >>> result = compute_on_gpu(large_array)
    """

    def __init__(
        self,
        low_memory_threshold: float = 0.2,    # 20% libre
        critical_threshold: float = 0.1,       # 10% libre
        auto_clear_on_low: bool = True,
        fallback_to_cpu: bool = True,
    ):
        """
        Args:
            low_memory_threshold: Seuil m√©moire basse (fraction libre)
            critical_threshold: Seuil critique (fraction libre)
            auto_clear_on_low: Nettoyage auto si m√©moire basse
            fallback_to_cpu: Fallback automatique vers CPU si OOM
        """
        self.low_threshold = low_memory_threshold
        self.critical_threshold = critical_threshold
        self.auto_clear = auto_clear_on_low
        self.fallback_to_cpu = fallback_to_cpu

        self._gpu_available = self._check_gpu_available()
        self._oom_count = 0
        self._fallback_count = 0

    def _check_gpu_available(self) -> bool:
        """V√©rifie si CuPy/GPU est disponible."""
        try:
            import cupy as cp
            cp.cuda.Device(0).use()
            return True
        except (ImportError, Exception):
            return False

    def get_memory_info(self) -> GPUMemoryInfo:
        """
        R√©cup√®re les informations m√©moire GPU.

        Returns:
            GPUMemoryInfo avec √©tat actuel
        """
        if not self._gpu_available:
            return GPUMemoryInfo(status=MemoryStatus.UNAVAILABLE)

        try:
            import cupy as cp

            mem = cp.cuda.Device(0).mem_info
            free, total = mem[0], mem[1]
            used = total - free

            # D√©terminer le status
            free_ratio = free / total if total > 0 else 0

            if free_ratio <= self.critical_threshold:
                status = MemoryStatus.CRITICAL
            elif free_ratio <= self.low_threshold:
                status = MemoryStatus.LOW
            else:
                status = MemoryStatus.OK

            return GPUMemoryInfo(
                total=total,
                used=used,
                free=free,
                status=status,
            )

        except Exception as e:
            logger.warning(f"Impossible de lire la m√©moire GPU: {e}")
            return GPUMemoryInfo(status=MemoryStatus.UNAVAILABLE)

    def clear_memory(self) -> bool:
        """
        Lib√®re la m√©moire GPU.

        Returns:
            True si nettoyage r√©ussi
        """
        if not self._gpu_available:
            return False

        try:
            import gc

            import cupy as cp

            # Garbage collection Python
            gc.collect()

            # Lib√©rer les pools CuPy
            cp.get_default_memory_pool().free_all_blocks()
            cp.get_default_pinned_memory_pool().free_all_blocks()

            # Synchroniser
            cp.cuda.Stream.null.synchronize()

            logger.debug("M√©moire GPU lib√©r√©e")
            return True

        except Exception as e:
            logger.warning(f"Erreur lors du nettoyage m√©moire: {e}")
            return False

    def estimate_memory_required(self, data_shape: Tuple[int, ...], dtype=np.float64) -> int:
        """
        Estime la m√©moire requise pour des donn√©es.

        Args:
            data_shape: Shape des donn√©es
            dtype: Type de donn√©es

        Returns:
            M√©moire estim√©e en bytes
        """
        element_size = np.dtype(dtype).itemsize
        num_elements = np.prod(data_shape)

        # Ajouter 20% pour overhead CuPy
        return int(num_elements * element_size * 1.2)

    def can_allocate(self, size_bytes: int) -> bool:
        """
        V√©rifie si une allocation est possible.

        Args:
            size_bytes: Taille √† allouer en bytes

        Returns:
            True si allocation possible
        """
        mem_info = self.get_memory_info()

        if mem_info.status == MemoryStatus.UNAVAILABLE:
            return False

        # Garder une marge de s√©curit√© de 10%
        available = mem_info.free * 0.9
        return size_bytes <= available

    def check_and_prepare(self, required_bytes: int) -> bool:
        """
        V√©rifie la m√©moire et pr√©pare si n√©cessaire.

        Args:
            required_bytes: M√©moire requise

        Returns:
            True si pr√™t pour l'allocation
        """
        mem_info = self.get_memory_info()

        # GPU non disponible
        if mem_info.status == MemoryStatus.UNAVAILABLE:
            return False

        # V√©rifier si assez de m√©moire
        if self.can_allocate(required_bytes):
            return True

        # Tenter de lib√©rer la m√©moire
        if self.auto_clear:
            self.clear_memory()

            # Re-v√©rifier
            if self.can_allocate(required_bytes):
                return True

        return False

    def handle_oom(self, exc: Exception) -> bool:
        """
        G√®re une erreur OOM.

        Args:
            exc: Exception OOM captur√©e

        Returns:
            True si r√©cup√©ration tent√©e
        """
        self._oom_count += 1
        logger.warning(f"GPU OOM d√©tect√© (count={self._oom_count}): {exc}")

        # Tenter le nettoyage
        self.clear_memory()

        return True

    def safe_gpu_operation(self, func: Callable) -> Callable:
        """
        D√©corateur pour op√©rations GPU s√©curis√©es.

        Attrape les OOM et fallback vers CPU si configur√©.

        Example:
            >>> @handler.safe_gpu_operation
            >>> def gpu_compute(data):
            >>>     import cupy as cp
            >>>     return cp.sum(cp.array(data))
        """
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # V√©rifier m√©moire avant
            mem_info = self.get_memory_info()

            if mem_info.status == MemoryStatus.CRITICAL and self.auto_clear:
                self.clear_memory()

            try:
                return func(*args, **kwargs)

            except Exception as exc:
                # V√©rifier si c'est une erreur OOM
                error_msg = str(exc).lower()
                is_oom = any(w in error_msg for w in [
                    "out of memory", "oom", "memory allocation",
                    "cuda", "gpu memory", "cupy"
                ])

                if is_oom or isinstance(exc, MemoryError):
                    self.handle_oom(exc)

                    if self.fallback_to_cpu:
                        self._fallback_count += 1
                        logger.info("Fallback vers CPU...")

                        # Retenter avec numpy
                        return self._run_on_cpu(func, *args, **kwargs)

                raise

        return wrapper

    def _run_on_cpu(self, func: Callable, *args, **kwargs) -> Any:
        """
        Ex√©cute une fonction en for√ßant CPU.

        Convertit les arrays CuPy en NumPy.
        """
        try:
            import cupy as cp

            # Convertir les args cupy -> numpy
            new_args = []
            for arg in args:
                if isinstance(arg, cp.ndarray):
                    new_args.append(cp.asnumpy(arg))
                else:
                    new_args.append(arg)

            # Convertir les kwargs
            new_kwargs = {}
            for key, val in kwargs.items():
                if isinstance(val, cp.ndarray):
                    new_kwargs[key] = cp.asnumpy(val)
                else:
                    new_kwargs[key] = val

            return func(*new_args, **new_kwargs)

        except ImportError:
            # CuPy pas install√©, ex√©cuter directement
            return func(*args, **kwargs)

    @contextmanager
    def memory_guard(self, required_mb: float = 100):
        """
        Context manager pour op√©rations n√©cessitant de la m√©moire GPU.

        Args:
            required_mb: M√©moire requise en MB

        Example:
            >>> with handler.memory_guard(required_mb=500):
            >>>     result = heavy_gpu_computation()
        """
        required_bytes = int(required_mb * 1024 * 1024)

        # V√©rifier et pr√©parer
        if not self.check_and_prepare(required_bytes):
            if self.fallback_to_cpu:
                logger.warning(
                    f"M√©moire GPU insuffisante ({required_mb}MB requis), "
                    "utilisation CPU recommand√©e"
                )
            else:
                raise MemoryError(
                    f"M√©moire GPU insuffisante: {required_mb}MB requis, "
                    f"{self.get_memory_info().free_mb:.0f}MB disponible"
                )

        try:
            yield
        finally:
            # Nettoyage optionnel apr√®s l'op√©ration
            mem_info = self.get_memory_info()
            if mem_info.status in (MemoryStatus.LOW, MemoryStatus.CRITICAL):
                self.clear_memory()

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du handler."""
        mem_info = self.get_memory_info()

        return {
            "gpu_available": self._gpu_available,
            "oom_count": self._oom_count,
            "fallback_count": self._fallback_count,
            "memory_status": mem_info.status.value,
            "memory_free_mb": mem_info.free_mb,
            "memory_usage_percent": mem_info.usage_percent,
        }


# Singleton global
_oom_handler: Optional[GPUOOMHandler] = None


def get_oom_handler() -> GPUOOMHandler:
    """Retourne le handler OOM singleton."""
    global _oom_handler
    if _oom_handler is None:
        _oom_handler = GPUOOMHandler()
    return _oom_handler


def safe_gpu(func: Callable) -> Callable:
    """
    D√©corateur raccourci pour op√©rations GPU s√©curis√©es.

    Example:
        >>> @safe_gpu
        >>> def my_gpu_function(data):
        >>>     import cupy as cp
        >>>     return cp.sum(cp.array(data))
    """
    return get_oom_handler().safe_gpu_operation(func)


@contextmanager
def gpu_memory_guard(required_mb: float = 100):
    """Context manager raccourci pour garde m√©moire GPU."""
    with get_oom_handler().memory_guard(required_mb):
        yield


def clear_gpu_memory():
    """Lib√®re la m√©moire GPU."""
    return get_oom_handler().clear_memory()


def get_gpu_memory_status() -> GPUMemoryInfo:
    """Retourne le status m√©moire GPU."""
    return get_oom_handler().get_memory_info()


__all__ = [
    "MemoryStatus",
    "GPUMemoryInfo",
    "GPUOOMHandler",
    "get_oom_handler",
    "safe_gpu",
    "gpu_memory_guard",
    "clear_gpu_memory",
    "get_gpu_memory_status",
]
```
<!-- MODULE-END: gpu_oom.py -->

<!-- MODULE-START: gpu_utils.py -->
```json
{
  "name": "gpu_utils.py",
  "path": "utils\\gpu_utils.py",
  "ext": ".py",
  "anchor": "gpu_utils_py"
}
```
## gpu_utils_py
*Chemin* : `utils\gpu_utils.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.gpu_utils

Purpose: Utilitaires GPU - conversions CuPy‚ÜîNumPy, d√©tection GPU, interop CPU/GPU.

Role in pipeline: performance

Key components: ensure_numpy_array, ensure_cupy_array, is_gpu_available, ArrayBackend

Inputs: Array NumPy ou CuPy, flag force_cpu

Outputs: Converted array (NumPy ou CuPy), device info

Dependencies: numpy, cupy (optionnel), importlib

Conventions: D√©tection CuPy runtime; conversions transparentes; fallback NumPy si pas GPU.

Read-if: Modification conversions, d√©tection GPU.

Skip-if: Vous utilisez juste ensure_numpy_array().
"""

from typing import Any, Optional, Union

import numpy as np

try:
    import cupy as cp
    HAS_CUPY = True
except ImportError:
    HAS_CUPY = False
    cp = None


def ensure_numpy_array(
    arr: Union[np.ndarray, Any, None]
) -> Optional[np.ndarray]:
    """
    Convertit un array CuPy en NumPy, laisse les NumPy arrays inchang√©s.

    Cette fonction d√©tecte automatiquement si l'objet est un CuPy array
    (via l'attribut __cuda_array_interface__) et le convertit en NumPy.
    Les NumPy arrays sont retourn√©s tels quels (pas de copie).

    **Cas d'usage:**
    - Garantir compatibilit√© avec biblioth√®ques CPU (pandas, matplotlib)
    - Pr√©parer r√©sultats GPU pour s√©rialisation (pickle, JSON)
    - Interface entre code GPU et strat√©gies CPU

    **Performance:**
    - Transfert GPU‚ÜíCPU: ~1-5ms selon taille (overhead n√©gligeable)
    - NumPy‚ÜíNumPy: Aucune copie (0ms)

    Args:
        arr: Array √† convertir (CuPy, NumPy, ou autre)
             - Si CuPy array: converti en NumPy via cp.asnumpy()
             - Si NumPy array: retourn√© tel quel (pas de copie)
             - Si None: retourne None
             - Si scalaire (int, float): retourn√© tel quel

    Returns:
        NumPy array (ou None si input est None)

    Raises:
        TypeError: Si l'objet n'est pas convertible

    Examples:
        >>> # CuPy ‚Üí NumPy
        >>> import cupy as cp
        >>> gpu_arr = cp.array([1.0, 2.0, 3.0])
        >>> cpu_arr = ensure_numpy_array(gpu_arr)
        >>> type(cpu_arr)
        <class 'numpy.ndarray'>

        >>> # NumPy ‚Üí NumPy (pas de copie)
        >>> np_arr = np.array([1.0, 2.0, 3.0])
        >>> result = ensure_numpy_array(np_arr)
        >>> result is np_arr  # M√™me objet
        True

        >>> # Tuple de CuPy arrays
        >>> gpu_tuple = (cp.array([1]), cp.array([2]))
        >>> cpu_tuple = ensure_numpy_array(gpu_tuple)
        >>> all(isinstance(a, np.ndarray) for a in cpu_tuple)
        True

        >>> # None ‚Üí None
        >>> ensure_numpy_array(None) is None
        True

        >>> # Scalaires passent inchang√©s
        >>> ensure_numpy_array(42)
        42
    """
    # Cas 1: None
    if arr is None:
        return None

    # Cas 2: Scalaires (int, float, bool)
    if isinstance(arr, (int, float, bool, str)):
        return arr

    # Cas 3: Tuple ou liste d'arrays (r√©cursif)
    if isinstance(arr, (tuple, list)):
        converted = [ensure_numpy_array(item) for item in arr]
        return type(arr)(converted)  # Pr√©serve type (tuple vs list)

    # Cas 4: D√©j√† un NumPy array ‚Üí retour direct (pas de copie)
    if isinstance(arr, np.ndarray):
        return arr

    # Cas 5: CuPy array (d√©tection via CUDA Array Interface)
    # Ref: https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html
    if hasattr(arr, '__cuda_array_interface__'):
        if not HAS_CUPY:
            raise RuntimeError(
                "D√©tection d'un CuPy array mais CuPy n'est pas install√©. "
                "Installez CuPy: pip install cupy-cuda12x"
            )
        # Conversion GPU ‚Üí CPU
        return cp.asnumpy(arr)

    # Cas 6: Objet avec .get() (interface CuPy alternative)
    if hasattr(arr, 'get') and callable(arr.get):
        try:
            return arr.get()  # CuPy arrays ont .get() ‚Üí NumPy
        except Exception:
            pass  # Fallback vers erreur

    # Cas 7: Objet inconnu ‚Üí tentative de conversion NumPy
    try:
        return np.asarray(arr)
    except Exception as e:
        raise TypeError(
            f"Impossible de convertir {type(arr)} en NumPy array. "
            "Types support√©s: CuPy array, NumPy array, tuple/list, None. "
            f"Erreur: {e}"
        )


def is_cupy_array(arr: Any) -> bool:
    """
    V√©rifie si un objet est un CuPy array.

    Args:
        arr: Objet √† v√©rifier

    Returns:
        True si CuPy array, False sinon

    Examples:
        >>> import cupy as cp
        >>> is_cupy_array(cp.array([1, 2, 3]))
        True

        >>> import numpy as np
        >>> is_cupy_array(np.array([1, 2, 3]))
        False
    """
    return hasattr(arr, '__cuda_array_interface__')


def is_numpy_array(arr: Any) -> bool:
    """
    V√©rifie si un objet est un NumPy array.

    Args:
        arr: Objet √† v√©rifier

    Returns:
        True si NumPy array, False sinon

    Examples:
        >>> import numpy as np
        >>> is_numpy_array(np.array([1, 2, 3]))
        True

        >>> is_numpy_array([1, 2, 3])
        False
    """
    return isinstance(arr, np.ndarray)


def get_array_backend(arr: Any) -> str:
    """
    Retourne le backend de l'array ('cupy', 'numpy', 'unknown').

    Args:
        arr: Array √† inspecter

    Returns:
        'cupy', 'numpy', ou 'unknown'

    Examples:
        >>> import numpy as np
        >>> get_array_backend(np.array([1, 2, 3]))
        'numpy'

        >>> import cupy as cp
        >>> get_array_backend(cp.array([1, 2, 3]))
        'cupy'

        >>> get_array_backend([1, 2, 3])
        'unknown'
    """
    if is_cupy_array(arr):
        return 'cupy'
    elif is_numpy_array(arr):
        return 'numpy'
    else:
        return 'unknown'


# ======================== Tests Unitaires Int√©gr√©s ========================

def _test_ensure_numpy_array():
    """Tests unitaires pour ensure_numpy_array()."""
    print("=" * 70)
    print("TESTS: ensure_numpy_array()")
    print("=" * 70)

    # Test 1: NumPy ‚Üí NumPy (pas de copie)
    print("\n[Test 1] NumPy array ‚Üí NumPy (pas de copie)")
    np_arr = np.array([1.0, 2.0, 3.0])
    result = ensure_numpy_array(np_arr)
    assert result is np_arr, "‚ùå NumPy array devrait √™tre retourn√© tel quel"
    assert isinstance(result, np.ndarray), "‚ùå Type incorrect"
    print(f"‚úÖ PASS - Type: {type(result)}, Same object: {result is np_arr}")

    # Test 2: None ‚Üí None
    print("\n[Test 2] None ‚Üí None")
    result = ensure_numpy_array(None)
    assert result is None, "‚ùå None devrait retourner None"
    print(f"‚úÖ PASS - Result: {result}")

    # Test 3: Scalaires
    print("\n[Test 3] Scalaires (int, float)")
    assert ensure_numpy_array(42) == 42, "‚ùå Scalaire int √©choue"
    assert ensure_numpy_array(3.14) == 3.14, "‚ùå Scalaire float √©choue"
    assert ensure_numpy_array(True) is True, "‚ùå Scalaire bool √©choue"
    print("‚úÖ PASS - Scalaires: 42, 3.14, True")

    # Test 4: Tuple de NumPy arrays
    print("\n[Test 4] Tuple de NumPy arrays")
    tuple_arr = (np.array([1]), np.array([2]), np.array([3]))
    result = ensure_numpy_array(tuple_arr)
    assert isinstance(result, tuple), "‚ùå Devrait retourner tuple"
    assert all(isinstance(a, np.ndarray) for a in result), "‚ùå √âl√©ments pas NumPy"
    print(f"‚úÖ PASS - Tuple de {len(result)} arrays")

    # Test 5: CuPy ‚Üí NumPy (si disponible)
    if HAS_CUPY:
        print("\n[Test 5] CuPy array ‚Üí NumPy")
        gpu_arr = cp.array([1.0, 2.0, 3.0])
        cpu_arr = ensure_numpy_array(gpu_arr)
        assert isinstance(cpu_arr, np.ndarray), "‚ùå Conversion CuPy √©chou√©e"
        assert not is_cupy_array(cpu_arr), "‚ùå R√©sultat encore sur GPU"
        assert np.allclose(cpu_arr, [1.0, 2.0, 3.0]), "‚ùå Valeurs incorrectes"
        print(f"‚úÖ PASS - CuPy ‚Üí NumPy: {cpu_arr}")

        print("\n[Test 6] Tuple de CuPy arrays")
        gpu_tuple = (cp.array([1]), cp.array([2]))
        cpu_tuple = ensure_numpy_array(gpu_tuple)
        assert isinstance(cpu_tuple, tuple), "‚ùå Devrait retourner tuple"
        assert all(isinstance(a, np.ndarray) for a in cpu_tuple), "‚ùå √âl√©ments pas NumPy"
        print(f"‚úÖ PASS - Tuple de {len(cpu_tuple)} CuPy arrays converti")
    else:
        print("\n[Test 5-6] CuPy non disponible, tests skipp√©s")

    print("\n" + "=" * 70)
    print("‚úÖ TOUS LES TESTS PASS√âS")
    print("=" * 70)


if __name__ == '__main__':
    # Ex√©cuter les tests si lanc√© directement
    _test_ensure_numpy_array()
```
<!-- MODULE-END: gpu_utils.py -->

<!-- MODULE-START: health.py -->
```json
{
  "name": "health.py",
  "path": "utils\\health.py",
  "ext": ".py",
  "anchor": "health_py"
}
```
## health_py
*Chemin* : `utils\health.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.health

Purpose: Health Monitor - surveillance CPU/RAM/GPU/Disk avec alertes et seuils.

Role in pipeline: performance / monitoring

Key components: HealthMonitor, HealthMetrics, HealthAlert, Severity enum

Inputs: Seuils (%), polling intervals

Outputs: M√©triques sant√©, alertes, d√©clenchement actions

Dependencies: psutil, threading, dataclasses, cpu_percent, memory_percent

Conventions: Seuils configurables; alertes s√©v√©rit√© (CRITICAL/WARNING); polling asynchrone.

Read-if: Modification seuils, m√©triques collect√©es, ou actions alertes.

Skip-if: Vous utilisez juste HealthMonitor.check().
"""

from __future__ import annotations

import gc
import logging
import os
import platform
import threading
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

logger = logging.getLogger(__name__)


class HealthStatus(Enum):
    """√âtats de sant√© du syst√®me."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


class ResourceType(Enum):
    """Types de ressources surveill√©es."""
    CPU = "cpu"
    MEMORY = "memory"
    GPU = "gpu"
    DISK = "disk"


@dataclass
class ResourceMetrics:
    """M√©triques d'une ressource."""
    resource_type: ResourceType
    usage_percent: float
    available: float  # En bytes ou %
    total: float      # En bytes ou %
    status: HealthStatus = HealthStatus.UNKNOWN
    details: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "resource": self.resource_type.value,
            "usage_percent": round(self.usage_percent, 2),
            "available": self.available,
            "total": self.total,
            "status": self.status.value,
            "details": self.details,
            "timestamp": self.timestamp.isoformat(),
        }


@dataclass
class HealthThresholds:
    """Seuils pour les alertes de sant√©."""
    # CPU
    cpu_warning: float = 80.0
    cpu_critical: float = 95.0

    # Memory
    memory_warning: float = 75.0
    memory_critical: float = 90.0

    # GPU
    gpu_warning: float = 85.0
    gpu_critical: float = 95.0

    # Disk
    disk_warning: float = 80.0
    disk_critical: float = 95.0

    def get_status(self, resource: ResourceType, usage: float) -> HealthStatus:
        """D√©termine le status bas√© sur l'usage."""
        if resource == ResourceType.CPU:
            warning, critical = self.cpu_warning, self.cpu_critical
        elif resource == ResourceType.MEMORY:
            warning, critical = self.memory_warning, self.memory_critical
        elif resource == ResourceType.GPU:
            warning, critical = self.gpu_warning, self.gpu_critical
        elif resource == ResourceType.DISK:
            warning, critical = self.disk_warning, self.disk_critical
        else:
            return HealthStatus.UNKNOWN

        if usage >= critical:
            return HealthStatus.CRITICAL
        elif usage >= warning:
            return HealthStatus.WARNING
        else:
            return HealthStatus.HEALTHY


@dataclass
class HealthSnapshot:
    """Snapshot complet de l'√©tat de sant√©."""
    timestamp: datetime
    overall_status: HealthStatus
    metrics: Dict[ResourceType, ResourceMetrics]
    alerts: List[str] = field(default_factory=list)
    system_info: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "overall_status": self.overall_status.value,
            "metrics": {k.value: v.to_dict() for k, v in self.metrics.items()},
            "alerts": self.alerts,
            "system_info": self.system_info,
        }


class HealthMonitor:
    """
    Moniteur de sant√© du syst√®me.

    Surveille CPU, RAM, GPU et disque avec alertes configurables.

    Example:
        >>> monitor = HealthMonitor()
        >>> snapshot = monitor.check_health()
        >>> print(snapshot.overall_status)
        >>>
        >>> # Surveillance continue
        >>> monitor.start_monitoring(interval=5.0)
        >>> # ... plus tard ...
        >>> monitor.stop_monitoring()
    """

    def __init__(
        self,
        thresholds: Optional[HealthThresholds] = None,
        on_alert: Optional[Callable[[str, HealthStatus], None]] = None
    ):
        """
        Initialise le moniteur.

        Args:
            thresholds: Seuils d'alerte personnalis√©s
            on_alert: Callback appel√© lors d'une alerte
        """
        self.thresholds = thresholds or HealthThresholds()
        self.on_alert = on_alert

        self._monitoring = False
        self._monitor_thread: Optional[threading.Thread] = None
        self._history: List[HealthSnapshot] = []
        self._max_history = 1000
        self._lock = threading.Lock()

        # D√©tecter les libs disponibles
        self._has_psutil = self._check_psutil()
        self._has_gpu = self._check_gpu()

        logger.debug(f"HealthMonitor initialis√© (psutil={self._has_psutil}, gpu={self._has_gpu})")

    def _check_psutil(self) -> bool:
        """V√©rifie si psutil est disponible."""
        try:
            import psutil  # noqa: F401
            return True
        except ImportError:
            logger.warning("psutil non disponible - m√©triques CPU/RAM limit√©es")
            return False

    def _check_gpu(self) -> bool:
        """V√©rifie si le monitoring GPU est disponible."""
        try:
            import pynvml
            pynvml.nvmlInit()
            pynvml.nvmlShutdown()
            return True
        except (ImportError, Exception):
            try:
                # Fallback: essayer via CuPy
                import cupy
                cupy.cuda.runtime.getDeviceCount()
                return True
            except (ImportError, Exception):
                return False

    def get_cpu_metrics(self) -> ResourceMetrics:
        """R√©cup√®re les m√©triques CPU."""
        try:
            if self._has_psutil:
                import psutil
                usage = psutil.cpu_percent(interval=0.1)
                freq = psutil.cpu_freq()

                details = {
                    "cores": psutil.cpu_count(logical=False),
                    "threads": psutil.cpu_count(logical=True),
                    "frequency_mhz": freq.current if freq else 0,
                }
            else:
                # Estimation basique sans psutil
                usage = 0.0
                details = {"cores": os.cpu_count() or 1}

            status = self.thresholds.get_status(ResourceType.CPU, usage)

            return ResourceMetrics(
                resource_type=ResourceType.CPU,
                usage_percent=usage,
                available=100.0 - usage,
                total=100.0,
                status=status,
                details=details,
            )
        except Exception as e:
            logger.error(f"Erreur CPU metrics: {e}")
            return ResourceMetrics(
                resource_type=ResourceType.CPU,
                usage_percent=0,
                available=0,
                total=0,
                status=HealthStatus.UNKNOWN,
            )

    def get_memory_metrics(self) -> ResourceMetrics:
        """R√©cup√®re les m√©triques m√©moire."""
        try:
            if self._has_psutil:
                import psutil
                mem = psutil.virtual_memory()

                usage = mem.percent
                available = mem.available
                total = mem.total

                details = {
                    "used_gb": round(mem.used / (1024**3), 2),
                    "available_gb": round(mem.available / (1024**3), 2),
                    "total_gb": round(mem.total / (1024**3), 2),
                    "cached_gb": round(getattr(mem, 'cached', 0) / (1024**3), 2),
                }
            else:
                # Estimation basique via gc
                gc.collect()
                usage = 50.0  # Estimation par d√©faut
                available = 0
                total = 0
                details = {}

            status = self.thresholds.get_status(ResourceType.MEMORY, usage)

            return ResourceMetrics(
                resource_type=ResourceType.MEMORY,
                usage_percent=usage,
                available=available,
                total=total,
                status=status,
                details=details,
            )
        except Exception as e:
            logger.error(f"Erreur memory metrics: {e}")
            return ResourceMetrics(
                resource_type=ResourceType.MEMORY,
                usage_percent=0,
                available=0,
                total=0,
                status=HealthStatus.UNKNOWN,
            )

    def get_gpu_metrics(self) -> ResourceMetrics:
        """R√©cup√®re les m√©triques GPU."""
        if not self._has_gpu:
            return ResourceMetrics(
                resource_type=ResourceType.GPU,
                usage_percent=0,
                available=0,
                total=0,
                status=HealthStatus.UNKNOWN,
                details={"available": False},
            )

        try:
            import pynvml
            pynvml.nvmlInit()

            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
            utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
            name = pynvml.nvmlDeviceGetName(handle)

            pynvml.nvmlShutdown()

            mem_usage = (memory.used / memory.total) * 100

            details = {
                "name": name if isinstance(name, str) else name.decode(),
                "memory_used_gb": round(memory.used / (1024**3), 2),
                "memory_total_gb": round(memory.total / (1024**3), 2),
                "gpu_utilization": utilization.gpu,
                "memory_utilization": utilization.memory,
            }

            status = self.thresholds.get_status(ResourceType.GPU, mem_usage)

            return ResourceMetrics(
                resource_type=ResourceType.GPU,
                usage_percent=mem_usage,
                available=memory.free,
                total=memory.total,
                status=status,
                details=details,
            )
        except Exception as e:
            logger.debug(f"GPU metrics via pynvml √©chou√©: {e}")

            # Fallback CuPy
            try:
                import cupy as cp

                mempool = cp.get_default_memory_pool()
                mem_used = mempool.used_bytes()
                mem_total = mempool.total_bytes() or (8 * 1024**3)  # D√©faut 8GB

                usage = (mem_used / mem_total) * 100 if mem_total > 0 else 0

                return ResourceMetrics(
                    resource_type=ResourceType.GPU,
                    usage_percent=usage,
                    available=mem_total - mem_used,
                    total=mem_total,
                    status=self.thresholds.get_status(ResourceType.GPU, usage),
                    details={"via": "cupy"},
                )
            except Exception:
                return ResourceMetrics(
                    resource_type=ResourceType.GPU,
                    usage_percent=0,
                    available=0,
                    total=0,
                    status=HealthStatus.UNKNOWN,
                )

    def get_disk_metrics(self, path: str = ".") -> ResourceMetrics:
        """R√©cup√®re les m√©triques disque."""
        try:
            if self._has_psutil:
                import psutil
                disk = psutil.disk_usage(path)

                usage = disk.percent
                available = disk.free
                total = disk.total

                details = {
                    "path": os.path.abspath(path),
                    "used_gb": round(disk.used / (1024**3), 2),
                    "free_gb": round(disk.free / (1024**3), 2),
                    "total_gb": round(disk.total / (1024**3), 2),
                }
            else:
                # Fallback basique
                import shutil
                total, used, free = shutil.disk_usage(path)
                usage = (used / total) * 100
                available = free
                details = {
                    "path": os.path.abspath(path),
                    "free_gb": round(free / (1024**3), 2),
                }

            status = self.thresholds.get_status(ResourceType.DISK, usage)

            return ResourceMetrics(
                resource_type=ResourceType.DISK,
                usage_percent=usage,
                available=available,
                total=total,
                status=status,
                details=details,
            )
        except Exception as e:
            logger.error(f"Erreur disk metrics: {e}")
            return ResourceMetrics(
                resource_type=ResourceType.DISK,
                usage_percent=0,
                available=0,
                total=0,
                status=HealthStatus.UNKNOWN,
            )

    def get_system_info(self) -> Dict[str, Any]:
        """R√©cup√®re les informations syst√®me."""
        info = {
            "platform": platform.system(),
            "platform_release": platform.release(),
            "platform_version": platform.version(),
            "architecture": platform.machine(),
            "processor": platform.processor(),
            "python_version": platform.python_version(),
            "hostname": platform.node(),
        }

        if self._has_psutil:
            import psutil
            boot_time = datetime.fromtimestamp(psutil.boot_time())
            uptime = datetime.now() - boot_time
            info["uptime_hours"] = round(uptime.total_seconds() / 3600, 2)
            info["boot_time"] = boot_time.isoformat()

        return info

    def check_health(self) -> HealthSnapshot:
        """
        Effectue un check de sant√© complet.

        Returns:
            HealthSnapshot avec toutes les m√©triques
        """
        metrics = {
            ResourceType.CPU: self.get_cpu_metrics(),
            ResourceType.MEMORY: self.get_memory_metrics(),
            ResourceType.GPU: self.get_gpu_metrics(),
            ResourceType.DISK: self.get_disk_metrics(),
        }

        # D√©terminer le status global
        statuses = [m.status for m in metrics.values() if m.status != HealthStatus.UNKNOWN]

        if any(s == HealthStatus.CRITICAL for s in statuses):
            overall = HealthStatus.CRITICAL
        elif any(s == HealthStatus.WARNING for s in statuses):
            overall = HealthStatus.WARNING
        elif statuses:
            overall = HealthStatus.HEALTHY
        else:
            overall = HealthStatus.UNKNOWN

        # G√©n√©rer les alertes
        alerts = []
        for resource, metric in metrics.items():
            if metric.status == HealthStatus.CRITICAL:
                alert = f"CRITICAL: {resource.value} √† {metric.usage_percent:.1f}%"
                alerts.append(alert)
                if self.on_alert:
                    self.on_alert(alert, HealthStatus.CRITICAL)
            elif metric.status == HealthStatus.WARNING:
                alert = f"WARNING: {resource.value} √† {metric.usage_percent:.1f}%"
                alerts.append(alert)
                if self.on_alert:
                    self.on_alert(alert, HealthStatus.WARNING)

        snapshot = HealthSnapshot(
            timestamp=datetime.now(),
            overall_status=overall,
            metrics=metrics,
            alerts=alerts,
            system_info=self.get_system_info(),
        )

        # Ajouter √† l'historique
        with self._lock:
            self._history.append(snapshot)
            if len(self._history) > self._max_history:
                self._history = self._history[-self._max_history:]

        return snapshot

    def get_history(self, last_n: int = 100) -> List[HealthSnapshot]:
        """Retourne les derniers snapshots."""
        with self._lock:
            return list(self._history[-last_n:])

    def get_average_usage(
        self,
        resource: ResourceType,
        duration_minutes: int = 5
    ) -> float:
        """Calcule l'usage moyen sur une p√©riode."""
        cutoff = datetime.now() - timedelta(minutes=duration_minutes)

        with self._lock:
            recent = [
                s.metrics[resource].usage_percent
                for s in self._history
                if s.timestamp >= cutoff and resource in s.metrics
            ]

        if not recent:
            return 0.0

        return sum(recent) / len(recent)

    def start_monitoring(self, interval: float = 10.0) -> None:
        """
        D√©marre la surveillance continue.

        Args:
            interval: Intervalle entre les checks en secondes
        """
        if self._monitoring:
            logger.warning("Monitoring d√©j√† actif")
            return

        self._monitoring = True

        def monitor_loop():
            while self._monitoring:
                try:
                    self.check_health()
                except Exception as e:
                    logger.error(f"Erreur monitoring: {e}")
                time.sleep(interval)

        self._monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self._monitor_thread.start()
        logger.info(f"Monitoring d√©marr√© (interval={interval}s)")

    def stop_monitoring(self) -> None:
        """Arr√™te la surveillance continue."""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=5.0)
            self._monitor_thread = None
        logger.info("Monitoring arr√™t√©")

    def is_healthy(self) -> bool:
        """V√©rifie si le syst√®me est en bonne sant√©."""
        snapshot = self.check_health()
        return snapshot.overall_status == HealthStatus.HEALTHY

    def wait_for_resources(
        self,
        memory_threshold: float = 80.0,
        timeout: float = 60.0,
        check_interval: float = 1.0
    ) -> bool:
        """
        Attend que les ressources soient disponibles.

        Utile avant de lancer une op√©ration lourde.

        Args:
            memory_threshold: Seuil de m√©moire acceptable
            timeout: Timeout en secondes
            check_interval: Intervalle de v√©rification

        Returns:
            True si ressources disponibles, False si timeout
        """
        start = time.time()

        while time.time() - start < timeout:
            mem = self.get_memory_metrics()

            if mem.usage_percent < memory_threshold:
                return True

            logger.debug(f"Attente ressources: RAM √† {mem.usage_percent:.1f}%")
            gc.collect()
            time.sleep(check_interval)

        logger.warning(f"Timeout attente ressources apr√®s {timeout}s")
        return False

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel de l'√©tat."""
        snapshot = self.check_health()

        lines = [
            "=== Health Monitor ===",
            f"Status: {snapshot.overall_status.value.upper()}",
            f"Time: {snapshot.timestamp.strftime('%H:%M:%S')}",
            "",
        ]

        for resource, metric in snapshot.metrics.items():
            status_icon = {
                HealthStatus.HEALTHY: "‚úÖ",
                HealthStatus.WARNING: "‚ö†Ô∏è",
                HealthStatus.CRITICAL: "üî¥",
                HealthStatus.UNKNOWN: "‚ùì",
            }.get(metric.status, "?")

            lines.append(f"{status_icon} {resource.value.upper()}: {metric.usage_percent:.1f}%")

        if snapshot.alerts:
            lines.append("")
            lines.append("Alerts:")
            for alert in snapshot.alerts:
                lines.append(f"  - {alert}")

        return "\n".join(lines)


# Singleton global
_monitor: Optional[HealthMonitor] = None


def get_health_monitor() -> HealthMonitor:
    """Retourne le moniteur de sant√© singleton."""
    global _monitor
    if _monitor is None:
        _monitor = HealthMonitor()
    return _monitor


def check_system_health() -> HealthSnapshot:
    """Raccourci pour v√©rifier la sant√© syst√®me."""
    return get_health_monitor().check_health()


def is_system_healthy() -> bool:
    """Raccourci pour v√©rifier si le syst√®me est sain."""
    return get_health_monitor().is_healthy()


__all__ = [
    "HealthStatus",
    "ResourceType",
    "ResourceMetrics",
    "HealthThresholds",
    "HealthSnapshot",
    "HealthMonitor",
    "get_health_monitor",
    "check_system_health",
    "is_system_healthy",
]
```
<!-- MODULE-END: health.py -->

<!-- MODULE-START: indicator_ranges.py -->
```json
{
  "name": "indicator_ranges.py",
  "path": "utils\\indicator_ranges.py",
  "ext": ".py",
  "anchor": "indicator_ranges_py"
}
```
## indicator_ranges_py
*Chemin* : `utils\indicator_ranges.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.indicator_ranges

Purpose: Charge plages param√©triques d'indicateurs depuis config/indicator_ranges.toml.

Role in pipeline: configuration

Key components: load_indicator_ranges(), _INDICATOR_RANGES_CACHE, tomllib wrapper

Inputs: TOML file config/indicator_ranges.toml

Outputs: Dict nested {indicator ‚Üí param ‚Üí spec} (cached)

Dependencies: tomllib/tomli, pathlib

Conventions: Cache global; None path ‚Üí r√©pertoire par d√©faut.

Read-if: Modification chargement config indicateurs.

Skip-if: Vous appelez load_indicator_ranges() en tant qu'utilisateur.
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Optional, TypedDict, Union

try:
    import tomllib
except ModuleNotFoundError:  # pragma: no cover - fallback for older Python
    import tomli as tomllib


class ParamSpec(TypedDict, total=False):
    """
    Sp√©cification d'un param√®tre d'indicateur.

    Attributes:
        min: Valeur minimale
        max: Valeur maximale
        step: Pas d'incr√©mentation
        default: Valeur par d√©faut
        description: Description du param√®tre
        options: Liste d'options valides (pour param√®tres cat√©goriels)
        type: Type explicite ("string", "bool", etc.)
    """
    min: Union[int, float]
    max: Union[int, float]
    step: Union[int, float]
    default: Union[int, float, str, bool]
    description: str
    options: List[str]
    type: str


_INDICATOR_RANGES_CACHE: Optional[Dict[str, Dict[str, ParamSpec]]] = None


def load_indicator_ranges(path: Optional[Path] = None) -> Dict[str, Dict[str, ParamSpec]]:
    """
    Load indicator ranges from TOML.

    Args:
        path: Optional custom path to the TOML file.
              If None, uses config/indicator_ranges.toml.

    Returns:
        Nested dict from TOML (indicator -> param -> spec).
        Example: {"rsi": {"period": {"min": 7, "max": 21, "default": 14, ...}}}

    Raises:
        ValueError: If TOML file is corrupted.

    Note:
        Results are cached when path=None for performance.
    """
    global _INDICATOR_RANGES_CACHE

    use_cache = path is None
    if _INDICATOR_RANGES_CACHE is not None and use_cache:
        return _INDICATOR_RANGES_CACHE

    if path is None:
        path = Path(__file__).resolve().parents[1] / "config" / "indicator_ranges.toml"

    if not path.exists():
        raise FileNotFoundError(
            f"Fichier de configuration introuvable: {path}\n"
            f"Cr√©ez le fichier config/indicator_ranges.toml ou sp√©cifiez un chemin valide."
        )

    try:
        with path.open("rb") as handle:
            data = tomllib.load(handle)
    except PermissionError as e:
        raise PermissionError(
            f"Acc√®s refus√© au fichier: {path}\n"
            f"V√©rifiez les permissions du fichier."
        ) from e
    except (tomllib.TOMLDecodeError if hasattr(tomllib, 'TOMLDecodeError') else Exception) as e:
        raise ValueError(
            f"Fichier TOML corrompu ou invalide: {path}\n"
            f"Erreur de parsing: {e}"
        ) from e
    except Exception as e:
        raise RuntimeError(
            f"Erreur inattendue lors du chargement de {path}: {e}"
        ) from e

    if use_cache:
        _INDICATOR_RANGES_CACHE = data

    return data


def get_indicator_param_specs(
    indicator_name: str,
    ranges: Optional[Dict[str, Dict[str, ParamSpec]]] = None
) -> Dict[str, ParamSpec]:
    """
    Return parameter specs for a single indicator.

    Args:
        indicator_name: Nom de l'indicateur (case-insensitive).
        ranges: Optional pre-loaded ranges dict. If None, loads from default path.

    Returns:
        Dict mapping parameter names to their specifications.
        Example: {"period": {"min": 7, "max": 21, "default": 14, ...}}

    Example:
        >>> specs = get_indicator_param_specs("rsi")
        >>> specs["period"]["default"]
        14
    """
    if ranges is None:
        ranges = load_indicator_ranges()

    return ranges.get(indicator_name.lower(), {})


__all__ = ["load_indicator_ranges", "get_indicator_param_specs", "ParamSpec"]
```
<!-- MODULE-END: indicator_ranges.py -->

<!-- MODULE-START: llm_memory.py -->
```json
{
  "name": "llm_memory.py",
  "path": "utils\\llm_memory.py",
  "ext": ".py",
  "anchor": "llm_memory_py"
}
```
## llm_memory_py
*Chemin* : `utils\llm_memory.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.llm_memory

Purpose: Lightweight memory pour runs LLM - session ephemeral + history JSONL append-only.

Role in pipeline: orchestration / data

Key components: SessionMemory, HistoryStorage, LLMMemoryTracker, approved-only persistence

Inputs: Session id, strategy/symbol/timeframe, propositions + √©valuations

Outputs: Fichiers JSON session (mutable), JSONL history (append-only)

Dependencies: json, pathlib, datetime, collections

Conventions: Session mutable par run; history immuable (approved results); dirs runs/llm_memory/session et history.

Read-if: Modification format fichiers, logique session/history.

Skip-if: Vous utilisez juste LLMMemoryTracker.save().
"""

from __future__ import annotations

import json
import re
from collections import deque
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

DEFAULT_BASE_DIR = Path("runs") / "llm_memory"
SESSION_DIRNAME = "session"
HISTORY_DIRNAME = "history"
DEFAULT_MAX_ENTRIES = 3
MAX_INSIGHTS = 5


def _utc_now_iso() -> str:
    ts = datetime.now(timezone.utc).replace(microsecond=0)
    return ts.isoformat().replace("+00:00", "Z")


def _safe_segment(value: Optional[str], fallback: str) -> str:
    if value is None:
        return fallback
    text = str(value).strip()
    if not text:
        return fallback
    text = text.replace(" ", "_")
    text = re.sub(r"[^A-Za-z0-9_.-]", "_", text)
    return text or fallback


def _ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def get_session_path(session_id: str, base_dir: Path = DEFAULT_BASE_DIR) -> Path:
    safe_id = _safe_segment(session_id, "session")
    return base_dir / SESSION_DIRNAME / f"{safe_id}.json"


def get_history_path(
    strategy: str,
    symbol: str,
    timeframe: str,
    base_dir: Path = DEFAULT_BASE_DIR,
) -> Path:
    safe_strategy = _safe_segment(strategy, "unknown_strategy")
    safe_symbol = _safe_segment(symbol, "unknown_symbol")
    safe_timeframe = _safe_segment(timeframe, "unknown_timeframe")
    return (
        base_dir
        / HISTORY_DIRNAME
        / safe_strategy
        / safe_symbol
        / f"{safe_timeframe}.jsonl"
    )


def extract_date_range(data: Any) -> Tuple[str, str]:
    if data is None:
        return "", ""
    try:
        import pandas as pd
    except Exception:
        return "", ""

    try:
        if hasattr(data, "index") and isinstance(data.index, pd.DatetimeIndex):
            start = data.index[0]
            end = data.index[-1]
            return str(start), str(end)

        if isinstance(data, pd.DataFrame):
            if "timestamp" in data.columns or "date" in data.columns:
                col = "timestamp" if "timestamp" in data.columns else "date"
                dates = pd.to_datetime(data[col])
                return str(dates.iloc[0]), str(dates.iloc[-1])
    except Exception:
        return "", ""

    return "", ""


def split_date_range(value: Optional[str]) -> Tuple[str, str]:
    if not value:
        return "", ""
    text = str(value)
    if "->" in text:
        start, end = text.split("->", 1)
        return start.strip(), end.strip()
    if "\u2192" in text:
        start, end = text.split("\u2192", 1)
        return start.strip(), end.strip()
    return text.strip(), ""


def _read_json(path: Path) -> Dict[str, Any]:
    if not path.exists():
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict):
            return data
    except Exception:
        return {}
    return {}


def _write_json(path: Path, payload: Dict[str, Any]) -> None:
    _ensure_dir(path.parent)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2, ensure_ascii=True)


def start_session(
    session_id: str,
    *,
    strategy: str,
    symbol: str,
    timeframe: str,
    period_start: str,
    period_end: str,
    model: str,
    data_rows: int,
    base_dir: Path = DEFAULT_BASE_DIR,
) -> Path:
    session_path = get_session_path(session_id, base_dir=base_dir)
    payload = {
        "session_id": session_id,
        "status": "running",
        "started_at": _utc_now_iso(),
        "updated_at": _utc_now_iso(),
        "strategy": strategy,
        "symbol": symbol,
        "timeframe": timeframe,
        "period_start": period_start,
        "period_end": period_end,
        "model": model,
        "data_rows": data_rows,
        "iterations": [],
    }
    _write_json(session_path, payload)
    return session_path


def append_session_iteration(
    session_path: Path,
    entry: Dict[str, Any],
) -> None:
    payload = _read_json(session_path)
    iterations = payload.get("iterations", [])
    if not isinstance(iterations, list):
        iterations = []
    iterations.append(entry)
    payload["iterations"] = iterations
    payload["updated_at"] = _utc_now_iso()
    _write_json(session_path, payload)


def set_session_status(session_path: Path, status: str) -> None:
    payload = _read_json(session_path)
    payload["status"] = status
    payload["updated_at"] = _utc_now_iso()
    _write_json(session_path, payload)


def delete_session(session_path: Path) -> bool:
    try:
        if session_path.exists():
            session_path.unlink()
            return True
    except Exception:
        return False
    return False


def append_history_entry(
    history_path: Path,
    entry: Dict[str, Any],
) -> None:
    _ensure_dir(history_path.parent)
    with open(history_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=True) + "\n")


def load_recent_history_entries(
    history_path: Path,
    limit: int = DEFAULT_MAX_ENTRIES,
) -> List[Dict[str, Any]]:
    if limit <= 0 or not history_path.exists():
        return []
    buffer: deque[Dict[str, Any]] = deque(maxlen=limit)
    try:
        with open(history_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    entry = json.loads(line)
                except Exception:
                    continue
                if isinstance(entry, dict):
                    buffer.append(entry)
    except Exception:
        return []
    return list(buffer)


def build_memory_summary(
    strategy: str,
    symbol: str,
    timeframe: str,
    limit: int = DEFAULT_MAX_ENTRIES,
    base_dir: Path = DEFAULT_BASE_DIR,
) -> str:
    history_path = get_history_path(
        strategy=strategy,
        symbol=symbol,
        timeframe=timeframe,
        base_dir=base_dir,
    )
    entries = load_recent_history_entries(history_path, limit=limit)
    if not entries:
        return ""
    lines = []
    for entry in entries:
        line = _format_history_line(entry)
        if line:
            lines.append(f"- {line}")
    return "\n".join(lines)


def _format_history_line(entry: Dict[str, Any]) -> str:
    timestamp = entry.get("timestamp") or entry.get("approved_at") or ""
    date = _format_date(timestamp)

    metrics = entry.get("metrics", {}) if isinstance(entry.get("metrics"), dict) else {}
    sharpe = _format_float(metrics.get("sharpe_ratio"))
    ret_pct = _format_pct(metrics.get("total_return_pct"))
    dd_pct = _format_pct(metrics.get("max_drawdown_pct"))
    win_pct = _format_pct(metrics.get("win_rate_pct"))
    trades = metrics.get("total_trades")

    parts = [date, f"sharpe={sharpe}"]
    if ret_pct != "n/a":
        parts.append(f"ret={ret_pct}")
    if dd_pct != "n/a":
        parts.append(f"dd={dd_pct}")
    if win_pct != "n/a":
        parts.append(f"win={win_pct}")
    if trades is not None:
        parts.append(f"trades={trades}")

    line = " ".join(parts)

    params = entry.get("params", {}) if isinstance(entry.get("params"), dict) else {}
    params_summary = _summarize_params(params, limit=3)
    if params_summary:
        line += f" | params: {params_summary}"

    insights = entry.get("insights", [])
    if isinstance(insights, list) and insights:
        note = str(insights[0])
        if note:
            line += f" | note: {note}"

    return line


def _format_date(value: str) -> str:
    if not value:
        return "n/a"
    text = str(value)
    try:
        normalized = text.replace("Z", "+00:00")
        dt = datetime.fromisoformat(normalized)
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return text


def _format_float(value: Any) -> str:
    try:
        return f"{float(value):.3f}"
    except Exception:
        return "n/a"


def _format_pct(value: Any) -> str:
    try:
        val = float(value)
    except Exception:
        return "n/a"
    if abs(val) <= 1.0 and abs(val) > 0.0001:
        val *= 100.0
    return f"{val:.1f}%"


def _summarize_params(params: Dict[str, Any], limit: int = 3) -> str:
    if not params:
        return ""
    items = sorted(params.items(), key=lambda kv: str(kv[0]))
    parts = []
    for key, value in items[:limit]:
        parts.append(f"{key}={_format_param(value)}")
    return " ".join(parts)


def _format_param(value: Any) -> str:
    if isinstance(value, float):
        return f"{value:.4g}"
    return str(value)
```
<!-- MODULE-END: llm_memory.py -->

<!-- MODULE-START: log.py -->
```json
{
  "name": "log.py",
  "path": "utils\\log.py",
  "ext": ".py",
  "anchor": "log_py"
}
```
## log_py
*Chemin* : `utils\log.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.log

Purpose: Logging simplifi√© avec colorisation optionnelle (legacy).

Role in pipeline: core

Key components: get_logger, ColoredFormatter, setup_logging

Inputs: Module name, level (DEBUG/INFO/WARNING/ERROR)

Outputs: Logger configur√© avec couleurs optionnelles

Dependencies: logging, colorama (optionnel), sys

Conventions: Colorama auto-detect; fallback sans couleurs; logger par module.

Read-if: Modification format logs, niveaux, couleurs.

Skip-if: Vous utilisez juste get_logger().
"""

import logging
import sys
from typing import Optional

# Import optionnel de colorama pour logs color√©s
try:
    from colorama import Fore, Style, init
    init(autoreset=True)
    COLORAMA_AVAILABLE = True
except ImportError:
    COLORAMA_AVAILABLE = False
    # Fallback: pas de couleurs

    class _DummyColor:
        def __getattr__(self, name):
            return ""

    Fore = Style = _DummyColor()

# Cache des loggers pour √©viter duplication
_loggers: dict[str, logging.Logger] = {}


class ColoredFormatter(logging.Formatter):
    """Formatter avec colorisation par niveau de log."""

    # Couleurs par niveau
    COLORS = {
        logging.DEBUG: Fore.CYAN,
        logging.INFO: Fore.GREEN,
        logging.WARNING: Fore.YELLOW,
        logging.ERROR: Fore.RED,
        logging.CRITICAL: Fore.RED + Style.BRIGHT,
    }

    def format(self, record):
        """Formate le message avec couleurs."""
        if COLORAMA_AVAILABLE:
            # Appliquer la couleur selon le niveau
            levelname_color = self.COLORS.get(record.levelno, "")
            record.levelname = f"{levelname_color}{record.levelname}{Style.RESET_ALL}"
        return super().format(record)


def get_logger(name: Optional[str] = None) -> logging.Logger:
    """
    Obtient un logger configur√© pour le module sp√©cifi√©.

    Args:
        name: Nom du module (utilise __name__ g√©n√©ralement)

    Returns:
        Logger configur√© avec format standard
    """
    if name is None:
        name = "backtest_core"

    # Retourner le logger en cache si existe
    if name in _loggers:
        return _loggers[name]

    # Cr√©er nouveau logger
    logger = logging.getLogger(name)

    # √âviter duplication si d√©j√† configur√©
    if not logger.handlers:
        logger.setLevel(logging.INFO)

        # Handler console
        handler = logging.StreamHandler(sys.stdout)
        handler.setLevel(logging.INFO)

        # Format simple et lisible avec colorisation
        formatter = ColoredFormatter(
            "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s",
            datefmt="%H:%M:%S"
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        # √âviter propagation vers le root logger
        logger.propagate = False

    _loggers[name] = logger
    return logger


def set_level(level: str) -> None:
    """
    Change le niveau de log global.

    Args:
        level: 'DEBUG', 'INFO', 'WARNING', 'ERROR'
    """
    level_map = {
        'DEBUG': logging.DEBUG,
        'INFO': logging.INFO,
        'WARNING': logging.WARNING,
        'ERROR': logging.ERROR
    }

    log_level = level_map.get(level.upper(), logging.INFO)

    for logger in _loggers.values():
        logger.setLevel(log_level)
        for handler in logger.handlers:
            handler.setLevel(log_level)


class CountingHandler(logging.Handler):
    """
    Handler qui compte les warnings et erreurs pour statistiques de run.

    Usage:
        counting_handler = CountingHandler()
        logger.addHandler(counting_handler)

        # Plus tard
        warnings_count = counting_handler.warnings
        errors_count = counting_handler.errors
    """

    def __init__(self):
        """Initialise le compteur."""
        super().__init__()
        self.warnings = 0
        self.errors = 0

    def emit(self, record):
        """Compte les warnings et erreurs."""
        if record.levelno == logging.WARNING:
            self.warnings += 1
        elif record.levelno >= logging.ERROR:
            self.errors += 1

    def reset(self):
        """R√©initialise les compteurs."""
        self.warnings = 0
        self.errors = 0


__all__ = ["get_logger", "set_level", "CountingHandler"]
```
<!-- MODULE-END: log.py -->

<!-- MODULE-START: memory.py -->
```json
{
  "name": "memory.py",
  "path": "utils\\memory.py",
  "ext": ".py",
  "anchor": "memory_py"
}
```
## memory_py
*Chemin* : `utils\memory.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.memory

Purpose: Gestion m√©moire intelligente (nettoyage auto, cache LRU, thresholds Windows).

Role in pipeline: performance / resilience

Key components: MemoryManager, ManagedCache, memory_pressure, cleanup_callback

Inputs: Thresholds (%, MB), objects √† tracker

Outputs: Notifications pression m√©moire, cache evictions

Dependencies: gc, psutil, threading, weakref, dataclasses

Conventions: Seuils configurables; thread-safe; integration Health Monitor; Windows-optimized.

Read-if: Modification thresholds, logique LRU, ou callbacks cleanup.

Skip-if: Vous utilisez juste MemoryManager.check().
"""

from __future__ import annotations

import gc
import logging
import threading
import time
import weakref
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Any, Callable, Dict, Generator, List, Optional, Set

logger = logging.getLogger(__name__)


@dataclass
class MemoryConfig:
    """Configuration du gestionnaire m√©moire."""

    # Seuils (en pourcentage)
    warning_threshold: float = 75.0
    critical_threshold: float = 90.0
    cleanup_threshold: float = 80.0

    # Comportement
    auto_cleanup: bool = True
    cleanup_interval: float = 30.0  # secondes
    aggressive_cleanup: bool = False

    # Limites
    max_cache_size_mb: float = 1024.0  # 1 GB
    max_array_size_mb: float = 512.0   # 512 MB

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "warning_threshold": self.warning_threshold,
            "critical_threshold": self.critical_threshold,
            "cleanup_threshold": self.cleanup_threshold,
            "auto_cleanup": self.auto_cleanup,
            "cleanup_interval": self.cleanup_interval,
            "aggressive_cleanup": self.aggressive_cleanup,
            "max_cache_size_mb": self.max_cache_size_mb,
            "max_array_size_mb": self.max_array_size_mb,
        }


@dataclass
class MemoryStats:
    """Statistiques m√©moire."""

    total_cleanups: int = 0
    bytes_freed: int = 0
    peak_usage_mb: float = 0.0
    current_usage_mb: float = 0.0
    managed_objects: int = 0
    cache_hits: int = 0
    cache_misses: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "total_cleanups": self.total_cleanups,
            "bytes_freed_mb": round(self.bytes_freed / (1024**2), 2),
            "peak_usage_mb": round(self.peak_usage_mb, 2),
            "current_usage_mb": round(self.current_usage_mb, 2),
            "managed_objects": self.managed_objects,
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
        }


class ManagedCache:
    """
    Cache avec gestion automatique de la taille.

    √âviction LRU quand la taille maximale est atteinte.
    """

    def __init__(self, max_size_mb: float = 512.0, name: str = "cache"):
        """
        Args:
            max_size_mb: Taille maximale en MB
            name: Nom du cache (pour logging)
        """
        self.max_size_bytes = int(max_size_mb * 1024 * 1024)
        self.name = name

        self._cache: Dict[str, Any] = {}
        self._access_order: List[str] = []
        self._sizes: Dict[str, int] = {}
        self._current_size = 0
        self._lock = threading.Lock()

        self._stats = MemoryStats()

    def _estimate_size(self, obj: Any) -> int:
        """Estime la taille d'un objet en bytes."""
        try:
            import numpy as np
            if isinstance(obj, np.ndarray):
                return obj.nbytes
        except ImportError:
            pass

        try:
            import pandas as pd
            if isinstance(obj, (pd.DataFrame, pd.Series)):
                return obj.memory_usage(deep=True).sum() if hasattr(obj, 'memory_usage') else 0
        except ImportError:
            pass

        # Estimation g√©n√©rique
        import sys
        return sys.getsizeof(obj)

    def get(self, key: str, default: Any = None) -> Any:
        """R√©cup√®re une valeur du cache."""
        with self._lock:
            if key in self._cache:
                # Mettre √† jour l'ordre d'acc√®s (LRU)
                if key in self._access_order:
                    self._access_order.remove(key)
                self._access_order.append(key)
                self._stats.cache_hits += 1
                return self._cache[key]

            self._stats.cache_misses += 1
            return default

    def set(self, key: str, value: Any) -> bool:
        """
        Ajoute une valeur au cache.

        Returns:
            True si ajout√©, False si trop gros
        """
        size = self._estimate_size(value)

        # V√©rifier si l'objet seul est trop gros
        if size > self.max_size_bytes:
            logger.warning(f"Objet trop gros pour cache {self.name}: {size / (1024**2):.1f} MB")
            return False

        with self._lock:
            # √âviction LRU si n√©cessaire
            while self._current_size + size > self.max_size_bytes and self._access_order:
                oldest_key = self._access_order.pop(0)
                if oldest_key in self._cache:
                    old_size = self._sizes.get(oldest_key, 0)
                    del self._cache[oldest_key]
                    del self._sizes[oldest_key]
                    self._current_size -= old_size
                    logger.debug(f"Cache {self.name}: √©viction de {oldest_key}")

            # Supprimer l'ancienne valeur si existe
            if key in self._cache:
                old_size = self._sizes.get(key, 0)
                self._current_size -= old_size
                if key in self._access_order:
                    self._access_order.remove(key)

            # Ajouter la nouvelle valeur
            self._cache[key] = value
            self._sizes[key] = size
            self._access_order.append(key)
            self._current_size += size

            return True

    def delete(self, key: str) -> bool:
        """Supprime une entr√©e du cache."""
        with self._lock:
            if key in self._cache:
                size = self._sizes.get(key, 0)
                del self._cache[key]
                del self._sizes[key]
                self._current_size -= size
                if key in self._access_order:
                    self._access_order.remove(key)
                return True
            return False

    def clear(self) -> int:
        """Vide le cache et retourne les bytes lib√©r√©s."""
        with self._lock:
            freed = self._current_size
            self._cache.clear()
            self._sizes.clear()
            self._access_order.clear()
            self._current_size = 0
            return freed

    def size_mb(self) -> float:
        """Retourne la taille actuelle en MB."""
        return self._current_size / (1024**2)

    def __len__(self) -> int:
        return len(self._cache)

    def __contains__(self, key: str) -> bool:
        return key in self._cache


class MemoryManager:
    """
    Gestionnaire de m√©moire intelligent.

    Features:
    - Surveillance automatique de l'usage m√©moire
    - Nettoyage intelligent (garbage collection)
    - Gestion de caches avec √©viction LRU
    - Support objets faibles (weak references)

    Example:
        >>> manager = MemoryManager()
        >>> manager.start_auto_cleanup()
        >>>
        >>> # Utiliser un cache manag√©
        >>> cache = manager.create_cache("indicators", max_size_mb=256)
        >>> cache.set("ema_20", data)
        >>>
        >>> # Contexte avec nettoyage automatique
        >>> with manager.memory_context():
        >>>     # Code gourmand en m√©moire
        >>>     pass  # Nettoyage automatique √† la sortie
    """

    def __init__(self, config: Optional[MemoryConfig] = None):
        """
        Args:
            config: Configuration personnalis√©e
        """
        self.config = config or MemoryConfig()
        self._stats = MemoryStats()

        self._caches: Dict[str, ManagedCache] = {}
        self._weak_refs: Set[weakref.ref] = set()
        self._cleanup_callbacks: List[Callable[[], int]] = []

        self._auto_cleanup_thread: Optional[threading.Thread] = None
        self._running = False
        self._lock = threading.Lock()

        # Importer psutil si disponible
        self._has_psutil = self._check_psutil()

        logger.debug("MemoryManager initialis√©")

    def _check_psutil(self) -> bool:
        """V√©rifie si psutil est disponible."""
        try:
            import psutil
            return psutil is not None
        except ImportError:
            return False

    def get_memory_usage(self) -> float:
        """Retourne l'usage m√©moire en pourcentage."""
        if self._has_psutil:
            import psutil
            return psutil.virtual_memory().percent
        return 50.0  # Estimation par d√©faut

    def get_memory_available_mb(self) -> float:
        """Retourne la m√©moire disponible en MB."""
        if self._has_psutil:
            import psutil
            return psutil.virtual_memory().available / (1024**2)
        return 4096.0  # Estimation 4GB

    def get_process_memory_mb(self) -> float:
        """Retourne la m√©moire utilis√©e par le processus en MB."""
        if self._has_psutil:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / (1024**2)
        return 0.0

    def create_cache(self, name: str, max_size_mb: float = 512.0) -> ManagedCache:
        """
        Cr√©e un cache manag√©.

        Args:
            name: Nom unique du cache
            max_size_mb: Taille maximale

        Returns:
            ManagedCache instance
        """
        with self._lock:
            if name in self._caches:
                return self._caches[name]

            cache = ManagedCache(max_size_mb=max_size_mb, name=name)
            self._caches[name] = cache
            logger.debug(f"Cache '{name}' cr√©√© ({max_size_mb:.0f} MB max)")
            return cache

    def get_cache(self, name: str) -> Optional[ManagedCache]:
        """R√©cup√®re un cache existant."""
        return self._caches.get(name)

    def register_cleanup_callback(self, callback: Callable[[], int]) -> None:
        """
        Enregistre un callback de nettoyage.

        Le callback doit retourner le nombre de bytes lib√©r√©s.
        """
        self._cleanup_callbacks.append(callback)

    def cleanup(self, aggressive: bool = False) -> int:
        """
        Effectue un nettoyage m√©moire.

        Args:
            aggressive: Si True, force un nettoyage complet

        Returns:
            Bytes lib√©r√©s (estimation)
        """
        bytes_freed = 0

        # 1. Garbage collection Python
        gc.collect()

        # 2. Nettoyer les caches si m√©moire haute
        usage = self.get_memory_usage()

        if aggressive or usage > self.config.cleanup_threshold:
            for name, cache in self._caches.items():
                if aggressive:
                    freed = cache.clear()
                    bytes_freed += freed
                    logger.debug(f"Cache {name} vid√©: {freed / (1024**2):.1f} MB")
                else:
                    # √âviction partielle (50% des entr√©es)
                    target = len(cache) // 2
                    for _ in range(target):
                        if cache._access_order:
                            key = cache._access_order[0]
                            cache.delete(key)

        # 3. Appeler les callbacks enregistr√©s
        for callback in self._cleanup_callbacks:
            try:
                freed = callback()
                bytes_freed += freed
            except Exception as e:
                logger.error(f"Erreur callback cleanup: {e}")

        # 4. Nettoyer les weak references mortes
        dead_refs = [ref for ref in self._weak_refs if ref() is None]
        for ref in dead_refs:
            self._weak_refs.discard(ref)

        # 5. GC final
        gc.collect()

        # Mettre √† jour les stats
        self._stats.total_cleanups += 1
        self._stats.bytes_freed += bytes_freed
        self._stats.current_usage_mb = self.get_process_memory_mb()
        self._stats.peak_usage_mb = max(
            self._stats.peak_usage_mb,
            self._stats.current_usage_mb
        )

        logger.debug(f"Cleanup effectu√©: ~{bytes_freed / (1024**2):.1f} MB lib√©r√©s")

        return bytes_freed

    def start_auto_cleanup(self) -> None:
        """D√©marre le nettoyage automatique."""
        if self._running:
            return

        self._running = True

        def cleanup_loop():
            while self._running:
                try:
                    usage = self.get_memory_usage()

                    if usage > self.config.critical_threshold:
                        logger.warning(f"M√©moire critique ({usage:.1f}%), nettoyage agressif")
                        self.cleanup(aggressive=True)
                    elif usage > self.config.cleanup_threshold:
                        logger.debug(f"M√©moire haute ({usage:.1f}%), nettoyage")
                        self.cleanup(aggressive=False)

                except Exception as e:
                    logger.error(f"Erreur auto-cleanup: {e}")

                time.sleep(self.config.cleanup_interval)

        self._auto_cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
        self._auto_cleanup_thread.start()
        logger.info("Auto-cleanup d√©marr√©")

    def stop_auto_cleanup(self) -> None:
        """Arr√™te le nettoyage automatique."""
        self._running = False
        if self._auto_cleanup_thread:
            self._auto_cleanup_thread.join(timeout=5.0)
            self._auto_cleanup_thread = None
        logger.info("Auto-cleanup arr√™t√©")

    @contextmanager
    def memory_context(
        self,
        cleanup_after: bool = True,
        check_before: bool = True
    ) -> Generator[None, None, None]:
        """
        Context manager pour op√©rations gourmandes en m√©moire.

        Args:
            cleanup_after: Nettoyer √† la sortie
            check_before: V√©rifier la m√©moire avant

        Example:
            >>> with manager.memory_context():
            >>>     # Code gourmand
            >>>     result = heavy_computation()
        """
        if check_before:
            usage = self.get_memory_usage()
            if usage > self.config.warning_threshold:
                logger.warning(f"M√©moire haute avant op√©ration: {usage:.1f}%")
                self.cleanup()

        try:
            yield
        finally:
            if cleanup_after:
                self.cleanup()

    def track_object(self, obj: Any) -> None:
        """Track un objet via weak reference pour monitoring."""
        try:
            ref = weakref.ref(obj)
            self._weak_refs.add(ref)
            self._stats.managed_objects += 1
        except TypeError:
            # L'objet ne supporte pas les weak references
            pass

    def get_stats(self) -> MemoryStats:
        """Retourne les statistiques."""
        self._stats.current_usage_mb = self.get_process_memory_mb()

        # Compter les objets vivants
        alive = sum(1 for ref in self._weak_refs if ref() is not None)
        self._stats.managed_objects = alive

        # Agr√©ger les stats des caches
        for cache in self._caches.values():
            self._stats.cache_hits += cache._stats.cache_hits
            self._stats.cache_misses += cache._stats.cache_misses

        return self._stats

    def get_cache_summary(self) -> Dict[str, Dict[str, Any]]:
        """Retourne un r√©sum√© de tous les caches."""
        return {
            name: {
                "size_mb": cache.size_mb(),
                "entries": len(cache),
                "max_size_mb": cache.max_size_bytes / (1024**2),
            }
            for name, cache in self._caches.items()
        }

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel."""
        stats = self.get_stats()

        lines = [
            "=== Memory Manager ===",
            f"Process Memory: {stats.current_usage_mb:.1f} MB",
            f"Peak Memory: {stats.peak_usage_mb:.1f} MB",
            f"System Memory: {self.get_memory_usage():.1f}%",
            f"Total Cleanups: {stats.total_cleanups}",
            f"Bytes Freed: {stats.bytes_freed / (1024**2):.1f} MB",
            "",
            "Caches:",
        ]

        for name, info in self.get_cache_summary().items():
            lines.append(f"  {name}: {info['size_mb']:.1f}/{info['max_size_mb']:.0f} MB ({info['entries']} entries)")

        return "\n".join(lines)


# Singleton global
_memory_manager: Optional[MemoryManager] = None


def get_memory_manager() -> MemoryManager:
    """Retourne le gestionnaire m√©moire singleton."""
    global _memory_manager
    if _memory_manager is None:
        _memory_manager = MemoryManager()
    return _memory_manager


def cleanup_memory(aggressive: bool = False) -> int:
    """Raccourci pour nettoyer la m√©moire."""
    return get_memory_manager().cleanup(aggressive)


__all__ = [
    "MemoryConfig",
    "MemoryStats",
    "ManagedCache",
    "MemoryManager",
    "get_memory_manager",
    "cleanup_memory",
]
```
<!-- MODULE-END: memory.py -->

<!-- MODULE-START: model_loader.py -->
```json
{
  "name": "model_loader.py",
  "path": "utils\\model_loader.py",
  "ext": ".py",
  "anchor": "model_loader_py"
}
```
## model_loader_py
*Chemin* : `utils\model_loader.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.model_loader

Purpose: Chargement et acc√®s aux mod√®les depuis D:\\models\\models.json

Role in pipeline: configuration

Key components: load_models_json(), get_model_by_id(), get_models_by_category()

Inputs: models.json path (default: D:\\models\\models.json)

Outputs: Dict de mod√®les avec infos (path, size, use_case, etc.)

Dependencies: json, pathlib

Conventions: Fallback si fichier absent; cache en m√©moire; mod√®les Ollama prioritaires.

Read-if: Modification de la logique de chargement des mod√®les.

Skip-if: Vous utilisez directement get_available_models().
"""

from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Dict, List, Optional

from utils.log import get_logger

logger = get_logger(__name__)

# Chemin par d√©faut vers models.json
DEFAULT_MODELS_JSON_PATH = Path("D:\\models\\models.json")

# Cache en m√©moire
_models_cache: Optional[Dict] = None


def _windows_to_wsl_path(path: Path) -> Optional[Path]:
    path_str = str(path)
    if len(path_str) < 3 or path_str[1] != ":":
        return None

    drive = path_str[0].lower()
    rest = path_str[2:].lstrip("\\/")
    if not rest:
        return None

    return Path(f"/mnt/{drive}/{rest.replace('\\', '/')}")


def get_models_json_path() -> Path:
    """
    Retourne le chemin vers models.json.

    Peut √™tre configur√© via variable d'environnement MODELS_JSON_PATH.

    Returns:
        Path: Chemin vers models.json
    """
    env_path = os.environ.get("MODELS_JSON_PATH")
    if env_path:
        return Path(env_path)

    if DEFAULT_MODELS_JSON_PATH.exists():
        return DEFAULT_MODELS_JSON_PATH

    wsl_path = _windows_to_wsl_path(DEFAULT_MODELS_JSON_PATH)
    if wsl_path and wsl_path.exists():
        return wsl_path

    return DEFAULT_MODELS_JSON_PATH


def load_models_json(force_reload: bool = False) -> Dict:
    """
    Charge le fichier models.json depuis D:\\models\\models.json.

    Args:
        force_reload: Si True, recharge le fichier m√™me si d√©j√† en cache

    Returns:
        Dict contenant la configuration des mod√®les

    Example:
        >>> data = load_models_json()
        >>> ollama_models = data.get("ollama_models", [])
        >>> for model in ollama_models:
        ...     print(f"{model['id']}: {model['name']}")
    """
    global _models_cache

    # Retourner le cache si disponible
    if _models_cache is not None and not force_reload:
        return _models_cache

    models_path = get_models_json_path()

    if not models_path.exists():
        logger.warning(
            "Fichier models.json introuvable √† %s, utilisation de la config par d√©faut",
            models_path
        )
        _models_cache = {
            "version": "1.0",
            "ollama_models": [],
            "huggingface_models": [],
            "diffusion_models": [],
            "model_categories": {},
            "recommended_by_task": {},
        }
        return _models_cache

    try:
        with open(models_path, encoding="utf-8-sig") as f:
            _models_cache = json.load(f)
        logger.info("‚úÖ Charg√© %d mod√®les depuis %s", _count_total_models(_models_cache), models_path)
        return _models_cache

    except (json.JSONDecodeError, IOError) as exc:
        logger.error("Erreur lors du chargement de %s: %s", models_path, exc)
        _models_cache = {
            "version": "1.0",
            "ollama_models": [],
            "huggingface_models": [],
            "diffusion_models": [],
            "model_categories": {},
            "recommended_by_task": {},
        }
        return _models_cache


def _count_total_models(data: Dict) -> int:
    """Compte le nombre total de mod√®les."""
    count = 0
    count += len(data.get("ollama_models", []))
    count += len(data.get("huggingface_models", []))
    count += len(data.get("diffusion_models", []))
    return count


def get_all_ollama_models() -> List[Dict]:
    """
    Retourne tous les mod√®les Ollama disponibles.

    Returns:
        List[Dict]: Liste des mod√®les Ollama avec leurs m√©tadonn√©es

    Example:
        >>> models = get_all_ollama_models()
        >>> for m in models:
        ...     print(f"{m['id']}: {m['size_gb']} GB - {m['use_case']}")
    """
    data = load_models_json()
    return data.get("ollama_models", [])


def get_all_huggingface_models() -> List[Dict]:
    """Retourne tous les mod√®les HuggingFace disponibles."""
    data = load_models_json()
    return data.get("huggingface_models", [])


def get_all_diffusion_models() -> List[Dict]:
    """Retourne tous les mod√®les de diffusion disponibles."""
    data = load_models_json()
    return data.get("diffusion_models", [])


def get_model_by_id(model_id: str) -> Optional[Dict]:
    """
    R√©cup√®re un mod√®le par son ID.

    Args:
        model_id: ID du mod√®le (ex: "llama3.1-8b", "deepseek-r1-32b")

    Returns:
        Dict contenant les m√©tadonn√©es du mod√®le ou None si introuvable

    Example:
        >>> model = get_model_by_id("llama3.1-8b")
        >>> if model:
        ...     print(f"Path: {model['path']}")
        ...     print(f"Size: {model['size_gb']} GB")
    """
    if not model_id:
        return None

    data = load_models_json()
    model_id = model_id.strip()

    # Chercher dans ollama_models
    for model in data.get("ollama_models", []):
        if model.get("id") == model_id:
            return model

    # Chercher dans huggingface_models
    for model in data.get("huggingface_models", []):
        if model.get("id") == model_id:
            return model

    # Chercher dans diffusion_models
    for model in data.get("diffusion_models", []):
        if model.get("id") == model_id:
            return model

    # Normaliser les noms Ollama (ex: nemotron-3-nano:30b -> model_name/tag)
    if ":" in model_id:
        base, tag = model_id.split(":", 1)
        for model in data.get("ollama_models", []):
            if model.get("model_name") == base and model.get("tag") == tag:
                return model

        # Ex: llama3.3-70b-optimized:latest -> llama3.3-70b-optimized-latest
        if "/" not in model_id:
            dashed_id = model_id.replace(":", "-")
            for model in data.get("ollama_models", []):
                if model.get("id") == dashed_id:
                    return model

    # Fallback: match par model_name si unique
    matches = [
        m for m in data.get("ollama_models", [])
        if m.get("model_name") == model_id
    ]
    if len(matches) == 1:
        return matches[0]

    logger.debug("Mod√®le %s introuvable dans models.json", model_id)
    return None


def get_models_by_category(category: str) -> List[Dict]:
    """
    R√©cup√®re tous les mod√®les d'une cat√©gorie.

    Args:
        category: Cat√©gorie (ex: "general", "reasoning", "finance", "image_generation")

    Returns:
        List[Dict]: Liste des mod√®les de cette cat√©gorie

    Example:
        >>> reasoning_models = get_models_by_category("reasoning")
        >>> for m in reasoning_models:
        ...     print(m['name'])
    """
    data = load_models_json()
    categories = data.get("model_categories", {})

    model_ids = categories.get(category, [])
    if not model_ids:
        return []

    # R√©cup√©rer les d√©tails de chaque mod√®le
    models = []
    for model_id in model_ids:
        model = get_model_by_id(model_id)
        if model:
            models.append(model)

    return models


def get_models_by_use_case(use_case: str) -> List[Dict]:
    """
    R√©cup√®re tous les mod√®les pour un cas d'usage.

    Args:
        use_case: Cas d'usage (ex: "general", "reasoning", "finance", "instruction")

    Returns:
        List[Dict]: Liste des mod√®les

    Example:
        >>> finance_models = get_models_by_use_case("reasoning_finance")
        >>> for m in finance_models:
        ...     print(f"{m['name']}: {m['description']}")
    """
    all_models = get_all_ollama_models() + get_all_huggingface_models()
    return [m for m in all_models if m.get("use_case") == use_case]


def get_recommended_model_for_task(task: str) -> Optional[str]:
    """
    Retourne le mod√®le recommand√© pour une t√¢che.

    Args:
        task: Nom de la t√¢che (ex: "backtest_strategy_generation", "backtest_analysis")

    Returns:
        str: ID du mod√®le recommand√© ou None

    Example:
        >>> model_id = get_recommended_model_for_task("backtest_strategy_generation")
        >>> if model_id:
        ...     model = get_model_by_id(model_id)
        ...     print(f"Recommand√©: {model['name']}")
    """
    data = load_models_json()
    recommendations = data.get("recommended_by_task", {})
    return recommendations.get(task)


def get_model_full_path(model_id: str) -> Optional[Path]:
    """
    Retourne le chemin complet vers un mod√®le.

    Args:
        model_id: ID du mod√®le

    Returns:
        Path: Chemin absolu vers le mod√®le ou None si introuvable

    Example:
        >>> path = get_model_full_path("llama3.1-8b")
        >>> if path:
        ...     print(f"Mod√®le √†: {path}")
    """
    model = get_model_by_id(model_id)
    if not model:
        return None

    data = load_models_json()
    base_dir = Path(data.get("models_directory", "D:\\models"))
    relative_path = model.get("path", "")

    if not relative_path:
        return None

    return base_dir / relative_path


def get_ollama_model_names() -> List[str]:
    """
    Retourne la liste des noms de mod√®les Ollama (pour compatibilit√© avec Ollama).

    Returns:
        List[str]: Liste des noms Ollama (model_name:tag, latest -> model_name)

    Example:
        >>> names = get_ollama_model_names()
        >>> print(names)
        ['llama3.1:8b', 'llama3.3-70b-optimized', 'mistral:7b-instruct', ...]
    """
    models = get_all_ollama_models()
    names = []
    for model in models:
        model_name = model.get("model_name")
        tag = model.get("tag")
        if model_name and tag:
            if tag == "latest":
                names.append(model_name)
            else:
                names.append(f"{model_name}:{tag}")
            continue
        if model_name:
            names.append(model_name)
            continue
        model_id = model.get("id")
        if model_id:
            names.append(model_id)
    return names


def get_model_info_for_ui(model_id: str) -> Dict:
    """
    Retourne les infos formatt√©es pour l'UI.

    Args:
        model_id: ID du mod√®le

    Returns:
        Dict: Informations formatt√©es {name, size_gb, description, use_case}

    Example:
        >>> info = get_model_info_for_ui("deepseek-r1-32b")
        >>> st.caption(f"{info['size_gb']} GB - {info['description']}")
    """
    model = get_model_by_id(model_id)
    if not model:
        return {
            "name": model_id,
            "size_gb": "?",
            "description": "Mod√®le inconnu",
            "use_case": "unknown",
        }

    return {
        "name": model.get("name", model_id),
        "size_gb": model.get("size_gb", "?"),
        "description": model.get("description", ""),
        "use_case": model.get("use_case", "general"),
        "parameters": model.get("parameters", ""),
        "context_length": model.get("context_length", 0),
    }


__all__ = [
    "load_models_json",
    "get_all_ollama_models",
    "get_all_huggingface_models",
    "get_all_diffusion_models",
    "get_model_by_id",
    "get_models_by_category",
    "get_models_by_use_case",
    "get_recommended_model_for_task",
    "get_model_full_path",
    "get_ollama_model_names",
    "get_model_info_for_ui",
]
```
<!-- MODULE-END: model_loader.py -->

<!-- MODULE-START: observability.py -->
```json
{
  "name": "observability.py",
  "path": "utils\\observability.py",
  "ext": ".py",
  "anchor": "observability_py"
}
```
## observability_py
*Chemin* : `utils\observability.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.observability

Purpose: Observabilit√© debug intelligent (lazy formatting, traces corr√©l√©es, sampling).

Role in pipeline: core / monitoring

Key components: get_obs_logger, trace_span, PerfCounters, DiagnosticPack, generate_run_id

Inputs: Module name, run_id, log level (env vars)

Outputs: Logs JSON structur√©s, traces span avec timing, pack diagnostique

Dependencies: logging, json, dataclasses, functools

Conventions: DEBUG mode lazy-evaluated; sampling configurable; run_id corr√©l√©; zero overhead prod.

Read-if: Modification logging structure, sampling, ou diagnostic export.

Skip-if: Vous utilisez juste get_obs_logger().
"""

from __future__ import annotations

import json
import logging
import os
import random
import sys
import time
import uuid
from contextlib import contextmanager
from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Any, Dict, Generator, Optional

import numpy as np
import pandas as pd

# ============================================================================
# CONFIGURATION VIA ENV VARS
# ============================================================================

_LOG_LEVEL = os.getenv("BACKTEST_LOG_LEVEL", "INFO").upper()
_LOG_SAMPLE = float(os.getenv("BACKTEST_LOG_SAMPLE", "1.0"))
_LOG_JSON = os.getenv("BACKTEST_LOG_JSON", "0") == "1"
_LOG_FILE = os.getenv("BACKTEST_LOG_FILE", "")
_LOG_ROTATE_MB = int(os.getenv("BACKTEST_LOG_ROTATE_MB", "10"))

# Mapping niveaux
_LEVEL_MAP = {
    "DEBUG": logging.DEBUG,
    "INFO": logging.INFO,
    "WARNING": logging.WARNING,
    "ERROR": logging.ERROR,
    "CRITICAL": logging.CRITICAL,
}


# ============================================================================
# JSON FORMATTER (pour logs structur√©s)
# ============================================================================

class JSONFormatter(logging.Formatter):
    """Formateur JSON Lines pour logs structur√©s."""

    def format(self, record: logging.LogRecord) -> str:
        log_obj = {
            "ts": datetime.now(timezone.utc).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "msg": record.getMessage(),
        }
        # Ajouter les champs extra du LoggerAdapter
        if hasattr(record, "run_id") and record.run_id:
            log_obj["run_id"] = record.run_id
        if hasattr(record, "strategy"):
            log_obj["strategy"] = record.strategy
        if hasattr(record, "symbol"):
            log_obj["symbol"] = record.symbol
        if hasattr(record, "timeframe"):
            log_obj["timeframe"] = record.timeframe
        # Champs arbitraires
        if hasattr(record, "extra_fields"):
            log_obj.update(record.extra_fields)
        return json.dumps(log_obj, default=str)


class HumanFormatter(logging.Formatter):
    """Formateur lisible avec run_id en pr√©fixe."""

    def __init__(self):
        super().__init__(
            "%(asctime)s | %(levelname)-5s | %(name)s | %(message)s",
            datefmt="%H:%M:%S"
        )

    def format(self, record: logging.LogRecord) -> str:
        # Pr√©fixer le message avec run_id si pr√©sent
        if hasattr(record, "run_id") and record.run_id:
            record.msg = f"[{record.run_id}] {record.msg}"
        return super().format(record)


# ============================================================================
# LOGGER ADAPTER AVEC CONTEXTE
# ============================================================================

class ObsLoggerAdapter(logging.LoggerAdapter):
    """
    Adapter qui injecte run_id et contexte dans chaque log.

    Le contexte est pass√© une seule fois √† la cr√©ation, puis r√©utilis√©.
    """

    def __init__(
        self,
        logger: logging.Logger,
        run_id: Optional[str] = None,
        strategy: Optional[str] = None,
        symbol: Optional[str] = None,
        timeframe: Optional[str] = None,
    ):
        extra = {
            "run_id": run_id,
            "strategy": strategy,
            "symbol": symbol,
            "timeframe": timeframe,
        }
        super().__init__(logger, extra)
        self._sample_rate = _LOG_SAMPLE

    def process(self, msg: str, kwargs: Dict[str, Any]) -> tuple:
        """Injecte le contexte dans chaque log."""
        extra = kwargs.get("extra", {})
        extra.update(self.extra)
        kwargs["extra"] = extra
        return msg, kwargs

    def with_context(self, **fields) -> "ObsLoggerAdapter":
        """Cr√©e un nouvel adapter avec contexte enrichi."""
        new_extra = {**self.extra, **fields}
        return ObsLoggerAdapter(
            self.logger,
            run_id=new_extra.get("run_id"),
            strategy=new_extra.get("strategy"),
            symbol=new_extra.get("symbol"),
            timeframe=new_extra.get("timeframe"),
        )

    def should_sample(self) -> bool:
        """Retourne True si ce run doit √™tre logg√© (sampling)."""
        return random.random() < self._sample_rate


# ============================================================================
# INITIALISATION GLOBALE
# ============================================================================

_initialized = False
_root_handler: Optional[logging.Handler] = None


def init_logging(
    level: Optional[str] = None,
    json_format: Optional[bool] = None,
    file_path: Optional[Path] = None,
    rotate_mb: Optional[int] = None,
) -> None:
    """
    Initialise le syst√®me de logging.

    Appel√© automatiquement au premier get_obs_logger(), mais peut √™tre
    appel√© manuellement pour forcer une configuration sp√©cifique.

    Args:
        level: Niveau de log (DEBUG, INFO, WARNING, ERROR)
        json_format: True pour JSON lines, False pour texte
        file_path: Chemin vers fichier de log (optionnel)
        rotate_mb: Taille max du fichier avant rotation (Mo)
    """
    global _initialized, _root_handler

    if _initialized:
        return

    # Utiliser env vars si pas sp√©cifi√©
    level = level or _LOG_LEVEL
    json_format = json_format if json_format is not None else _LOG_JSON
    file_path = file_path or (Path(_LOG_FILE) if _LOG_FILE else None)
    rotate_mb = rotate_mb or _LOG_ROTATE_MB

    log_level = _LEVEL_MAP.get(level.upper(), logging.INFO)

    # Formateur
    formatter = JSONFormatter() if json_format else HumanFormatter()

    # Handler console
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(log_level)
    console_handler.setFormatter(formatter)

    # Handler fichier (optionnel)
    file_handler = None
    if file_path:
        file_handler = RotatingFileHandler(
            file_path,
            maxBytes=rotate_mb * 1024 * 1024,
            backupCount=3,
            encoding="utf-8",
        )
        file_handler.setLevel(log_level)
        file_handler.setFormatter(formatter)

    # Configurer le root logger "backtest"
    root_logger = logging.getLogger("backtest")
    root_logger.setLevel(log_level)
    root_logger.handlers.clear()
    root_logger.addHandler(console_handler)
    if file_handler:
        root_logger.addHandler(file_handler)
    root_logger.propagate = False

    _root_handler = console_handler
    _initialized = True


def get_obs_logger(
    name: str,
    run_id: Optional[str] = None,
    **context,
) -> ObsLoggerAdapter:
    """
    Obtient un logger avec contexte d'observabilit√©.

    Args:
        name: Nom du module (utiliser __name__)
        run_id: Identifiant unique du run (g√©n√©r√© si None)
        **context: Champs additionnels (strategy, symbol, timeframe)

    Returns:
        ObsLoggerAdapter configur√©

    Usage:
        logger = get_obs_logger(__name__, run_id="abc123", strategy="ema_cross")
        logger.info("Pipeline started")  # [abc123] Pipeline started
    """
    init_logging()

    # Pr√©fixer avec "backtest." si pas d√©j√†
    if not name.startswith("backtest."):
        name = f"backtest.{name}"

    logger = logging.getLogger(name)
    return ObsLoggerAdapter(
        logger,
        run_id=run_id,
        strategy=context.get("strategy"),
        symbol=context.get("symbol"),
        timeframe=context.get("timeframe"),
    )


def generate_run_id(
    strategy: Optional[str] = None,
    symbol: Optional[str] = None,
    timeframe: Optional[str] = None,
    seed: Optional[int] = None
) -> str:
    """
    G√©n√®re un run_id unique et lisible pour tra√ßabilit√© compl√®te.

    Format court (si pas de param√®tres): 8 caract√®res UUID
    Format complet: {strategy}_{symbol}_{timeframe}_{timestamp}_{unique}[_s{seed}]

    Args:
        strategy: Nom de la strat√©gie (ex: "ema_cross"). Si None, format court.
        symbol: Actif trad√© (ex: "BTCUSDT")
        timeframe: Timeframe (ex: "1h", "4h", "1d")
        seed: Seed optionnel pour reproductibilit√©

    Returns:
        run_id unique et lisible

    Examples:
        >>> generate_run_id()  # Format court
        'a3f7b2c1'
        >>> generate_run_id("ema_cross", "BTCUSDT", "1h", 42)  # Format complet
        'ema_cross_BTCUSDT_1h_20250228_143052_a3f7b2c1_s42'
    """
    # Format court si pas de param√®tres
    if not strategy and not symbol and not timeframe:
        return uuid.uuid4().hex[:8]

    # Format complet avec contexte
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique = uuid.uuid4().hex[:8]

    parts = []
    if strategy:
        parts.append(strategy)
    if symbol:
        parts.append(symbol)
    if timeframe:
        parts.append(timeframe)

    parts.extend([timestamp, unique])

    if seed is not None:
        parts.append(f"s{seed}")

    return "_".join(parts)


# ============================================================================
# TRACE SPAN - Mesure de dur√©e
# ============================================================================

@contextmanager
def trace_span(
    logger: ObsLoggerAdapter,
    name: str,
    log_level: int = logging.DEBUG,
    **fields,
) -> Generator[Dict[str, Any], None, None]:
    """
    Context manager pour tracer la dur√©e d'une op√©ration.

    ZERO OVERHEAD si le niveau n'est pas activ√©:
    - Pas de string formatting
    - Pas de calcul de dur√©e

    Args:
        logger: Logger avec contexte
        name: Nom du span (ex: "indicators", "simulation")
        log_level: Niveau de log (DEBUG par d√©faut)
        **fields: Champs additionnels √† loguer

    Yields:
        Dict pour stocker des m√©triques pendant le span

    Usage:
        with trace_span(logger, "indicators", count=5) as span:
            # ... calculs ...
            span["computed"] = 42
    """
    span_data: Dict[str, Any] = {}

    # Check niveau AVANT toute op√©ration
    if not logger.isEnabledFor(log_level):
        yield span_data
        return

    start = time.perf_counter()
    logger.log(log_level, "span_start: %s %s", name, fields or "")

    try:
        yield span_data
    finally:
        duration_ms = (time.perf_counter() - start) * 1000
        all_fields = {**fields, **span_data, "duration_ms": round(duration_ms, 2)}
        logger.log(log_level, "span_end: %s %s", name, all_fields)


# ============================================================================
# SAFE STATS - R√©sum√©s sans dump complet
# ============================================================================

def safe_stats_df(df: pd.DataFrame, max_rows: int = 3) -> Dict[str, Any]:
    """
    Statistiques s√ªres d'un DataFrame (jamais le contenu complet).

    Args:
        df: DataFrame √† r√©sumer
        max_rows: Nombre max de lignes pour head() (d√©faut: 3)

    Returns:
        Dict avec shape, dtypes, nan_count, sample_values
    """
    if df is None or df.empty:
        return {"shape": (0, 0), "empty": True}

    stats = {
        "shape": df.shape,
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "nan_count": int(df.isna().sum().sum()),
        "memory_mb": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2),
    }

    # Index info
    if isinstance(df.index, pd.DatetimeIndex):
        stats["index_range"] = [str(df.index.min()), str(df.index.max())]

    # Sample (head) seulement si demand√©
    if max_rows > 0 and len(df) > 0:
        stats["head"] = df.head(max_rows).to_dict("records")

    return stats


def safe_stats_array(x: np.ndarray, name: str = "array") -> Dict[str, Any]:
    """
    Statistiques s√ªres d'un array numpy.

    Args:
        x: Array √† r√©sumer
        name: Nom pour identification

    Returns:
        Dict avec shape, dtype, nan_count, min/max/mean
    """
    if x is None:
        return {"name": name, "value": None}

    if not isinstance(x, np.ndarray):
        return {"name": name, "type": type(x).__name__, "value": str(x)[:100]}

    stats = {
        "name": name,
        "shape": x.shape,
        "dtype": str(x.dtype),
    }

    # Stats num√©riques (prot√©g√© contre types non-num√©riques)
    if np.issubdtype(x.dtype, np.number):
        finite_mask = np.isfinite(x)
        stats["nan_count"] = int((~finite_mask).sum())
        if finite_mask.any():
            finite_x = x[finite_mask]
            stats["min"] = float(np.min(finite_x))
            stats["max"] = float(np.max(finite_x))
            stats["mean"] = float(np.mean(finite_x))

    return stats


def safe_stats_series(s: pd.Series, name: str = "series") -> Dict[str, Any]:
    """
    Statistiques s√ªres d'une Series pandas.
    """
    if s is None or s.empty:
        return {"name": name, "empty": True}

    return {
        "name": name,
        "shape": s.shape,
        "dtype": str(s.dtype),
        "nan_count": int(s.isna().sum()),
        "min": float(s.min()) if pd.api.types.is_numeric_dtype(s) else None,
        "max": float(s.max()) if pd.api.types.is_numeric_dtype(s) else None,
    }


# ============================================================================
# PERF COUNTERS - Compteurs l√©gers O(1)
# ============================================================================

@dataclass
class PerfCounters:
    """
    Compteurs de performance l√©gers pour le pipeline.

    Usage:
        counters = PerfCounters()
        counters.start("indicators")
        # ... calculs ...
        counters.stop("indicators")

        print(counters.summary())
    """
    _starts: Dict[str, float] = field(default_factory=dict)
    _durations: Dict[str, float] = field(default_factory=dict)
    _counts: Dict[str, int] = field(default_factory=dict)

    def start(self, name: str) -> None:
        """D√©marre un chrono."""
        self._starts[name] = time.perf_counter()

    def stop(self, name: str) -> float:
        """Arr√™te un chrono et retourne la dur√©e en ms."""
        if name not in self._starts:
            return 0.0
        duration_ms = (time.perf_counter() - self._starts[name]) * 1000
        self._durations[name] = duration_ms
        return duration_ms

    def increment(self, name: str, delta: int = 1) -> None:
        """Incr√©mente un compteur."""
        self._counts[name] = self._counts.get(name, 0) + delta

    def get_duration(self, name: str) -> float:
        """Retourne la dur√©e en ms."""
        return self._durations.get(name, 0.0)

    def summary(self) -> Dict[str, Any]:
        """Retourne un r√©sum√© des compteurs."""
        return {
            "durations_ms": {k: round(v, 2) for k, v in self._durations.items()},
            "counts": self._counts.copy(),
            "total_ms": round(sum(self._durations.values()), 2),
        }


# ============================================================================
# DIAGNOSTIC PACK
# ============================================================================

@dataclass
class DiagnosticPack:
    """Pack diagnostic compact pour analyse rapide."""
    run_id: str
    timestamp: str
    strategy: Optional[str]
    symbol: Optional[str]
    timeframe: Optional[str]
    params: Dict[str, Any]
    counters: Dict[str, Any]
    result_summary: Dict[str, Any]
    error: Optional[str]
    error_type: Optional[str]

    def to_json(self) -> str:
        """S√©rialise en JSON compact."""
        return json.dumps(asdict(self), indent=2, default=str)

    def to_file(self, path: Path) -> None:
        """Exporte vers un fichier."""
        path.write_text(self.to_json(), encoding="utf-8")


def build_diagnostic_summary(
    run_id: str,
    request: Optional[Dict[str, Any]] = None,
    result: Optional[Any] = None,  # RunResult ou dict
    counters: Optional[PerfCounters] = None,
    last_exception: Optional[Exception] = None,
) -> DiagnosticPack:
    """
    Construit un pack diagnostic compact.

    Args:
        run_id: Identifiant du run
        request: Dict de la requ√™te (strategy, params, etc.)
        result: R√©sultat du backtest (RunResult ou dict de metrics)
        counters: Compteurs de performance
        last_exception: Derni√®re exception si erreur

    Returns:
        DiagnosticPack pr√™t √† exporter
    """
    request = request or {}

    # Extraire les infos du r√©sultat
    result_summary = {}
    if result is not None:
        if hasattr(result, "metrics"):
            # RunResult
            metrics = result.metrics
            result_summary = {
                "sharpe_ratio": metrics.get("sharpe_ratio"),
                "total_return": metrics.get("total_return"),
                "max_drawdown": metrics.get("max_drawdown"),
                "total_trades": metrics.get("total_trades"),
                "win_rate": metrics.get("win_rate"),
            }
        elif isinstance(result, dict):
            result_summary = {
                k: result.get(k)
                for k in ["sharpe_ratio", "total_return", "max_drawdown", "total_trades"]
                if k in result
            }

    return DiagnosticPack(
        run_id=run_id,
        timestamp=datetime.now(timezone.utc).isoformat(),
        strategy=request.get("strategy"),
        symbol=request.get("symbol"),
        timeframe=request.get("timeframe"),
        params=request.get("params", {}),
        counters=counters.summary() if counters else {},
        result_summary=result_summary,
        error=str(last_exception) if last_exception else None,
        error_type=type(last_exception).__name__ if last_exception else None,
    )


# ============================================================================
# CONFIGURATION DYNAMIQUE (UI toggle)
# ============================================================================

def set_log_level(level: str) -> None:
    """
    Change le niveau de log dynamiquement.

    Utilis√© par le toggle UI pour activer DEBUG √† la vol√©e.
    Met √† jour tous les loggers (backtest, backtest_core et leurs enfants).
    """
    log_level = _LEVEL_MAP.get(level.upper(), logging.INFO)

    # Mettre √† jour le logger "backtest" et ses enfants
    root_logger = logging.getLogger("backtest")
    root_logger.setLevel(log_level)
    for handler in root_logger.handlers:
        handler.setLevel(log_level)

    # Mettre √† jour aussi "backtest_core" utilis√© par utils.log
    core_logger = logging.getLogger("backtest_core")
    core_logger.setLevel(log_level)
    for handler in core_logger.handlers:
        handler.setLevel(log_level)

    # Mettre √† jour tous les loggers enfants existants
    for name, logger in logging.Logger.manager.loggerDict.items():
        if isinstance(logger, logging.Logger) and (
            name.startswith("backtest.") or name.startswith("backtest_core.")
        ):
            logger.setLevel(log_level)
            for handler in logger.handlers:
                handler.setLevel(log_level)


def set_sample_rate(rate: float) -> None:
    """Change le taux d'√©chantillonnage (0.0 √† 1.0)."""
    global _LOG_SAMPLE
    _LOG_SAMPLE = max(0.0, min(1.0, rate))


def is_debug_enabled() -> bool:
    """Retourne True si DEBUG est activ√©."""
    # V√©rifier les deux loggers racines
    backtest_debug = logging.getLogger("backtest").isEnabledFor(logging.DEBUG)
    core_debug = logging.getLogger("backtest_core").isEnabledFor(logging.DEBUG)
    return backtest_debug or core_debug


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    # Loggers
    "get_obs_logger",
    "init_logging",
    "generate_run_id",
    "ObsLoggerAdapter",
    # Spans
    "trace_span",
    # Stats s√ªres
    "safe_stats_df",
    "safe_stats_array",
    "safe_stats_series",
    # Compteurs
    "PerfCounters",
    # Diagnostic
    "DiagnosticPack",
    "build_diagnostic_summary",
    # Config dynamique
    "set_log_level",
    "set_sample_rate",
    "is_debug_enabled",
]
```
<!-- MODULE-END: observability.py -->

<!-- MODULE-START: parameters.py -->
```json
{
  "name": "parameters.py",
  "path": "utils\\parameters.py",
  "ext": ".py",
  "anchor": "parameters_py"
}
```
## parameters_py
*Chemin* : `utils\parameters.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.parameters

Purpose: Gestion granularit√© param√®tres, presets, contraintes (contr√¥le combinatoire).

Role in pipeline: configuration

Key components: ParameterSpec, Preset, ConstraintValidator, SearchSpaceStats, versioned presets

Inputs: Strategy parameter_specs, constraint rules, TOML presets

Outputs: Param grids, SearchSpaceStats, validated presets, versioned snapshots

Dependencies: dataclasses, pathlib, tomllib, typing

Conventions: Granularit√© 0.0=fin‚Üí1.0=grossier; BPS unit√©s; presets source plages optim.

Read-if: Modification presets, contraintes, ou gestion versioning.

Skip-if: Vous appelez juste generate_param_grid() ou list_presets().

TABLE DES MATI√àRES (r√©f√©rence architecture)
==============================================

I.   INFRASTRUCTURE & CONFIGURATION (lignes ~35-250)
     1.1. Imports
     1.2. Logger et constantes
     1.3. Helpers priv√©s de normalisation et conversion
          - _normalize_slug()
          - _to_builtin()
          - _semver_key(), _parse_created_at(), _preset_sort_key()
          - _parse_versioned_id(), _apply_versioned_defaults()
     1.4. Helpers priv√©s de construction
          - _build_fixed_parameter_specs()
          - _compute_param_count() [D√âPLAC√â depuis ancienne ligne 355]
          - _get_repo_root(), _migrate_legacy_presets()

II.  TYPES & STRUCTURES DE DONN√âES (lignes ~250-410)
     2.1. ParameterSpec (dataclass)
     2.2. SearchSpaceStats (dataclass)
     2.3. Preset (dataclass)
     2.4. ParameterConstraint (dataclass)

III. G√âN√âRATION D'ESPACES DE RECHERCHE (lignes ~410-600)
     3.1. parameter_values() - G√©n√©ration de valeurs selon granularit√©
     3.2. calculate_combinations() - Calcul du nombre de combinaisons
     3.3. generate_param_grid() - Grille cart√©sienne de param√®tres
     3.4. compute_search_space_stats() - Statistiques unifi√©es

IV.  SYST√àME DE CONTRAINTES (lignes ~600-850)
     4.1. ConstraintValidator (classe)
     4.2. COMMON_CONSTRAINTS (registre)
     4.3. get_common_constraints()
     4.4. generate_constrained_param_grid()

V.   PRESETS SIMPLES (IN-MEMORY) (lignes ~850-1070)
     5.1. D√©finitions des presets
          - SAFE_RANGES_PRESET
          - MINIMAL_PRESET
          - EMA_CROSS_PRESET
          - MACD_CROSS_PRESET
          - RSI_REVERSAL_PRESET
          - ATR_CHANNEL_PRESET
     5.2. Registre PRESETS
     5.3. Fonctions d'acc√®s
          - get_preset()
          - list_presets()

VI.  PRESETS I/O (DISQUE) (lignes ~1070-1120)
     6.1. save_preset()
     6.2. load_preset()

VII. PRESETS VERSIONN√âS (SYST√àME AVANC√â) (lignes ~1120-1400)
     7.1. Configuration et gestion du r√©pertoire
          - get_versioned_presets_dir()
     7.2. Sauvegarde et chargement
          - save_versioned_preset()
          - load_strategy_version()
     7.3. Listage et r√©solution
          - list_strategy_versions()
          - resolve_latest_version()
     7.4. Validation
          - validate_before_use()

VIII. EXPORTS (lignes ~1400-1450)
     8.1. __all__

---

NOTES IMPORTANTES
=================

SOURCE OF TRUTH pour les valeurs par d√©faut:
--------------------------------------------
Les valeurs par d√©faut (default) sont d√©finies dans les classes de strat√©gies
(strategies/*.py) via la propri√©t√© `parameter_specs`.

Les PRESETS dans ce fichier d√©finissent les PLAGES D'OPTIMISATION (min/max)
et peuvent avoir des defaults DIFF√âRENTS des strat√©gies pour certains cas d'usage
(ex: MINIMAL_PRESET avec granularit√©=1.0 pour tests rapides).

R√®gle: Les strat√©gies sont la source de v√©rit√©. Les presets sont des configurations
d'optimisation qui peuvent d√©river de ces valeurs.

Architecture des responsabilit√©s:
---------------------------------
- Chapitre I-II: Fondations (types, helpers)
- Chapitre III: Moteur de g√©n√©ration d'espaces de recherche
- Chapitre IV: Filtrage et contraintes
- Chapitre V-VI: Presets simples (configs pr√©d√©finies)
- Chapitre VII: Syst√®me avanc√© de versioning (snapshot de r√©sultats)

Concepts cl√©s:
-------------
- Granularit√© 0% = tr√®s fin (beaucoup de valeurs)
- Granularit√© 100% = tr√®s grossier (peu de valeurs, souvent juste la m√©diane)
- Maximum 4 valeurs par param√®tre (r√®gle de plafonnement)
- Contraintes inter-param√®tres (ex: slow > fast)
"""

# pylint: disable=too-many-lines

# =============================================================================
# I. INFRASTRUCTURE & CONFIGURATION
# =============================================================================

# --- 1.1. Imports ---
import json
import os
import re
import shutil
from dataclasses import dataclass, field
from datetime import datetime
from itertools import product
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

from utils.log import get_logger

logger = get_logger(__name__)


# --- 1.2. Logger et constantes ---
VERSIONED_PRESETS_DIR_ENV = "BACKTEST_PRESETS_DIR"
DEFAULT_STRATEGY_VERSION = "0.0.1"
_VERSIONED_NAME_RE = re.compile(
    r"^(?P<strategy>[a-z0-9_-]+)@(?P<version>[^_]+)__(?P<preset>[a-z0-9_-]+)$"
)


# --- 1.3. Helpers priv√©s de normalisation et conversion ---

def _normalize_slug(value: str) -> str:
    """Normalise une cha√Æne en slug (minuscules, underscores)."""
    text = (value or "").strip().lower()
    text = re.sub(r"[^a-z0-9_-]+", "_", text)
    text = re.sub(r"_+", "_", text).strip("_")
    return text or "preset"


def _to_builtin(value: Any) -> Any:
    """Convertit les types numpy en types Python natifs pour s√©rialisation JSON."""
    if isinstance(value, np.generic):
        return value.item()
    if isinstance(value, dict):
        return {k: _to_builtin(v) for k, v in value.items()}
    if isinstance(value, (list, tuple)):
        return [_to_builtin(v) for v in value]
    return value


def _parse_versioned_id(value: str) -> Optional[Dict[str, str]]:
    """Parse un ID de preset versionn√© (format: strategy@version__preset)."""
    match = _VERSIONED_NAME_RE.match(value)
    if not match:
        return None
    return match.groupdict()


def _semver_key(version: str) -> Tuple[int, int, int, str]:
    """Cl√© de tri pour semantic versioning."""
    match = re.match(r"^(\d+)\.(\d+)\.(\d+)", version or "")
    if not match:
        return (0, 0, 0, version or "")
    major, minor, patch = match.groups()
    return (int(major), int(minor), int(patch), version or "")


def _parse_created_at(value: Optional[str]) -> Optional[datetime]:
    """Parse une date ISO 8601."""
    if not value:
        return None
    try:
        if value.endswith("Z"):
            value = value[:-1]
        return datetime.fromisoformat(value)
    except ValueError:
        return None


def _preset_sort_key(preset: "Preset") -> Tuple[Tuple[int, int, int, str], int, str]:
    """Cl√© de tri pour presets (par version, date, nom)."""
    meta = preset.metadata or {}
    version = meta.get("version") or ""
    created_at = _parse_created_at(meta.get("created_at"))
    created_rank = int(created_at.timestamp()) if created_at else 0
    return (_semver_key(version), created_rank, preset.name)


def _apply_versioned_defaults(
    preset: "Preset",
    strategy_name: str,
    parsed: Optional[Dict[str, str]],
    source_path: Optional[Path],
) -> None:
    """Applique les m√©tadonn√©es par d√©faut √† un preset versionn√©."""
    preset.metadata = preset.metadata or {}
    if "strategy" not in preset.metadata and strategy_name:
        preset.metadata["strategy"] = strategy_name
    if parsed:
        preset.metadata.setdefault("strategy_slug", parsed["strategy"])
        preset.metadata.setdefault("version", parsed["version"])
        preset.metadata.setdefault("preset_slug", parsed["preset"])
    if "preset_name" not in preset.metadata:
        preset.metadata["preset_name"] = preset.name
    if source_path is not None:
        preset.metadata.setdefault("source_path", str(source_path))


# --- 1.4. Helpers priv√©s de construction ---

def _build_fixed_parameter_specs(
    params_values: Dict[str, Any]
) -> Dict[str, "ParameterSpec"]:
    """Construit des ParameterSpec √† partir de valeurs fixes."""
    specs: Dict[str, "ParameterSpec"] = {}
    for name, raw_value in params_values.items():
        value = _to_builtin(raw_value)
        if isinstance(value, float) and value.is_integer():
            value = int(value)

        if isinstance(value, bool):
            specs[name] = ParameterSpec(
                name=name,
                min_val=0,
                max_val=1,
                default=int(value),
                step=1,
                param_type="bool",
                description="Fixed value",
            )
        elif isinstance(value, int):
            specs[name] = ParameterSpec(
                name=name,
                min_val=value,
                max_val=value,
                default=value,
                step=1,
                param_type="int",
                description="Fixed value",
            )
        elif isinstance(value, float):
            specs[name] = ParameterSpec(
                name=name,
                min_val=value,
                max_val=value,
                default=value,
                step=0.01,
                param_type="float",
                description="Fixed value",
            )
        else:
            raise ValueError(
                f"Unsupported param type for '{name}': {type(value)}"
            )
    return specs


def _compute_param_count(
    spec: Any,
    granularity: Optional[float] = None,
) -> int:
    """
    Calcule le nombre de valeurs pour un param√®tre.

    Returns:
        Nombre de valeurs, ou -1 si continu
    """
    # Cas 1: ParameterSpec
    if isinstance(spec, ParameterSpec):
        if granularity is not None:
            # Utiliser la logique de granularit√©
            values = parameter_values(
                min_val=spec.min_val,
                max_val=spec.max_val,
                granularity=granularity,
                param_type=spec.param_type,
            )
            return len(values)
        elif spec.step and spec.step > 0:
            return int((spec.max_val - spec.min_val) / spec.step) + 1
        else:
            return -1  # Continu

    # Cas 2: Tuple (min, max) ou (min, max, step)
    if isinstance(spec, tuple):
        if len(spec) == 3:
            min_v, max_v, step = spec
            if step and step > 0:
                return int((max_v - min_v) / step) + 1
            return -1
        elif len(spec) == 2:
            return -1  # Continu
        return 1

    # Cas 3: Dict avec "min", "max", "step"
    if isinstance(spec, dict):
        min_v = spec.get("min", spec.get("min_val"))
        max_v = spec.get("max", spec.get("max_val"))
        step = spec.get("step")
        count = spec.get("count")

        # Si count d√©j√† fourni (UI)
        if count is not None:
            return count

        if min_v is not None and max_v is not None:
            if step and step > 0:
                return int((max_v - min_v) / step) + 1
            return -1
        return 1

    # Fallback: valeur unique
    return 1


def _get_repo_root() -> Path:
    """Retourne la racine du repository."""
    return Path(__file__).resolve().parents[1]


def _migrate_legacy_presets(target_dir: Path) -> None:
    """Migre les anciens presets depuis ui/data/presets vers le nouveau r√©pertoire."""
    repo_root = _get_repo_root()
    legacy_dirs = [
        repo_root / "ui" / "data" / "presets",
    ]
    for legacy_dir in legacy_dirs:
        if not legacy_dir.exists():
            continue
        moved = 0
        for path in legacy_dir.glob("*.json"):
            target_dir.mkdir(parents=True, exist_ok=True)
            dest = target_dir / path.name
            if dest.exists():
                continue
            try:
                shutil.move(str(path), str(dest))
                moved += 1
            except Exception as exc:
                logger.warning(
                    "Failed to migrate preset %s: %s", path, exc
                )
        if moved:
            logger.info(
                "Migrated %s preset files from %s",
                moved,
                legacy_dir,
            )


# =============================================================================
# II. TYPES & STRUCTURES DE DONN√âES
# =============================================================================

# --- 2.1. ParameterSpec ---

@dataclass
class ParameterSpec:
    """
    Sp√©cification d'un param√®tre avec ses bornes et contraintes.

    Attributes:
        name: Nom du param√®tre
        min_val: Valeur minimale
        max_val: Valeur maximale
        default: Valeur par d√©faut
        step: Pas d'incr√©mentation (optionnel)
        param_type: Type ('int', 'float', 'bool')
        description: Description pour l'UI
        optimize: Inclus par d√©faut dans l'exploration des grilles
    """
    name: str
    min_val: float
    max_val: float
    default: float
    step: Optional[float] = None
    param_type: str = "float"
    description: str = ""
    optimize: bool = True

    def __post_init__(self):
        if self.step is None:
            # Calculer un step raisonnable
            range_size = self.max_val - self.min_val
            if self.param_type == "int":
                self.step = max(1, int(range_size / 10))
            else:
                self.step = range_size / 10

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "min": self.min_val,
            "max": self.max_val,
            "default": self.default,
            "step": self.step,
            "type": self.param_type,
            "description": self.description,
            "optimize": self.optimize,
        }


# --- 2.2. SearchSpaceStats ---

@dataclass
class SearchSpaceStats:
    """
    Statistiques unifi√©es d'un espace de recherche.

    Utilis√© par:
    - CLI sweep: pour afficher le nombre de combinaisons
    - UI Grille: pour valider avant ex√©cution
    - UI LLM: pour estimer l'espace (si step connu)

    Attributes:
        total_combinations: Nombre total de combinaisons (-1 si continu)
        per_param_counts: Nombre de valeurs par param√®tre
        warnings: Liste d'avertissements
        has_overflow: True si d√©passe max_combinations
        is_continuous: True si au moins un param sans step
    """
    total_combinations: int
    per_param_counts: Dict[str, int]
    warnings: List[str]
    has_overflow: bool
    is_continuous: bool

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel."""
        if self.is_continuous:
            return "Espace continu (exploration adaptative)"
        return f"{self.total_combinations:,} combinaisons"

    def to_dict(self) -> Dict[str, Any]:
        """Conversion en dict pour s√©rialisation."""
        return {
            "total_combinations": self.total_combinations,
            "per_param_counts": self.per_param_counts,
            "warnings": self.warnings,
            "has_overflow": self.has_overflow,
            "is_continuous": self.is_continuous,
        }


# --- 2.3. Preset ---

@dataclass
class Preset:
    """
    Preset de configuration (ex: Safe Ranges).

    D√©finit un ensemble d'indicateurs/param√®tres pr√©-configur√©s
    pour un usage courant.
    """
    name: str
    description: str
    parameters: Dict[str, ParameterSpec] = field(default_factory=dict)
    indicators: List[str] = field(default_factory=list)
    default_granularity: float = 0.5
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {k: v.to_dict() for k, v in self.parameters.items()},
            "indicators": self.indicators,
            "default_granularity": self.default_granularity,
            "metadata": self.metadata,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Preset":
        params = {}
        for name, spec in data.get("parameters", {}).items():
            params[name] = ParameterSpec(
                name=name,
                min_val=spec["min"],
                max_val=spec["max"],
                default=spec["default"],
                step=spec.get("step"),
                param_type=spec.get("type", "float"),
                description=spec.get("description", ""),
                optimize=spec.get("optimize", True)
            )

        return cls(
            name=data["name"],
            description=data.get("description", ""),
            parameters=params,
            indicators=data.get("indicators", []),
            default_granularity=data.get("default_granularity", 0.5),
            metadata=data.get("metadata", {}),
        )

    def get_default_values(self) -> Dict[str, Any]:
        """Retourne les valeurs par d√©faut de tous les param√®tres."""
        return {name: spec.default for name, spec in self.parameters.items()}

    def estimate_combinations(
        self, granularity: Optional[float] = None
    ) -> int:
        """Estime le nombre de combinaisons pour une granularit√© donn√©e."""
        if granularity is None:
            g = self.default_granularity
        else:
            g = granularity
        total, _ = calculate_combinations(self.parameters, g)
        return total


# --- 2.4. RangeProposal ---

@dataclass
class RangeProposal:
    """
    Proposition de plages de param√®tres pour grid search par le LLM.

    Permet au LLM de demander une exploration de param√®tres au lieu de
    configurations individuelles (ex: "bb_period entre 20-25 avec step 1").

    Attributes:
        ranges: Dict {param_name: {"min": x, "max": y, "step": z}}
        rationale: Raison de cette exploration (pour logs/debug)
        optimize_for: M√©trique cible (sharpe_ratio, sortino_ratio, etc.)
        max_combinations: Limite du nombre de combinaisons √† tester
        early_stop_threshold: Arr√™t anticip√© si m√©trique atteinte

    Example:
        >>> proposal = RangeProposal(
        ...     ranges={
        ...         "bb_period": {"min": 20, "max": 25, "step": 1},
        ...         "bb_std": {"min": 2.0, "max": 2.5, "step": 0.1}
        ...     },
        ...     rationale="Explorer corr√©lation bb_period vs bb_std",
        ...     max_combinations=50
        ... )
    """
    ranges: Dict[str, Dict[str, float]]
    rationale: str
    optimize_for: str = "sharpe_ratio"
    max_combinations: int = 100
    early_stop_threshold: Optional[float] = None


# --- 2.5. ParameterConstraint ---

@dataclass
class ParameterConstraint:
    """
    Contrainte inter-param√®tres pour filtrer les combinaisons invalides.

    Types de contraintes:
    - 'greater_than': param_a > param_b
    - 'less_than': param_a < param_b
    - 'ratio_min': param_a / param_b >= ratio
    - 'ratio_max': param_a / param_b <= ratio
    - 'sum_max': param_a + param_b <= value
    - 'custom': fonction personnalis√©e

    Examples:
        # slow_period doit √™tre > fast_period
        ParameterConstraint('slow_period', 'greater_than', 'fast_period')

        # slow doit √™tre au moins 1.5x plus grand que fast
        ParameterConstraint(
            'slow_period', 'ratio_min', 'fast_period', ratio=1.5
        )

        # √âcart minimum de 5 entre slow et fast
        ParameterConstraint(
            'slow_period', 'difference_min', 'fast_period', value=5
        )
    """
    param_a: str
    constraint_type: str
    param_b: Optional[str] = None
    value: Optional[float] = None
    ratio: Optional[float] = None
    description: str = ""

    def validate(self, params: Dict[str, Any]) -> bool:
        """
        V√©rifie si la combinaison de param√®tres respecte la contrainte.

        Args:
            params: Dictionnaire des param√®tres

        Returns:
            True si la contrainte est respect√©e
        """
        val_a = params.get(self.param_a)
        if val_a is None:
            return True  # Param√®tre absent, skip

        if self.constraint_type == 'greater_than':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return val_a > val_b

        elif self.constraint_type == 'greater_than_equal':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return val_a >= val_b

        elif self.constraint_type == 'less_than':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return val_a < val_b

        elif self.constraint_type == 'less_than_equal':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return val_a <= val_b

        elif self.constraint_type == 'ratio_min':
            val_b = params.get(self.param_b)
            if val_b is None or val_b == 0:
                return True
            return (val_a / val_b) >= (self.ratio or 1.0)

        elif self.constraint_type == 'ratio_max':
            val_b = params.get(self.param_b)
            if val_b is None or val_b == 0:
                return True
            return (val_a / val_b) <= (self.ratio or 1.0)

        elif self.constraint_type == 'difference_min':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return (val_a - val_b) >= (self.value or 0)

        elif self.constraint_type == 'difference_max':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return (val_a - val_b) <= (self.value or float('inf'))

        elif self.constraint_type == 'min_value':
            return val_a >= (self.value or 0)

        elif self.constraint_type == 'max_value':
            return val_a <= (self.value or float('inf'))

        elif self.constraint_type == 'sum_max':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return (val_a + val_b) <= (self.value or float('inf'))

        elif self.constraint_type == 'sum_min':
            val_b = params.get(self.param_b)
            if val_b is None:
                return True
            return (val_a + val_b) >= (self.value or 0)

        else:
            logger.warning(
                "Type de contrainte inconnu: %s",
                self.constraint_type,
            )
            return True

    def to_dict(self) -> Dict[str, Any]:
        return {
            "param_a": self.param_a,
            "constraint_type": self.constraint_type,
            "param_b": self.param_b,
            "value": self.value,
            "ratio": self.ratio,
            "description": self.description,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ParameterConstraint":
        return cls(
            param_a=data["param_a"],
            constraint_type=data["constraint_type"],
            param_b=data.get("param_b"),
            value=data.get("value"),
            ratio=data.get("ratio"),
            description=data.get("description", ""),
        )


# =============================================================================
# III. G√âN√âRATION D'ESPACES DE RECHERCHE
# =============================================================================

def parameter_values(
    min_val: float,
    max_val: float,
    granularity: float = 0.5,
    base_steps: int = 10,
    max_values: int = 4,
    param_type: str = "float"
) -> np.ndarray:
    """
    G√©n√®re les valeurs d'un param√®tre selon la granularit√©.

    Cette fonction applique une logique de r√©duction intelligente:
    - Granularit√© 0% = maximum de valeurs (jusqu'√† base_steps)
    - Granularit√© 100% = valeur m√©diane uniquement
    - Plafond de max_values valeurs pour √©viter l'explosion combinatoire
    - R√©duction dynamique si la plage est petite

    Args:
        min_val: Valeur minimale
        max_val: Valeur maximale
        granularity: Coefficient de granularit√© (0.0 √† 1.0)
        base_steps: Nombre de pas de base (avant r√©duction)
        max_values: Nombre maximum de valeurs retourn√©es
        param_type: Type de param√®tre ('int', 'float')

    Returns:
        Array numpy des valeurs √† tester

    Examples:
        >>> parameter_values(10, 50, granularity=0.0)  # Fin
        array([10., 20., 30., 40., 50.])

        >>> parameter_values(10, 50, granularity=1.0)  # Grossier
        array([30.])  # Juste la m√©diane
    """
    # Cas d√©g√©n√©r√©
    if min_val >= max_val:
        return np.array([min_val])

    granularity = float(granularity)
    if granularity < 0.0:
        granularity = 0.0
    elif granularity > 1.0:
        granularity = 1.0

    range_size = max_val - min_val

    # Granularit√© maximale = juste la m√©diane
    if granularity >= 0.99:
        median = (min_val + max_val) / 2
        if param_type == "int":
            return np.array([int(round(median))])
        return np.array([median])

    # Calculer le nombre de valeurs selon la granularit√©.
    # Plus la granularit√© est √©lev√©e, plus on r√©duit agressivement.
    # Forme non-lin√©aire pour √©viter une explosion combinatoire avec de nombreux param√®tres.
    effective_steps = max(1, int(base_steps * (1 - granularity) ** 2))

    # R√©duction dynamique pour petites plages
    # Si la plage est < 5% de la valeur moyenne, r√©duire encore
    avg_val = (min_val + max_val) / 2
    if avg_val > 0:
        relative_range = range_size / avg_val
        if relative_range < 0.05:
            effective_steps = max(1, effective_steps // 2)

    # Appliquer le plafond
    n_values = min(effective_steps + 1, max_values)

    # G√©n√©rer les valeurs
    if n_values == 1:
        values = np.array([(min_val + max_val) / 2])
    else:
        values = np.linspace(min_val, max_val, n_values)

    # Convertir en entiers si n√©cessaire
    if param_type == "int":
        values = np.unique(np.round(values).astype(int))
        # S'assurer qu'on respecte encore le plafond apr√®s arrondis
        if len(values) > max_values:
            indices = np.linspace(0, len(values) - 1, max_values, dtype=int)
            values = values[indices]

    return values


def calculate_combinations(
    params_specs: Dict[str, ParameterSpec],
    granularity: float = 0.5,
    max_values_per_param: int = 4
) -> Tuple[int, Dict[str, np.ndarray]]:
    """
    Calcule le nombre total de combinaisons et les valeurs pour chaque
    param√®tre.

    Args:
        params_specs: Dictionnaire des sp√©cifications de param√®tres
        granularity: Granularit√© globale
        max_values_per_param: Plafond par param√®tre

    Returns:
        Tuple (nombre_total_combinaisons, dict_valeurs_par_param)
    """
    param_values_dict = {}
    total = 1

    for name, spec in params_specs.items():
        values = parameter_values(
            min_val=spec.min_val,
            max_val=spec.max_val,
            granularity=granularity,
            max_values=max_values_per_param,
            param_type=spec.param_type
        )
        param_values_dict[name] = values
        total *= len(values)

    return total, param_values_dict


def generate_param_grid(
    params_specs: Dict[str, ParameterSpec],
    granularity: float = 0.5,
    max_values_per_param: int = 4,
    max_total_combinations: int = 10000
) -> List[Dict[str, Any]]:
    """
    G√©n√®re une grille de combinaisons de param√®tres.

    Args:
        params_specs: Sp√©cifications des param√®tres
        granularity: Granularit√©
        max_values_per_param: Plafond par param√®tre
        max_total_combinations: Limite totale de combinaisons

    Returns:
        Liste de dictionnaires, chaque dict = une combinaison

    Raises:
        ValueError: Si le nombre de combinaisons d√©passe la limite
    """
    total, param_values = calculate_combinations(
        params_specs, granularity, max_values_per_param
    )

    if total > max_total_combinations:
        raise ValueError(
            f"Trop de combinaisons ({total:,}). "
            f"Augmentez la granularit√© ou r√©duisez les param√®tres. "
            f"Limite: {max_total_combinations:,}"
        )

    # G√©n√©rer toutes les combinaisons via produit cart√©sien
    param_names = list(param_values.keys())
    param_arrays = [param_values[name] for name in param_names]

    combinations = []
    for combo in product(*param_arrays):
        combinations.append(dict(zip(param_names, combo)))

    return combinations


def compute_search_space_stats(
    param_space: Dict[str, Any],
    max_combinations: int = 100000,
    granularity: Optional[float] = None,
) -> SearchSpaceStats:
    """
    Calcule les statistiques d'un espace de recherche de mani√®re unifi√©e.

    Cette fonction accepte plusieurs formats d'entr√©e:
    - Dict[str, ParameterSpec]: sp√©cifications compl√®tes
    - Dict[str, Tuple[min, max]]: bornes seulement (continu)
    - Dict[str, Tuple[min, max, step]]: bornes avec step (discret)
    - Dict[str, dict]: avec cl√©s "min", "max", "step" (optionnel)

    Args:
        param_space: Dictionnaire d√©crivant l'espace des param√®tres
        max_combinations: Seuil d'avertissement pour overflow
        granularity: Si fourni, utilise parameter_values() pour le calcul

    Returns:
        SearchSpaceStats avec toutes les statistiques

    Examples:
        >>> # Avec ParameterSpec
        >>> stats = compute_search_space_stats({"fast": spec1, "slow": spec2})

        >>> # Avec tuples (min, max, step)
        >>> stats = compute_search_space_stats({
        ...     "fast_period": (5, 20, 1),
        ...     "slow_period": (20, 50, 5),
        ... })

        >>> # Avec bornes seulement (retourne is_continuous=True)
        >>> stats = compute_search_space_stats({
        ...     "fast_period": (5, 20),
        ...     "slow_period": (20, 50),
        ... })
    """
    total = 1
    counts: Dict[str, int] = {}
    warnings: List[str] = []
    is_continuous = False

    for name, spec in param_space.items():
        count = _compute_param_count(spec, granularity)

        if count == -1:
            is_continuous = True
            counts[name] = -1
        else:
            counts[name] = count
            if count > 0:
                total *= count

    # Si continu, total n'a pas de sens
    if is_continuous:
        total = -1
        warnings.append(
            "Espace continu: nombre de combinaisons non d√©fini (pas de step)"
        )

    # V√©rifier overflow
    has_overflow = not is_continuous and total > max_combinations
    if has_overflow:
        warnings.append(f"Limite d√©pass√©e: {total:,} > {max_combinations:,}")

    return SearchSpaceStats(
        total_combinations=total,
        per_param_counts=counts,
        warnings=warnings,
        has_overflow=has_overflow,
        is_continuous=is_continuous,
    )


# --- 3.5. normalize_param_ranges ---

def normalize_param_ranges(
    param_specs: List[ParameterSpec],
    ranges: Dict[str, Dict[str, float]]
) -> Dict[str, List[float]]:
    """
    Normalise et valide les ranges demand√©es par le LLM pour grid search.

    - Clamp aux bornes des ParameterSpec
    - V√©rifie min <= max, step > 0
    - Rejette cl√©s inconnues
    - Retourne param_grid compatible avec SweepEngine

    Args:
        param_specs: Liste des sp√©cifications de param√®tres (bornes autoris√©es)
        ranges: Ranges demand√©es par le LLM {param: {"min": x, "max": y, "step": z}}

    Returns:
        Dict[str, List[float]]: Grille de param√®tres pr√™te pour SweepEngine

    Raises:
        ValueError: Si ranges invalides (param inconnu, min > max, etc.)

    Example:
        >>> specs = [
        ...     ParameterSpec("bb_period", min_val=10, max_val=50, default=20, step=1),
        ...     ParameterSpec("bb_std", min_val=1.0, max_val=3.0, default=2.0, step=0.1)
        ... ]
        >>> ranges = {
        ...     "bb_period": {"min": 20, "max": 25, "step": 1},
        ...     "bb_std": {"min": 2.0, "max": 2.5, "step": 0.1}
        ... }
        >>> grid = normalize_param_ranges(specs, ranges)
        >>> grid["bb_period"]
        [20, 21, 22, 23, 24, 25]
        >>> grid["bb_std"]
        [2.0, 2.1, 2.2, 2.3, 2.4, 2.5]
    """
    param_grid: Dict[str, List[float]] = {}
    specs_dict = {spec.name: spec for spec in param_specs}

    for param_name, range_def in ranges.items():
        # V√©rifier que le param√®tre existe
        if param_name not in specs_dict:
            raise ValueError(
                f"Param√®tre inconnu '{param_name}'. "
                f"Param√®tres disponibles: {list(specs_dict.keys())}"
            )

        spec = specs_dict[param_name]

        # Extraire min/max/step
        min_val = range_def.get("min")
        max_val = range_def.get("max")
        step = range_def.get("step")

        if min_val is None or max_val is None:
            raise ValueError(
                f"Param√®tre '{param_name}': 'min' et 'max' sont obligatoires"
            )

        # Clamp aux bornes du ParameterSpec
        clamped_min = max(min_val, spec.min_val)
        clamped_max = min(max_val, spec.max_val)

        # Log si clamping appliqu√©
        if clamped_min != min_val or clamped_max != max_val:
            logger.warning(
                f"Ranges clamped pour '{param_name}': "
                f"[{min_val}, {max_val}] ‚Üí [{clamped_min}, {clamped_max}] "
                f"(limites: [{spec.min_val}, {spec.max_val}])"
            )

        # V√©rifier coh√©rence min/max
        if clamped_min > clamped_max:
            raise ValueError(
                f"Param√®tre '{param_name}': min ({clamped_min}) > max ({clamped_max}) "
                f"apr√®s clamping aux limites [{spec.min_val}, {spec.max_val}]"
            )

        # Utiliser step fourni ou step du spec
        if step is None:
            step = spec.step if spec.step is not None else (clamped_max - clamped_min) / 10

        if step <= 0:
            raise ValueError(
                f"Param√®tre '{param_name}': step doit √™tre > 0 (re√ßu: {step})"
            )

        # G√©n√©rer valeurs (m√©thode robuste pour √©viter erreurs de pr√©cision float)
        n_steps = int(round((clamped_max - clamped_min) / step)) + 1
        values: List[float] = []

        for i in range(n_steps):
            current = clamped_min + (i * step)

            # S'assurer de ne pas d√©passer max (avec tol√©rance pour pr√©cision float)
            if current > clamped_max + 1e-9:
                break

            # Arrondir pour √©viter probl√®mes de pr√©cision float
            if spec.param_type == "int":
                values.append(int(round(current)))
            else:
                values.append(round(current, 10))

        if not values:
            raise ValueError(
                f"Param√®tre '{param_name}': aucune valeur g√©n√©r√©e "
                f"(min={clamped_min}, max={clamped_max}, step={step})"
            )

        param_grid[param_name] = values

    logger.info(
        f"Grid normalis√©: {len(param_grid)} param√®tres, "
        f"{sum(len(vals) for vals in param_grid.values())} valeurs totales"
    )

    return param_grid


# =============================================================================
# IV. SYST√àME DE CONTRAINTES
# =============================================================================

class ConstraintValidator:
    """
    Validateur de contraintes pour filtrer les combinaisons de param√®tres.

    Usage:
        validator = ConstraintValidator()
        validator.add_constraint(
            ParameterConstraint('slow', 'greater_than', 'fast')
        )

        # Filtrer une grille
        valid_combos = validator.filter_grid(param_grid)

        # V√©rifier une combinaison
        is_valid = validator.validate({'slow': 26, 'fast': 12})
    """

    def __init__(
        self, constraints: Optional[List[ParameterConstraint]] = None
    ):
        self.constraints: List[ParameterConstraint] = constraints or []

    def add_constraint(self, constraint: ParameterConstraint) -> None:
        """Ajoute une contrainte."""
        self.constraints.append(constraint)
        logger.debug(
            "Contrainte ajout√©e: %s %s",
            constraint.param_a,
            constraint.constraint_type,
        )

    def add_greater_than(
        self, param_a: str, param_b: str, description: str = ""
    ) -> None:
        """Raccourci pour ajouter une contrainte param_a > param_b."""
        self.add_constraint(ParameterConstraint(
            param_a=param_a,
            constraint_type='greater_than',
            param_b=param_b,
            description=description or f"{param_a} doit √™tre > {param_b}"
        ))

    def add_ratio_min(
        self,
        param_a: str,
        param_b: str,
        ratio: float,
        description: str = "",
    ) -> None:
        """Raccourci pour ajouter une contrainte param_a / param_b >= ratio."""
        self.add_constraint(ParameterConstraint(
            param_a=param_a,
            constraint_type='ratio_min',
            param_b=param_b,
            ratio=ratio,
            description=description
            or f"{param_a} / {param_b} doit √™tre >= {ratio}"
        ))

    def add_difference_min(
        self,
        param_a: str,
        param_b: str,
        diff: float,
        description: str = "",
    ) -> None:
        """Raccourci pour ajouter une contrainte param_a - param_b >= diff."""
        self.add_constraint(ParameterConstraint(
            param_a=param_a,
            constraint_type='difference_min',
            param_b=param_b,
            value=diff,
            description=description
            or f"{param_a} - {param_b} doit √™tre >= {diff}"
        ))

    def validate(self, params: Dict[str, Any]) -> bool:
        """
        V√©rifie si une combinaison de param√®tres respecte toutes les
        contraintes.

        Args:
            params: Dictionnaire des param√®tres

        Returns:
            True si toutes les contraintes sont respect√©es
        """
        return all(c.validate(params) for c in self.constraints)

    def filter_grid(
        self,
        param_grid: List[Dict[str, Any]],
        log_filtered: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Filtre une grille de param√®tres selon les contraintes.

        Args:
            param_grid: Liste de combinaisons de param√®tres
            log_filtered: Si True, log les combinaisons filtr√©es

        Returns:
            Liste des combinaisons valides
        """
        if not self.constraints:
            return param_grid

        valid = []
        filtered_count = 0

        for params in param_grid:
            if self.validate(params):
                valid.append(params)
            else:
                filtered_count += 1
                if log_filtered:
                    logger.debug("Combinaison filtr√©e: %s", params)

        if filtered_count > 0:
            logger.info(
                "Contraintes: %s/%s combinaisons filtr√©es (%s valides)",
                filtered_count,
                len(param_grid),
                len(valid),
            )

        return valid

    def get_violations(self, params: Dict[str, Any]) -> List[str]:
        """
        Retourne la liste des contraintes viol√©es.

        Args:
            params: Dictionnaire des param√®tres

        Returns:
            Liste des descriptions des contraintes viol√©es
        """
        violations = []
        for constraint in self.constraints:
            if not constraint.validate(params):
                desc = constraint.description or (
                    f"{constraint.param_a} {constraint.constraint_type} "
                    f"{constraint.param_b or constraint.value}"
                )
                violations.append(desc)
        return violations

    def to_dict(self) -> List[Dict[str, Any]]:
        return [c.to_dict() for c in self.constraints]

    @classmethod
    def from_dict(cls, data: List[Dict[str, Any]]) -> "ConstraintValidator":
        constraints = [ParameterConstraint.from_dict(c) for c in data]
        return cls(constraints=constraints)


# Contraintes pr√©d√©finies courantes
COMMON_CONSTRAINTS = {
    "ema_cross": ConstraintValidator([
        ParameterConstraint(
            param_a="slow_period",
            constraint_type="greater_than",
            param_b="fast_period",
            description="La p√©riode lente doit √™tre > p√©riode rapide"
        ),
        ParameterConstraint(
            param_a="slow_period",
            constraint_type="ratio_min",
            param_b="fast_period",
            ratio=1.5,
            description="La p√©riode lente doit √™tre au moins 1.5x la rapide"
        ),
    ]),
    "bollinger": ConstraintValidator([
        ParameterConstraint(
            param_a="bb_std",
            constraint_type="min_value",
            value=1.0,
            description="L'√©cart-type doit √™tre >= 1.0"
        ),
    ]),
    "atr_stop": ConstraintValidator([
        ParameterConstraint(
            param_a="k_sl",
            constraint_type="min_value",
            value=0.5,
            description="Le multiplicateur SL doit √™tre >= 0.5"
        ),
        ParameterConstraint(
            param_a="k_sl",
            constraint_type="max_value",
            value=5.0,
            description="Le multiplicateur SL doit √™tre <= 5.0"
        ),
    ]),
}


def get_common_constraints(strategy_type: str) -> ConstraintValidator:
    """R√©cup√®re les contraintes pr√©d√©finies pour un type de strat√©gie."""
    return COMMON_CONSTRAINTS.get(strategy_type, ConstraintValidator())


def generate_constrained_param_grid(
    params_specs: Dict[str, ParameterSpec],
    constraints: Optional[ConstraintValidator] = None,
    granularity: float = 0.5,
    max_values_per_param: int = 4,
    max_total_combinations: int = 10000
) -> List[Dict[str, Any]]:
    """
    G√©n√®re une grille de param√®tres avec filtrage par contraintes.

    Args:
        params_specs: Sp√©cifications des param√®tres
        constraints: Validateur de contraintes (optionnel)
        granularity: Granularit√©
        max_values_per_param: Plafond par param√®tre
        max_total_combinations: Limite totale de combinaisons

    Returns:
        Liste de combinaisons valides
    """
    # G√©n√©rer la grille brute
    grid = generate_param_grid(
        params_specs=params_specs,
        granularity=granularity,
        max_values_per_param=max_values_per_param,
        max_total_combinations=max_total_combinations
    )

    # Appliquer les contraintes si pr√©sentes
    if constraints:
        grid = constraints.filter_grid(grid)

    return grid


# =============================================================================
# V. PRESETS SIMPLES (IN-MEMORY)
# =============================================================================

# --- 5.1. D√©finitions des presets ---

SAFE_RANGES_PRESET = Preset(
    name="Safe Ranges",
    description="Configuration conservative avec 4 indicateurs de base. "
                "~750 combinaisons pour une optimisation rapide.",
    parameters={
        # Bollinger Bands
        "bb_period": ParameterSpec(
            name="bb_period",
            min_val=10,
            max_val=50,
            default=20,
            param_type="int",
            description="P√©riode des Bandes de Bollinger"
        ),
        "bb_std": ParameterSpec(
            name="bb_std",
            min_val=1.5,
            max_val=3.0,
            default=2.0,
            param_type="float",
            description="Nombre d'√©carts-types pour les bandes"
        ),
        # ATR
        "atr_period": ParameterSpec(
            name="atr_period",
            min_val=7,
            max_val=21,
            default=14,
            param_type="int",
            description="P√©riode de l'ATR"
        ),
        # Stop Loss
        "k_sl": ParameterSpec(
            name="k_sl",
            min_val=1.0,
            max_val=3.0,
            default=1.5,
            param_type="float",
            description="Multiplicateur ATR pour stop-loss"
        ),
        # Leverage (non optimis√©, fix√© √† 1)
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=["bollinger", "atr"],
    default_granularity=0.5
)


MINIMAL_PRESET = Preset(
    name="Minimal",
    description="Configuration minimale pour tests rapides. "
                "Param√®tres par d√©faut, pas d'optimisation.",
    parameters={
        "bb_period": ParameterSpec("bb_period", 20, 20, 20, param_type="int"),
        "bb_std": ParameterSpec("bb_std", 2.0, 2.0, 2.0),
        "atr_period": ParameterSpec(
            "atr_period", 14, 14, 14, param_type="int"
        ),
        "k_sl": ParameterSpec("k_sl", 1.5, 1.5, 1.5),
        "leverage": ParameterSpec("leverage", 1, 1, 1, param_type="int", optimize=False),
    },
    indicators=["bollinger", "atr"],
    default_granularity=1.0
)


EMA_CROSS_PRESET = Preset(
    name="EMA Cross",
    description="Configuration pour strat√©gie de croisement EMA.",
    parameters={
        "fast_period": ParameterSpec(
            name="fast_period",
            min_val=5,
            max_val=20,
            default=12,
            param_type="int",
            description="P√©riode EMA rapide"
        ),
        "slow_period": ParameterSpec(
            name="slow_period",
            min_val=20,
            max_val=50,
            default=26,
            param_type="int",
            description="P√©riode EMA lente"
        ),
        "k_sl": ParameterSpec(
            name="k_sl",
            min_val=1.0,
            max_val=3.0,
            default=2.0,
            param_type="float",
            description="Multiplicateur pour stop-loss %"
        ),
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=[],  # EMA calcul√©e internement par la strat√©gie
    default_granularity=0.5
)


MACD_CROSS_PRESET = Preset(
    name="MACD Cross",
    description="Configuration pour strat√©gie MACD Crossover. "
                "~256 combinaisons.",
    parameters={
        "fast_period": ParameterSpec(
            name="fast_period",
            min_val=8,
            max_val=20,
            default=12,
            param_type="int",
            description="P√©riode EMA rapide MACD"
        ),
        "slow_period": ParameterSpec(
            name="slow_period",
            min_val=20,
            max_val=35,
            default=26,
            param_type="int",
            description="P√©riode EMA lente MACD"
        ),
        "signal_period": ParameterSpec(
            name="signal_period",
            min_val=5,
            max_val=15,
            default=9,
            param_type="int",
            description="P√©riode ligne signal"
        ),
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=["macd"],
    default_granularity=0.5
)


RSI_REVERSAL_PRESET = Preset(
    name="RSI Reversal",
    description="Configuration pour strat√©gie RSI mean-reversion. "
                "~256 combinaisons.",
    parameters={
        "rsi_period": ParameterSpec(
            name="rsi_period",
            min_val=7,
            max_val=21,
            default=14,
            param_type="int",
            description="P√©riode RSI"
        ),
        "oversold_level": ParameterSpec(
            name="oversold_level",
            min_val=20,
            max_val=40,
            default=30,
            param_type="int",
            description="Seuil survente"
        ),
        "overbought_level": ParameterSpec(
            name="overbought_level",
            min_val=60,
            max_val=80,
            default=70,
            param_type="int",
            description="Seuil surachat"
        ),
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=["rsi"],
    default_granularity=0.5
)


ATR_CHANNEL_PRESET = Preset(
    name="ATR Channel",
    description="Configuration pour strat√©gie ATR Channel breakout. "
                "~256 combinaisons.",
    parameters={
        "atr_period": ParameterSpec(
            name="atr_period",
            min_val=7,
            max_val=21,
            default=14,
            param_type="int",
            description="P√©riode ATR et EMA"
        ),
        "atr_mult": ParameterSpec(
            name="atr_mult",
            min_val=1.0,
            max_val=4.0,
            default=2.0,
            param_type="float",
            description="Multiplicateur ATR pour canal"
        ),
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=["atr", "ema"],
    default_granularity=0.5
)


BOLLINGER_ATR_PRESET = Preset(
    name="Bollinger ATR",
    description="Configuration pour strat√©gie Bollinger + filtre ATR. ~128-2000 combinaisons selon granularit√©.",
    parameters={
        "bb_period": ParameterSpec(
            name="bb_period",
            min_val=10,
            max_val=40,
            default=20,
            param_type="int",
            description="P√©riode des bandes de Bollinger",
        ),
        "bb_std": ParameterSpec(
            name="bb_std",
            min_val=1.5,
            max_val=3.0,
            default=2.0,
            param_type="float",
            description="√âcart-type des bandes",
        ),
        "entry_z": ParameterSpec(
            name="entry_z",
            min_val=1.0,
            max_val=3.0,
            default=2.0,
            param_type="float",
            description="Seuil Z-score d'entr√©e",
        ),
        "atr_period": ParameterSpec(
            name="atr_period",
            min_val=7,
            max_val=21,
            default=14,
            param_type="int",
            description="P√©riode ATR",
        ),
        "atr_percentile": ParameterSpec(
            name="atr_percentile",
            min_val=10,
            max_val=60,
            default=30,
            param_type="int",
            description="Percentile de filtre volatilit√© (ATR)",
        ),
        "k_sl": ParameterSpec(
            name="k_sl",
            min_val=0.5,
            max_val=3.0,
            default=1.5,
            param_type="float",
            description="Multiplicateur stop-loss (ATR)",
        ),
        "leverage": ParameterSpec(
            name="leverage",
            min_val=1,
            max_val=1,
            default=1,
            param_type="int",
            description="Levier de trading (fix√© √† 1)",
            optimize=False,
        ),
    },
    indicators=["bollinger", "atr"],
    default_granularity=0.7,
)


# --- 5.2. Registre PRESETS ---

PRESETS: Dict[str, Preset] = {
    "safe_ranges": SAFE_RANGES_PRESET,
    "minimal": MINIMAL_PRESET,
    "bollinger_atr": BOLLINGER_ATR_PRESET,
    "ema_cross": EMA_CROSS_PRESET,
    "macd_cross": MACD_CROSS_PRESET,
    "rsi_reversal": RSI_REVERSAL_PRESET,
    "atr_channel": ATR_CHANNEL_PRESET,
}


# --- 5.3. Fonctions d'acc√®s ---

def get_preset(name: str) -> Preset:
    """R√©cup√®re un preset par son nom."""
    if name not in PRESETS:
        available = ", ".join(PRESETS.keys())
        raise ValueError(
            f"Preset '{name}' non trouv√©. Disponibles: {available}"
        )
    return PRESETS[name]


def list_presets() -> List[str]:
    """Liste les presets disponibles."""
    return list(PRESETS.keys())


# =============================================================================
# VI. PRESETS I/O (DISQUE)
# =============================================================================

def save_preset(preset: Preset, filepath: Path) -> None:
    """Sauvegarde un preset en JSON."""
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(preset.to_dict(), f, indent=2, ensure_ascii=False)


def load_preset(filepath: Path) -> Preset:
    """Charge un preset depuis un fichier JSON."""
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    return Preset.from_dict(data)


# =============================================================================
# VII. PRESETS VERSIONN√âS (SYST√àME AVANC√â)
# =============================================================================

# --- 7.1. Configuration et gestion du r√©pertoire ---

def get_versioned_presets_dir() -> Path:
    """Return directory for versioned presets."""
    env_value = os.getenv(VERSIONED_PRESETS_DIR_ENV)
    if env_value:
        return Path(env_value)
    repo_root = _get_repo_root()
    target = repo_root / "data" / "presets"
    _migrate_legacy_presets(target)
    return target


# --- 7.2. Sauvegarde et chargement ---

def save_versioned_preset(
    strategy_name: str,
    version: str,
    preset_name: str,
    params_values: Dict[str, Any],
    indicators: Optional[List[str]] = None,
    description: Optional[str] = None,
    metrics: Optional[Dict[str, Any]] = None,
    *,
    origin: Optional[str] = None,
    origin_run_id: Optional[str] = None,
    extra_metadata: Optional[Dict[str, Any]] = None,
) -> Preset:
    """
    Save a versioned preset to disk and return it.

    Naming convention:
        <strategy>@<version>__<preset_slug>
    """
    preset_name = (preset_name or "winner").strip() or "winner"
    version = (version or DEFAULT_STRATEGY_VERSION).strip()
    if not version:
        version = DEFAULT_STRATEGY_VERSION
    strategy_slug = _normalize_slug(strategy_name)
    preset_slug = _normalize_slug(preset_name)
    preset_id = f"{strategy_slug}@{version}__{preset_slug}"

    if indicators is None:
        from utils.preset_validation import auto_fill_indicators_from_strategy
        indicators = auto_fill_indicators_from_strategy(strategy_name)

    params_values = params_values or {}
    param_specs = _build_fixed_parameter_specs(params_values)
    created_at = datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

    metadata: Dict[str, Any] = {
        "strategy": strategy_name,
        "strategy_slug": strategy_slug,
        "version": version,
        "preset_name": preset_name,
        "preset_slug": preset_slug,
        "origin": origin or "manual",
        "created_at": created_at,
        "params_values": _to_builtin(params_values),
    }
    if metrics:
        metadata["metrics"] = _to_builtin(metrics)
    if origin_run_id:
        metadata["origin_run_id"] = origin_run_id
    if extra_metadata:
        metadata.update(_to_builtin(extra_metadata))

    preset = Preset(
        name=preset_id,
        description=description or f"Versioned preset for {strategy_name}",
        parameters=param_specs,
        indicators=indicators or [],
        default_granularity=0.5,
        metadata=metadata,
    )

    presets_dir = get_versioned_presets_dir()
    presets_dir.mkdir(parents=True, exist_ok=True)
    filepath = presets_dir / f"{preset_id}.json"
    if filepath.exists():
        logger.warning("Overwriting preset file: %s", filepath)
    save_preset(preset, filepath)
    return preset


def load_strategy_version(
    strategy_name: str,
    version: Optional[str] = None,
    preset_name: Optional[str] = None,
) -> Preset:
    """
    Load a versioned preset for a strategy, validated against indicators.
    """
    presets = list_strategy_versions(strategy_name)
    if not presets:
        raise ValueError(
            f"No versioned presets found for strategy '{strategy_name}'"
        )

    if version is None:
        version = resolve_latest_version(strategy_name)
    version = version.strip()

    filtered = [
        p for p in presets
        if (p.metadata or {}).get("version") == version
    ]

    if preset_name:
        preset_slug = _normalize_slug(preset_name)
        filtered = [
            p for p in filtered
            if (
                (p.metadata or {}).get("preset_slug") == preset_slug
                or (p.metadata or {}).get("preset_name") == preset_name
                or p.name == preset_name
            )
        ]

    if not filtered:
        raise ValueError(
            "No matching versioned preset for strategy "
            f"'{strategy_name}' version='{version}'"
        )

    filtered.sort(key=_preset_sort_key, reverse=True)
    preset = filtered[0]
    return validate_before_use(preset, strategy_name)


# --- 7.3. Listage et r√©solution ---

def list_strategy_versions(strategy_name: str) -> List[Preset]:
    """List versioned presets for a strategy."""
    presets_dir = get_versioned_presets_dir()
    if not presets_dir.exists():
        return []

    strategy_slug = _normalize_slug(strategy_name)
    presets: List[Preset] = []

    for path in presets_dir.glob("*.json"):
        parsed = _parse_versioned_id(path.stem)
        if not parsed or parsed["strategy"] != strategy_slug:
            continue
        try:
            preset = load_preset(path)
        except Exception as exc:
            logger.warning("Failed to load preset %s: %s", path, exc)
            continue
        _apply_versioned_defaults(preset, strategy_name, parsed, path)
        presets.append(preset)

    presets.sort(key=_preset_sort_key, reverse=True)
    return presets


def resolve_latest_version(strategy_name: str) -> str:
    """Resolve latest version for a strategy or fallback default."""
    presets = list_strategy_versions(strategy_name)
    if not presets:
        return DEFAULT_STRATEGY_VERSION
    versions = [
        (preset.metadata or {}).get("version", "")
        for preset in presets
    ]
    versions = [v for v in versions if v]
    if not versions:
        return DEFAULT_STRATEGY_VERSION
    versions.sort(key=_semver_key, reverse=True)
    return versions[0]


# --- 7.4. Validation ---

def validate_before_use(preset: Preset, strategy_name: str) -> Preset:
    """Validate preset against strategy indicators before use."""
    from utils.preset_validation import validate_preset_against_strategy

    result = validate_preset_against_strategy(preset, strategy_name)
    if not result.is_valid:
        details = "; ".join(result.errors + result.warnings)
        raise ValueError(
            f"Preset validation failed for '{strategy_name}': {details}"
        )
    return preset


# =============================================================================
# VIII. EXPORTS
# =============================================================================

__all__ = [
    # Types
    "ParameterSpec",
    "ParameterConstraint",
    "ConstraintValidator",
    "Preset",
    "SearchSpaceStats",
    "RangeProposal",
    # Search space generation
    "parameter_values",
    "calculate_combinations",
    "compute_search_space_stats",
    "normalize_param_ranges",
    "generate_param_grid",
    "generate_constrained_param_grid",
    # Presets simple
    "get_preset",
    "list_presets",
    "save_preset",
    "load_preset",
    # Presets versionn√©s
    "get_versioned_presets_dir",
    "save_versioned_preset",
    "list_strategy_versions",
    "load_strategy_version",
    "resolve_latest_version",
    "validate_before_use",
    "DEFAULT_STRATEGY_VERSION",
    # Contraintes
    "get_common_constraints",
    "COMMON_CONSTRAINTS",
    # Presets pr√©d√©finis
    "SAFE_RANGES_PRESET",
    "MINIMAL_PRESET",
    "EMA_CROSS_PRESET",
    "MACD_CROSS_PRESET",
    "RSI_REVERSAL_PRESET",
    "ATR_CHANNEL_PRESET",
    "PRESETS",
]
```
<!-- MODULE-END: parameters.py -->

<!-- MODULE-START: preset_validation.py -->
```json
{
  "name": "preset_validation.py",
  "path": "utils\\preset_validation.py",
  "ext": ".py",
  "anchor": "preset_validation_py"
}
```
## preset_validation_py
*Chemin* : `utils\preset_validation.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.preset_validation

Purpose: Valide/remplit presets (coh√©rence indicateurs et params vs strat√©gies).

Role in pipeline: configuration

Key components: PresetValidationResult, validate_preset(), auto_fill_indicators_from_strategy()

Inputs: Preset dict, strategy name, expected indicators

Outputs: ValidationResult {is_valid, errors[], warnings[], summary()}

Dependencies: dataclasses, typing, log

Conventions: Auto-fill indicateurs depuis mapping; erreurs = breaks validit√©; warnings = info.

Read-if: Modification validation ou preset auto-fill.

Skip-if: Vous appelez juste validate_preset(preset_name).
"""

from dataclasses import dataclass
from typing import TYPE_CHECKING, Dict, List, Optional

from utils.log import get_logger

if TYPE_CHECKING:
    from utils.parameters import Preset

logger = get_logger(__name__)


@dataclass
class PresetValidationResult:
    """R√©sultat de validation d'un Preset."""

    preset_name: str
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    indicators_match: bool
    indicators_expected: List[str]
    indicators_actual: List[str]

    def summary(self) -> str:
        """Retourne un r√©sum√© textuel."""
        if self.is_valid:
            return f"‚úì {self.preset_name}: VALIDE"
        else:
            errors_str = ", ".join(self.errors)
            return f"‚úó {self.preset_name}: INVALIDE - {errors_str}"


def auto_fill_indicators_from_strategy(strategy_name: str) -> List[str]:
    """
    Auto-remplit les indicateurs requis depuis le mapping de strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie

    Returns:
        Liste des indicateurs requis

    Example:
        >>> indicators = auto_fill_indicators_from_strategy("bollinger_atr")
        >>> print(indicators)
        ['bollinger', 'atr']
    """
    try:
        from strategies.indicators_mapping import get_required_indicators
        return get_required_indicators(strategy_name)
    except ImportError:
        logger.warning("Module indicators_mapping non disponible")
        return []
    except KeyError:
        logger.warning(f"Strat√©gie '{strategy_name}' non trouv√©e dans le mapping")
        return []


def validate_preset_against_strategy(
    preset: "Preset",  # type: ignore
    strategy_name: str
) -> PresetValidationResult:
    """
    Valide qu'un Preset correspond bien aux indicateurs requis par une strat√©gie.

    Args:
        preset: Instance de Preset √† valider
        strategy_name: Nom de la strat√©gie associ√©e

    Returns:
        PresetValidationResult avec tous les d√©tails
    """
    errors = []
    warnings = []

    # R√©cup√©rer les indicateurs attendus
    try:
        from strategies.indicators_mapping import get_required_indicators
        expected_indicators = get_required_indicators(strategy_name)
    except ImportError:
        errors.append("Module indicators_mapping non disponible")
        return PresetValidationResult(
            preset_name=preset.name,
            is_valid=False,
            errors=errors,
            warnings=warnings,
            indicators_match=False,
            indicators_expected=[],
            indicators_actual=preset.indicators
        )
    except KeyError:
        errors.append(f"Strat√©gie '{strategy_name}' non trouv√©e")
        return PresetValidationResult(
            preset_name=preset.name,
            is_valid=False,
            errors=errors,
            warnings=warnings,
            indicators_match=False,
            indicators_expected=[],
            indicators_actual=preset.indicators
        )

    # Comparer les indicateurs
    expected_set = set(expected_indicators)
    actual_set = set(preset.indicators)

    if expected_set != actual_set:
        missing = expected_set - actual_set
        extra = actual_set - expected_set

        if missing:
            errors.append(f"Indicateurs manquants: {sorted(missing)}")
        if extra:
            warnings.append(f"Indicateurs en trop: {sorted(extra)}")

    indicators_match = expected_set == actual_set
    is_valid = len(errors) == 0 and indicators_match

    return PresetValidationResult(
        preset_name=preset.name,
        is_valid=is_valid,
        errors=errors,
        warnings=warnings,
        indicators_match=indicators_match,
        indicators_expected=expected_indicators,
        indicators_actual=preset.indicators
    )


def validate_all_presets() -> Dict[str, PresetValidationResult]:
    """
    Valide tous les Presets du registre.

    Returns:
        Dict mapping preset_name ‚Üí PresetValidationResult
    """
    from utils.parameters import PRESETS

    # Mapping Preset ‚Üí Strat√©gie
    preset_to_strategy = {
        "safe_ranges": "bollinger_atr",
        "minimal": "bollinger_atr",
        "ema_cross": "ema_cross",
        "macd_cross": "macd_cross",
        "rsi_reversal": "rsi_reversal",
        "atr_channel": "atr_channel",
    }

    results = {}

    for preset_name, preset in PRESETS.items():
        if preset_name in preset_to_strategy:
            strategy_name = preset_to_strategy[preset_name]
            result = validate_preset_against_strategy(preset, strategy_name)
            results[preset_name] = result
        else:
            logger.warning(f"Preset '{preset_name}' sans strat√©gie associ√©e")

    return results


def create_preset_from_strategy(
    strategy_name: str,
    preset_name: Optional[str] = None,
    description: Optional[str] = None,
    granularity: float = 0.5
) -> "Preset":  # type: ignore
    """
    Cr√©e un Preset automatiquement depuis une strat√©gie.

    Args:
        strategy_name: Nom de la strat√©gie
        preset_name: Nom du preset (d√©faut: strategy_name + "_default")
        description: Description (d√©faut: auto-g√©n√©r√©)
        granularity: Granularit√© par d√©faut

    Returns:
        Instance de Preset avec indicateurs auto-remplis

    Example:
        >>> preset = create_preset_from_strategy("bollinger_atr")
        >>> print(preset.indicators)
        ['bollinger', 'atr']
    """
    from strategies.base import get_strategy
    from strategies.indicators_mapping import get_required_indicators
    from utils.parameters import Preset

    # Charger la strat√©gie
    strategy_class = get_strategy(strategy_name)
    strategy = strategy_class()

    # Auto-remplir les indicateurs
    indicators = get_required_indicators(strategy_name)

    # G√©n√©rer le nom et la description
    if preset_name is None:
        preset_name = f"{strategy_name}_default"

    if description is None:
        description = f"Configuration auto-g√©n√©r√©e pour {strategy.name}"

    # Cr√©er le Preset
    preset = Preset(
        name=preset_name,
        description=description,
        parameters=strategy.parameter_specs,
        indicators=indicators,
        default_granularity=granularity
    )

    return preset


def format_validation_report(results: Dict[str, PresetValidationResult]) -> str:
    """
    Formate un rapport de validation complet.

    Args:
        results: R√©sultats de validation

    Returns:
        Rapport format√© en texte
    """
    lines = ["=" * 80]
    lines.append("RAPPORT DE VALIDATION DES PRESETS")
    lines.append("=" * 80)
    lines.append("")

    valid_count = sum(1 for r in results.values() if r.is_valid)
    total_count = len(results)

    lines.append(f"‚úì {valid_count}/{total_count} Presets valides")
    lines.append("")

    for preset_name, result in results.items():
        if result.is_valid:
            lines.append(f"‚úì {result.preset_name}")
            lines.append(f"   Indicateurs: {result.indicators_actual}")
        else:
            lines.append(f"‚úó {result.preset_name}")
            for error in result.errors:
                lines.append(f"   ERREUR: {error}")
            for warning in result.warnings:
                lines.append(f"   WARN: {warning}")
            lines.append(f"   Attendu: {result.indicators_expected}")
            lines.append(f"   Actuel:  {result.indicators_actual}")
        lines.append("")

    lines.append("=" * 80)

    return "\n".join(lines)


__all__ = [
    "PresetValidationResult",
    "auto_fill_indicators_from_strategy",
    "validate_preset_against_strategy",
    "validate_all_presets",
    "create_preset_from_strategy",
    "format_validation_report",
]
```
<!-- MODULE-END: preset_validation.py -->

<!-- MODULE-START: run_tracker.py -->
```json
{
  "name": "run_tracker.py",
  "path": "utils\\run_tracker.py",
  "ext": ".py",
  "anchor": "run_tracker_py"
}
```
## run_tracker_py
*Chemin* : `utils\run_tracker.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.run_tracker

Purpose: D√©duplique runs d'optimisation cross-sessions (detect d√©j√† ex√©cut√©s).

Role in pipeline: optimization

Key components: RunTracker, RunSignature, compute_hash(), DuplicateDetector

Inputs: Strategy name, data path, initial params, LLM model, mode

Outputs: Run hash, duplicates_found flag, cached results if available

Dependencies: hashlib, json, dataclasses, pathlib, datetime

Conventions: Hash stable (cl√©s tri√©es); d√©tection inter-runs; stockage disque.

Read-if: Modification d√©tection duplicates ou gestion cache.

Skip-if: Vous appelez tracker.get_cached_result(signature).
"""

import hashlib
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class RunSignature:
    """Signature unique d'un run d'optimisation."""

    strategy_name: str
    data_path: str
    initial_params: Dict[str, Any]
    llm_model: Optional[str] = None
    mode: str = "multi_agents"  # "multi_agents", "autonomous", "grid", etc.

    # M√©tadonn√©es
    timestamp: str = ""
    session_id: str = ""

    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

    def compute_hash(self) -> str:
        """Calcule un hash unique pour cette configuration."""
        # Cr√©er un dict normalis√© pour garantir le m√™me hash
        data = {
            "strategy": self.strategy_name,
            "data": self.data_path,
            "params": sorted(self.initial_params.items()),
            "model": self.llm_model or "",
            "mode": self.mode,
        }

        # Convertir en JSON stable (cl√©s tri√©es)
        json_str = json.dumps(data, sort_keys=True, ensure_ascii=False)

        # Hash SHA256
        return hashlib.sha256(json_str.encode()).hexdigest()[:16]

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "strategy_name": self.strategy_name,
            "data_path": self.data_path,
            "initial_params": self.initial_params,
            "llm_model": self.llm_model,
            "mode": self.mode,
            "timestamp": self.timestamp,
            "session_id": self.session_id,
            "hash": self.compute_hash(),
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "RunSignature":
        """Cr√©e depuis un dictionnaire."""
        return cls(
            strategy_name=data.get("strategy_name", ""),
            data_path=data.get("data_path", ""),
            initial_params=data.get("initial_params", {}),
            llm_model=data.get("llm_model"),
            mode=data.get("mode", "multi_agents"),
            timestamp=data.get("timestamp", ""),
            session_id=data.get("session_id", ""),
        )


class RunTracker:
    """
    Tracker des runs d'optimisation pour √©viter les doublons.

    Usage:
        tracker = RunTracker()
        signature = RunSignature(strategy="...", data_path="...", ...)

        if tracker.is_duplicate(signature):
            print("Configuration d√©j√† test√©e!")
        else:
            tracker.register(signature)
            # ... lancer l'optimisation
    """

    def __init__(self, cache_file: Optional[Path] = None):
        """
        Initialise le tracker.

        Args:
            cache_file: Fichier JSON pour persister les runs (d√©faut: runs/.run_cache.json)
        """
        self.cache_file = cache_file or Path("runs") / ".run_cache.json"
        self.runs: List[RunSignature] = []

        # Charger le cache existant
        self._load_cache()

    def _load_cache(self) -> None:
        """Charge le cache depuis le disque."""
        if not self.cache_file.exists():
            logger.debug(f"Pas de cache existant: {self.cache_file}")
            return

        try:
            with open(self.cache_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            self.runs = [RunSignature.from_dict(item) for item in data.get("runs", [])]
            logger.info(f"Cache charg√©: {len(self.runs)} runs enregistr√©s")

        except Exception as e:
            logger.warning(f"Erreur lors du chargement du cache: {e}")
            self.runs = []

    def _save_cache(self) -> None:
        """Sauvegarde le cache sur disque."""
        try:
            # Cr√©er le r√©pertoire si n√©cessaire
            self.cache_file.parent.mkdir(parents=True, exist_ok=True)

            data = {
                "version": "1.0",
                "updated_at": datetime.now().isoformat(),
                "total_runs": len(self.runs),
                "runs": [run.to_dict() for run in self.runs],
            }

            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logger.debug(f"Cache sauvegard√©: {len(self.runs)} runs")

        except Exception as e:
            logger.warning(f"Erreur lors de la sauvegarde du cache: {e}")

    def is_duplicate(self, signature: RunSignature) -> bool:
        """
        V√©rifie si cette configuration a d√©j√† √©t√© ex√©cut√©e.

        Args:
            signature: Signature du run √† v√©rifier

        Returns:
            True si c'est un doublon, False sinon
        """
        target_hash = signature.compute_hash()

        for existing in self.runs:
            if existing.compute_hash() == target_hash:
                logger.warning(
                    f"Configuration dupliqu√©e d√©tect√©e! "
                    f"Strat√©gie: {signature.strategy_name}, "
                    f"Run pr√©c√©dent: {existing.timestamp}"
                )
                return True

        return False

    def find_similar(self, signature: RunSignature) -> List[RunSignature]:
        """
        Trouve les runs similaires (m√™me strat√©gie et donn√©es).

        Args:
            signature: Signature de r√©f√©rence

        Returns:
            Liste des runs similaires
        """
        similar = []

        for existing in self.runs:
            if (
                existing.strategy_name == signature.strategy_name
                and existing.data_path == signature.data_path
                and existing.mode == signature.mode
            ):
                similar.append(existing)

        return similar

    def register(self, signature: RunSignature) -> None:
        """
        Enregistre un nouveau run.

        Args:
            signature: Signature du run √† enregistrer
        """
        # V√©rifier si d√©j√† pr√©sent (ne pas ajouter de doublons)
        if self.is_duplicate(signature):
            logger.warning("Run d√©j√† enregistr√©, pas de duplication")
            return

        self.runs.append(signature)
        self._save_cache()

        logger.info(
            f"Run enregistr√©: {signature.strategy_name} "
            f"(hash: {signature.compute_hash()})"
        )

    def clear_old_runs(self, max_age_days: int = 30) -> int:
        """
        Nettoie les runs plus anciens que max_age_days.

        Args:
            max_age_days: Age maximum en jours

        Returns:
            Nombre de runs supprim√©s
        """
        from datetime import timedelta

        cutoff = datetime.now() - timedelta(days=max_age_days)
        initial_count = len(self.runs)

        self.runs = [
            run
            for run in self.runs
            if datetime.fromisoformat(run.timestamp) > cutoff
        ]

        removed = initial_count - len(self.runs)

        if removed > 0:
            self._save_cache()
            logger.info(f"Nettoyage: {removed} runs anciens supprim√©s")

        return removed

    def get_stats(self) -> Dict[str, Any]:
        """Retourne des statistiques sur les runs enregistr√©s."""
        if not self.runs:
            return {
                "total_runs": 0,
                "strategies": {},
                "modes": {},
            }

        # Compter par strat√©gie
        strategies = {}
        for run in self.runs:
            strategies[run.strategy_name] = strategies.get(run.strategy_name, 0) + 1

        # Compter par mode
        modes = {}
        for run in self.runs:
            modes[run.mode] = modes.get(run.mode, 0) + 1

        return {
            "total_runs": len(self.runs),
            "strategies": strategies,
            "modes": modes,
            "oldest": min(run.timestamp for run in self.runs),
            "newest": max(run.timestamp for run in self.runs),
        }


# Instance globale pour utilisation dans l'UI
_global_tracker: Optional[RunTracker] = None


def get_global_tracker() -> RunTracker:
    """Retourne l'instance globale du tracker."""
    global _global_tracker
    if _global_tracker is None:
        _global_tracker = RunTracker()
    return _global_tracker


__all__ = [
    "RunSignature",
    "RunTracker",
    "get_global_tracker",
]
```
<!-- MODULE-END: run_tracker.py -->

<!-- MODULE-START: session_param_tracker.py -->
```json
{
  "name": "session_param_tracker.py",
  "path": "utils\\session_param_tracker.py",
  "ext": ".py",
  "anchor": "session_param_tracker_py"
}
```
## session_param_tracker_py
*Chemin* : `utils\session_param_tracker.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.session_param_tracker

Purpose: D√©duplie param√®tres test√©s DANS UNE SESSION d'optimisation (vs run_tracker cross-sessions).

Role in pipeline: optimization

Key components: SessionParameterTracker, TestedParams, compute_hash()

Inputs: Dict de param√®tres, scores (Sharpe, return)

Outputs: Hash param, flag already_tested, tested_history

Dependencies: hashlib, json, dataclasses, datetime

Conventions: Normalisation JSON + tri cl√©s pour hash stable; stockage session-local.

Read-if: Modification hachage ou d√©tection doublons intra-session.

Skip-if: Vous appelez tracker.is_already_tested(params).
"""

import hashlib
import json
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Set

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class TestedParams:
    """Repr√©sente une combinaison de param√®tres test√©e."""

    params: Dict[str, Any]
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    sharpe_ratio: Optional[float] = None
    total_return: Optional[float] = None

    def compute_hash(self) -> str:
        """Calcule un hash unique pour cette combinaison de param√®tres."""
        # Normaliser les param√®tres (trier les cl√©s, convertir en JSON)
        normalized = json.dumps(self.params, sort_keys=True, ensure_ascii=False)
        return hashlib.sha256(normalized.encode()).hexdigest()[:12]

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "params": self.params,
            "hash": self.compute_hash(),
            "timestamp": self.timestamp,
            "sharpe_ratio": self.sharpe_ratio,
            "total_return": self.total_return,
        }


class SessionParameterTracker:
    """
    Tracker de param√®tres pour UNE session d'optimisation.

    Usage dans l'optimisation LLM:
        # Au d√©but de l'optimisation
        tracker = SessionParameterTracker(session_id="opt_123")

        # Avant chaque test
        params = {"period": 20, "std_dev": 2.0}
        if tracker.was_tested(params):
            print("‚ö†Ô∏è Param√®tres d√©j√† test√©s, essayer autre chose!")
        else:
            result = run_backtest(params)
            tracker.register(params, result)
    """

    def __init__(self, session_id: Optional[str] = None):
        """
        Initialise le tracker pour une session.

        Args:
            session_id: Identifiant de la session (auto-g√©n√©r√© si None)
        """
        self.session_id = session_id or f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.tested_params: List[TestedParams] = []
        self.tested_hashes: Set[str] = set()

        # Stats
        self.session_start = datetime.now()
        self.total_tests = 0
        self.duplicates_prevented = 0

        logger.info(f"üìä Nouvelle session de tracking: {self.session_id}")

    def was_tested(self, params: Dict[str, Any]) -> bool:
        """
        V√©rifie si cette combinaison de param√®tres a d√©j√† √©t√© test√©e DANS CETTE SESSION.

        Args:
            params: Dictionnaire des param√®tres √† v√©rifier

        Returns:
            True si d√©j√† test√©, False sinon
        """
        test_params = TestedParams(params=params)
        param_hash = test_params.compute_hash()

        if param_hash in self.tested_hashes:
            self.duplicates_prevented += 1
            logger.warning(
                f"‚ö†Ô∏è Param√®tres D√âJ√Ä TEST√âS dans cette session! "
                f"Hash: {param_hash} | Params: {params}"
            )
            return True

        return False

    def register(
        self,
        params: Dict[str, Any],
        sharpe_ratio: Optional[float] = None,
        total_return: Optional[float] = None
    ) -> None:
        """
        Enregistre une nouvelle combinaison de param√®tres test√©e.

        Args:
            params: Param√®tres test√©s
            sharpe_ratio: Sharpe ratio obtenu (optionnel)
            total_return: Rendement total obtenu (optionnel)
        """
        tested = TestedParams(
            params=params,
            sharpe_ratio=sharpe_ratio,
            total_return=total_return
        )

        param_hash = tested.compute_hash()

        # V√©rifier si d√©j√† pr√©sent (s√©curit√©)
        if param_hash in self.tested_hashes:
            logger.warning("Tentative d'enregistrement de param√®tres d√©j√† test√©s (ignor√©)")
            return

        self.tested_params.append(tested)
        self.tested_hashes.add(param_hash)
        self.total_tests += 1

        sharpe_str = f"{sharpe_ratio:.3f}" if sharpe_ratio is not None else "N/A"
        logger.info(
            f"‚úÖ Param√®tres enregistr√©s ({self.total_tests}/{self.total_tests}): "
            f"Hash={param_hash} | Sharpe={sharpe_str}"
        )

    def get_best_params(self, metric: str = "sharpe_ratio") -> Optional[TestedParams]:
        """
        Retourne les meilleurs param√®tres selon la m√©trique.

        Args:
            metric: "sharpe_ratio" ou "total_return"

        Returns:
            TestedParams avec la meilleure performance, ou None si aucun
        """
        if not self.tested_params:
            return None

        # Filtrer ceux qui ont la m√©trique
        valid = [p for p in self.tested_params if getattr(p, metric) is not None]

        if not valid:
            return None

        return max(valid, key=lambda p: getattr(p, metric))

    def get_tested_count(self) -> int:
        """Nombre de combinaisons diff√©rentes test√©es."""
        return len(self.tested_params)

    def get_duplicates_prevented(self) -> int:
        """Nombre de duplications √©vit√©es."""
        return self.duplicates_prevented

    def get_all_params(self) -> List[Dict[str, Any]]:
        """Retourne toutes les combinaisons test√©es (pour analyse)."""
        return [tp.params for tp in self.tested_params]

    def get_summary(self) -> str:
        """
        Retourne un r√©sum√© de la session pour les LLMs.

        Format utilisable par les LLMs pour √©viter les duplications.
        """
        if not self.tested_params:
            return "Aucun param√®tre test√© dans cette session."

        best_sharpe = self.get_best_params("sharpe_ratio")
        best_return = self.get_best_params("total_return")

        summary = [
            f"üìä R√©sum√© Session: {self.session_id}",
            "",
            f"üî¢ Tests effectu√©s: {self.total_tests}",
            f"üö´ Duplications √©vit√©es: {self.duplicates_prevented}",
            "",
            "‚úÖ PARAM√àTRES D√âJ√Ä TEST√âS (NE PAS RETESTER):",
        ]

        # Lister tous les param√®tres test√©s
        for i, tested in enumerate(self.tested_params[-10:], 1):  # Derniers 10
            params_str = json.dumps(tested.params, sort_keys=True)
            perf_str = ""
            if tested.sharpe_ratio:
                perf_str = f" | Sharpe={tested.sharpe_ratio:.3f}"
            if tested.total_return:
                perf_str += f" | Return={tested.total_return:.2%}"

            summary.append(f"  {i}. {params_str}{perf_str}")

        if len(self.tested_params) > 10:
            summary.append(f"  ... et {len(self.tested_params) - 10} autres")

        summary.append("")
        summary.append("üèÜ MEILLEURS R√âSULTATS:")

        if best_sharpe:
            summary.append(
                f"  Meilleur Sharpe: {best_sharpe.sharpe_ratio:.3f} "
                f"avec {json.dumps(best_sharpe.params)}"
            )

        if best_return:
            summary.append(
                f"  Meilleur Return: {best_return.total_return:.2%} "
                f"avec {json.dumps(best_return.params)}"
            )

        return "\n".join(summary)

    def to_dict(self) -> Dict[str, Any]:
        """Exporte la session compl√®te en dict (pour sauvegarde)."""
        return {
            "session_id": self.session_id,
            "session_start": self.session_start.isoformat(),
            "total_tests": self.total_tests,
            "duplicates_prevented": self.duplicates_prevented,
            "tested_params": [tp.to_dict() for tp in self.tested_params],
        }

    def save(self, path: str) -> None:
        """Sauvegarde la session dans un fichier JSON."""
        from pathlib import Path

        save_path = Path(path)
        save_path.parent.mkdir(parents=True, exist_ok=True)

        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)

        logger.info(f"Session sauvegard√©e: {save_path}")


__all__ = ["SessionParameterTracker", "TestedParams"]
```
<!-- MODULE-END: session_param_tracker.py -->

<!-- MODULE-START: session_ranges_tracker.py -->
```json
{
  "name": "session_ranges_tracker.py",
  "path": "utils\\session_ranges_tracker.py",
  "ext": ".py",
  "anchor": "session_ranges_tracker_py"
}
```
## session_ranges_tracker_py
*Chemin* : `utils\session_ranges_tracker.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.session_ranges_tracker

Purpose: Tracker de ranges de grid search test√©es dans une session pour √©viter boucles infinies.

Role in pipeline: optimization

Key components: SessionRangesTracker, TestedRange

Inputs: Dict de ranges (param: {min, max, step})

Outputs: Hash range, flag already_tested, ranges_history

Dependencies: hashlib, json, dataclasses, datetime

Conventions: Normalisation JSON + tri cl√©s pour hash stable; stockage session-local.

Read-if: Modification hachage ou d√©tection doublons ranges.

Skip-if: Vous appelez tracker.was_tested(ranges).
"""

import hashlib
import json
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Set

from utils.log import get_logger

logger = get_logger(__name__)


@dataclass
class TestedRange:
    """Repr√©sente une range de grid search test√©e."""

    ranges: Dict[str, Dict[str, float]]  # {"param": {"min": x, "max": y, "step": z}}
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    n_combinations: int = 0
    best_sharpe: Optional[float] = None
    rationale: str = ""

    def compute_hash(self) -> str:
        """Calcule un hash unique pour cette range."""
        # Normaliser les ranges (trier les cl√©s, convertir en JSON)
        normalized = json.dumps(self.ranges, sort_keys=True, ensure_ascii=False)
        return hashlib.sha256(normalized.encode()).hexdigest()[:12]

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "ranges": self.ranges,
            "hash": self.compute_hash(),
            "timestamp": self.timestamp,
            "n_combinations": self.n_combinations,
            "best_sharpe": self.best_sharpe,
            "rationale": self.rationale,
        }


class SessionRangesTracker:
    """
    Tracker de ranges de grid search pour UNE session d'optimisation.

    Usage dans l'optimisation LLM:
        # Au d√©but de l'optimisation
        tracker = SessionRangesTracker(session_id="opt_123")

        # Avant chaque sweep
        ranges = {"bb_period": {"min": 20, "max": 25, "step": 1}}
        if tracker.was_tested(ranges):
            print("‚ö†Ô∏è Ranges d√©j√† test√©es, essayer autre chose!")
        else:
            result = run_sweep(ranges)
            tracker.register(ranges, result)
    """

    def __init__(self, session_id: Optional[str] = None):
        """
        Initialise le tracker pour une session.

        Args:
            session_id: Identifiant de session (optionnel)
        """
        self.session_id = session_id or "default"
        self._tested_hashes: Set[str] = set()
        self._tested_ranges: List[TestedRange] = []

        logger.info(f"üìä Nouvelle session de tracking ranges: {self.session_id}")

    def was_tested(self, ranges: Dict[str, Dict[str, float]]) -> bool:
        """
        V√©rifie si ces ranges ont d√©j√† √©t√© test√©es dans cette session.

        Args:
            ranges: Dict de ranges √† v√©rifier

        Returns:
            True si d√©j√† test√©es, False sinon
        """
        tested_range = TestedRange(ranges=ranges)
        range_hash = tested_range.compute_hash()
        return range_hash in self._tested_hashes

    def register(
        self,
        ranges: Dict[str, Dict[str, float]],
        n_combinations: int = 0,
        best_sharpe: Optional[float] = None,
        rationale: str = "",
    ) -> str:
        """
        Enregistre une range test√©e.

        Args:
            ranges: Dict de ranges test√©es
            n_combinations: Nombre de combinaisons test√©es
            best_sharpe: Meilleur Sharpe trouv√© (optionnel)
            rationale: Raison du sweep (optionnel)

        Returns:
            Hash de la range
        """
        tested_range = TestedRange(
            ranges=ranges,
            n_combinations=n_combinations,
            best_sharpe=best_sharpe,
            rationale=rationale,
        )

        range_hash = tested_range.compute_hash()

        if range_hash in self._tested_hashes:
            logger.warning(
                f"‚ö†Ô∏è Range d√©j√† test√©e: {range_hash} | "
                f"Params={list(ranges.keys())}"
            )
            return range_hash

        self._tested_hashes.add(range_hash)
        self._tested_ranges.append(tested_range)

        logger.debug(
            f"‚úÖ Range enregistr√©e: {range_hash} | "
            f"Params={list(ranges.keys())} | "
            f"N_combos={n_combinations}"
        )

        return range_hash

    def get_summary(self, max_ranges: int = 5) -> str:
        """
        G√©n√®re un r√©sum√© des ranges test√©es pour feedback LLM.

        Args:
            max_ranges: Nombre maximum de ranges √† afficher

        Returns:
            R√©sum√© textuel
        """
        if not self._tested_ranges:
            return "Aucune range test√©e dans cette session."

        summary = f"**Ranges d√©j√† test√©es dans cette session ({len(self._tested_ranges)} total):**\n\n"

        for i, tested in enumerate(self._tested_ranges[:max_ranges], 1):
            params_str = ", ".join(
                f"{param}: [{r['min']}-{r['max']}]"
                for param, r in tested.ranges.items()
            )
            summary += f"{i}. {params_str} | {tested.n_combinations} combos | "
            if tested.best_sharpe is not None:
                summary += f"Best Sharpe={tested.best_sharpe:.3f}"
            else:
                summary += "No result"
            summary += "\n"

        if len(self._tested_ranges) > max_ranges:
            summary += f"\n... et {len(self._tested_ranges) - max_ranges} autres ranges test√©es."

        return summary

    def get_all_ranges(self) -> List[Dict[str, Any]]:
        """Retourne toutes les ranges test√©es."""
        return [tested.to_dict() for tested in self._tested_ranges]

    def clear(self) -> None:
        """Efface toutes les ranges test√©es (nouveau d√©but de session)."""
        self._tested_hashes.clear()
        self._tested_ranges.clear()
        logger.info(f"üßπ Tracker ranges r√©initialis√©: {self.session_id}")
```
<!-- MODULE-END: session_ranges_tracker.py -->

<!-- MODULE-START: sweep_diagnostics.py -->
```json
{
  "name": "sweep_diagnostics.py",
  "path": "utils\\sweep_diagnostics.py",
  "ext": ".py",
  "anchor": "sweep_diagnostics_py"
}
```
## sweep_diagnostics_py
*Chemin* : `utils\sweep_diagnostics.py`  
*Type* : `.py`  

```python
"""Syst√®me de diagnostic pour sweeps multiprocess."""
import logging
import os
import time
import traceback
from datetime import datetime
from pathlib import Path
from typing import Any, Dict


class SweepDiagnostics:
    """Logger de diagnostic pour sweeps avec journalisation fichier d√©taill√©e."""

    def __init__(self, run_id: str):
        self.run_id = run_id
        self.start_time = time.perf_counter()
        self.log_dir = Path("sweep_diagnostics")
        self.log_dir.mkdir(exist_ok=True)

        # Fichier de log unique pour ce run
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.log_dir / f"sweep_{timestamp}_{run_id}.log"

        # Logger Python
        self.logger = logging.getLogger(f"sweep_diag.{run_id}")
        self.logger.setLevel(logging.DEBUG)

        # Handler fichier avec format d√©taill√©
        fh = logging.FileHandler(self.log_file, encoding="utf-8")
        fh.setLevel(logging.DEBUG)
        # Note: %f (microseconds) n'est pas support√© par time.strftime()
        # Utiliser un formateur custom ou accepter la pr√©cision √† la seconde
        formatter = logging.Formatter(
            "%(asctime)s | %(levelname)-8s | %(message)s",
            datefmt="%H:%M:%S"
        )
        fh.setFormatter(formatter)
        self.logger.addHandler(fh)

        # Compteurs
        self.submitted = 0
        self.completed = 0
        self.errors = 0
        self.timeouts = 0
        self.last_completion_time = time.perf_counter()

        self._log_header()

    def _log_header(self):
        """Log d'en-t√™te avec infos syst√®me."""
        self.logger.info("="*80)
        self.logger.info(f"SWEEP DIAGNOSTICS - Run ID: {self.run_id}")
        self.logger.info(f"Log file: {self.log_file}")
        self.logger.info(f"Python PID: {os.getpid()}")
        self.logger.info(f"Workers: {os.environ.get('BACKTEST_WORKER_THREADS', 'N/A')} threads")
        self.logger.info("="*80)

    def log_pool_start(self, n_workers: int, thread_limit: int, total_combos: int):
        """Log d√©marrage du pool."""
        self.logger.info(f"‚ñ∂ POOL START: {n_workers} workers √ó {thread_limit} threads")
        self.logger.info(f"‚ñ∂ Total combinaisons: {total_combos:,}")

    def log_submit(self, combo_idx: int, params: Dict[str, Any]):
        """Log soumission d'une combinaison."""
        self.submitted += 1
        elapsed = time.perf_counter() - self.start_time
        self.logger.debug(f"‚û§ SUBMIT #{combo_idx} ({self.submitted} total) @ {elapsed:.1f}s | {params}")

    def log_completion(self, combo_idx: int, params: Dict[str, Any], result: Dict[str, Any], duration_ms: float):
        """Log compl√©tion normale."""
        self.completed += 1
        self.last_completion_time = time.perf_counter()
        elapsed = time.perf_counter() - self.start_time

        if "error" in result:
            self.errors += 1
            error_msg = result["error"][:100]
            self.logger.warning(f"‚úó COMPLETE #{combo_idx} ERROR @ {elapsed:.1f}s ({duration_ms:.0f}ms) | {error_msg}")
        else:
            pnl = result.get("total_pnl", 0)
            sharpe = result.get("sharpe", 0)
            self.logger.debug(f"‚úì COMPLETE #{combo_idx} @ {elapsed:.1f}s ({duration_ms:.0f}ms) | PnL={pnl:.2f} Sharpe={sharpe:.2f}")

    def log_timeout(self, combo_idx: int, params: Dict[str, Any], timeout_sec: float):
        """Log timeout worker."""
        self.timeouts += 1
        elapsed = time.perf_counter() - self.start_time
        self.logger.error(f"‚è± TIMEOUT #{combo_idx} @ {elapsed:.1f}s (>{timeout_sec:.0f}s) | {params}")

    def log_future_exception(self, combo_idx: int, params: Dict[str, Any], exc: Exception):
        """Log exception future."""
        self.errors += 1
        elapsed = time.perf_counter() - self.start_time
        self.logger.error(f"üí• EXCEPTION #{combo_idx} @ {elapsed:.1f}s | {type(exc).__name__}: {exc}")
        self.logger.debug(f"   Params: {params}")
        self.logger.debug(f"   Traceback:\n{traceback.format_exc()}")

    def log_pool_broken(self, reason: str, exc: Exception = None):
        """Log pool cass√©."""
        elapsed = time.perf_counter() - self.start_time
        self.logger.critical(f"üî• POOL BROKEN @ {elapsed:.1f}s | Reason: {reason}")
        if exc:
            self.logger.critical(f"   Exception: {type(exc).__name__}: {exc}")
            self.logger.debug(f"   Traceback:\n{traceback.format_exc()}")

    def log_stall(self, stall_duration: float, pending_count: int):
        """Log d√©tection de stall."""
        elapsed = time.perf_counter() - self.start_time
        self.logger.error(f"‚ö† STALL DETECTED @ {elapsed:.1f}s | No completion for {stall_duration:.0f}s | {pending_count} pending")

    def log_sequential_fallback(self, remaining_combos: int):
        """Log bascule en s√©quentiel."""
        elapsed = time.perf_counter() - self.start_time
        self.logger.warning(f"üîÑ FALLBACK SEQUENTIAL @ {elapsed:.1f}s | {remaining_combos} combos remaining")

    def log_pool_shutdown(self, success: bool):
        """Log arr√™t du pool."""
        elapsed = time.perf_counter() - self.start_time
        status = "SUCCESS" if success else "FAILURE"
        self.logger.info(f"‚èπ POOL SHUTDOWN @ {elapsed:.1f}s | Status: {status}")
        self.logger.info(f"   Submitted: {self.submitted}")
        self.logger.info(f"   Completed: {self.completed}")
        self.logger.info(f"   Errors: {self.errors}")
        self.logger.info(f"   Timeouts: {self.timeouts}")
        self.logger.info(f"   Success rate: {self.completed/(self.submitted or 1)*100:.1f}%")

    def log_final_summary(self):
        """Log r√©sum√© final."""
        elapsed = time.perf_counter() - self.start_time
        self.logger.info("="*80)
        self.logger.info(f"SWEEP COMPLETED @ {elapsed:.1f}s")
        self.logger.info(f"Log saved to: {self.log_file}")
        self.logger.info("="*80)

    def get_stats(self) -> Dict[str, Any]:
        """Retourne stats actuelles."""
        return {
            "submitted": self.submitted,
            "completed": self.completed,
            "errors": self.errors,
            "timeouts": self.timeouts,
            "elapsed": time.perf_counter() - self.start_time,
        }
```
<!-- MODULE-END: sweep_diagnostics.py -->

<!-- MODULE-START: template.py -->
```json
{
  "name": "template.py",
  "path": "utils\\template.py",
  "ext": ".py",
  "anchor": "template_py"
}
```
## template_py
*Chemin* : `utils\template.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.template

Purpose: Template Jinja2 centralis√© pour prompts LLM agents.

Role in pipeline: orchestration / LLM

Key components: render_prompt, TemplateLoader, prompt templates (analyst.jinja2, etc.)

Inputs: Template name, context dict (strategy, metrics, proposals)

Outputs: Prompt string format√© pr√™t pour LLM

Dependencies: jinja2, pathlib, logging

Conventions: Templates dans templates/ folder; variables contexte nomm√©es; fallback strings si fichier manquant.

Read-if: Modification templates, variables contexte.

Skip-if: Vous appelez juste render_prompt().
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Dict, Optional

from jinja2 import Environment, FileSystemLoader, TemplateNotFound
from jinja2.runtime import Undefined

logger = logging.getLogger(__name__)

# Chemin vers le dossier templates (robuste pour installation en paquet)
# Utiliser importlib.resources pour Python 3.9+, sinon fallback
try:
    # Python 3.9+
    from importlib.resources import files
    TEMPLATES_DIR = Path(str(files("backtest_core") / "templates"))
except (ImportError, TypeError):
    # Fallback pour Python < 3.9 ou si backtest_core n'est pas un paquet install√©
    try:
        from importlib_resources import files
        TEMPLATES_DIR = Path(str(files("backtest_core") / "templates"))
    except (ImportError, TypeError):
        # Dernier fallback : utiliser le chemin relatif r√©solu
        TEMPLATES_DIR = (Path(__file__).resolve().parent.parent / "templates").expanduser()

# Environment Jinja2 global (lazy init)
_jinja_env: Optional[Environment] = None


def get_jinja_env() -> Environment:
    """
    Retourne l'environnement Jinja2 (singleton).

    Returns:
        Environment Jinja2 configur√©
    """
    global _jinja_env

    if _jinja_env is None:
        _jinja_env = Environment(
            loader=FileSystemLoader(str(TEMPLATES_DIR)),
            autoescape=False,  # Pas d'auto-escape pour les prompts
            trim_blocks=True,  # Supprimer les newlines apr√®s {% %}
            lstrip_blocks=True,  # Supprimer indentation avant {% %}
        )

        # Ajouter des filtres personnalis√©s si n√©cessaire
        def _format_float(x: Any, n: int = 2) -> str:
            if x is None or isinstance(x, Undefined):
                return "N/A"
            try:
                return f"{float(x):.{int(n)}f}"
            except Exception:
                return "N/A"

        def _format_percent(x: Any) -> str:
            if x is None or isinstance(x, Undefined):
                return "N/A"
            try:
                return f"{float(x):.2%}"
            except Exception:
                return "N/A"

        _jinja_env.filters['format_percent'] = _format_percent
        _jinja_env.filters['format_float'] = _format_float

        logger.debug(f"Jinja2 environment initialis√©: {TEMPLATES_DIR}")

    return _jinja_env


def render_prompt(template_name: str, context: Dict[str, Any]) -> str:
    """
    Rend un template de prompt avec le contexte fourni.

    Args:
        template_name: Nom du fichier template (ex: "analyst.jinja2")
        context: Dictionnaire de variables √† injecter dans le template

    Returns:
        Prompt rendu sous forme de cha√Æne

    Raises:
        TemplateNotFound: Si le template n'existe pas
        Exception: Si erreur de rendu

    Example:
        >>> prompt = render_prompt("analyst.jinja2", {
        ...     "strategy_name": "ema_cross",
        ...     "current_metrics": {"sharpe_ratio": 1.5},
        ... })
    """
    try:
        env = get_jinja_env()
        template = env.get_template(template_name)
        rendered = template.render(**context)

        logger.debug(f"Template '{template_name}' rendu avec {len(context)} variables")
        return rendered

    except TemplateNotFound:
        logger.error(f"Template introuvable: {template_name}")
        raise
    except Exception as e:
        logger.error(f"Erreur rendu template '{template_name}': {e}")
        raise


def render_prompt_from_string(template_str: str, context: Dict[str, Any]) -> str:
    """
    Rend un template √† partir d'une cha√Æne (pour tests ou usage ponctuel).

    Args:
        template_str: Template Jinja2 sous forme de cha√Æne
        context: Dictionnaire de variables

    Returns:
        Prompt rendu

    Example:
        >>> render_prompt_from_string("Hello {{ name }}", {"name": "Agent"})
        'Hello Agent'
    """
    env = get_jinja_env()
    template = env.from_string(template_str)
    return template.render(**context)


def list_available_templates() -> list[str]:
    """
    Liste tous les templates disponibles.

    Returns:
        Liste des noms de fichiers templates
    """
    if not TEMPLATES_DIR.exists():
        return []

    templates = [
        f.name for f in TEMPLATES_DIR.glob("*.jinja2")
    ]
    return sorted(templates)


# Fonction helper pour formater les m√©triques
def format_metrics_summary(metrics: Any) -> str:
    """
    Formate un objet MetricsSnapshot en r√©sum√© texte.

    Args:
        metrics: Objet avec attributs sharpe_ratio, total_return, etc.

    Returns:
        R√©sum√© format√©
    """
    if not metrics:
        return "No metrics available"

    lines = [
        "Performance Metrics:",
        f"  Sharpe Ratio: {metrics.sharpe_ratio:.3f}",
        f"  Total Return: {metrics.total_return:.2%}",
        f"  Max Drawdown: {metrics.max_drawdown:.2%}",
        f"  Win Rate: {metrics.win_rate:.2%}",
        f"  Profit Factor: {metrics.profit_factor:.2f}",
        f"  Total Trades: {metrics.total_trades}",
    ]

    return "\n".join(lines)


# Ajouter le helper comme filtre Jinja2
def _register_filters():
    """Enregistre les filtres personnalis√©s."""
    env = get_jinja_env()
    env.filters['format_metrics'] = format_metrics_summary


# Initialiser les filtres au chargement du module
_register_filters()
```
<!-- MODULE-END: template.py -->

<!-- MODULE-START: validate_presets.py -->
```json
{
  "name": "validate_presets.py",
  "path": "utils\\validate_presets.py",
  "ext": ".py",
  "anchor": "validate_presets_py"
}
```
## validate_presets_py
*Chemin* : `utils\validate_presets.py`  
*Type* : `.py`  

```python
"""
Script pour valider tous les presets dans profitable_presets.toml.

Usage:
    python utils/validate_presets.py
"""

import sys
from pathlib import Path

# Ajouter le r√©pertoire racine au PYTHONPATH pour les imports
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

if sys.version_info >= (3, 11):
    import tomllib
else:
    try:
        import tomli as tomllib
    except ImportError:
        print("‚ùå Python < 3.11 n√©cessite 'tomli'. Installez avec: pip install tomli")
        sys.exit(1)

from utils.config_validator import validate_params

# Chemin vers profitable_presets.toml
PRESETS_PATH = PROJECT_ROOT / "config" / "profitable_presets.toml"


def main():
    """Valide tous les presets."""
    print("=== Validation des presets de configurations ===\n")

    if not PRESETS_PATH.exists():
        print(f"‚ùå Fichier introuvable: {PRESETS_PATH}")
        sys.exit(1)

    with open(PRESETS_PATH, "rb") as f:
        config = tomllib.load(f)

    # Liste de tous les presets (ignorer [meta])
    preset_names = [k for k in config.keys() if k != "meta"]

    print(f"üìã {len(preset_names)} presets √† valider:\n")

    all_valid = True
    results = []

    for preset_name in preset_names:
        preset = config[preset_name]

        # Extraire strategy et params
        strategy = preset.get("strategy")
        params = preset.get("params", {})

        if not strategy:
            print(f"‚ö†Ô∏è  {preset_name}: Pas de strat√©gie d√©finie, ignor√©")
            continue

        # Valider
        is_valid, errors = validate_params(strategy, params)

        status = "‚úÖ" if is_valid else "‚ùå"
        results.append((preset_name, strategy, is_valid, errors))

        if is_valid:
            print(f"{status} {preset_name} ({strategy})")
        else:
            print(f"{status} {preset_name} ({strategy})")
            for error in errors:
                print(f"    ‚Æ° {error}")
            all_valid = False

    # R√©sum√©
    print(f"\n{'='*60}")
    valid_count = sum(1 for _, _, valid, _ in results if valid)
    total_count = len(results)

    if all_valid:
        print(f"‚úÖ Tous les presets sont valides ({valid_count}/{total_count})")
        return 0
    else:
        print(f"‚ùå {total_count - valid_count} preset(s) invalide(s) sur {total_count}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```
<!-- MODULE-END: validate_presets.py -->

<!-- MODULE-START: version.py -->
```json
{
  "name": "version.py",
  "path": "utils\\version.py",
  "ext": ".py",
  "anchor": "version_py"
}
```
## version_py
*Chemin* : `utils\version.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.version

Purpose: Gestion version et tra√ßabilit√© Git (commit hash pour reproducibilit√©).

Role in pipeline: observability

Key components: get_git_commit(), get_version(), BUILD_INFO

Inputs: None (queries Git locally)

Outputs: Commit hash short/long, version string, build metadata

Dependencies: subprocess, pathlib

Conventions: git rev-parse pour commit; short=True (7 chars) d√©faut.

Read-if: Modification version retrieval ou build metadata.

Skip-if: Vous appelez get_git_commit().
"""

import subprocess


def get_git_commit(short: bool = True) -> str:
    """
    R√©cup√®re le hash du commit Git courant.

    Utile pour tra√ßabilit√© : permet de savoir quelle version du code
    a produit un r√©sultat de backtest sp√©cifique.

    Args:
        short: Si True, retourne hash court (7 chars). Si False, hash complet.

    Returns:
        Hash du commit Git ou "unknown" si indisponible

    Examples:
        >>> commit = get_git_commit()
        >>> print(f"Run ex√©cut√© avec commit: {commit}")
        Run ex√©cut√© avec commit: a3f7b2c
    """
    try:
        cmd = ["git", "rev-parse"]
        if short:
            cmd.append("--short")
        cmd.append("HEAD")

        commit = subprocess.check_output(
            cmd,
            stderr=subprocess.DEVNULL,
            text=True,
            timeout=2  # Timeout pour √©viter blocage
        ).strip()

        return commit if commit else "unknown"

    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        # Git non disponible, pas un repo git, ou timeout
        return "unknown"


def get_git_branch() -> str:
    """
    R√©cup√®re le nom de la branche Git courante.

    Returns:
        Nom de la branche ou "unknown" si indisponible
    """
    try:
        branch = subprocess.check_output(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"],
            stderr=subprocess.DEVNULL,
            text=True,
            timeout=2
        ).strip()

        return branch if branch else "unknown"

    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        return "unknown"


def is_git_dirty() -> bool:
    """
    V√©rifie si le r√©pertoire Git a des modifications non committ√©es.

    Returns:
        True si modifications pr√©sentes, False sinon ou si Git indisponible
    """
    try:
        result = subprocess.check_output(
            ["git", "status", "--porcelain"],
            stderr=subprocess.DEVNULL,
            text=True,
            timeout=2
        ).strip()

        return len(result) > 0

    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        return False


__all__ = ["get_git_commit", "get_git_branch", "is_git_dirty"]
```
<!-- MODULE-END: version.py -->

<!-- MODULE-START: visualization.py -->
```json
{
  "name": "visualization.py",
  "path": "utils\\visualization.py",
  "ext": ".py",
  "anchor": "visualization_py"
}
```
## visualization_py
*Chemin* : `utils\visualization.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.visualization

Purpose: Visualisation interactive - candlesticks, trades, equity curve, dashboard.

Role in pipeline: UI / reporting

Key components: plot_trades, visualize_results, TradePlotter, Plotly-based

Inputs: DataFrame OHLCV, trades (signaux, entries/exits), metrics

Outputs: Graphiques Plotly interactifs, HTML reports

Dependencies: plotly, pandas, numpy, json

Conventions: Candlesticks OHLCV; marqueurs triangles trades (entr√©e/sortie); equity curve + drawdown; tooltips.

Read-if: Modification graphiques, markers, layout.

Skip-if: Vous n'avez pas besoin visualiser r√©sultats.
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import pandas as pd

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    go = None

logger = logging.getLogger(__name__)


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class TradeMarker:
    """Marqueur de trade pour visualisation."""
    timestamp: pd.Timestamp
    price: float
    side: str  # "LONG" ou "SHORT"
    action: str  # "entry" ou "exit"
    pnl: Optional[float] = None
    trade_id: int = 0
    exit_reason: Optional[str] = None
    size: Optional[float] = None


@dataclass
class BacktestVisualData:
    """Donn√©es compl√®tes pour visualisation d'un backtest."""
    ohlcv: pd.DataFrame
    trades: List[Dict[str, Any]]
    equity_curve: Optional[List[float]] = None
    signals: Optional[pd.Series] = None
    params: Dict[str, Any] = field(default_factory=dict)
    metrics: Dict[str, Any] = field(default_factory=dict)
    strategy_name: str = ""
    symbol: str = ""
    timeframe: str = ""


# ============================================================================
# CORE PLOTTING FUNCTIONS
# ============================================================================

def plot_trades(
    df: pd.DataFrame,
    trades: List[Dict[str, Any]],
    title: str = "Backtest - Trades",
    show_volume: bool = True,
    height: int = 800,
    max_candles: int = 2000,
) -> "go.Figure":
    """
    Cr√©e un graphique candlestick avec les marqueurs de trades.

    Args:
        df: DataFrame OHLCV avec colonnes open, high, low, close, volume
        trades: Liste de trades (dicts avec entry_ts, exit_ts, pnl, side, etc.)
        title: Titre du graphique
        show_volume: Afficher le volume en sous-graphique
        height: Hauteur du graphique en pixels
        max_candles: Nombre maximum de bougies √† afficher

    Returns:
        Figure Plotly interactive
    """
    if not PLOTLY_AVAILABLE:
        raise ImportError("Plotly requis: pip install plotly")

    # Limiter le nombre de bougies pour performance
    if len(df) > max_candles:
        df = df.iloc[-max_candles:]

    # Pr√©parer les donn√©es
    df = df.copy()
    if not isinstance(df.index, pd.DatetimeIndex):
        if 'timestamp' in df.columns:
            df.set_index('timestamp', inplace=True)
        elif 'date' in df.columns:
            df.set_index('date', inplace=True)

    # Cr√©er la figure avec subplots
    rows = 2 if show_volume else 1
    row_heights = [0.75, 0.25] if show_volume else [1.0]

    fig = make_subplots(
        rows=rows,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.03,
        row_heights=row_heights,
        subplot_titles=("", "Volume") if show_volume else None,
    )

    # === Candlestick ===
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df['open'],
            high=df['high'],
            low=df['low'],
            close=df['close'],
            name='OHLC',
            increasing_line_color='#26a69a',
            decreasing_line_color='#ef5350',
            increasing_fillcolor='#26a69a',
            decreasing_fillcolor='#ef5350',
        ),
        row=1, col=1,
    )

    # === Volume ===
    if show_volume and 'volume' in df.columns:
        colors = ['#26a69a' if c >= o else '#ef5350'
                  for o, c in zip(df['open'], df['close'])]

        fig.add_trace(
            go.Bar(
                x=df.index,
                y=df['volume'],
                name='Volume',
                marker_color=colors,
                opacity=0.7,
            ),
            row=2, col=1,
        )

    # === Marqueurs de trades ===
    if trades:
        entries_long = []
        entries_short = []
        exits_win = []
        exits_loss = []

        for i, trade in enumerate(trades):
            # Conversion des timestamps avec validation
            try:
                entry_ts_raw = trade.get('entry_ts')
                exit_ts_raw = trade.get('exit_ts')

                if entry_ts_raw is None or exit_ts_raw is None:
                    logger.warning(f"Trade #{i} missing timestamps, skip")
                    continue

                entry_ts = pd.Timestamp(entry_ts_raw)
                exit_ts = pd.Timestamp(exit_ts_raw)
            except (ValueError, TypeError, KeyError) as e:
                logger.warning(f"Trade #{i} timestamp conversion error: {e}")
                continue

            # V√©rifier si le trade est dans la plage affich√©e
            if entry_ts < df.index[0] and exit_ts < df.index[0]:
                continue

            side = trade.get('side', 'LONG')
            pnl = trade.get('pnl', 0)
            entry_price = trade.get('price_entry', trade.get('entry_price', 0))
            exit_price = trade.get('price_exit', trade.get('exit_price', 0))
            exit_reason = trade.get('exit_reason', 'unknown')
            size = trade.get('size', 0)

            # Entr√©e
            entry_marker = {
                'ts': entry_ts,
                'price': entry_price,
                'text': f"<b>ENTR√âE {side}</b><br>"
                        f"Trade #{i+1}<br>"
                        f"Prix: {entry_price:,.2f}<br>"
                        f"Taille: {size:,.4f}",
                'trade_id': i + 1,
            }

            if side == 'LONG':
                entries_long.append(entry_marker)
            else:
                entries_short.append(entry_marker)

            # Sortie
            exit_marker = {
                'ts': exit_ts,
                'price': exit_price,
                'text': f"<b>SORTIE {side}</b><br>"
                        f"Trade #{i+1}<br>"
                        f"Prix: {exit_price:,.2f}<br>"
                        f"PnL: <b style='color:{'#26a69a' if pnl >= 0 else '#ef5350'}'>"
                        f"{pnl:+,.2f}</b><br>"
                        f"Raison: {exit_reason}",
                'trade_id': i + 1,
                'pnl': pnl,
            }

            if pnl >= 0:
                exits_win.append(exit_marker)
            else:
                exits_loss.append(exit_marker)

        # Ajouter les marqueurs d'entr√©e LONG (triangle vert vers le haut)
        if entries_long:
            fig.add_trace(
                go.Scatter(
                    x=[m['ts'] for m in entries_long],
                    y=[m['price'] for m in entries_long],
                    mode='markers',
                    name='Entr√©e LONG',
                    marker=dict(
                        symbol='triangle-up',
                        size=14,
                        color='#00e676',
                        line=dict(color='white', width=1),
                    ),
                    text=[m['text'] for m in entries_long],
                    hoverinfo='text',
                    hovertemplate='%{text}<extra></extra>',
                ),
                row=1, col=1,
            )

        # Entr√©es SHORT (triangle rouge vers le bas)
        if entries_short:
            fig.add_trace(
                go.Scatter(
                    x=[m['ts'] for m in entries_short],
                    y=[m['price'] for m in entries_short],
                    mode='markers',
                    name='Entr√©e SHORT',
                    marker=dict(
                        symbol='triangle-down',
                        size=14,
                        color='#ff5252',
                        line=dict(color='white', width=1),
                    ),
                    text=[m['text'] for m in entries_short],
                    hoverinfo='text',
                    hovertemplate='%{text}<extra></extra>',
                ),
                row=1, col=1,
            )

        # Sorties gagnantes (cercle vert)
        if exits_win:
            fig.add_trace(
                go.Scatter(
                    x=[m['ts'] for m in exits_win],
                    y=[m['price'] for m in exits_win],
                    mode='markers',
                    name='Sortie Win',
                    marker=dict(
                        symbol='circle',
                        size=12,
                        color='#00e676',
                        line=dict(color='white', width=2),
                    ),
                    text=[m['text'] for m in exits_win],
                    hoverinfo='text',
                    hovertemplate='%{text}<extra></extra>',
                ),
                row=1, col=1,
            )

        # Sorties perdantes (cercle rouge)
        if exits_loss:
            fig.add_trace(
                go.Scatter(
                    x=[m['ts'] for m in exits_loss],
                    y=[m['price'] for m in exits_loss],
                    mode='markers',
                    name='Sortie Loss',
                    marker=dict(
                        symbol='circle',
                        size=12,
                        color='#ff5252',
                        line=dict(color='white', width=2),
                    ),
                    text=[m['text'] for m in exits_loss],
                    hoverinfo='text',
                    hovertemplate='%{text}<extra></extra>',
                ),
                row=1, col=1,
            )

        # Lignes connectant entr√©e et sortie
        for i, trade in enumerate(trades):
            entry_ts = pd.Timestamp(trade.get('entry_ts'))
            exit_ts = pd.Timestamp(trade.get('exit_ts'))

            if entry_ts < df.index[0] and exit_ts < df.index[0]:
                continue

            entry_price = trade.get('price_entry', trade.get('entry_price', 0))
            exit_price = trade.get('price_exit', trade.get('exit_price', 0))
            pnl = trade.get('pnl', 0)

            line_color = 'rgba(0, 230, 118, 0.4)' if pnl >= 0 else 'rgba(255, 82, 82, 0.4)'

            fig.add_trace(
                go.Scatter(
                    x=[entry_ts, exit_ts],
                    y=[entry_price, exit_price],
                    mode='lines',
                    line=dict(color=line_color, width=1, dash='dot'),
                    showlegend=False,
                    hoverinfo='skip',
                ),
                row=1, col=1,
            )

    # === Layout ===
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=18),
        ),
        template='plotly_dark',
        height=height,
        xaxis_rangeslider_visible=False,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=0.01,
            bgcolor='rgba(0,0,0,0.5)',
        ),
        hovermode='x unified',
    )

    # Formater les axes
    fig.update_xaxes(
        showgrid=True,
        gridwidth=1,
        gridcolor='rgba(128,128,128,0.2)',
    )
    fig.update_yaxes(
        showgrid=True,
        gridwidth=1,
        gridcolor='rgba(128,128,128,0.2)',
    )

    return fig


def plot_equity_curve(
    equity_curve: List[float],
    trades: Optional[List[Dict[str, Any]]] = None,
    initial_capital: float = 10000,
    title: str = "Equity Curve",
    height: int = 400,
) -> "go.Figure":
    """
    Cr√©e un graphique de la courbe d'equity.

    Args:
        equity_curve: Liste des valeurs d'equity
        trades: Trades pour marquer les positions
        initial_capital: Capital initial
        title: Titre du graphique
        height: Hauteur en pixels

    Returns:
        Figure Plotly
    """
    if not PLOTLY_AVAILABLE:
        raise ImportError("Plotly requis: pip install plotly")

    fig = go.Figure()

    x = list(range(len(equity_curve)))

    # Courbe d'equity
    fig.add_trace(
        go.Scatter(
            x=x,
            y=equity_curve,
            mode='lines',
            name='Equity',
            line=dict(color='#00e676', width=2),
            fill='tozeroy',
            fillcolor='rgba(0, 230, 118, 0.1)',
        )
    )

    # Ligne de capital initial
    fig.add_hline(
        y=initial_capital,
        line_dash="dash",
        line_color="rgba(255,255,255,0.5)",
        annotation_text=f"Capital initial: {initial_capital:,.0f}",
    )

    # High water mark
    hwm = pd.Series(equity_curve).cummax()
    fig.add_trace(
        go.Scatter(
            x=x,
            y=hwm,
            mode='lines',
            name='High Water Mark',
            line=dict(color='rgba(255,255,255,0.3)', width=1, dash='dot'),
        )
    )

    # PnL final
    final_equity = equity_curve[-1] if equity_curve else initial_capital
    pnl = final_equity - initial_capital
    pnl_pct = (pnl / initial_capital) * 100

    fig.add_annotation(
        x=len(equity_curve) - 1,
        y=final_equity,
        text=f"PnL: {pnl:+,.2f} ({pnl_pct:+.1f}%)",
        showarrow=True,
        arrowhead=2,
        font=dict(
            color='#00e676' if pnl >= 0 else '#ff5252',
            size=14,
        ),
        bgcolor='rgba(0,0,0,0.7)',
        borderpad=4,
    )

    fig.update_layout(
        title=title,
        template='plotly_dark',
        height=height,
        xaxis_title='Barres',
        yaxis_title='Equity',
        showlegend=True,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="right",
            x=0.99,
        ),
    )

    return fig


def plot_drawdown(
    equity_curve: List[float],
    title: str = "Drawdown",
    height: int = 250,
) -> "go.Figure":
    """
    Cr√©e un graphique de drawdown.

    Args:
        equity_curve: Liste des valeurs d'equity
        title: Titre
        height: Hauteur en pixels

    Returns:
        Figure Plotly
    """
    if not PLOTLY_AVAILABLE:
        raise ImportError("Plotly requis: pip install plotly")

    equity = pd.Series(equity_curve)
    hwm = equity.cummax()
    drawdown = (equity - hwm) / hwm * 100  # En pourcentage

    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=list(range(len(drawdown))),
            y=drawdown,
            mode='lines',
            name='Drawdown',
            line=dict(color='#ff5252', width=1),
            fill='tozeroy',
            fillcolor='rgba(255, 82, 82, 0.3)',
        )
    )

    # Max drawdown
    max_dd = drawdown.min()
    max_dd_idx = drawdown.idxmin()

    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd,
        text=f"Max DD: {max_dd:.1f}%",
        showarrow=True,
        arrowhead=2,
        font=dict(color='#ff5252', size=12),
    )

    fig.update_layout(
        title=title,
        template='plotly_dark',
        height=height,
        xaxis_title='Barres',
        yaxis_title='Drawdown %',
        showlegend=False,
    )

    return fig


def create_performance_cards(metrics: Dict[str, Any]) -> str:
    """
    Cr√©e des cartes HTML pour les m√©triques de performance.

    Args:
        metrics: Dict des m√©triques

    Returns:
        HTML string
    """
    pnl = metrics.get('pnl', metrics.get('total_pnl', 0))
    total_return_pct = metrics.get('total_return_pct')
    sharpe = metrics.get('sharpe_ratio', 0)
    sortino = metrics.get('sortino_ratio', 0)
    max_dd = metrics.get('max_drawdown', 0)
    win_rate = metrics.get('win_rate', 0)
    num_trades = metrics.get('total_trades', metrics.get('num_trades', 0))
    profit_factor = metrics.get('profit_factor', 0)

    # calculate_metrics returns percentages; agent outputs use fractions.
    if total_return_pct is None:
        total_return_pct = metrics.get('total_return', 0) * 100
        max_dd *= 100
        win_rate *= 100

    pnl_color = '#00e676' if pnl >= 0 else '#ff5252'

    html = f"""
    <div style="display: flex; flex-wrap: wrap; gap: 15px; margin: 20px 0;">
        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
                    padding: 20px; border-radius: 12px; min-width: 150px;
                    border: 1px solid {pnl_color};">
            <div style="color: #888; font-size: 12px;">PnL</div>
            <div style="color: {pnl_color}; font-size: 28px; font-weight: bold;">
                {pnl:+,.2f}
            </div>
            <div style="color: {pnl_color}; font-size: 14px;">
                {total_return_pct:+.2f}%
            </div>
        </div>

        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
                    padding: 20px; border-radius: 12px; min-width: 150px;
                    border: 1px solid #3498db;">
            <div style="color: #888; font-size: 12px;">Sharpe Ratio</div>
            <div style="color: #3498db; font-size: 28px; font-weight: bold;">
                {sharpe:.2f}
            </div>
            <div style="color: #888; font-size: 14px;">
                Sortino: {sortino:.2f}
            </div>
        </div>

        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
                    padding: 20px; border-radius: 12px; min-width: 150px;
                    border: 1px solid #ff5252;">
            <div style="color: #888; font-size: 12px;">Max Drawdown</div>
            <div style="color: #ff5252; font-size: 28px; font-weight: bold;">
                {max_dd:.1f}%
            </div>
        </div>

        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
                    padding: 20px; border-radius: 12px; min-width: 150px;
                    border: 1px solid #9b59b6;">
            <div style="color: #888; font-size: 12px;">Win Rate</div>
            <div style="color: #9b59b6; font-size: 28px; font-weight: bold;">
                {win_rate:.1f}%
            </div>
            <div style="color: #888; font-size: 14px;">
                {num_trades} trades
            </div>
        </div>

        <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
                    padding: 20px; border-radius: 12px; min-width: 150px;
                    border: 1px solid #f39c12;">
            <div style="color: #888; font-size: 12px;">Profit Factor</div>
            <div style="color: #f39c12; font-size: 28px; font-weight: bold;">
                {profit_factor:.2f}
            </div>
        </div>
    </div>
    """

    return html


def create_trades_table(trades: List[Dict[str, Any]], max_rows: int = 50) -> str:
    """
    Cr√©e une table HTML des trades.

    Args:
        trades: Liste des trades
        max_rows: Nombre maximum de lignes

    Returns:
        HTML string
    """
    html = """
    <style>
        .trades-table {
            width: 100%;
            border-collapse: collapse;
            font-family: 'Consolas', monospace;
            font-size: 13px;
            background: #1a1a2e;
        }
        .trades-table th {
            background: #16213e;
            color: #fff;
            padding: 12px 8px;
            text-align: left;
            border-bottom: 2px solid #3498db;
            position: sticky;
            top: 0;
        }
        .trades-table td {
            padding: 10px 8px;
            border-bottom: 1px solid #2a2a4e;
        }
        .trades-table tr:hover {
            background: #2a2a4e;
        }
        .pnl-positive { color: #00e676; font-weight: bold; }
        .pnl-negative { color: #ff5252; font-weight: bold; }
        .side-long { color: #00e676; }
        .side-short { color: #ff5252; }
    </style>
    <div style="max-height: 400px; overflow-y: auto; border-radius: 8px;">
    <table class="trades-table">
        <thead>
            <tr>
                <th>#</th>
                <th>Side</th>
                <th>Entr√©e</th>
                <th>Sortie</th>
                <th>Prix Entr√©e</th>
                <th>Prix Sortie</th>
                <th>PnL</th>
                <th>Return %</th>
                <th>Raison</th>
            </tr>
        </thead>
        <tbody>
    """

    for i, trade in enumerate(trades[:max_rows]):
        side = trade.get('side', 'LONG')
        entry_ts = pd.Timestamp(trade.get('entry_ts')).strftime('%Y-%m-%d %H:%M')
        exit_ts = pd.Timestamp(trade.get('exit_ts')).strftime('%Y-%m-%d %H:%M')
        entry_price = trade.get('price_entry', trade.get('entry_price', 0))
        exit_price = trade.get('price_exit', trade.get('exit_price', 0))
        pnl = trade.get('pnl', 0)
        return_pct = trade.get('return_pct', 0)
        exit_reason = trade.get('exit_reason', '-')

        pnl_class = 'pnl-positive' if pnl >= 0 else 'pnl-negative'
        side_class = 'side-long' if side == 'LONG' else 'side-short'

        html += f"""
            <tr>
                <td>{i + 1}</td>
                <td class="{side_class}">{side}</td>
                <td>{entry_ts}</td>
                <td>{exit_ts}</td>
                <td>{entry_price:,.2f}</td>
                <td>{exit_price:,.2f}</td>
                <td class="{pnl_class}">{pnl:+,.2f}</td>
                <td class="{pnl_class}">{return_pct*100:+.2f}%</td>
                <td>{exit_reason}</td>
            </tr>
        """

    if len(trades) > max_rows:
        html += f"""
            <tr>
                <td colspan="9" style="text-align: center; color: #888;">
                    ... et {len(trades) - max_rows} trades de plus
                </td>
            </tr>
        """

    html += "</tbody></table></div>"
    return html


# ============================================================================
# HIGH-LEVEL VISUALIZATION
# ============================================================================

def visualize_backtest(
    df: pd.DataFrame,
    trades: List[Dict[str, Any]],
    metrics: Dict[str, Any],
    equity_curve: Optional[List[float]] = None,
    title: str = "Backtest Results",
    output_path: Optional[Union[str, Path]] = None,
    show: bool = True,
) -> Dict[str, Any]:
    """
    Cr√©e une visualisation compl√®te d'un backtest.

    Args:
        df: DataFrame OHLCV
        trades: Liste des trades
        metrics: M√©triques de performance
        equity_curve: Courbe d'equity optionnelle
        title: Titre du rapport
        output_path: Chemin de sortie HTML (optionnel)
        show: Ouvrir dans le navigateur

    Returns:
        Dict avec les figures g√©n√©r√©es
    """
    if not PLOTLY_AVAILABLE:
        raise ImportError("Plotly requis: pip install plotly")

    figures = {}

    # Graphique principal avec trades
    fig_trades = plot_trades(df, trades, title=f"{title} - Trades")
    figures['trades'] = fig_trades

    # Equity curve si disponible
    if equity_curve:
        fig_equity = plot_equity_curve(
            equity_curve,
            trades=trades,
            initial_capital=metrics.get('initial_capital', 10000),
            title=f"{title} - Equity Curve",
        )
        figures['equity'] = fig_equity

        fig_dd = plot_drawdown(equity_curve, title=f"{title} - Drawdown")
        figures['drawdown'] = fig_dd

    # G√©n√©rer HTML si output_path
    if output_path:
        output_path = Path(output_path)

        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>{title}</title>
    <meta charset="utf-8">
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <style>
        body {{
            font-family: 'Segoe UI', Arial, sans-serif;
            background: #0a0a1a;
            color: #fff;
            margin: 0;
            padding: 20px;
        }}
        h1 {{
            color: #fff;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #888;
            margin-top: 30px;
        }}
        .chart-container {{
            background: #1a1a2e;
            border-radius: 12px;
            padding: 15px;
            margin: 20px 0;
        }}
        .timestamp {{
            color: #666;
            font-size: 12px;
            text-align: right;
        }}
    </style>
</head>
<body>
    <h1>üèÜ {title}</h1>
    <p class="timestamp">G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

    <h2>üìä Performance</h2>
    {create_performance_cards(metrics)}

    <h2>üìà Graphique des Trades</h2>
    <div class="chart-container" id="chart-trades"></div>

"""

        if equity_curve:
            html_content += """
    <h2>üí∞ Equity Curve</h2>
    <div class="chart-container" id="chart-equity"></div>

    <h2>üìâ Drawdown</h2>
    <div class="chart-container" id="chart-drawdown"></div>
"""

        html_content += f"""
    <h2>üìã D√©tail des Trades ({len(trades)} trades)</h2>
    {create_trades_table(trades)}

    <script>
        Plotly.newPlot('chart-trades', {fig_trades.to_json()}.data, {fig_trades.to_json()}.layout);
"""

        if equity_curve:
            html_content += f"""
        Plotly.newPlot('chart-equity', {fig_equity.to_json()}.data, {fig_equity.to_json()}.layout);
        Plotly.newPlot('chart-drawdown', {fig_dd.to_json()}.data, {fig_dd.to_json()}.layout);
"""

        html_content += """
    </script>
</body>
</html>
"""

        output_path.write_text(html_content, encoding='utf-8')
        print(f"‚úÖ Rapport sauvegard√©: {output_path}")

    # Afficher
    if show:
        fig_trades.show()

    return figures


def load_and_visualize(
    results_path: Union[str, Path],
    data_path: Optional[Union[str, Path]] = None,
    output_path: Optional[Union[str, Path]] = None,
    show: bool = True,
) -> Dict[str, Any]:
    """
    Charge un fichier de r√©sultats et g√©n√®re la visualisation.

    Args:
        results_path: Chemin vers le fichier JSON de r√©sultats
        data_path: Chemin vers les donn√©es OHLCV (optionnel)
        output_path: Chemin de sortie HTML
        show: Ouvrir dans le navigateur

    Returns:
        Dict avec les r√©sultats et figures
    """
    results_path = Path(results_path)

    with open(results_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # Extraire les informations
    trades = data.get('trades', [])
    metrics = data.get('metrics', {})
    equity_curve = data.get('equity_curve')
    params = data.get('params', {})
    strategy = data.get('strategy', 'Unknown')

    # Charger les donn√©es OHLCV si fournies
    df = None
    if data_path:
        data_path = Path(data_path)
        if data_path.suffix == '.parquet':
            df = pd.read_parquet(data_path)
        elif data_path.suffix == '.csv':
            df = pd.read_csv(data_path)

        # Normaliser les colonnes
        df.columns = df.columns.str.lower()
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)

    # Si pas de donn√©es OHLCV et pas de trades, erreur
    if df is None and not trades:
        raise ValueError("Aucune donn√©e OHLCV ou trade √† visualiser")

    # Cr√©er un DataFrame minimal si n√©cessaire
    if df is None and trades:
        print("‚ö†Ô∏è Pas de donn√©es OHLCV fournies, graphique limit√©")
        # Cr√©er un df minimal depuis les trades
        all_prices = []
        all_times = []
        for t in trades:
            all_times.append(pd.Timestamp(t.get('entry_ts')))
            all_times.append(pd.Timestamp(t.get('exit_ts')))
            all_prices.append(t.get('price_entry', t.get('entry_price', 0)))
            all_prices.append(t.get('price_exit', t.get('exit_price', 0)))

        df = pd.DataFrame({
            'open': all_prices,
            'high': all_prices,
            'low': all_prices,
            'close': all_prices,
        }, index=all_times).sort_index()

    # G√©n√©rer titre
    title = f"Backtest - {strategy}"
    if params:
        params_str = ", ".join(f"{k}={v}" for k, v in list(params.items())[:3])
        title += f" ({params_str})"

    return visualize_backtest(
        df=df,
        trades=trades,
        metrics=metrics,
        equity_curve=equity_curve,
        title=title,
        output_path=output_path,
        show=show,
    )


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    'plot_trades',
    'plot_equity_curve',
    'plot_drawdown',
    'create_performance_cards',
    'create_trades_table',
    'visualize_backtest',
    'load_and_visualize',
    'BacktestVisualData',
    'TradeMarker',
    'PLOTLY_AVAILABLE',
]
```
<!-- MODULE-END: visualization.py -->

<!-- MODULE-START: __init__.py -->
```json
{
  "name": "__init__.py",
  "path": "utils\\__init__.py",
  "ext": ".py",
  "anchor": "init___py"
}
```
## init___py
*Chemin* : `utils\__init__.py`  
*Type* : `.py`  

```python
"""
Module-ID: utils.__init__

Purpose: Package utils - exports config, log, visualization, observability.

Role in pipeline: core infrastructure

Key components: Re-exports Config, get_logger, visualization functions

Inputs: None (module imports only)

Outputs: Public API via __all__

Dependencies: Internal (config, log, visualization modules)

Conventions: __all__ d√©finit API publique; imports conditionnels si deps optionnelles.

Read-if: Modification exports ou ordre imports.

Skip-if: Vous importez directement depuis utils.config ou utils.log.
"""

from .config import Config
from .log import get_logger
from .visualization import (
    PLOTLY_AVAILABLE,
    load_and_visualize,
    plot_drawdown,
    plot_equity_curve,
    plot_trades,
    visualize_backtest,
)

__all__ = [
    "get_logger",
    "Config",
    "plot_trades",
    "plot_equity_curve",
    "plot_drawdown",
    "visualize_backtest",
    "load_and_visualize",
    "PLOTLY_AVAILABLE",
]
```
<!-- MODULE-END: __init__.py -->
